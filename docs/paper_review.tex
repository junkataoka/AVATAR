\documentclass[a4paper, 9pt]{scrartcl}
\usepackage{amssymb, amsmath} % needed for math
\usepackage[utf8]{inputenc}   % this is needed for umlauts
\usepackage[USenglish]{babel} % this is needed for umlauts
\usepackage[T1]{fontenc}      % this is needed for correct output of umlauts in pdf
\usepackage[margin=2.5cm]{geometry} %layout
\usepackage{hyperref}         % hyperlinks
\usepackage{color}
\usepackage{framed}
\usepackage{enumerate}  % for advanced numbering of lists
\usepackage{csquotes}   % for enquote

\font\myfont=cmr12 at 12pt
\newcommand\titletext{\myfont Comments to the reviewed paper: Deep Residual
Surrogate Model}

\title{\titletext}

\hypersetup{
  pdfauthor = {},
  pdfkeywords = {peer review},
  pdftitle = {Review of Deep Residual Surrogate Model}}

\usepackage{microtype}

\begin{document}
\maketitle

\section{Introduction}
The authors proposed a surrogate model to improve the efficiency of a complex
calculation to model raw problems with simpler and computationally efficient
forms. The model combines deep residual surrogate model (DRS) and first derivate
validation (FDV), but this paper's methodology and experiment sections do not
deliver its novelty well. First, sequentially fitting models on residuals as DRS
has been studied previously, and its originality lies in the methodology is rather
questionable. Second, fitting a model on the validation dataset in FDV would
overestimate its test performance. Lastly, explanation and clarification on
experimental settings and results are insufficient to convince readers of the
model's novelty. Due to these limitations, I recommend rejecting this version of
the manuscript.

\section{Overall Feedback}
To improve this paper, I suggest the below comments.


\begin{itemize}
    \item The idea of sequentially selecting and fitting several models on
        residuals is rather trivial and already well studied (e.g, boosting),
        and therefore novelty of RDS is questionable. At the same time, authors
        should thoroughly compare the model's performance against a more diverse
        set of models to evaluate the novelty of RDS. As the authors describe
        Artificial Neural Network (ANN) as one of the surrogate model, it should
        also be compared with RDS in their experimental results.

    \item The authors proposed FDV as a new validation method, but its validity
        is questionable. In algorithm 1, a target model is trained on both
        training and validation data sets. Validation of a machine learning
        model should be conducted without fitting the model on the validation
        dataset to properly approximate the model's performance on the test
        dataset. However, FDV fits the model on the validation dataset, and it
        may overestimate the model's performance on the test dataset.

    \item  FDV samples validation data points based on derivative of the target
        model with respect to its error. This procedure is incorrect. To
        approximate test performance well, validation data should have a similar
        distributional shape as test and training dataset. This is why
        stratified sampling is commonly used with leave-one-out or K-fold
        cross-validation. As FDV samples data with smaller first derivative,
        distributional shapes of training and validation dataset could be completely
        different, and therefore this sampling procedure is invalid.

    \item FDV is compared against K-fold cross-validation where K = 7 and
        "simple cross-validation". Different numbers of folds should also be
        compared for K-fold cross-validation. Also, the authors should use
        holdout cross-validation as terminology, instead of "simple
        cross-validation". In addition, there is no clarification about how much
        of a training dataset is taken out as a validation dataset for the holdout
        cross-validation.

    \item Visualization of DRS, specifically Figure 5 lacks description and
        explanation. It is difficult for readers to understand what the
        figure is delivering.

    \item The second column of Table 2 contains DRS as a validation method, which is
        misleading.

    \item In Figure 6, the authors should clarify what models are in the model pool.

    \item In stead of using box-plots in Figure 3, 4 and 7, describing results
        with tables and provide actual numbers with their standard deviations
        would be sufficient, as delivered information from the figures and tables
        is redundant.

    \item  Exact input data generation process is not clarified in the
        experiment section. The authors should describe how the sample data is
        generated.

\end{itemize}

Due to the above limitations, this paper is not appropriate for publication, and
the authors should do some extra work by addressing my comments.

\end{document}
