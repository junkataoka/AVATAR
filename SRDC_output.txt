==> creating model 'resnet50' 
/data/home/jkataok1/alexnet_resnet_finetune/checkpoints/amazon_to_webcam_resnet50.pkl
Source pre-trained model has been loaded!
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
==> creating model 'resnet50' 
/data/home/jkataok1/CycleGAN-PyTorch/checkpoints/dslr_to_amazon_resnet50.pkl
Source pre-trained model has been loaded!
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (fc2): Linear(in_features=512, out_features=31, bias=True)
  (domain_classifier): Sequential(
    (d_fc1): Linear(in_features=2560, out_features=512, bias=True)
    (d_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (d_relu1): ReLU(inplace=True)
    (d_fc2): Linear(in_features=512, out_features=2, bias=True)
    (d_softmax): LogSoftmax(dim=1)
  )
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (fc2): Linear(in_features=512, out_features=31, bias=True)
  (domain_classifier): Sequential(
    (d_fc1): Linear(in_features=2560, out_features=512, bias=True)
    (d_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (d_relu1): ReLU(inplace=True)
    (d_fc2): Linear(in_features=512, out_features=2, bias=True)
    (d_softmax): LogSoftmax(dim=1)
  )
)
https://app.neptune.ai/junkataoka/SRDC/e/SRDC-111
)
https://app.neptune.ai/junkataoka/SRDC/e/SRDC-110
Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.
Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.
begin training
begin training
Test on T training set - [0][0/45]	T 0.454 (0.454)	D 0.340 (0.340)	T@1 85.714 (85.714)	T@5 98.413 (98.413)	L 2.2211 (2.2211)
Test on T training set - [0][10/45]	T 0.295 (0.326)	D 0.183 (0.209)	T@1 34.921 (73.882)	T@5 71.429 (91.053)	L 2.7946 (2.3495)
Test on T training set - [0][20/45]	T 0.318 (0.321)	D 0.197 (0.204)	T@1 66.667 (69.992)	T@5 98.413 (90.174)	L 2.5281 (2.4297)
Test on T training set - [0][30/45]	T 0.490 (0.325)	D 0.370 (0.207)	T@1 76.190 (68.203)	T@5 95.238 (88.479)	L 2.5034 (2.4583)
Test on T training set - [0][40/45]	T 0.325 (0.322)	D 0.212 (0.205)	T@1 49.206 (65.196)	T@5 73.016 (84.204)	L 2.7474 (2.5131)
 * Test on T training set - Prec@1 61.803, Prec@5 82.144
Test on T training set - [0][0/13]	T 1.169 (1.169)	D 1.039 (1.039)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1956 (0.1956)
Test on T training set - [0][10/13]	T 0.532 (0.651)	D 0.417 (0.530)	T@1 76.190 (81.530)	T@5 100.000 (94.517)	L 0.8891 (0.7919)
 * Test on T training set - Prec@1 81.132, Prec@5 94.843
Test on T test set - [0][0/13]	Time 0.721 (0.721)	Loss 0.1956 (0.1956)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [0][10/13]	Time 0.494 (0.508)	Loss 0.8891 (0.7919)	Prec@1 76.190 (81.530)	Prec@5 100.000 (94.517)
 * Test on T test set - Prec@1 81.132, Prec@5 94.843
Epoch 0, K-means clustering 0, Average clustering time 0.019, Prec@1 74.465
Epoch 0, K-means clustering 1, Average clustering time 0.067, Prec@1 81.258
Epoch 0, K-means clustering 2, Average clustering time 0.066, Prec@1 82.013
Epoch 0, K-means clustering 3, Average clustering time 0.065, Prec@1 82.138
Epoch 0, K-means clustering 4, Average clustering time 0.085, Prec@1 82.642
Epoch 0, K-means clustering 0, Average clustering time 0.001, Prec@1 77.610
Epoch 0, K-means clustering 1, Average clustering time 0.031, Prec@1 83.648
Epoch 0, K-means clustering 2, Average clustering time 0.042, Prec@1 85.283
Epoch 0, K-means clustering 3, Average clustering time 0.047, Prec@1 86.038
Epoch 0, K-means clustering 4, Average clustering time 0.053, Prec@1 86.289
Test on T test set - [0][0/45]	Time 0.467 (0.467)	Loss 2.2211 (2.2211)	Prec@1 85.714 (85.714)	Prec@5 98.413 (98.413)
Test on T test set - [0][10/45]	Time 0.323 (0.336)	Loss 2.7946 (2.3495)	Prec@1 34.921 (73.882)	Prec@5 71.429 (91.053)
Test on T test set - [0][20/45]	Time 0.314 (0.327)	Loss 2.5281 (2.4297)	Prec@1 66.667 (69.992)	Prec@5 98.413 (90.174)
Test on T test set - [0][30/45]	Time 0.316 (0.326)	Loss 2.5034 (2.4583)	Prec@1 76.190 (68.203)	Prec@5 95.238 (88.479)
Test on T test set - [0][40/45]	Time 0.540 (0.333)	Loss 2.7474 (2.5131)	Prec@1 49.206 (65.196)	Prec@5 73.016 (84.204)
 * Test on T test set - Prec@1 61.803, Prec@5 82.144
Epoch 0, K-means clustering 0, Average clustering time 0.028, Prec@1 66.454
Epoch 0, K-means clustering 1, Average clustering time 0.073, Prec@1 72.524
Epoch 0, K-means clustering 2, Average clustering time 0.085, Prec@1 73.873
Epoch 0, K-means clustering 3, Average clustering time 0.093, Prec@1 73.837
Epoch 0, K-means clustering 4, Average clustering time 0.096, Prec@1 74.015
Epoch 0, K-means clustering 0, Average clustering time 0.003, Prec@1 65.495
Epoch 0, K-means clustering 1, Average clustering time 0.034, Prec@1 69.720
Epoch 0, K-means clustering 2, Average clustering time 0.046, Prec@1 70.891
Epoch 0, K-means clustering 3, Average clustering time 0.054, Prec@1 71.672
Epoch 0, K-means clustering 4, Average clustering time 0.058, Prec@1 71.565
Train - epoch [0/200]	BT 2.318 (2.318)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0000 (0.0000)
The penalty weight is 0.000000
Train - epoch [0/200]	BT 1.469 (1.469)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 2.328 (2.328)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 0.0000 (0.0000)
The penalty weight is 0.000000
Train - epoch [0/200]	BT 1.223 (1.223)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.535 (1.535)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.039 (1.039)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.230 (1.230)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.508 (1.508)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.221 (1.221)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.510 (1.510)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.095 (1.095)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 0.0000 (0.0000)
Train - epoch [0/200]	BT 1.487 (1.487)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0000 (0.0000)
Test on T training set - [0][0/13]	T 0.755 (0.755)	D 0.625 (0.625)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1255 (0.1255)
Test on T training set - [0][10/13]	T 0.517 (0.531)	D 0.391 (0.408)	T@1 65.079 (81.385)	T@5 100.000 (95.671)	L 0.8657 (0.7151)
 * Test on T training set - Prec@1 80.252, Prec@5 95.723
Train - epoch [0/200]	BT 1.561 (1.561)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0000 (0.0000)
Test on T test set - [0][0/13]	Time 0.738 (0.738)	Loss 0.1255 (0.1255)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [0][10/13]	Time 0.569 (0.530)	Loss 0.8657 (0.7151)	Prec@1 65.079 (81.385)	Prec@5 100.000 (95.671)
 * Test on T test set - Prec@1 80.252, Prec@5 95.723
Epoch 0, K-means clustering 0, Average clustering time 0.262, Prec@1 87.673
Epoch 0, K-means clustering 1, Average clustering time 0.213, Prec@1 89.057
Epoch 0, K-means clustering 2, Average clustering time 0.176, Prec@1 89.057
Epoch 0, K-means clustering 3, Average clustering time 0.157, Prec@1 88.805
Epoch 0, K-means clustering 4, Average clustering time 0.145, Prec@1 88.805
Epoch 0, K-means clustering 0, Average clustering time 0.001, Prec@1 86.164
Epoch 0, K-means clustering 1, Average clustering time 0.044, Prec@1 87.799
Epoch 0, K-means clustering 2, Average clustering time 0.060, Prec@1 88.050
Epoch 0, K-means clustering 3, Average clustering time 0.069, Prec@1 87.421
Epoch 0, K-means clustering 4, Average clustering time 0.074, Prec@1 87.421
The penalty weight is 0.024995
Train - epoch [1/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 0.5102 (0.5102)
Train - epoch [1/200]	BT 1.152 (1.152)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 0.4722 (0.4722)
Test on T training set - [0][0/45]	T 0.543 (0.543)	D 0.420 (0.420)	T@1 82.540 (82.540)	T@5 98.413 (98.413)	L 0.7904 (0.7904)
Test on T training set - [0][10/45]	T 0.352 (0.352)	D 0.230 (0.232)	T@1 28.571 (77.778)	T@5 61.905 (91.198)	L 2.8151 (0.9243)
Test on T training set - [0][20/45]	T 0.340 (0.343)	D 0.224 (0.224)	T@1 87.302 (74.452)	T@5 100.000 (89.040)	L 0.5048 (1.0543)
Test on T training set - [0][30/45]	T 0.350 (0.341)	D 0.232 (0.221)	T@1 73.016 (71.992)	T@5 93.651 (88.018)	L 1.1625 (1.1351)
Test on T training set - [0][40/45]	T 0.336 (0.340)	D 0.215 (0.220)	T@1 38.095 (67.557)	T@5 79.365 (84.282)	L 2.1670 (1.3340)
 * Test on T training set - Prec@1 65.211, Prec@5 83.777
Test on T test set - [0][0/45]	Time 0.546 (0.546)	Loss 0.7904 (0.7904)	Prec@1 82.540 (82.540)	Prec@5 98.413 (98.413)
Test on T test set - [0][10/45]	Time 0.331 (0.351)	Loss 2.8151 (0.9243)	Prec@1 28.571 (77.778)	Prec@5 61.905 (91.198)
Test on T test set - [0][20/45]	Time 0.340 (0.342)	Loss 0.5048 (1.0543)	Prec@1 87.302 (74.452)	Prec@5 100.000 (89.040)
Test on T test set - [0][30/45]	Time 0.324 (0.339)	Loss 1.1625 (1.1351)	Prec@1 73.016 (71.992)	Prec@5 93.651 (88.018)
Test on T test set - [0][40/45]	Time 0.343 (0.338)	Loss 2.1670 (1.3340)	Prec@1 38.095 (67.557)	Prec@5 79.365 (84.282)
 * Test on T test set - Prec@1 65.211, Prec@5 83.777
Epoch 0, K-means clustering 0, Average clustering time 0.321, Prec@1 72.630
Epoch 0, K-means clustering 1, Average clustering time 0.255, Prec@1 74.299
Epoch 0, K-means clustering 2, Average clustering time 0.215, Prec@1 74.476
Epoch 0, K-means clustering 3, Average clustering time 0.189, Prec@1 74.334
Epoch 0, K-means clustering 4, Average clustering time 0.174, Prec@1 74.086
Epoch 0, K-means clustering 0, Average clustering time 0.003, Prec@1 70.146
Epoch 0, K-means clustering 1, Average clustering time 0.251, Prec@1 71.388
Epoch 0, K-means clustering 2, Average clustering time 0.197, Prec@1 71.672
Epoch 0, K-means clustering 3, Average clustering time 0.175, Prec@1 71.885
Epoch 0, K-means clustering 4, Average clustering time 0.163, Prec@1 71.743
Train - epoch [1/200]	BT 1.091 (1.091)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 0.4995 (0.4995)
Train - epoch [1/200]	BT 1.218 (1.218)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 0.5071 (0.5071)
The penalty weight is 0.024995
Train - epoch [1/200]	BT 1.532 (1.532)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.4633 (0.4633)
Train - epoch [1/200]	BT 1.108 (1.108)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 0.4892 (0.4892)
Train - epoch [1/200]	BT 1.635 (1.635)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 0.4620 (0.4620)
Train - epoch [1/200]	BT 1.668 (1.668)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.5259 (0.5259)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 0.4461 (0.4461)
Train - epoch [1/200]	BT 1.456 (1.456)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.4917 (0.4917)
Test on T training set - [1][0/13]	T 0.760 (0.760)	D 0.637 (0.637)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1283 (0.1283)
Test on T training set - [1][10/13]	T 0.501 (0.528)	D 0.386 (0.404)	T@1 68.254 (81.962)	T@5 100.000 (95.382)	L 0.8808 (0.7206)
 * Test on T training set - Prec@1 80.755, Prec@5 95.472
Train - epoch [1/200]	BT 2.113 (2.113)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.4712 (0.4712)
Train - epoch [1/200]	BT 1.444 (1.444)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.4708 (0.4708)
Test on T test set - [1][0/13]	Time 0.746 (0.746)	Loss 0.1283 (0.1283)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [1][10/13]	Time 0.509 (0.518)	Loss 0.8808 (0.7206)	Prec@1 68.254 (81.962)	Prec@5 100.000 (95.382)
 * Test on T test set - Prec@1 80.755, Prec@5 95.472
Epoch 1, K-means clustering 0, Average clustering time 0.018, Prec@1 87.296
Epoch 1, K-means clustering 1, Average clustering time 0.076, Prec@1 88.553
Epoch 1, K-means clustering 2, Average clustering time 0.075, Prec@1 88.553
Epoch 1, K-means clustering 3, Average clustering time 0.075, Prec@1 88.050
Epoch 1, K-means clustering 4, Average clustering time 0.074, Prec@1 88.050
Epoch 1, K-means clustering 0, Average clustering time 0.001, Prec@1 86.415
Epoch 1, K-means clustering 1, Average clustering time 0.032, Prec@1 88.302
Epoch 1, K-means clustering 2, Average clustering time 0.047, Prec@1 88.679
Epoch 1, K-means clustering 3, Average clustering time 0.054, Prec@1 88.176
Epoch 1, K-means clustering 4, Average clustering time 0.061, Prec@1 87.799
Train - epoch [1/200]	BT 1.543 (1.543)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.5055 (0.5055)
The penalty weight is 0.049958
Train - epoch [2/200]	BT 1.153 (1.153)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 1.0016 (1.0016)
Train - epoch [2/200]	BT 1.176 (1.176)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 1.0119 (1.0119)
Train - epoch [1/200]	BT 1.513 (1.513)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.4900 (0.4900)
Train - epoch [2/200]	BT 1.223 (1.223)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 1.0042 (1.0042)
Test on T training set - [1][0/45]	T 0.504 (0.504)	D 0.390 (0.390)	T@1 80.952 (80.952)	T@5 96.825 (96.825)	L 0.8166 (0.8166)
Test on T training set - [1][10/45]	T 0.330 (0.348)	D 0.211 (0.230)	T@1 28.571 (77.489)	T@5 63.492 (91.342)	L 2.8384 (0.9137)
Test on T training set - [1][20/45]	T 0.323 (0.339)	D 0.204 (0.220)	T@1 85.714 (73.923)	T@5 100.000 (89.418)	L 0.5280 (1.0625)
Test on T training set - [1][30/45]	T 0.344 (0.340)	D 0.219 (0.222)	T@1 71.429 (71.173)	T@5 93.651 (87.967)	L 1.1800 (1.1508)
Test on T training set - [1][40/45]	T 0.348 (0.340)	D 0.224 (0.221)	T@1 38.095 (66.589)	T@5 79.365 (84.088)	L 2.1076 (1.3534)
 * Test on T training set - Prec@1 64.217, Prec@5 83.493
Train - epoch [2/200]	BT 1.699 (1.699)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 0.9665 (0.9665)
Train - epoch [2/200]	BT 1.242 (1.242)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 1.0122 (1.0122)
Test on T test set - [1][0/45]	Time 0.497 (0.497)	Loss 0.8166 (0.8166)	Prec@1 80.952 (80.952)	Prec@5 96.825 (96.825)
Test on T test set - [1][10/45]	Time 0.330 (0.340)	Loss 2.8384 (0.9137)	Prec@1 28.571 (77.489)	Prec@5 63.492 (91.342)
Test on T test set - [1][20/45]	Time 0.365 (0.340)	Loss 0.5280 (1.0625)	Prec@1 85.714 (73.923)	Prec@5 100.000 (89.418)
Test on T test set - [1][30/45]	Time 0.324 (0.337)	Loss 1.1800 (1.1508)	Prec@1 71.429 (71.173)	Prec@5 93.651 (87.967)
Test on T test set - [1][40/45]	Time 0.359 (0.336)	Loss 2.1076 (1.3534)	Prec@1 38.095 (66.589)	Prec@5 79.365 (84.088)
 * Test on T test set - Prec@1 64.217, Prec@5 83.493
Epoch 1, K-means clustering 0, Average clustering time 0.027, Prec@1 72.346
Epoch 1, K-means clustering 1, Average clustering time 0.094, Prec@1 74.086
Epoch 1, K-means clustering 2, Average clustering time 0.102, Prec@1 74.228
Epoch 1, K-means clustering 3, Average clustering time 0.108, Prec@1 74.192
Epoch 1, K-means clustering 4, Average clustering time 0.110, Prec@1 73.837
Epoch 1, K-means clustering 0, Average clustering time 0.003, Prec@1 70.394
Epoch 1, K-means clustering 1, Average clustering time 0.045, Prec@1 70.998
Epoch 1, K-means clustering 2, Average clustering time 0.060, Prec@1 71.636
Epoch 1, K-means clustering 3, Average clustering time 0.066, Prec@1 71.920
Epoch 1, K-means clustering 4, Average clustering time 0.070, Prec@1 72.062
Train - epoch [2/200]	BT 1.227 (1.227)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 0.9820 (0.9820)
Train - epoch [2/200]	BT 1.098 (1.098)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 0.9689 (0.9689)
The penalty weight is 0.049958
Train - epoch [2/200]	BT 1.583 (1.583)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.9972 (0.9972)
Test on T training set - [2][0/13]	T 0.731 (0.731)	D 0.606 (0.606)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1651 (0.1651)
Test on T training set - [2][10/13]	T 0.504 (0.524)	D 0.381 (0.401)	T@1 66.667 (82.107)	T@5 100.000 (96.248)	L 0.8939 (0.7049)
 * Test on T training set - Prec@1 81.132, Prec@5 96.226
Test on T test set - [2][0/13]	Time 0.738 (0.738)	Loss 0.1651 (0.1651)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [2][10/13]	Time 0.508 (0.523)	Loss 0.8939 (0.7049)	Prec@1 66.667 (82.107)	Prec@5 100.000 (96.248)
 * Test on T test set - Prec@1 81.132, Prec@5 96.226
Epoch 2, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 2, K-means clustering 1, Average clustering time 0.077, Prec@1 89.560
Epoch 2, K-means clustering 2, Average clustering time 0.087, Prec@1 88.931
Epoch 2, K-means clustering 3, Average clustering time 0.085, Prec@1 88.805
Epoch 2, K-means clustering 4, Average clustering time 0.083, Prec@1 88.805
Epoch 2, K-means clustering 0, Average clustering time 0.001, Prec@1 87.170
Epoch 2, K-means clustering 1, Average clustering time 0.034, Prec@1 88.428
Epoch 2, K-means clustering 2, Average clustering time 0.044, Prec@1 88.050
Epoch 2, K-means clustering 3, Average clustering time 0.051, Prec@1 87.547
Epoch 2, K-means clustering 4, Average clustering time 0.057, Prec@1 87.296
Train - epoch [2/200]	BT 1.424 (1.424)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.9652 (0.9652)
Train - epoch [2/200]	BT 1.449 (1.449)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.0181 (1.0181)
The penalty weight is 0.074860
Train - epoch [3/200]	BT 1.056 (1.056)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 1.5215 (1.5215)
Train - epoch [2/200]	BT 1.537 (1.537)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.0354 (1.0354)
Train - epoch [3/200]	BT 1.141 (1.141)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 1.4680 (1.4680)
Train - epoch [3/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 1.4701 (1.4701)
Train - epoch [2/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8831 (0.8831)
Train - epoch [3/200]	BT 1.146 (1.146)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 1.4408 (1.4408)
Train - epoch [3/200]	BT 1.109 (1.109)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 1.5196 (1.5196)
Train - epoch [2/200]	BT 1.440 (1.440)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.0047 (1.0047)
Train - epoch [2/200]	BT 1.855 (1.855)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.0339 (1.0339)
Train - epoch [3/200]	BT 1.315 (1.315)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 1.5757 (1.5757)
Test on T training set - [2][0/45]	T 0.543 (0.543)	D 0.421 (0.421)	T@1 82.540 (82.540)	T@5 96.825 (96.825)	L 0.8110 (0.8110)
Test on T training set - [2][10/45]	T 0.342 (0.351)	D 0.220 (0.231)	T@1 28.571 (78.211)	T@5 65.079 (91.342)	L 2.8114 (0.9080)
Test on T training set - [2][20/45]	T 0.325 (0.343)	D 0.207 (0.223)	T@1 82.540 (74.225)	T@5 100.000 (89.645)	L 0.5285 (1.0511)
Test on T training set - [2][30/45]	T 0.318 (0.339)	D 0.206 (0.220)	T@1 74.603 (71.531)	T@5 95.238 (88.274)	L 1.0050 (1.1378)
Test on T training set - [2][40/45]	T 0.347 (0.345)	D 0.223 (0.226)	T@1 42.857 (67.131)	T@5 79.365 (84.088)	L 1.9918 (1.3379)
 * Test on T training set - Prec@1 64.892, Prec@5 83.600
Test on T training set - [3][0/13]	T 0.763 (0.763)	D 0.633 (0.633)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1305 (0.1305)
Test on T training set - [3][10/13]	T 0.519 (0.533)	D 0.397 (0.412)	T@1 61.905 (82.251)	T@5 100.000 (95.815)	L 0.9076 (0.6951)
 * Test on T training set - Prec@1 81.006, Prec@5 95.849
Test on T test set - [3][0/13]	Time 0.751 (0.751)	Loss 0.1305 (0.1305)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [3][10/13]	Time 0.523 (0.536)	Loss 0.9076 (0.6951)	Prec@1 61.905 (82.251)	Prec@5 100.000 (95.815)
 * Test on T test set - Prec@1 81.006, Prec@5 95.849
Epoch 3, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 3, K-means clustering 1, Average clustering time 0.085, Prec@1 89.434
Epoch 3, K-means clustering 2, Average clustering time 0.094, Prec@1 88.679
Epoch 3, K-means clustering 3, Average clustering time 0.093, Prec@1 88.428
Epoch 3, K-means clustering 4, Average clustering time 0.092, Prec@1 88.302
Epoch 3, K-means clustering 0, Average clustering time 0.001, Prec@1 86.918
Epoch 3, K-means clustering 1, Average clustering time 0.038, Prec@1 88.805
Epoch 3, K-means clustering 2, Average clustering time 0.051, Prec@1 88.553
Epoch 3, K-means clustering 3, Average clustering time 0.059, Prec@1 87.925
Epoch 3, K-means clustering 4, Average clustering time 0.065, Prec@1 87.799
Test on T test set - [2][0/45]	Time 0.517 (0.517)	Loss 0.8110 (0.8110)	Prec@1 82.540 (82.540)	Prec@5 96.825 (96.825)
Test on T test set - [2][10/45]	Time 0.326 (0.361)	Loss 2.8114 (0.9080)	Prec@1 28.571 (78.211)	Prec@5 65.079 (91.342)
Test on T test set - [2][20/45]	Time 0.325 (0.347)	Loss 0.5285 (1.0511)	Prec@1 82.540 (74.225)	Prec@5 100.000 (89.645)
Test on T test set - [2][30/45]	Time 0.329 (0.349)	Loss 1.0050 (1.1378)	Prec@1 74.603 (71.531)	Prec@5 95.238 (88.274)
Test on T test set - [2][40/45]	Time 0.354 (0.345)	Loss 1.9918 (1.3379)	Prec@1 42.857 (67.131)	Prec@5 79.365 (84.088)
 * Test on T test set - Prec@1 64.892, Prec@5 83.600
Epoch 2, K-means clustering 0, Average clustering time 0.029, Prec@1 72.524
Epoch 2, K-means clustering 1, Average clustering time 0.098, Prec@1 74.334
Epoch 2, K-means clustering 2, Average clustering time 0.104, Prec@1 74.370
Epoch 2, K-means clustering 3, Average clustering time 0.108, Prec@1 74.299
Epoch 2, K-means clustering 4, Average clustering time 0.107, Prec@1 74.086
Epoch 2, K-means clustering 0, Average clustering time 0.003, Prec@1 70.785
Epoch 2, K-means clustering 1, Average clustering time 0.041, Prec@1 71.672
Epoch 2, K-means clustering 2, Average clustering time 0.062, Prec@1 72.240
Epoch 2, K-means clustering 3, Average clustering time 0.071, Prec@1 72.240
Epoch 2, K-means clustering 4, Average clustering time 0.079, Prec@1 72.169
The penalty weight is 0.074860
Train - epoch [3/200]	BT 1.583 (1.583)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.5688 (1.5688)
The penalty weight is 0.099668
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 2.0080 (2.0080)
Train - epoch [4/200]	BT 1.432 (1.432)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 1.9301 (1.9301)
Train - epoch [3/200]	BT 1.659 (1.659)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.4699 (1.4699)
Train - epoch [4/200]	BT 1.111 (1.111)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 2.0648 (2.0648)
Train - epoch [4/200]	BT 1.166 (1.166)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.0323 (2.0323)
Train - epoch [3/200]	BT 1.506 (1.506)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.3084 (1.3084)
Train - epoch [4/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.0417 (2.0417)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 1.9013 (1.9013)
Train - epoch [3/200]	BT 1.506 (1.506)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.5007 (1.5007)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 2.0312 (2.0312)
Train - epoch [3/200]	BT 1.544 (1.544)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.4605 (1.4605)
Test on T training set - [4][0/13]	T 0.739 (0.739)	D 0.612 (0.612)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1393 (0.1393)
Test on T training set - [4][10/13]	T 0.680 (0.557)	D 0.556 (0.436)	T@1 63.492 (82.395)	T@5 100.000 (95.382)	L 0.8967 (0.7083)
 * Test on T training set - Prec@1 81.132, Prec@5 95.723
Train - epoch [3/200]	BT 1.553 (1.553)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.5497 (1.5497)
Test on T test set - [4][0/13]	Time 0.739 (0.739)	Loss 0.1393 (0.1393)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [4][10/13]	Time 0.509 (0.516)	Loss 0.8967 (0.7083)	Prec@1 63.492 (82.395)	Prec@5 100.000 (95.382)
 * Test on T test set - Prec@1 81.132, Prec@5 95.723
Epoch 4, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 4, K-means clustering 1, Average clustering time 0.081, Prec@1 89.434
Epoch 4, K-means clustering 2, Average clustering time 0.082, Prec@1 88.931
Epoch 4, K-means clustering 3, Average clustering time 0.082, Prec@1 88.428
Epoch 4, K-means clustering 4, Average clustering time 0.083, Prec@1 88.428
Epoch 4, K-means clustering 0, Average clustering time 0.001, Prec@1 86.667
Epoch 4, K-means clustering 1, Average clustering time 0.038, Prec@1 87.925
Epoch 4, K-means clustering 2, Average clustering time 0.057, Prec@1 87.547
Epoch 4, K-means clustering 3, Average clustering time 0.061, Prec@1 87.296
Epoch 4, K-means clustering 4, Average clustering time 0.065, Prec@1 87.421
The penalty weight is 0.124353
Train - epoch [5/200]	BT 1.185 (1.185)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 2.3557 (2.3557)
Train - epoch [5/200]	BT 1.070 (1.070)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 2.5658 (2.5658)
Test on T training set - [3][0/45]	T 0.504 (0.504)	D 0.381 (0.381)	T@1 82.540 (82.540)	T@5 96.825 (96.825)	L 0.8511 (0.8511)
Test on T training set - [3][10/45]	T 0.308 (0.346)	D 0.196 (0.228)	T@1 28.571 (77.778)	T@5 65.079 (91.053)	L 2.7557 (0.9142)
Test on T training set - [3][20/45]	T 0.330 (0.342)	D 0.218 (0.223)	T@1 84.127 (73.998)	T@5 100.000 (89.494)	L 0.5164 (1.0620)
Test on T training set - [3][30/45]	T 0.319 (0.339)	D 0.207 (0.221)	T@1 74.603 (71.531)	T@5 95.238 (88.326)	L 1.0886 (1.1460)
Test on T training set - [3][40/45]	T 0.321 (0.338)	D 0.203 (0.219)	T@1 41.270 (67.054)	T@5 80.952 (84.553)	L 2.0044 (1.3377)
 * Test on T training set - Prec@1 64.679, Prec@5 83.990
Test on T test set - [3][0/45]	Time 0.520 (0.520)	Loss 0.8511 (0.8511)	Prec@1 82.540 (82.540)	Prec@5 96.825 (96.825)
Test on T test set - [3][10/45]	Time 0.325 (0.354)	Loss 2.7557 (0.9142)	Prec@1 28.571 (77.778)	Prec@5 65.079 (91.053)
Test on T test set - [3][20/45]	Time 0.350 (0.343)	Loss 0.5164 (1.0620)	Prec@1 84.127 (73.998)	Prec@5 100.000 (89.494)
Test on T test set - [3][30/45]	Time 0.319 (0.349)	Loss 1.0886 (1.1460)	Prec@1 74.603 (71.531)	Prec@5 95.238 (88.326)
Test on T test set - [3][40/45]	Time 0.322 (0.346)	Loss 2.0044 (1.3377)	Prec@1 41.270 (67.054)	Prec@5 80.952 (84.553)
 * Test on T test set - Prec@1 64.679, Prec@5 83.990
Epoch 3, K-means clustering 0, Average clustering time 0.029, Prec@1 72.382
Epoch 3, K-means clustering 1, Average clustering time 0.097, Prec@1 73.411
Epoch 3, K-means clustering 2, Average clustering time 0.101, Prec@1 73.873
Epoch 3, K-means clustering 3, Average clustering time 0.102, Prec@1 73.695
Epoch 3, K-means clustering 4, Average clustering time 0.107, Prec@1 73.695
Epoch 3, K-means clustering 0, Average clustering time 0.003, Prec@1 70.323
Epoch 3, K-means clustering 1, Average clustering time 0.042, Prec@1 71.459
Epoch 3, K-means clustering 2, Average clustering time 0.108, Prec@1 71.672
Epoch 3, K-means clustering 3, Average clustering time 0.109, Prec@1 71.991
Epoch 3, K-means clustering 4, Average clustering time 0.105, Prec@1 72.062
Train - epoch [5/200]	BT 1.082 (1.082)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 2.5888 (2.5888)
Train - epoch [5/200]	BT 1.089 (1.089)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 2.3788 (2.3788)
The penalty weight is 0.099668
Train - epoch [4/200]	BT 1.468 (1.468)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.0220 (2.0220)
Train - epoch [5/200]	BT 1.157 (1.157)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.5408 (2.5408)
Train - epoch [4/200]	BT 1.451 (1.451)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.0160 (2.0160)
Train - epoch [5/200]	BT 1.118 (1.118)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 2.2899 (2.2899)
Train - epoch [5/200]	BT 1.085 (1.085)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 2.4487 (2.4487)
Train - epoch [4/200]	BT 2.049 (2.049)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.0007 (2.0007)
Train - epoch [4/200]	BT 1.461 (1.461)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.9772 (1.9772)
Test on T training set - [5][0/13]	T 0.757 (0.757)	D 0.629 (0.629)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1356 (0.1356)
Test on T training set - [5][10/13]	T 0.533 (0.527)	D 0.418 (0.406)	T@1 65.079 (82.540)	T@5 100.000 (95.815)	L 0.8772 (0.6973)
 * Test on T training set - Prec@1 81.132, Prec@5 95.849
Train - epoch [4/200]	BT 1.522 (1.522)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.0536 (2.0536)
Test on T test set - [5][0/13]	Time 0.763 (0.763)	Loss 0.1356 (0.1356)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [5][10/13]	Time 0.544 (0.526)	Loss 0.8772 (0.6973)	Prec@1 65.079 (82.540)	Prec@5 100.000 (95.815)
 * Test on T test set - Prec@1 81.132, Prec@5 95.849
Epoch 5, K-means clustering 0, Average clustering time 0.018, Prec@1 88.050
Epoch 5, K-means clustering 1, Average clustering time 0.082, Prec@1 89.434
Epoch 5, K-means clustering 2, Average clustering time 0.082, Prec@1 88.428
Epoch 5, K-means clustering 3, Average clustering time 0.086, Prec@1 88.050
Epoch 5, K-means clustering 4, Average clustering time 0.090, Prec@1 87.799
Epoch 5, K-means clustering 0, Average clustering time 0.001, Prec@1 86.792
Epoch 5, K-means clustering 1, Average clustering time 0.049, Prec@1 87.925
Epoch 5, K-means clustering 2, Average clustering time 0.060, Prec@1 87.673
Epoch 5, K-means clustering 3, Average clustering time 0.064, Prec@1 87.421
Epoch 5, K-means clustering 4, Average clustering time 0.067, Prec@1 87.421
Train - epoch [4/200]	BT 1.546 (1.546)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.7617 (1.7617)
The penalty weight is 0.148885
Train - epoch [6/200]	BT 1.174 (1.174)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 2.9765 (2.9765)
Train - epoch [4/200]	BT 1.457 (1.457)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.8238 (1.8238)
Train - epoch [6/200]	BT 1.700 (1.700)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 3.0039 (3.0039)
Train - epoch [6/200]	BT 1.209 (1.209)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 2.8205 (2.8205)
Test on T training set - [4][0/45]	T 0.524 (0.524)	D 0.405 (0.405)	T@1 84.127 (84.127)	T@5 96.825 (96.825)	L 0.7423 (0.7423)
Test on T training set - [4][10/45]	T 0.333 (0.350)	D 0.211 (0.230)	T@1 25.397 (77.778)	T@5 61.905 (90.909)	L 2.8118 (0.8955)
Test on T training set - [4][20/45]	T 0.333 (0.368)	D 0.213 (0.249)	T@1 87.302 (74.150)	T@5 100.000 (89.267)	L 0.4681 (1.0476)
Test on T training set - [4][30/45]	T 0.313 (0.359)	D 0.201 (0.239)	T@1 71.429 (71.480)	T@5 92.063 (87.967)	L 1.2197 (1.1450)
Test on T training set - [4][40/45]	T 0.335 (0.353)	D 0.215 (0.233)	T@1 39.683 (66.628)	T@5 79.365 (84.243)	L 2.0518 (1.3509)
 * Test on T training set - Prec@1 64.324, Prec@5 83.919
Train - epoch [6/200]	BT 1.234 (1.234)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 2.9116 (2.9116)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 3.0188 (3.0188)
Test on T test set - [4][0/45]	Time 0.535 (0.535)	Loss 0.7423 (0.7423)	Prec@1 84.127 (84.127)	Prec@5 96.825 (96.825)
Test on T test set - [4][10/45]	Time 0.459 (0.362)	Loss 2.8118 (0.8955)	Prec@1 25.397 (77.778)	Prec@5 61.905 (90.909)
Test on T test set - [4][20/45]	Time 0.346 (0.351)	Loss 0.4681 (1.0476)	Prec@1 87.302 (74.150)	Prec@5 100.000 (89.267)
Test on T test set - [4][30/45]	Time 0.331 (0.345)	Loss 1.2197 (1.1450)	Prec@1 71.429 (71.480)	Prec@5 92.063 (87.967)
Test on T test set - [4][40/45]	Time 0.339 (0.350)	Loss 2.0518 (1.3509)	Prec@1 39.683 (66.628)	Prec@5 79.365 (84.243)
 * Test on T test set - Prec@1 64.324, Prec@5 83.919
Epoch 4, K-means clustering 0, Average clustering time 0.027, Prec@1 72.488
Epoch 4, K-means clustering 1, Average clustering time 0.101, Prec@1 73.944
Epoch 4, K-means clustering 2, Average clustering time 0.103, Prec@1 74.405
Epoch 4, K-means clustering 3, Average clustering time 0.101, Prec@1 74.263
Epoch 4, K-means clustering 4, Average clustering time 0.106, Prec@1 74.121
Epoch 4, K-means clustering 0, Average clustering time 0.003, Prec@1 69.720
Epoch 4, K-means clustering 1, Average clustering time 0.049, Prec@1 71.388
Epoch 4, K-means clustering 2, Average clustering time 0.061, Prec@1 71.565
Epoch 4, K-means clustering 3, Average clustering time 0.074, Prec@1 71.814
Epoch 4, K-means clustering 4, Average clustering time 0.081, Prec@1 71.530
Train - epoch [6/200]	BT 1.110 (1.110)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 2.9043 (2.9043)
The penalty weight is 0.124353
Train - epoch [5/200]	BT 1.446 (1.446)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.3678 (2.3678)
Test on T training set - [6][0/13]	T 0.797 (0.797)	D 0.680 (0.680)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1051 (0.1051)
Test on T training set - [6][10/13]	T 0.592 (0.529)	D 0.471 (0.405)	T@1 65.079 (82.251)	T@5 98.413 (96.392)	L 0.9091 (0.6996)
 * Test on T training set - Prec@1 81.132, Prec@5 96.478
Test on T test set - [6][0/13]	Time 0.743 (0.743)	Loss 0.1051 (0.1051)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [6][10/13]	Time 0.522 (0.522)	Loss 0.9091 (0.6996)	Prec@1 65.079 (82.251)	Prec@5 98.413 (96.392)
 * Test on T test set - Prec@1 81.132, Prec@5 96.478
Epoch 6, K-means clustering 0, Average clustering time 0.018, Prec@1 88.679
Epoch 6, K-means clustering 1, Average clustering time 0.083, Prec@1 89.434
Epoch 6, K-means clustering 2, Average clustering time 0.085, Prec@1 89.308
Epoch 6, K-means clustering 3, Average clustering time 0.087, Prec@1 88.931
Epoch 6, K-means clustering 4, Average clustering time 0.089, Prec@1 89.057
Epoch 6, K-means clustering 0, Average clustering time 0.001, Prec@1 86.918
Epoch 6, K-means clustering 1, Average clustering time 0.046, Prec@1 87.925
Epoch 6, K-means clustering 2, Average clustering time 0.060, Prec@1 87.925
Epoch 6, K-means clustering 3, Average clustering time 0.065, Prec@1 88.050
Epoch 6, K-means clustering 4, Average clustering time 0.067, Prec@1 87.673
Train - epoch [5/200]	BT 1.511 (1.511)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.3437 (2.3437)
Train - epoch [5/200]	BT 1.472 (1.472)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.2307 (2.2307)
The penalty weight is 0.173235
Train - epoch [7/200]	BT 1.014 (1.014)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 3.3552 (3.3552)
Train - epoch [7/200]	BT 1.125 (1.125)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 3.2873 (3.2873)
Train - epoch [5/200]	BT 1.590 (1.590)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.3731 (2.3731)
Train - epoch [7/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 3.5464 (3.5464)
Train - epoch [7/200]	BT 1.083 (1.083)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 3.2888 (3.2888)
Train - epoch [5/200]	BT 1.509 (1.509)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.6050 (2.6050)
Train - epoch [7/200]	BT 1.504 (1.504)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 3.2714 (3.2714)
Train - epoch [7/200]	BT 0.968 (0.968)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 3.5165 (3.5165)
Train - epoch [5/200]	BT 2.017 (2.017)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.5904 (2.5904)
Train - epoch [5/200]	BT 1.111 (1.111)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.6279 (2.6279)
Train - epoch [7/200]	BT 1.132 (1.132)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 3.5107 (3.5107)
Test on T training set - [5][0/45]	T 0.525 (0.525)	D 0.395 (0.395)	T@1 80.952 (80.952)	T@5 96.825 (96.825)	L 0.8470 (0.8470)
Test on T training set - [5][10/45]	T 0.337 (0.349)	D 0.213 (0.229)	T@1 26.984 (77.633)	T@5 61.905 (90.909)	L 2.7658 (0.9112)
Test on T training set - [5][20/45]	T 0.442 (0.346)	D 0.322 (0.228)	T@1 84.127 (74.528)	T@5 100.000 (89.720)	L 0.5543 (1.0504)
Test on T training set - [5][30/45]	T 0.348 (0.354)	D 0.226 (0.236)	T@1 73.016 (71.889)	T@5 95.238 (88.428)	L 1.0579 (1.1340)
Test on T training set - [5][40/45]	T 0.749 (0.359)	D 0.628 (0.240)	T@1 38.095 (67.596)	T@5 79.365 (84.514)	L 2.1103 (1.3292)
 * Test on T training set - Prec@1 65.176, Prec@5 83.990
Test on T training set - [7][0/13]	T 0.806 (0.806)	D 0.690 (0.690)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1241 (0.1241)
Test on T training set - [7][10/13]	T 0.513 (0.530)	D 0.394 (0.411)	T@1 65.079 (82.973)	T@5 100.000 (96.392)	L 0.8348 (0.6776)
 * Test on T training set - Prec@1 81.887, Prec@5 96.478
Test on T test set - [7][0/13]	Time 0.750 (0.750)	Loss 0.1241 (0.1241)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [7][10/13]	Time 0.529 (0.525)	Loss 0.8348 (0.6776)	Prec@1 65.079 (82.973)	Prec@5 100.000 (96.392)
 * Test on T test set - Prec@1 81.887, Prec@5 96.478
Epoch 7, K-means clustering 0, Average clustering time 0.018, Prec@1 88.302
Epoch 7, K-means clustering 1, Average clustering time 0.081, Prec@1 88.931
Epoch 7, K-means clustering 2, Average clustering time 0.083, Prec@1 88.679
Epoch 7, K-means clustering 3, Average clustering time 0.088, Prec@1 88.302
Epoch 7, K-means clustering 4, Average clustering time 0.089, Prec@1 88.176
Epoch 7, K-means clustering 0, Average clustering time 0.001, Prec@1 87.799
Epoch 7, K-means clustering 1, Average clustering time 0.052, Prec@1 88.553
Epoch 7, K-means clustering 2, Average clustering time 0.062, Prec@1 88.302
Epoch 7, K-means clustering 3, Average clustering time 0.067, Prec@1 87.799
Epoch 7, K-means clustering 4, Average clustering time 0.070, Prec@1 87.673
Test on T test set - [5][0/45]	Time 0.508 (0.508)	Loss 0.8470 (0.8470)	Prec@1 80.952 (80.952)	Prec@5 96.825 (96.825)
Test on T test set - [5][10/45]	Time 0.353 (0.347)	Loss 2.7658 (0.9112)	Prec@1 26.984 (77.633)	Prec@5 61.905 (90.909)
Test on T test set - [5][20/45]	Time 0.329 (0.344)	Loss 0.5543 (1.0504)	Prec@1 84.127 (74.528)	Prec@5 100.000 (89.720)
Test on T test set - [5][30/45]	Time 0.324 (0.342)	Loss 1.0579 (1.1340)	Prec@1 73.016 (71.889)	Prec@5 95.238 (88.428)
Test on T test set - [5][40/45]	Time 0.328 (0.341)	Loss 2.1103 (1.3292)	Prec@1 38.095 (67.596)	Prec@5 79.365 (84.514)
 * Test on T test set - Prec@1 65.176, Prec@5 83.990
Epoch 5, K-means clustering 0, Average clustering time 0.027, Prec@1 72.772
Epoch 5, K-means clustering 1, Average clustering time 0.091, Prec@1 74.050
Epoch 5, K-means clustering 2, Average clustering time 0.094, Prec@1 74.299
Epoch 5, K-means clustering 3, Average clustering time 0.093, Prec@1 73.802
Epoch 5, K-means clustering 4, Average clustering time 0.097, Prec@1 73.624
Epoch 5, K-means clustering 0, Average clustering time 0.003, Prec@1 70.785
Epoch 5, K-means clustering 1, Average clustering time 0.051, Prec@1 71.849
Epoch 5, K-means clustering 2, Average clustering time 0.063, Prec@1 72.311
Epoch 5, K-means clustering 3, Average clustering time 0.068, Prec@1 72.453
Epoch 5, K-means clustering 4, Average clustering time 0.072, Prec@1 72.382
The penalty weight is 0.197375
Train - epoch [8/200]	BT 1.070 (1.070)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 3.9707 (3.9707)
Train - epoch [8/200]	BT 1.174 (1.174)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 3.4634 (3.4634)
The penalty weight is 0.148885
Train - epoch [6/200]	BT 1.554 (1.554)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.6855 (2.6855)
Train - epoch [6/200]	BT 1.550 (1.550)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.9801 (2.9801)
Train - epoch [8/200]	BT 1.036 (1.036)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 3.5456 (3.5456)
Train - epoch [8/200]	BT 1.150 (1.150)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 3.9742 (3.9742)
Train - epoch [6/200]	BT 1.575 (1.575)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.8438 (2.8438)
Train - epoch [8/200]	BT 1.092 (1.092)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 4.0012 (4.0012)
Train - epoch [6/200]	BT 1.525 (1.525)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.8142 (2.8142)
Train - epoch [8/200]	BT 1.627 (1.627)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 4.0132 (4.0132)
Train - epoch [8/200]	BT 1.115 (1.115)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.9335 (3.9335)
Train - epoch [6/200]	BT 1.569 (1.569)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 2.9920 (2.9920)
Test on T training set - [8][0/13]	T 0.741 (0.741)	D 0.611 (0.611)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1284 (0.1284)
Test on T training set - [8][10/13]	T 0.508 (0.530)	D 0.386 (0.409)	T@1 63.492 (81.962)	T@5 100.000 (95.815)	L 0.8695 (0.6895)
 * Test on T training set - Prec@1 80.755, Prec@5 95.849
Train - epoch [6/200]	BT 1.551 (1.551)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.0355 (3.0355)
Test on T test set - [8][0/13]	Time 0.747 (0.747)	Loss 0.1284 (0.1284)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [8][10/13]	Time 0.527 (0.533)	Loss 0.8695 (0.6895)	Prec@1 63.492 (81.962)	Prec@5 100.000 (95.815)
 * Test on T test set - Prec@1 80.755, Prec@5 95.849
Epoch 8, K-means clustering 0, Average clustering time 0.018, Prec@1 87.799
Epoch 8, K-means clustering 1, Average clustering time 0.078, Prec@1 89.182
Epoch 8, K-means clustering 2, Average clustering time 0.079, Prec@1 88.679
Epoch 8, K-means clustering 3, Average clustering time 0.080, Prec@1 88.302
Epoch 8, K-means clustering 4, Average clustering time 0.080, Prec@1 88.428
Epoch 8, K-means clustering 0, Average clustering time 0.001, Prec@1 86.667
Epoch 8, K-means clustering 1, Average clustering time 0.055, Prec@1 87.925
Epoch 8, K-means clustering 2, Average clustering time 0.065, Prec@1 87.547
Epoch 8, K-means clustering 3, Average clustering time 0.072, Prec@1 87.044
Epoch 8, K-means clustering 4, Average clustering time 0.072, Prec@1 87.044
The penalty weight is 0.221278
Train - epoch [9/200]	BT 1.176 (1.176)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 4.1931 (4.1931)
Train - epoch [9/200]	BT 1.086 (1.086)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 4.5384 (4.5384)
Test on T training set - [6][0/45]	T 0.529 (0.529)	D 0.406 (0.406)	T@1 80.952 (80.952)	T@5 95.238 (95.238)	L 0.8946 (0.8946)
Test on T training set - [6][10/45]	T 0.328 (0.411)	D 0.204 (0.292)	T@1 25.397 (77.201)	T@5 55.556 (90.043)	L 2.9453 (0.9366)
Test on T training set - [6][20/45]	T 0.540 (0.394)	D 0.416 (0.275)	T@1 85.714 (73.167)	T@5 100.000 (88.511)	L 0.4353 (1.0818)
Test on T training set - [6][30/45]	T 0.335 (0.378)	D 0.211 (0.258)	T@1 69.841 (70.405)	T@5 92.063 (87.353)	L 1.2597 (1.1703)
Test on T training set - [6][40/45]	T 0.355 (0.371)	D 0.243 (0.252)	T@1 41.270 (65.854)	T@5 79.365 (83.701)	L 2.0620 (1.3735)
 * Test on T training set - Prec@1 63.543, Prec@5 83.280
Test on T test set - [6][0/45]	Time 0.509 (0.509)	Loss 0.8946 (0.8946)	Prec@1 80.952 (80.952)	Prec@5 95.238 (95.238)
Test on T test set - [6][10/45]	Time 0.340 (0.352)	Loss 2.9453 (0.9366)	Prec@1 25.397 (77.201)	Prec@5 55.556 (90.043)
Test on T test set - [6][20/45]	Time 0.335 (0.342)	Loss 0.4353 (1.0818)	Prec@1 85.714 (73.167)	Prec@5 100.000 (88.511)
Test on T test set - [6][30/45]	Time 0.344 (0.341)	Loss 1.2597 (1.1703)	Prec@1 69.841 (70.405)	Prec@5 92.063 (87.353)
Test on T test set - [6][40/45]	Time 0.334 (0.339)	Loss 2.0620 (1.3735)	Prec@1 41.270 (65.854)	Prec@5 79.365 (83.701)
 * Test on T test set - Prec@1 63.543, Prec@5 83.280
Epoch 6, K-means clustering 0, Average clustering time 0.027, Prec@1 72.453
Epoch 6, K-means clustering 1, Average clustering time 0.086, Prec@1 73.731
Epoch 6, K-means clustering 2, Average clustering time 0.094, Prec@1 73.553
Epoch 6, K-means clustering 3, Average clustering time 0.100, Prec@1 73.234
Epoch 6, K-means clustering 4, Average clustering time 0.100, Prec@1 72.843
Epoch 6, K-means clustering 0, Average clustering time 0.003, Prec@1 69.471
Epoch 6, K-means clustering 1, Average clustering time 0.052, Prec@1 71.175
Epoch 6, K-means clustering 2, Average clustering time 0.066, Prec@1 71.246
Epoch 6, K-means clustering 3, Average clustering time 0.073, Prec@1 71.388
Epoch 6, K-means clustering 4, Average clustering time 0.082, Prec@1 71.282
Train - epoch [9/200]	BT 1.193 (1.193)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 4.4445 (4.4445)
The penalty weight is 0.173235
Train - epoch [7/200]	BT 1.468 (1.468)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.5149 (3.5149)
Train - epoch [9/200]	BT 1.239 (1.239)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 4.2249 (4.2249)
Train - epoch [9/200]	BT 1.226 (1.226)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 4.4242 (4.4242)
Train - epoch [7/200]	BT 2.185 (2.185)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.3976 (3.3976)
Train - epoch [7/200]	BT 1.467 (1.467)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.4511 (3.4511)
Train - epoch [9/200]	BT 1.431 (1.431)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 4.5547 (4.5547)
Train - epoch [7/200]	BT 1.537 (1.537)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.5838 (3.5838)
Test on T training set - [9][0/13]	T 0.733 (0.733)	D 0.616 (0.616)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1366 (0.1366)
Test on T training set - [9][10/13]	T 0.516 (0.560)	D 0.396 (0.437)	T@1 66.667 (83.261)	T@5 100.000 (96.825)	L 1.0105 (0.6911)
 * Test on T training set - Prec@1 81.887, Prec@5 96.855
Test on T test set - [9][0/13]	Time 0.752 (0.752)	Loss 0.1366 (0.1366)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [9][10/13]	Time 0.519 (0.528)	Loss 1.0105 (0.6911)	Prec@1 66.667 (83.261)	Prec@5 100.000 (96.825)
 * Test on T test set - Prec@1 81.887, Prec@5 96.855
Epoch 9, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 9, K-means clustering 1, Average clustering time 0.085, Prec@1 89.560
Epoch 9, K-means clustering 2, Average clustering time 0.089, Prec@1 89.182
Epoch 9, K-means clustering 3, Average clustering time 0.097, Prec@1 88.931
Epoch 9, K-means clustering 4, Average clustering time 0.096, Prec@1 88.931
Epoch 9, K-means clustering 0, Average clustering time 0.001, Prec@1 87.044
Epoch 9, K-means clustering 1, Average clustering time 0.037, Prec@1 88.050
Epoch 9, K-means clustering 2, Average clustering time 0.047, Prec@1 88.176
Epoch 9, K-means clustering 3, Average clustering time 0.051, Prec@1 87.673
Epoch 9, K-means clustering 4, Average clustering time 0.054, Prec@1 87.673
Train - epoch [7/200]	BT 1.518 (1.518)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.3633 (3.3633)
Train - epoch [7/200]	BT 1.691 (1.691)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.4633 (3.4633)
Train - epoch [10/200]	BT 1.159 (1.159)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 4.7242 (4.7242)
The penalty weight is 0.244919
Train - epoch [10/200]	BT 1.157 (1.157)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 4.4414 (4.4414)
Train - epoch [7/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.4965 (3.4965)
Train - epoch [10/200]	BT 1.297 (1.297)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 4.8194 (4.8194)
Train - epoch [10/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 4.8694 (4.8694)
Test on T training set - [7][0/45]	T 0.531 (0.531)	D 0.414 (0.414)	T@1 82.540 (82.540)	T@5 96.825 (96.825)	L 0.8047 (0.8047)
Test on T training set - [7][10/45]	T 0.343 (0.363)	D 0.220 (0.246)	T@1 30.159 (78.066)	T@5 63.492 (91.486)	L 2.6669 (0.8942)
Test on T training set - [7][20/45]	T 0.344 (0.351)	D 0.221 (0.232)	T@1 84.127 (75.208)	T@5 100.000 (89.720)	L 0.5602 (1.0368)
Test on T training set - [7][30/45]	T 0.322 (0.347)	D 0.203 (0.228)	T@1 76.190 (72.606)	T@5 95.238 (88.530)	L 0.9788 (1.1129)
Test on T training set - [7][40/45]	T 0.346 (0.350)	D 0.224 (0.231)	T@1 38.095 (67.789)	T@5 79.365 (84.475)	L 2.0737 (1.3181)
 * Test on T training set - Prec@1 65.531, Prec@5 83.955
Train - epoch [10/200]	BT 1.173 (1.173)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 5.0751 (5.0751)
Train - epoch [10/200]	BT 1.129 (1.129)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 4.5910 (4.5910)
Test on T test set - [7][0/45]	Time 0.537 (0.537)	Loss 0.8047 (0.8047)	Prec@1 82.540 (82.540)	Prec@5 96.825 (96.825)
Test on T test set - [7][10/45]	Time 0.478 (0.384)	Loss 2.6669 (0.8942)	Prec@1 30.159 (78.066)	Prec@5 63.492 (91.486)
Test on T test set - [7][20/45]	Time 0.331 (0.359)	Loss 0.5602 (1.0368)	Prec@1 84.127 (75.208)	Prec@5 100.000 (89.720)
Test on T test set - [7][30/45]	Time 0.312 (0.351)	Loss 0.9788 (1.1129)	Prec@1 76.190 (72.606)	Prec@5 95.238 (88.530)
Test on T test set - [7][40/45]	Time 0.334 (0.350)	Loss 2.0737 (1.3181)	Prec@1 38.095 (67.789)	Prec@5 79.365 (84.475)
 * Test on T test set - Prec@1 65.531, Prec@5 83.955
Epoch 7, K-means clustering 0, Average clustering time 0.029, Prec@1 72.488
Epoch 7, K-means clustering 1, Average clustering time 0.102, Prec@1 73.944
Epoch 7, K-means clustering 2, Average clustering time 0.109, Prec@1 73.979
Epoch 7, K-means clustering 3, Average clustering time 0.108, Prec@1 73.979
Epoch 7, K-means clustering 4, Average clustering time 0.109, Prec@1 73.731
Epoch 7, K-means clustering 0, Average clustering time 0.006, Prec@1 70.536
Epoch 7, K-means clustering 1, Average clustering time 0.071, Prec@1 71.424
Epoch 7, K-means clustering 2, Average clustering time 0.071, Prec@1 71.601
Epoch 7, K-means clustering 3, Average clustering time 0.080, Prec@1 71.672
Epoch 7, K-means clustering 4, Average clustering time 0.093, Prec@1 71.707
Train - epoch [10/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 4.9790 (4.9790)
The penalty weight is 0.197375
Train - epoch [8/200]	BT 2.512 (2.512)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.6919 (3.6919)
Test on T training set - [10][0/13]	T 0.744 (0.744)	D 0.610 (0.610)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1219 (0.1219)
Test on T training set - [10][10/13]	T 0.527 (0.529)	D 0.405 (0.405)	T@1 65.079 (82.973)	T@5 98.413 (95.960)	L 0.9277 (0.6734)
 * Test on T training set - Prec@1 81.761, Prec@5 95.975
Test on T test set - [10][0/13]	Time 0.728 (0.728)	Loss 0.1219 (0.1219)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [10][10/13]	Time 0.529 (0.534)	Loss 0.9277 (0.6734)	Prec@1 65.079 (82.973)	Prec@5 98.413 (95.960)
 * Test on T test set - Prec@1 81.761, Prec@5 95.975
Epoch 10, K-means clustering 0, Average clustering time 0.018, Prec@1 88.050
Epoch 10, K-means clustering 1, Average clustering time 0.083, Prec@1 89.057
Epoch 10, K-means clustering 2, Average clustering time 0.085, Prec@1 89.434
Epoch 10, K-means clustering 3, Average clustering time 0.087, Prec@1 88.805
Epoch 10, K-means clustering 4, Average clustering time 0.090, Prec@1 88.428
Epoch 10, K-means clustering 0, Average clustering time 0.001, Prec@1 86.918
Epoch 10, K-means clustering 1, Average clustering time 0.076, Prec@1 88.302
Epoch 10, K-means clustering 2, Average clustering time 0.082, Prec@1 88.050
Epoch 10, K-means clustering 3, Average clustering time 0.087, Prec@1 87.673
Epoch 10, K-means clustering 4, Average clustering time 0.086, Prec@1 87.547
Train - epoch [8/200]	BT 1.541 (1.541)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.0328 (4.0328)
Train - epoch [8/200]	BT 1.493 (1.493)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.0078 (4.0078)
The penalty weight is 0.268271
Train - epoch [11/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 4.9135 (4.9135)
Train - epoch [11/200]	BT 1.173 (1.173)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.2121 (5.2121)
Train - epoch [8/200]	BT 1.501 (1.501)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 3.4723 (3.4723)
Train - epoch [11/200]	BT 1.184 (1.184)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 4.8519 (4.8519)
Train - epoch [11/200]	BT 1.218 (1.218)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 4.9225 (4.9225)
Train - epoch [8/200]	BT 2.022 (2.022)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.0599 (4.0599)
Train - epoch [8/200]	BT 1.435 (1.435)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.0538 (4.0538)
Train - epoch [11/200]	BT 1.370 (1.370)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 5.1319 (5.1319)
Train - epoch [11/200]	BT 1.012 (1.012)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 5.3743 (5.3743)
Train - epoch [8/200]	BT 1.495 (1.495)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.0235 (4.0235)
Train - epoch [11/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 5.0681 (5.0681)
Test on T training set - [8][0/45]	T 0.527 (0.527)	D 0.409 (0.409)	T@1 82.540 (82.540)	T@5 98.413 (98.413)	L 0.8056 (0.8056)
Test on T training set - [8][10/45]	T 0.337 (0.352)	D 0.219 (0.234)	T@1 30.159 (78.644)	T@5 73.016 (92.496)	L 2.6081 (0.8783)
Test on T training set - [8][20/45]	T 0.338 (0.344)	D 0.216 (0.225)	T@1 80.952 (76.039)	T@5 100.000 (91.081)	L 0.6214 (1.0133)
Test on T training set - [8][30/45]	T 0.360 (0.342)	D 0.238 (0.223)	T@1 76.190 (73.169)	T@5 95.238 (89.247)	L 0.9842 (1.1057)
Test on T training set - [8][40/45]	T 0.335 (0.340)	D 0.215 (0.221)	T@1 39.683 (68.448)	T@5 80.952 (85.095)	L 1.9900 (1.3132)
 * Test on T training set - Prec@1 65.992, Prec@5 84.416
Test on T training set - [11][0/13]	T 0.754 (0.754)	D 0.639 (0.639)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1315 (0.1315)
Test on T training set - [11][10/13]	T 0.505 (0.534)	D 0.390 (0.412)	T@1 65.079 (83.550)	T@5 98.413 (95.815)	L 0.9368 (0.6741)
 * Test on T training set - Prec@1 82.264, Prec@5 95.975
Test on T test set - [11][0/13]	Time 0.747 (0.747)	Loss 0.1315 (0.1315)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [11][10/13]	Time 0.520 (0.531)	Loss 0.9368 (0.6741)	Prec@1 65.079 (83.550)	Prec@5 98.413 (95.815)
 * Test on T test set - Prec@1 82.264, Prec@5 95.975
Epoch 11, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 11, K-means clustering 1, Average clustering time 0.092, Prec@1 89.434
Epoch 11, K-means clustering 2, Average clustering time 0.091, Prec@1 88.428
Epoch 11, K-means clustering 3, Average clustering time 0.089, Prec@1 88.176
Epoch 11, K-means clustering 4, Average clustering time 0.089, Prec@1 88.050
Epoch 11, K-means clustering 0, Average clustering time 0.001, Prec@1 87.421
Epoch 11, K-means clustering 1, Average clustering time 0.040, Prec@1 87.925
Epoch 11, K-means clustering 2, Average clustering time 0.053, Prec@1 87.170
Epoch 11, K-means clustering 3, Average clustering time 0.065, Prec@1 87.170
Epoch 11, K-means clustering 4, Average clustering time 0.069, Prec@1 87.044
Test on T test set - [8][0/45]	Time 0.537 (0.537)	Loss 0.8056 (0.8056)	Prec@1 82.540 (82.540)	Prec@5 98.413 (98.413)
Test on T test set - [8][10/45]	Time 0.356 (0.358)	Loss 2.6081 (0.8783)	Prec@1 30.159 (78.644)	Prec@5 73.016 (92.496)
Test on T test set - [8][20/45]	Time 0.339 (0.346)	Loss 0.6214 (1.0133)	Prec@1 80.952 (76.039)	Prec@5 100.000 (91.081)
Test on T test set - [8][30/45]	Time 0.357 (0.344)	Loss 0.9842 (1.1057)	Prec@1 76.190 (73.169)	Prec@5 95.238 (89.247)
Test on T test set - [8][40/45]	Time 0.330 (0.350)	Loss 1.9900 (1.3132)	Prec@1 39.683 (68.448)	Prec@5 80.952 (85.095)
 * Test on T test set - Prec@1 65.992, Prec@5 84.416
Epoch 8, K-means clustering 0, Average clustering time 0.027, Prec@1 72.914
Epoch 8, K-means clustering 1, Average clustering time 0.087, Prec@1 74.157
Epoch 8, K-means clustering 2, Average clustering time 0.093, Prec@1 74.157
Epoch 8, K-means clustering 3, Average clustering time 0.097, Prec@1 73.873
Epoch 8, K-means clustering 4, Average clustering time 0.098, Prec@1 73.731
Epoch 8, K-means clustering 0, Average clustering time 0.003, Prec@1 70.678
Epoch 8, K-means clustering 1, Average clustering time 0.045, Prec@1 71.246
Epoch 8, K-means clustering 2, Average clustering time 0.064, Prec@1 71.246
Epoch 8, K-means clustering 3, Average clustering time 0.070, Prec@1 71.282
Epoch 8, K-means clustering 4, Average clustering time 0.074, Prec@1 71.459
The penalty weight is 0.291313
Train - epoch [12/200]	BT 2.625 (2.625)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 5.6462 (5.6462)
Train - epoch [12/200]	BT 2.251 (2.251)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 5.4600 (5.4600)
The penalty weight is 0.221278
Train - epoch [9/200]	BT 2.687 (2.687)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.5500 (4.5500)
Train - epoch [12/200]	BT 1.096 (1.096)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 5.2966 (5.2966)
Train - epoch [9/200]	BT 1.524 (1.524)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.4522 (4.4522)
Train - epoch [9/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.0736 (4.0736)
Train - epoch [12/200]	BT 1.690 (1.690)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 5.8959 (5.8959)
Train - epoch [12/200]	BT 1.103 (1.103)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.8918 (5.8918)
Train - epoch [9/200]	BT 1.569 (1.569)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.4104 (4.4104)
Train - epoch [12/200]	BT 1.101 (1.101)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 5.8346 (5.8346)
Train - epoch [12/200]	BT 1.085 (1.085)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 5.3758 (5.3758)
Train - epoch [9/200]	BT 1.461 (1.461)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.2313 (4.2313)
Test on T training set - [12][0/13]	T 0.745 (0.745)	D 0.623 (0.623)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1137 (0.1137)
Test on T training set - [12][10/13]	T 0.542 (0.528)	D 0.414 (0.405)	T@1 63.492 (83.405)	T@5 100.000 (96.825)	L 0.9388 (0.6643)
 * Test on T training set - Prec@1 82.642, Prec@5 96.855
Test on T test set - [12][0/13]	Time 0.739 (0.739)	Loss 0.1137 (0.1137)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [12][10/13]	Time 0.511 (0.547)	Loss 0.9388 (0.6643)	Prec@1 63.492 (83.405)	Prec@5 100.000 (96.825)
 * Test on T test set - Prec@1 82.642, Prec@5 96.855
Epoch 12, K-means clustering 0, Average clustering time 0.018, Prec@1 88.553
Epoch 12, K-means clustering 1, Average clustering time 0.079, Prec@1 89.057
Epoch 12, K-means clustering 2, Average clustering time 0.081, Prec@1 88.428
Epoch 12, K-means clustering 3, Average clustering time 0.081, Prec@1 88.428
Epoch 12, K-means clustering 4, Average clustering time 0.081, Prec@1 88.428
Epoch 12, K-means clustering 0, Average clustering time 0.001, Prec@1 87.296
Epoch 12, K-means clustering 1, Average clustering time 0.042, Prec@1 87.673
Epoch 12, K-means clustering 2, Average clustering time 0.056, Prec@1 87.547
Epoch 12, K-means clustering 3, Average clustering time 0.065, Prec@1 87.673
Epoch 12, K-means clustering 4, Average clustering time 0.071, Prec@1 87.799
Train - epoch [9/200]	BT 1.549 (1.549)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.0211 (4.0211)
The penalty weight is 0.314021
Train - epoch [13/200]	BT 1.179 (1.179)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 6.3227 (6.3227)
Test on T training set - [9][0/45]	T 0.518 (0.518)	D 0.401 (0.401)	T@1 82.540 (82.540)	T@5 98.413 (98.413)	L 0.8338 (0.8338)
Test on T training set - [9][10/45]	T 0.333 (0.348)	D 0.209 (0.228)	T@1 26.984 (77.489)	T@5 58.730 (91.053)	L 2.8579 (0.9326)
Test on T training set - [9][20/45]	T 0.336 (0.340)	D 0.214 (0.220)	T@1 87.302 (74.528)	T@5 100.000 (89.191)	L 0.4598 (1.0627)
Test on T training set - [9][30/45]	T 0.326 (0.340)	D 0.207 (0.220)	T@1 71.429 (71.992)	T@5 93.651 (88.223)	L 1.1764 (1.1376)
Test on T training set - [9][40/45]	T 0.331 (0.340)	D 0.209 (0.220)	T@1 39.683 (67.480)	T@5 80.952 (84.514)	L 2.1051 (1.3388)
 * Test on T training set - Prec@1 65.034, Prec@5 83.990
Train - epoch [13/200]	BT 1.385 (1.385)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 6.4641 (6.4641)
Train - epoch [13/200]	BT 1.061 (1.061)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 6.3582 (6.3582)
Test on T test set - [9][0/45]	Time 0.551 (0.551)	Loss 0.8338 (0.8338)	Prec@1 82.540 (82.540)	Prec@5 98.413 (98.413)
Test on T test set - [9][10/45]	Time 0.582 (0.380)	Loss 2.8579 (0.9326)	Prec@1 26.984 (77.489)	Prec@5 58.730 (91.053)
Test on T test set - [9][20/45]	Time 0.320 (0.359)	Loss 0.4598 (1.0627)	Prec@1 87.302 (74.528)	Prec@5 100.000 (89.191)
Test on T test set - [9][30/45]	Time 0.340 (0.356)	Loss 1.1764 (1.1376)	Prec@1 71.429 (71.992)	Prec@5 93.651 (88.223)
Test on T test set - [9][40/45]	Time 0.356 (0.351)	Loss 2.1051 (1.3388)	Prec@1 39.683 (67.480)	Prec@5 80.952 (84.514)
 * Test on T test set - Prec@1 65.034, Prec@5 83.990
Epoch 9, K-means clustering 0, Average clustering time 0.027, Prec@1 72.843
Epoch 9, K-means clustering 1, Average clustering time 0.097, Prec@1 74.263
Epoch 9, K-means clustering 2, Average clustering time 0.100, Prec@1 74.441
Epoch 9, K-means clustering 3, Average clustering time 0.104, Prec@1 74.192
Epoch 9, K-means clustering 4, Average clustering time 0.105, Prec@1 73.979
Epoch 9, K-means clustering 0, Average clustering time 0.003, Prec@1 70.607
Epoch 9, K-means clustering 1, Average clustering time 0.073, Prec@1 71.494
Epoch 9, K-means clustering 2, Average clustering time 0.093, Prec@1 71.956
Epoch 9, K-means clustering 3, Average clustering time 0.091, Prec@1 72.169
Epoch 9, K-means clustering 4, Average clustering time 0.091, Prec@1 72.204
Train - epoch [13/200]	BT 1.154 (1.154)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 6.1236 (6.1236)
Train - epoch [13/200]	BT 1.187 (1.187)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 6.3663 (6.3663)
Train - epoch [10/200]	BT 1.935 (1.935)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.3429 (4.3429)
The penalty weight is 0.244919
Train - epoch [10/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.3401 (4.3401)
Train - epoch [13/200]	BT 1.421 (1.421)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 6.3917 (6.3917)
Train - epoch [10/200]	BT 1.473 (1.473)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.6941 (4.6941)
Train - epoch [10/200]	BT 1.457 (1.457)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.4242 (4.4242)
Test on T training set - [13][0/13]	T 0.720 (0.720)	D 0.604 (0.604)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1407 (0.1407)
Test on T training set - [13][10/13]	T 0.525 (0.525)	D 0.398 (0.404)	T@1 66.667 (83.405)	T@5 98.413 (96.537)	L 0.8741 (0.6501)
 * Test on T training set - Prec@1 82.516, Prec@5 96.478
Test on T test set - [13][0/13]	Time 0.753 (0.753)	Loss 0.1407 (0.1407)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [13][10/13]	Time 0.512 (0.553)	Loss 0.8741 (0.6501)	Prec@1 66.667 (83.405)	Prec@5 98.413 (96.537)
 * Test on T test set - Prec@1 82.516, Prec@5 96.478
Epoch 13, K-means clustering 0, Average clustering time 0.018, Prec@1 88.553
Epoch 13, K-means clustering 1, Average clustering time 0.086, Prec@1 88.679
Epoch 13, K-means clustering 2, Average clustering time 0.090, Prec@1 88.302
Epoch 13, K-means clustering 3, Average clustering time 0.091, Prec@1 88.176
Epoch 13, K-means clustering 4, Average clustering time 0.091, Prec@1 88.050
Epoch 13, K-means clustering 0, Average clustering time 0.001, Prec@1 88.050
Epoch 13, K-means clustering 1, Average clustering time 0.040, Prec@1 88.428
Epoch 13, K-means clustering 2, Average clustering time 0.052, Prec@1 87.799
Epoch 13, K-means clustering 3, Average clustering time 0.059, Prec@1 87.547
Epoch 13, K-means clustering 4, Average clustering time 0.061, Prec@1 87.547
Train - epoch [10/200]	BT 1.518 (1.518)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.5254 (4.5254)
The penalty weight is 0.336376
Train - epoch [14/200]	BT 1.161 (1.161)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 6.9560 (6.9560)
Train - epoch [14/200]	BT 1.320 (1.320)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 6.6127 (6.6127)
Train - epoch [10/200]	BT 1.475 (1.475)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 4.8591 (4.8591)
Train - epoch [10/200]	BT 1.493 (1.493)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.1096 (5.1096)
Train - epoch [14/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 6.0691 (6.0691)
Train - epoch [14/200]	BT 1.084 (1.084)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 6.3854 (6.3854)
Train - epoch [14/200]	BT 1.066 (1.066)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 6.7743 (6.7743)
Train - epoch [14/200]	BT 1.199 (1.199)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 6.4307 (6.4307)
Test on T training set - [10][0/45]	T 0.505 (0.505)	D 0.390 (0.390)	T@1 84.127 (84.127)	T@5 96.825 (96.825)	L 0.8038 (0.8038)
Test on T training set - [10][10/45]	T 0.338 (0.362)	D 0.226 (0.241)	T@1 30.159 (78.644)	T@5 63.492 (91.198)	L 2.7700 (0.8990)
Test on T training set - [10][20/45]	T 0.359 (0.352)	D 0.233 (0.231)	T@1 85.714 (74.981)	T@5 100.000 (89.720)	L 0.5396 (1.0409)
Test on T training set - [10][30/45]	T 0.323 (0.349)	D 0.208 (0.229)	T@1 74.603 (72.350)	T@5 95.238 (88.530)	L 1.0259 (1.1170)
Test on T training set - [10][40/45]	T 0.359 (0.354)	D 0.238 (0.234)	T@1 38.095 (67.441)	T@5 79.365 (84.514)	L 2.0814 (1.3270)
 * Test on T training set - Prec@1 65.140, Prec@5 84.026
Train - epoch [14/200]	BT 1.178 (1.178)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 6.6747 (6.6747)
Test on T test set - [10][0/45]	Time 0.543 (0.543)	Loss 0.8038 (0.8038)	Prec@1 84.127 (84.127)	Prec@5 96.825 (96.825)
Test on T test set - [10][10/45]	Time 0.320 (0.370)	Loss 2.7700 (0.8990)	Prec@1 30.159 (78.644)	Prec@5 63.492 (91.198)
Test on T test set - [10][20/45]	Time 0.340 (0.354)	Loss 0.5396 (1.0409)	Prec@1 85.714 (74.981)	Prec@5 100.000 (89.720)
Test on T test set - [10][30/45]	Time 0.353 (0.349)	Loss 1.0259 (1.1170)	Prec@1 74.603 (72.350)	Prec@5 95.238 (88.530)
Test on T test set - [10][40/45]	Time 0.339 (0.345)	Loss 2.0814 (1.3270)	Prec@1 38.095 (67.441)	Prec@5 79.365 (84.514)
 * Test on T test set - Prec@1 65.140, Prec@5 84.026
Epoch 10, K-means clustering 0, Average clustering time 0.029, Prec@1 72.666
Epoch 10, K-means clustering 1, Average clustering time 0.091, Prec@1 73.979
Epoch 10, K-means clustering 2, Average clustering time 0.102, Prec@1 74.299
Epoch 10, K-means clustering 3, Average clustering time 0.101, Prec@1 74.121
Epoch 10, K-means clustering 4, Average clustering time 0.104, Prec@1 73.873
Epoch 10, K-means clustering 0, Average clustering time 0.003, Prec@1 70.607
Epoch 10, K-means clustering 1, Average clustering time 0.071, Prec@1 71.991
Epoch 10, K-means clustering 2, Average clustering time 0.079, Prec@1 71.956
Epoch 10, K-means clustering 3, Average clustering time 0.087, Prec@1 72.133
Epoch 10, K-means clustering 4, Average clustering time 0.087, Prec@1 71.991
The penalty weight is 0.268271
Train - epoch [11/200]	BT 1.481 (1.481)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.3281 (5.3281)
Test on T training set - [14][0/13]	T 0.755 (0.755)	D 0.636 (0.636)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1486 (0.1486)
Test on T training set - [14][10/13]	T 0.534 (0.530)	D 0.417 (0.408)	T@1 68.254 (82.828)	T@5 100.000 (96.104)	L 0.8265 (0.6839)
 * Test on T training set - Prec@1 82.138, Prec@5 96.352
Test on T test set - [14][0/13]	Time 0.937 (0.937)	Loss 0.1486 (0.1486)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [14][10/13]	Time 0.495 (0.536)	Loss 0.8265 (0.6839)	Prec@1 68.254 (82.828)	Prec@5 100.000 (96.104)
 * Test on T test set - Prec@1 82.138, Prec@5 96.352
Epoch 14, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 14, K-means clustering 1, Average clustering time 0.078, Prec@1 89.308
Epoch 14, K-means clustering 2, Average clustering time 0.083, Prec@1 88.679
Epoch 14, K-means clustering 3, Average clustering time 0.086, Prec@1 88.679
Epoch 14, K-means clustering 4, Average clustering time 0.088, Prec@1 88.553
Epoch 14, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 14, K-means clustering 1, Average clustering time 0.044, Prec@1 89.308
Epoch 14, K-means clustering 2, Average clustering time 0.055, Prec@1 89.308
Epoch 14, K-means clustering 3, Average clustering time 0.063, Prec@1 88.805
Epoch 14, K-means clustering 4, Average clustering time 0.066, Prec@1 88.805
Train - epoch [11/200]	BT 1.462 (1.462)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.3775 (5.3775)
The penalty weight is 0.358357
Train - epoch [15/200]	BT 1.109 (1.109)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 6.7381 (6.7381)
Train - epoch [15/200]	BT 1.090 (1.090)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 7.2878 (7.2878)
Train - epoch [11/200]	BT 1.443 (1.443)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.4605 (5.4605)
Train - epoch [11/200]	BT 2.059 (2.059)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.2371 (5.2371)
Train - epoch [11/200]	BT 1.501 (1.501)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.5323 (5.5323)
Train - epoch [15/200]	BT 1.059 (1.059)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 7.5115 (7.5115)
Train - epoch [15/200]	BT 1.145 (1.145)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 6.7667 (6.7667)
Train - epoch [11/200]	BT 1.526 (1.526)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.4236 (5.4236)
Train - epoch [15/200]	BT 1.068 (1.068)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 7.1007 (7.1007)
Train - epoch [11/200]	BT 1.527 (1.527)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.4606 (5.4606)
Train - epoch [15/200]	BT 1.167 (1.167)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 7.3779 (7.3779)
Train - epoch [15/200]	BT 1.192 (1.192)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 6.8559 (6.8559)
Test on T training set - [15][0/13]	T 0.770 (0.770)	D 0.640 (0.640)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1077 (0.1077)
Test on T training set - [15][10/13]	T 0.523 (0.534)	D 0.401 (0.412)	T@1 66.667 (83.694)	T@5 98.413 (96.104)	L 0.9715 (0.6683)
 * Test on T training set - Prec@1 82.642, Prec@5 96.101
Test on T training set - [11][0/45]	T 0.507 (0.507)	D 0.384 (0.384)	T@1 79.365 (79.365)	T@5 96.825 (96.825)	L 0.8387 (0.8387)
Test on T training set - [11][10/45]	T 0.334 (0.346)	D 0.218 (0.225)	T@1 28.571 (77.056)	T@5 66.667 (91.631)	L 2.7358 (0.9139)
Test on T training set - [11][20/45]	T 0.370 (0.345)	D 0.247 (0.224)	T@1 84.127 (73.243)	T@5 100.000 (89.645)	L 0.5194 (1.0831)
Test on T training set - [11][30/45]	T 0.330 (0.343)	D 0.209 (0.223)	T@1 73.016 (71.377)	T@5 95.238 (88.735)	L 1.0716 (1.1374)
Test on T training set - [11][40/45]	T 0.344 (0.343)	D 0.222 (0.224)	T@1 36.508 (66.976)	T@5 80.952 (84.746)	L 2.0831 (1.3392)
 * Test on T training set - Prec@1 64.785, Prec@5 84.239
Test on T test set - [15][0/13]	Time 0.731 (0.731)	Loss 0.1077 (0.1077)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [15][10/13]	Time 0.530 (0.537)	Loss 0.9715 (0.6683)	Prec@1 66.667 (83.694)	Prec@5 98.413 (96.104)
 * Test on T test set - Prec@1 82.642, Prec@5 96.101
Epoch 15, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 15, K-means clustering 1, Average clustering time 0.083, Prec@1 88.679
Epoch 15, K-means clustering 2, Average clustering time 0.089, Prec@1 87.799
Epoch 15, K-means clustering 3, Average clustering time 0.090, Prec@1 87.799
Epoch 15, K-means clustering 4, Average clustering time 0.094, Prec@1 87.799
Epoch 15, K-means clustering 0, Average clustering time 0.001, Prec@1 87.799
Epoch 15, K-means clustering 1, Average clustering time 0.039, Prec@1 88.050
Epoch 15, K-means clustering 2, Average clustering time 0.051, Prec@1 87.799
Epoch 15, K-means clustering 3, Average clustering time 0.058, Prec@1 87.547
Epoch 15, K-means clustering 4, Average clustering time 0.066, Prec@1 87.421
Test on T test set - [11][0/45]	Time 0.503 (0.503)	Loss 0.8387 (0.8387)	Prec@1 79.365 (79.365)	Prec@5 96.825 (96.825)
Test on T test set - [11][10/45]	Time 0.328 (0.352)	Loss 2.7358 (0.9139)	Prec@1 28.571 (77.056)	Prec@5 66.667 (91.631)
Test on T test set - [11][20/45]	Time 0.327 (0.345)	Loss 0.5194 (1.0831)	Prec@1 84.127 (73.243)	Prec@5 100.000 (89.645)
Test on T test set - [11][30/45]	Time 0.322 (0.348)	Loss 1.0716 (1.1374)	Prec@1 73.016 (71.377)	Prec@5 95.238 (88.735)
Test on T test set - [11][40/45]	Time 0.399 (0.347)	Loss 2.0831 (1.3392)	Prec@1 36.508 (66.976)	Prec@5 80.952 (84.746)
 * Test on T test set - Prec@1 64.785, Prec@5 84.239
Epoch 11, K-means clustering 0, Average clustering time 0.027, Prec@1 72.772
Epoch 11, K-means clustering 1, Average clustering time 0.083, Prec@1 74.086
Epoch 11, K-means clustering 2, Average clustering time 0.111, Prec@1 74.547
Epoch 11, K-means clustering 3, Average clustering time 0.108, Prec@1 74.405
Epoch 11, K-means clustering 4, Average clustering time 0.105, Prec@1 74.192
Epoch 11, K-means clustering 0, Average clustering time 0.003, Prec@1 70.465
Epoch 11, K-means clustering 1, Average clustering time 0.038, Prec@1 71.636
Epoch 11, K-means clustering 2, Average clustering time 0.052, Prec@1 72.027
Epoch 11, K-means clustering 3, Average clustering time 0.059, Prec@1 72.204
Epoch 11, K-means clustering 4, Average clustering time 0.064, Prec@1 72.240
The penalty weight is 0.379949
Train - epoch [16/200]	BT 1.045 (1.045)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 7.3238 (7.3238)
The penalty weight is 0.291313
Train - epoch [12/200]	BT 1.522 (1.522)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.8166 (5.8166)
Train - epoch [16/200]	BT 1.678 (1.678)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 7.4109 (7.4109)
Train - epoch [16/200]	BT 1.132 (1.132)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.6239 (7.6239)
Train - epoch [12/200]	BT 1.440 (1.440)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.7417 (5.7417)
Train - epoch [12/200]	BT 1.475 (1.475)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.5669 (5.5669)
Train - epoch [16/200]	BT 1.092 (1.092)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 7.5510 (7.5510)
Train - epoch [16/200]	BT 1.042 (1.042)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 7.6179 (7.6179)
Train - epoch [16/200]	BT 1.170 (1.170)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 7.6087 (7.6087)
Train - epoch [12/200]	BT 1.551 (1.551)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.7681 (5.7681)
Train - epoch [12/200]	BT 1.512 (1.512)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.0238 (6.0238)
Test on T training set - [16][0/13]	T 0.733 (0.733)	D 0.604 (0.604)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1395 (0.1395)
Test on T training set - [16][10/13]	T 0.845 (0.564)	D 0.717 (0.444)	T@1 65.079 (82.973)	T@5 100.000 (96.392)	L 0.9385 (0.6733)
 * Test on T training set - Prec@1 82.264, Prec@5 96.604
Test on T test set - [16][0/13]	Time 1.115 (1.115)	Loss 0.1395 (0.1395)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [16][10/13]	Time 0.501 (0.581)	Loss 0.9385 (0.6733)	Prec@1 65.079 (82.973)	Prec@5 100.000 (96.392)
 * Test on T test set - Prec@1 82.264, Prec@5 96.604
Epoch 16, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 16, K-means clustering 1, Average clustering time 0.085, Prec@1 89.308
Epoch 16, K-means clustering 2, Average clustering time 0.091, Prec@1 88.679
Epoch 16, K-means clustering 3, Average clustering time 0.094, Prec@1 88.176
Epoch 16, K-means clustering 4, Average clustering time 0.095, Prec@1 88.176
Epoch 16, K-means clustering 0, Average clustering time 0.001, Prec@1 87.547
Epoch 16, K-means clustering 1, Average clustering time 0.045, Prec@1 88.302
Epoch 16, K-means clustering 2, Average clustering time 0.055, Prec@1 88.050
Epoch 16, K-means clustering 3, Average clustering time 0.061, Prec@1 87.799
Epoch 16, K-means clustering 4, Average clustering time 0.064, Prec@1 87.673
Train - epoch [12/200]	BT 1.640 (1.640)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.9336 (5.9336)
Train - epoch [12/200]	BT 1.864 (1.864)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.6945 (5.6945)
The penalty weight is 0.401134
Train - epoch [17/200]	BT 1.107 (1.107)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 7.8588 (7.8588)
Train - epoch [17/200]	BT 1.199 (1.199)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.5860 (7.5860)
Test on T training set - [12][0/45]	T 0.527 (0.527)	D 0.401 (0.401)	T@1 85.714 (85.714)	T@5 98.413 (98.413)	L 0.7655 (0.7655)
Test on T training set - [12][10/45]	T 0.327 (0.366)	D 0.206 (0.245)	T@1 28.571 (78.066)	T@5 66.667 (91.919)	L 2.7013 (0.9028)
Test on T training set - [12][20/45]	T 0.333 (0.353)	D 0.218 (0.232)	T@1 84.127 (75.359)	T@5 100.000 (90.401)	L 0.5892 (1.0314)
Test on T training set - [12][30/45]	T 0.486 (0.353)	D 0.374 (0.233)	T@1 76.190 (73.528)	T@5 95.238 (89.350)	L 1.0142 (1.0924)
Test on T training set - [12][40/45]	T 0.315 (0.350)	D 0.202 (0.230)	T@1 42.857 (69.144)	T@5 79.365 (85.250)	L 1.9908 (1.2979)
 * Test on T training set - Prec@1 66.631, Prec@5 84.665
Train - epoch [17/200]	BT 1.130 (1.130)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 8.1226 (8.1226)
Train - epoch [17/200]	BT 1.158 (1.158)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 8.2986 (8.2986)
Test on T test set - [12][0/45]	Time 0.535 (0.535)	Loss 0.7655 (0.7655)	Prec@1 85.714 (85.714)	Prec@5 98.413 (98.413)
Test on T test set - [12][10/45]	Time 0.335 (0.353)	Loss 2.7013 (0.9028)	Prec@1 28.571 (78.066)	Prec@5 66.667 (91.919)
Test on T test set - [12][20/45]	Time 0.331 (0.389)	Loss 0.5892 (1.0314)	Prec@1 84.127 (75.359)	Prec@5 100.000 (90.401)
Test on T test set - [12][30/45]	Time 0.329 (0.378)	Loss 1.0142 (1.0924)	Prec@1 76.190 (73.528)	Prec@5 95.238 (89.350)
Test on T test set - [12][40/45]	Time 0.349 (0.368)	Loss 1.9908 (1.2979)	Prec@1 42.857 (69.144)	Prec@5 79.365 (85.250)
 * Test on T test set - Prec@1 66.631, Prec@5 84.665
Epoch 12, K-means clustering 0, Average clustering time 0.028, Prec@1 72.985
Epoch 12, K-means clustering 1, Average clustering time 0.102, Prec@1 74.370
Epoch 12, K-means clustering 2, Average clustering time 0.107, Prec@1 74.192
Epoch 12, K-means clustering 3, Average clustering time 0.111, Prec@1 73.944
Epoch 12, K-means clustering 4, Average clustering time 0.110, Prec@1 73.908
Epoch 12, K-means clustering 0, Average clustering time 0.003, Prec@1 71.424
Epoch 12, K-means clustering 1, Average clustering time 0.044, Prec@1 72.027
Epoch 12, K-means clustering 2, Average clustering time 0.060, Prec@1 72.595
Epoch 12, K-means clustering 3, Average clustering time 0.074, Prec@1 72.417
Epoch 12, K-means clustering 4, Average clustering time 0.078, Prec@1 72.559
Train - epoch [17/200]	BT 1.925 (1.925)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 7.8697 (7.8697)
Train - epoch [17/200]	BT 1.242 (1.242)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 8.0588 (8.0588)
The penalty weight is 0.314021
Train - epoch [13/200]	BT 1.538 (1.538)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.0687 (6.0687)
Train - epoch [17/200]	BT 1.236 (1.236)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 8.1403 (8.1403)
Train - epoch [13/200]	BT 1.498 (1.498)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.9267 (5.9267)
Train - epoch [13/200]	BT 1.526 (1.526)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.2600 (6.2600)
Test on T training set - [17][0/13]	T 0.750 (0.750)	D 0.612 (0.612)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1195 (0.1195)
Test on T training set - [17][10/13]	T 0.504 (0.521)	D 0.389 (0.397)	T@1 65.079 (82.684)	T@5 100.000 (96.392)	L 0.9232 (0.6589)
 * Test on T training set - Prec@1 82.264, Prec@5 96.478
Test on T test set - [17][0/13]	Time 0.752 (0.752)	Loss 0.1195 (0.1195)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [17][10/13]	Time 0.533 (0.546)	Loss 0.9232 (0.6589)	Prec@1 65.079 (82.684)	Prec@5 100.000 (96.392)
 * Test on T test set - Prec@1 82.264, Prec@5 96.478
Epoch 17, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 17, K-means clustering 1, Average clustering time 0.085, Prec@1 88.553
Epoch 17, K-means clustering 2, Average clustering time 0.093, Prec@1 88.176
Epoch 17, K-means clustering 3, Average clustering time 0.092, Prec@1 87.925
Epoch 17, K-means clustering 4, Average clustering time 0.093, Prec@1 87.925
Epoch 17, K-means clustering 0, Average clustering time 0.001, Prec@1 87.421
Epoch 17, K-means clustering 1, Average clustering time 0.039, Prec@1 88.176
Epoch 17, K-means clustering 2, Average clustering time 0.053, Prec@1 87.547
Epoch 17, K-means clustering 3, Average clustering time 0.058, Prec@1 87.296
Epoch 17, K-means clustering 4, Average clustering time 0.062, Prec@1 87.296
Train - epoch [13/200]	BT 1.510 (1.510)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.2834 (6.2834)
Train - epoch [13/200]	BT 1.489 (1.489)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 5.4447 (5.4447)
The penalty weight is 0.421899
Train - epoch [18/200]	BT 1.197 (1.197)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 8.3900 (8.3900)
Train - epoch [18/200]	BT 1.101 (1.101)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 8.3666 (8.3666)
Train - epoch [13/200]	BT 1.414 (1.414)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.1383 (6.1383)
Train - epoch [18/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 8.3225 (8.3225)
Train - epoch [18/200]	BT 1.113 (1.113)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 8.4615 (8.4615)
Train - epoch [18/200]	BT 1.164 (1.164)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 8.5261 (8.5261)
Test on T training set - [13][0/45]	T 0.513 (0.513)	D 0.398 (0.398)	T@1 84.127 (84.127)	T@5 98.413 (98.413)	L 0.7404 (0.7404)
Test on T training set - [13][10/45]	T 0.325 (0.350)	D 0.213 (0.231)	T@1 25.397 (77.633)	T@5 63.492 (91.342)	L 2.7105 (0.8951)
Test on T training set - [13][20/45]	T 0.339 (0.351)	D 0.227 (0.233)	T@1 85.714 (74.906)	T@5 100.000 (89.872)	L 0.5428 (1.0435)
Test on T training set - [13][30/45]	T 0.371 (0.359)	D 0.245 (0.240)	T@1 73.016 (72.555)	T@5 92.063 (88.684)	L 1.1558 (1.1087)
Test on T training set - [13][40/45]	T 0.324 (0.354)	D 0.203 (0.234)	T@1 39.683 (68.099)	T@5 80.952 (84.785)	L 2.0605 (1.3108)
 * Test on T training set - Prec@1 65.779, Prec@5 84.274
Train - epoch [18/200]	BT 1.719 (1.719)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 8.6757 (8.6757)
Train - epoch [18/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 8.1279 (8.1279)
Test on T test set - [13][0/45]	Time 0.511 (0.511)	Loss 0.7404 (0.7404)	Prec@1 84.127 (84.127)	Prec@5 98.413 (98.413)
Test on T test set - [13][10/45]	Time 0.322 (0.346)	Loss 2.7105 (0.8951)	Prec@1 25.397 (77.633)	Prec@5 63.492 (91.342)
Test on T test set - [13][20/45]	Time 0.337 (0.343)	Loss 0.5428 (1.0435)	Prec@1 85.714 (74.906)	Prec@5 100.000 (89.872)
Test on T test set - [13][30/45]	Time 0.348 (0.340)	Loss 1.1558 (1.1087)	Prec@1 73.016 (72.555)	Prec@5 92.063 (88.684)
Test on T test set - [13][40/45]	Time 0.324 (0.344)	Loss 2.0605 (1.3108)	Prec@1 39.683 (68.099)	Prec@5 80.952 (84.785)
 * Test on T test set - Prec@1 65.779, Prec@5 84.274
Epoch 13, K-means clustering 0, Average clustering time 0.027, Prec@1 72.843
Epoch 13, K-means clustering 1, Average clustering time 0.093, Prec@1 74.228
Epoch 13, K-means clustering 2, Average clustering time 0.101, Prec@1 74.334
Epoch 13, K-means clustering 3, Average clustering time 0.105, Prec@1 74.263
Epoch 13, K-means clustering 4, Average clustering time 0.107, Prec@1 73.908
Epoch 13, K-means clustering 0, Average clustering time 0.003, Prec@1 70.962
Epoch 13, K-means clustering 1, Average clustering time 0.046, Prec@1 71.991
Epoch 13, K-means clustering 2, Average clustering time 0.061, Prec@1 72.240
Epoch 13, K-means clustering 3, Average clustering time 0.070, Prec@1 72.453
Epoch 13, K-means clustering 4, Average clustering time 0.077, Prec@1 72.417
The penalty weight is 0.336376
Train - epoch [14/200]	BT 1.493 (1.493)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.4003 (6.4003)
Test on T training set - [18][0/13]	T 0.754 (0.754)	D 0.628 (0.628)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1150 (0.1150)
Test on T training set - [18][10/13]	T 0.513 (0.525)	D 0.386 (0.404)	T@1 68.254 (82.973)	T@5 98.413 (96.537)	L 0.8764 (0.6562)
 * Test on T training set - Prec@1 82.642, Prec@5 96.604
Test on T test set - [18][0/13]	Time 0.741 (0.741)	Loss 0.1150 (0.1150)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [18][10/13]	Time 0.535 (0.527)	Loss 0.8764 (0.6562)	Prec@1 68.254 (82.973)	Prec@5 98.413 (96.537)
 * Test on T test set - Prec@1 82.642, Prec@5 96.604
Epoch 18, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 18, K-means clustering 1, Average clustering time 0.082, Prec@1 88.302
Epoch 18, K-means clustering 2, Average clustering time 0.086, Prec@1 87.925
Epoch 18, K-means clustering 3, Average clustering time 0.088, Prec@1 87.925
Epoch 18, K-means clustering 4, Average clustering time 0.110, Prec@1 87.925
Epoch 18, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 18, K-means clustering 1, Average clustering time 0.037, Prec@1 88.931
Epoch 18, K-means clustering 2, Average clustering time 0.050, Prec@1 87.799
Epoch 18, K-means clustering 3, Average clustering time 0.058, Prec@1 87.547
Epoch 18, K-means clustering 4, Average clustering time 0.060, Prec@1 87.547
Train - epoch [14/200]	BT 1.421 (1.421)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.5310 (6.5310)
The penalty weight is 0.442230
Train - epoch [19/200]	BT 1.164 (1.164)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 8.6983 (8.6983)
Train - epoch [19/200]	BT 1.095 (1.095)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 8.5626 (8.5626)
Train - epoch [14/200]	BT 2.032 (2.032)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.5371 (6.5371)
Train - epoch [14/200]	BT 1.015 (1.015)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.5015 (6.5015)
Train - epoch [14/200]	BT 1.543 (1.543)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.7199 (6.7199)
Train - epoch [19/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 9.1273 (9.1273)
Train - epoch [14/200]	BT 1.573 (1.573)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.5919 (6.5919)
Train - epoch [19/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 8.1015 (8.1015)
Train - epoch [19/200]	BT 1.195 (1.195)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 8.9168 (8.9168)
Train - epoch [14/200]	BT 1.477 (1.477)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.7629 (6.7629)
Train - epoch [19/200]	BT 1.215 (1.215)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 8.7031 (8.7031)
Test on T training set - [19][0/13]	T 0.798 (0.798)	D 0.672 (0.672)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1176 (0.1176)
Test on T training set - [19][10/13]	T 0.520 (0.528)	D 0.390 (0.404)	T@1 65.079 (83.550)	T@5 98.413 (96.537)	L 0.9403 (0.6525)
 * Test on T training set - Prec@1 83.019, Prec@5 96.730
Test on T training set - [14][0/45]	T 0.505 (0.505)	D 0.381 (0.381)	T@1 85.714 (85.714)	T@5 98.413 (98.413)	L 0.7120 (0.7120)
Test on T training set - [14][10/45]	T 0.329 (0.364)	D 0.208 (0.243)	T@1 28.571 (78.932)	T@5 63.492 (91.775)	L 2.6714 (0.8759)
Test on T training set - [14][20/45]	T 0.334 (0.350)	D 0.221 (0.230)	T@1 87.302 (75.661)	T@5 100.000 (90.325)	L 0.5393 (1.0248)
Test on T training set - [14][30/45]	T 0.324 (0.346)	D 0.206 (0.227)	T@1 73.016 (73.272)	T@5 95.238 (89.401)	L 1.0494 (1.0991)
Test on T training set - [14][40/45]	T 0.327 (0.343)	D 0.215 (0.223)	T@1 38.095 (68.757)	T@5 80.952 (85.250)	L 2.0442 (1.3053)
 * Test on T training set - Prec@1 66.489, Prec@5 84.665
Test on T test set - [19][0/13]	Time 0.733 (0.733)	Loss 0.1176 (0.1176)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [19][10/13]	Time 0.520 (0.520)	Loss 0.9403 (0.6525)	Prec@1 65.079 (83.550)	Prec@5 98.413 (96.537)
 * Test on T test set - Prec@1 83.019, Prec@5 96.730
Epoch 19, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 19, K-means clustering 1, Average clustering time 0.081, Prec@1 89.308
Epoch 19, K-means clustering 2, Average clustering time 0.090, Prec@1 88.679
Epoch 19, K-means clustering 3, Average clustering time 0.090, Prec@1 88.553
Epoch 19, K-means clustering 4, Average clustering time 0.090, Prec@1 88.679
Epoch 19, K-means clustering 0, Average clustering time 0.001, Prec@1 88.176
Epoch 19, K-means clustering 1, Average clustering time 0.038, Prec@1 88.302
Epoch 19, K-means clustering 2, Average clustering time 0.051, Prec@1 87.673
Epoch 19, K-means clustering 3, Average clustering time 0.058, Prec@1 87.673
Epoch 19, K-means clustering 4, Average clustering time 0.066, Prec@1 87.673
Test on T test set - [14][0/45]	Time 0.504 (0.504)	Loss 0.7120 (0.7120)	Prec@1 85.714 (85.714)	Prec@5 98.413 (98.413)
Test on T test set - [14][10/45]	Time 0.329 (0.340)	Loss 2.6714 (0.8759)	Prec@1 28.571 (78.932)	Prec@5 63.492 (91.775)
Test on T test set - [14][20/45]	Time 0.312 (0.335)	Loss 0.5393 (1.0248)	Prec@1 87.302 (75.661)	Prec@5 100.000 (90.325)
Test on T test set - [14][30/45]	Time 0.333 (0.352)	Loss 1.0494 (1.0991)	Prec@1 73.016 (73.272)	Prec@5 95.238 (89.401)
Test on T test set - [14][40/45]	Time 0.345 (0.348)	Loss 2.0442 (1.3053)	Prec@1 38.095 (68.757)	Prec@5 80.952 (85.250)
 * Test on T test set - Prec@1 66.489, Prec@5 84.665
Epoch 14, K-means clustering 0, Average clustering time 0.027, Prec@1 73.163
Epoch 14, K-means clustering 1, Average clustering time 0.095, Prec@1 74.121
Epoch 14, K-means clustering 2, Average clustering time 0.096, Prec@1 74.334
Epoch 14, K-means clustering 3, Average clustering time 0.099, Prec@1 74.228
Epoch 14, K-means clustering 4, Average clustering time 0.102, Prec@1 74.050
Epoch 14, K-means clustering 0, Average clustering time 0.003, Prec@1 71.317
Epoch 14, K-means clustering 1, Average clustering time 0.043, Prec@1 72.098
Epoch 14, K-means clustering 2, Average clustering time 0.067, Prec@1 72.311
Epoch 14, K-means clustering 3, Average clustering time 0.075, Prec@1 72.382
Epoch 14, K-means clustering 4, Average clustering time 0.076, Prec@1 72.453
Train - epoch [20/200]	BT 1.006 (1.006)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 8.9574 (8.9574)
The penalty weight is 0.462117
Train - epoch [20/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 8.7048 (8.7048)
The penalty weight is 0.358357
Train - epoch [15/200]	BT 1.564 (1.564)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.8143 (6.8143)
Train - epoch [20/200]	BT 1.075 (1.075)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 8.3112 (8.3112)
Train - epoch [20/200]	BT 1.131 (1.131)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 8.8303 (8.8303)
Train - epoch [15/200]	BT 1.474 (1.474)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.7076 (6.7076)
Train - epoch [15/200]	BT 1.582 (1.582)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.3933 (7.3933)
Train - epoch [20/200]	BT 1.128 (1.128)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 9.3293 (9.3293)
Train - epoch [20/200]	BT 1.121 (1.121)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.9188 (8.9188)
Train - epoch [20/200]	BT 1.116 (1.116)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 9.1486 (9.1486)
Train - epoch [15/200]	BT 1.480 (1.480)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.0641 (7.0641)
Train - epoch [15/200]	BT 1.507 (1.507)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.7554 (6.7554)
Test on T training set - [20][0/13]	T 0.755 (0.755)	D 0.624 (0.624)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1298 (0.1298)
Test on T training set - [20][10/13]	T 0.542 (0.531)	D 0.414 (0.409)	T@1 68.254 (83.983)	T@5 98.413 (97.114)	L 0.9009 (0.6438)
 * Test on T training set - Prec@1 83.396, Prec@5 96.981
Test on T test set - [20][0/13]	Time 0.727 (0.727)	Loss 0.1298 (0.1298)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [20][10/13]	Time 0.662 (0.560)	Loss 0.9009 (0.6438)	Prec@1 68.254 (83.983)	Prec@5 98.413 (97.114)
 * Test on T test set - Prec@1 83.396, Prec@5 96.981
Epoch 20, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 20, K-means clustering 1, Average clustering time 0.076, Prec@1 88.176
Epoch 20, K-means clustering 2, Average clustering time 0.086, Prec@1 88.176
Epoch 20, K-means clustering 3, Average clustering time 0.086, Prec@1 88.176
Epoch 20, K-means clustering 4, Average clustering time 0.086, Prec@1 88.176
Epoch 20, K-means clustering 0, Average clustering time 0.001, Prec@1 87.799
Epoch 20, K-means clustering 1, Average clustering time 0.035, Prec@1 87.925
Epoch 20, K-means clustering 2, Average clustering time 0.047, Prec@1 87.547
Epoch 20, K-means clustering 3, Average clustering time 0.056, Prec@1 87.421
Epoch 20, K-means clustering 4, Average clustering time 0.060, Prec@1 87.296
Train - epoch [15/200]	BT 2.072 (2.072)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.2713 (7.2713)
Train - epoch [15/200]	BT 1.245 (1.245)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.2447 (7.2447)
The penalty weight is 0.481550
Train - epoch [21/200]	BT 1.158 (1.158)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 9.5052 (9.5052)
Train - epoch [21/200]	BT 1.136 (1.136)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 8.4764 (8.4764)
Test on T training set - [15][0/45]	T 0.553 (0.553)	D 0.430 (0.430)	T@1 82.540 (82.540)	T@5 96.825 (96.825)	L 0.9064 (0.9064)
Test on T training set - [15][10/45]	T 0.327 (0.364)	D 0.214 (0.243)	T@1 26.984 (77.056)	T@5 63.492 (91.342)	L 2.6856 (0.9345)
Test on T training set - [15][20/45]	T 0.339 (0.353)	D 0.217 (0.233)	T@1 87.302 (74.376)	T@5 100.000 (89.494)	L 0.5151 (1.0684)
Test on T training set - [15][30/45]	T 0.322 (0.349)	D 0.207 (0.229)	T@1 74.603 (72.709)	T@5 93.651 (88.838)	L 1.1686 (1.1254)
Test on T training set - [15][40/45]	T 0.324 (0.353)	D 0.204 (0.232)	T@1 38.095 (67.983)	T@5 80.952 (84.863)	L 2.0173 (1.3281)
 * Test on T training set - Prec@1 65.602, Prec@5 84.239
Train - epoch [21/200]	BT 1.132 (1.132)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 9.2350 (9.2350)
Train - epoch [21/200]	BT 1.313 (1.313)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 9.5085 (9.5085)
Test on T test set - [15][0/45]	Time 0.574 (0.574)	Loss 0.9064 (0.9064)	Prec@1 82.540 (82.540)	Prec@5 96.825 (96.825)
Test on T test set - [15][10/45]	Time 0.329 (0.352)	Loss 2.6856 (0.9345)	Prec@1 26.984 (77.056)	Prec@5 63.492 (91.342)
Test on T test set - [15][20/45]	Time 0.325 (0.346)	Loss 0.5151 (1.0684)	Prec@1 87.302 (74.376)	Prec@5 100.000 (89.494)
Test on T test set - [15][30/45]	Time 0.356 (0.344)	Loss 1.1686 (1.1254)	Prec@1 74.603 (72.709)	Prec@5 93.651 (88.838)
Test on T test set - [15][40/45]	Time 0.338 (0.344)	Loss 2.0173 (1.3281)	Prec@1 38.095 (67.983)	Prec@5 80.952 (84.863)
 * Test on T test set - Prec@1 65.602, Prec@5 84.239
Epoch 15, K-means clustering 0, Average clustering time 0.027, Prec@1 73.305
Epoch 15, K-means clustering 1, Average clustering time 0.093, Prec@1 74.299
Epoch 15, K-means clustering 2, Average clustering time 0.098, Prec@1 74.583
Epoch 15, K-means clustering 3, Average clustering time 0.096, Prec@1 74.441
Epoch 15, K-means clustering 4, Average clustering time 0.117, Prec@1 74.370
Epoch 15, K-means clustering 0, Average clustering time 0.009, Prec@1 70.962
Epoch 15, K-means clustering 1, Average clustering time 0.051, Prec@1 71.885
Epoch 15, K-means clustering 2, Average clustering time 0.065, Prec@1 72.098
Epoch 15, K-means clustering 3, Average clustering time 0.079, Prec@1 72.346
Epoch 15, K-means clustering 4, Average clustering time 0.082, Prec@1 72.275
Train - epoch [21/200]	BT 1.144 (1.144)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 9.7311 (9.7311)
Train - epoch [21/200]	BT 1.141 (1.141)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 9.0887 (9.0887)
The penalty weight is 0.379949
Train - epoch [16/200]	BT 1.558 (1.558)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.6622 (7.6622)
Train - epoch [21/200]	BT 1.323 (1.323)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 8.6408 (8.6408)
Train - epoch [16/200]	BT 1.542 (1.542)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.6123 (7.6123)
Train - epoch [16/200]	BT 1.509 (1.509)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.3575 (7.3575)
Test on T training set - [21][0/13]	T 0.742 (0.742)	D 0.624 (0.624)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1395 (0.1395)
Test on T training set - [21][10/13]	T 0.519 (0.521)	D 0.403 (0.401)	T@1 65.079 (83.983)	T@5 98.413 (96.681)	L 0.9760 (0.6532)
 * Test on T training set - Prec@1 83.270, Prec@5 96.604
Test on T test set - [21][0/13]	Time 0.751 (0.751)	Loss 0.1395 (0.1395)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [21][10/13]	Time 0.522 (0.524)	Loss 0.9760 (0.6532)	Prec@1 65.079 (83.983)	Prec@5 98.413 (96.681)
 * Test on T test set - Prec@1 83.270, Prec@5 96.604
Epoch 21, K-means clustering 0, Average clustering time 0.018, Prec@1 88.302
Epoch 21, K-means clustering 1, Average clustering time 0.082, Prec@1 88.176
Epoch 21, K-means clustering 2, Average clustering time 0.085, Prec@1 87.925
Epoch 21, K-means clustering 3, Average clustering time 0.092, Prec@1 88.050
Epoch 21, K-means clustering 4, Average clustering time 0.092, Prec@1 88.176
Epoch 21, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 21, K-means clustering 1, Average clustering time 0.039, Prec@1 88.553
Epoch 21, K-means clustering 2, Average clustering time 0.050, Prec@1 88.302
Epoch 21, K-means clustering 3, Average clustering time 0.056, Prec@1 87.799
Epoch 21, K-means clustering 4, Average clustering time 0.061, Prec@1 87.673
Train - epoch [16/200]	BT 1.494 (1.494)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.1686 (7.1686)
The penalty weight is 0.500520
Train - epoch [22/200]	BT 1.146 (1.146)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 9.5147 (9.5147)
Train - epoch [22/200]	BT 1.132 (1.132)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.9009 (9.9009)
Train - epoch [16/200]	BT 1.503 (1.503)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 6.9958 (6.9958)
Train - epoch [16/200]	BT 1.527 (1.527)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.7564 (7.7564)
Train - epoch [22/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 9.3139 (9.3139)
Train - epoch [22/200]	BT 1.759 (1.759)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 9.4463 (9.4463)
Train - epoch [22/200]	BT 1.160 (1.160)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 10.1829 (10.1829)
Test on T training set - [16][0/45]	T 0.545 (0.545)	D 0.422 (0.422)	T@1 84.127 (84.127)	T@5 98.413 (98.413)	L 0.7693 (0.7693)
Test on T training set - [16][10/45]	T 0.336 (0.354)	D 0.218 (0.234)	T@1 26.984 (79.076)	T@5 58.730 (91.053)	L 2.7535 (0.8911)
Test on T training set - [16][20/45]	T 0.325 (0.345)	D 0.203 (0.225)	T@1 88.889 (74.754)	T@5 100.000 (89.191)	L 0.5182 (1.0542)
Test on T training set - [16][30/45]	T 0.330 (0.345)	D 0.213 (0.226)	T@1 71.429 (72.555)	T@5 93.651 (88.582)	L 1.1119 (1.1161)
Test on T training set - [16][40/45]	T 0.395 (0.344)	D 0.277 (0.225)	T@1 41.270 (68.099)	T@5 80.952 (84.630)	L 2.0959 (1.3259)
 * Test on T training set - Prec@1 65.566, Prec@5 84.061
Train - epoch [22/200]	BT 1.185 (1.185)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 9.6015 (9.6015)
Train - epoch [22/200]	BT 0.950 (0.950)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.2051 (9.2051)
Test on T test set - [16][0/45]	Time 0.507 (0.507)	Loss 0.7693 (0.7693)	Prec@1 84.127 (84.127)	Prec@5 98.413 (98.413)
Test on T test set - [16][10/45]	Time 0.321 (0.352)	Loss 2.7535 (0.8911)	Prec@1 26.984 (79.076)	Prec@5 58.730 (91.053)
Test on T test set - [16][20/45]	Time 0.330 (0.346)	Loss 0.5182 (1.0542)	Prec@1 88.889 (74.754)	Prec@5 100.000 (89.191)
Test on T test set - [16][30/45]	Time 0.350 (0.343)	Loss 1.1119 (1.1161)	Prec@1 71.429 (72.555)	Prec@5 93.651 (88.582)
Test on T test set - [16][40/45]	Time 0.574 (0.348)	Loss 2.0959 (1.3259)	Prec@1 41.270 (68.099)	Prec@5 80.952 (84.630)
 * Test on T test set - Prec@1 65.566, Prec@5 84.061
Epoch 16, K-means clustering 0, Average clustering time 0.030, Prec@1 72.630
Epoch 16, K-means clustering 1, Average clustering time 0.094, Prec@1 73.802
Epoch 16, K-means clustering 2, Average clustering time 0.104, Prec@1 73.837
Epoch 16, K-means clustering 3, Average clustering time 0.101, Prec@1 73.589
Epoch 16, K-means clustering 4, Average clustering time 0.100, Prec@1 73.447
Epoch 16, K-means clustering 0, Average clustering time 0.003, Prec@1 70.501
Epoch 16, K-means clustering 1, Average clustering time 0.041, Prec@1 72.169
Epoch 16, K-means clustering 2, Average clustering time 0.056, Prec@1 72.595
Epoch 16, K-means clustering 3, Average clustering time 0.067, Prec@1 72.701
Epoch 16, K-means clustering 4, Average clustering time 0.070, Prec@1 72.453
Test on T training set - [22][0/13]	T 0.746 (0.746)	D 0.621 (0.621)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1076 (0.1076)
Test on T training set - [22][10/13]	T 0.526 (0.565)	D 0.398 (0.443)	T@1 65.079 (83.694)	T@5 98.413 (96.681)	L 0.9420 (0.6465)
 * Test on T training set - Prec@1 83.396, Prec@5 96.855
The penalty weight is 0.401134
Train - epoch [17/200]	BT 1.457 (1.457)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.0170 (8.0170)
Test on T test set - [22][0/13]	Time 0.737 (0.737)	Loss 0.1076 (0.1076)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [22][10/13]	Time 0.617 (0.554)	Loss 0.9420 (0.6465)	Prec@1 65.079 (83.694)	Prec@5 98.413 (96.681)
 * Test on T test set - Prec@1 83.396, Prec@5 96.855
Epoch 22, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 22, K-means clustering 1, Average clustering time 0.078, Prec@1 88.805
Epoch 22, K-means clustering 2, Average clustering time 0.120, Prec@1 88.050
Epoch 22, K-means clustering 3, Average clustering time 0.110, Prec@1 87.925
Epoch 22, K-means clustering 4, Average clustering time 0.110, Prec@1 88.050
Epoch 22, K-means clustering 0, Average clustering time 0.001, Prec@1 88.176
Epoch 22, K-means clustering 1, Average clustering time 0.053, Prec@1 88.679
Epoch 22, K-means clustering 2, Average clustering time 0.101, Prec@1 88.050
Epoch 22, K-means clustering 3, Average clustering time 0.093, Prec@1 87.925
Epoch 22, K-means clustering 4, Average clustering time 0.090, Prec@1 87.799
Train - epoch [17/200]	BT 2.079 (2.079)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.7872 (7.7872)
Train - epoch [17/200]	BT 1.426 (1.426)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.9894 (7.9894)
The penalty weight is 0.519022
Train - epoch [23/200]	BT 1.151 (1.151)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 9.9833 (9.9833)
Train - epoch [17/200]	BT 1.507 (1.507)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.7658 (7.7658)
Train - epoch [23/200]	BT 1.083 (1.083)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 10.1597 (10.1597)
Train - epoch [23/200]	BT 1.149 (1.149)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 10.4831 (10.4831)
Train - epoch [17/200]	BT 1.482 (1.482)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.1467 (8.1467)
Train - epoch [17/200]	BT 1.617 (1.617)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.0853 (8.0853)
Train - epoch [23/200]	BT 1.092 (1.092)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 9.9646 (9.9646)
Train - epoch [23/200]	BT 1.464 (1.464)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 10.4343 (10.4343)
Train - epoch [17/200]	BT 1.444 (1.444)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.9454 (7.9454)
Train - epoch [23/200]	BT 1.191 (1.191)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 10.7500 (10.7500)
Test on T training set - [23][0/13]	T 1.032 (1.032)	D 0.895 (0.895)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1218 (0.1218)
Test on T training set - [23][10/13]	T 0.524 (0.563)	D 0.396 (0.439)	T@1 65.079 (84.271)	T@5 98.413 (97.114)	L 1.0021 (0.6445)
 * Test on T training set - Prec@1 83.774, Prec@5 97.233
Test on T training set - [17][0/45]	T 0.570 (0.570)	D 0.446 (0.446)	T@1 85.714 (85.714)	T@5 98.413 (98.413)	L 0.7450 (0.7450)
Test on T training set - [17][10/45]	T 0.312 (0.346)	D 0.200 (0.228)	T@1 28.571 (78.499)	T@5 58.730 (90.765)	L 2.7553 (0.9258)
Test on T training set - [17][20/45]	T 0.337 (0.356)	D 0.224 (0.237)	T@1 87.302 (75.888)	T@5 100.000 (89.796)	L 0.5169 (1.0457)
Test on T training set - [17][30/45]	T 0.333 (0.349)	D 0.209 (0.230)	T@1 74.603 (73.989)	T@5 95.238 (89.196)	L 1.0586 (1.0968)
Test on T training set - [17][40/45]	T 0.334 (0.346)	D 0.213 (0.227)	T@1 38.095 (69.222)	T@5 79.365 (85.288)	L 2.1629 (1.3008)
 * Test on T training set - Prec@1 66.915, Prec@5 84.558
Test on T test set - [23][0/13]	Time 0.731 (0.731)	Loss 0.1218 (0.1218)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [23][10/13]	Time 0.533 (0.566)	Loss 1.0021 (0.6445)	Prec@1 65.079 (84.271)	Prec@5 98.413 (97.114)
 * Test on T test set - Prec@1 83.774, Prec@5 97.233
Epoch 23, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 23, K-means clustering 1, Average clustering time 0.085, Prec@1 88.428
Epoch 23, K-means clustering 2, Average clustering time 0.094, Prec@1 88.050
Epoch 23, K-means clustering 3, Average clustering time 0.093, Prec@1 88.050
Epoch 23, K-means clustering 4, Average clustering time 0.095, Prec@1 88.050
Epoch 23, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 23, K-means clustering 1, Average clustering time 0.038, Prec@1 88.679
Epoch 23, K-means clustering 2, Average clustering time 0.051, Prec@1 88.176
Epoch 23, K-means clustering 3, Average clustering time 0.063, Prec@1 88.050
Epoch 23, K-means clustering 4, Average clustering time 0.067, Prec@1 88.050
Test on T test set - [17][0/45]	Time 0.906 (0.906)	Loss 0.7450 (0.7450)	Prec@1 85.714 (85.714)	Prec@5 98.413 (98.413)
Test on T test set - [17][10/45]	Time 0.321 (0.384)	Loss 2.7553 (0.9258)	Prec@1 28.571 (78.499)	Prec@5 58.730 (90.765)
Test on T test set - [17][20/45]	Time 0.324 (0.385)	Loss 0.5169 (1.0457)	Prec@1 87.302 (75.888)	Prec@5 100.000 (89.796)
Test on T test set - [17][30/45]	Time 0.329 (0.371)	Loss 1.0586 (1.0968)	Prec@1 74.603 (73.989)	Prec@5 95.238 (89.196)
Test on T test set - [17][40/45]	Time 0.327 (0.362)	Loss 2.1629 (1.3008)	Prec@1 38.095 (69.222)	Prec@5 79.365 (85.288)
 * Test on T test set - Prec@1 66.915, Prec@5 84.558
Epoch 17, K-means clustering 0, Average clustering time 0.027, Prec@1 73.731
Epoch 17, K-means clustering 1, Average clustering time 0.101, Prec@1 74.476
Epoch 17, K-means clustering 2, Average clustering time 0.107, Prec@1 74.547
Epoch 17, K-means clustering 3, Average clustering time 0.111, Prec@1 74.370
Epoch 17, K-means clustering 4, Average clustering time 0.110, Prec@1 74.263
Epoch 17, K-means clustering 0, Average clustering time 0.003, Prec@1 71.707
Epoch 17, K-means clustering 1, Average clustering time 0.050, Prec@1 72.133
Epoch 17, K-means clustering 2, Average clustering time 0.064, Prec@1 72.382
Epoch 17, K-means clustering 3, Average clustering time 0.071, Prec@1 72.382
Epoch 17, K-means clustering 4, Average clustering time 0.074, Prec@1 72.524
The penalty weight is 0.537050
Train - epoch [24/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 9.8384 (9.8384)
Train - epoch [24/200]	BT 1.130 (1.130)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 10.9692 (10.9692)
The penalty weight is 0.421899
Train - epoch [18/200]	BT 1.545 (1.545)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.0839 (8.0839)
Train - epoch [24/200]	BT 1.159 (1.159)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 10.8805 (10.8805)
Train - epoch [24/200]	BT 1.083 (1.083)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 10.7236 (10.7236)
Train - epoch [18/200]	BT 1.521 (1.521)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.5420 (8.5420)
Train - epoch [24/200]	BT 1.136 (1.136)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 10.7881 (10.7881)
Train - epoch [24/200]	BT 1.117 (1.117)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 10.5075 (10.5075)
Train - epoch [18/200]	BT 1.606 (1.606)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.2199 (8.2199)
Train - epoch [24/200]	BT 1.140 (1.140)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 10.6578 (10.6578)
Train - epoch [18/200]	BT 1.441 (1.441)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 7.5794 (7.5794)
Train - epoch [18/200]	BT 2.003 (2.003)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.5009 (8.5009)
Train - epoch [18/200]	BT 1.426 (1.426)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.2870 (8.2870)
Test on T training set - [24][0/13]	T 0.754 (0.754)	D 0.631 (0.631)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1368 (0.1368)
Test on T training set - [24][10/13]	T 0.500 (0.535)	D 0.385 (0.412)	T@1 69.841 (84.271)	T@5 98.413 (96.970)	L 0.9029 (0.6304)
 * Test on T training set - Prec@1 84.025, Prec@5 97.107
Test on T test set - [24][0/13]	Time 0.749 (0.749)	Loss 0.1368 (0.1368)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [24][10/13]	Time 0.505 (0.517)	Loss 0.9029 (0.6304)	Prec@1 69.841 (84.271)	Prec@5 98.413 (96.970)
 * Test on T test set - Prec@1 84.025, Prec@5 97.107
Epoch 24, K-means clustering 0, Average clustering time 0.018, Prec@1 89.182
Epoch 24, K-means clustering 1, Average clustering time 0.082, Prec@1 88.302
Epoch 24, K-means clustering 2, Average clustering time 0.084, Prec@1 88.050
Epoch 24, K-means clustering 3, Average clustering time 0.086, Prec@1 88.050
Epoch 24, K-means clustering 4, Average clustering time 0.086, Prec@1 88.050
Epoch 24, K-means clustering 0, Average clustering time 0.001, Prec@1 88.805
Epoch 24, K-means clustering 1, Average clustering time 0.041, Prec@1 88.679
Epoch 24, K-means clustering 2, Average clustering time 0.056, Prec@1 88.176
Epoch 24, K-means clustering 3, Average clustering time 0.065, Prec@1 88.176
Epoch 24, K-means clustering 4, Average clustering time 0.077, Prec@1 88.050
Train - epoch [18/200]	BT 1.507 (1.507)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.1382 (8.1382)
The penalty weight is 0.554600
Train - epoch [25/200]	BT 1.239 (1.239)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 10.7743 (10.7743)
Train - epoch [25/200]	BT 1.210 (1.210)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 10.5076 (10.5076)
Test on T training set - [18][0/45]	T 0.521 (0.521)	D 0.408 (0.408)	T@1 87.302 (87.302)	T@5 98.413 (98.413)	L 0.6831 (0.6831)
Test on T training set - [18][10/45]	T 0.355 (0.352)	D 0.240 (0.231)	T@1 30.159 (78.932)	T@5 61.905 (91.775)	L 2.6260 (0.9012)
Test on T training set - [18][20/45]	T 0.333 (0.347)	D 0.211 (0.226)	T@1 87.302 (75.359)	T@5 100.000 (90.401)	L 0.5537 (1.0457)
Test on T training set - [18][30/45]	T 0.361 (0.349)	D 0.233 (0.228)	T@1 76.190 (73.886)	T@5 95.238 (89.862)	L 1.0181 (1.0913)
Test on T training set - [18][40/45]	T 0.324 (0.346)	D 0.211 (0.226)	T@1 42.857 (69.570)	T@5 80.952 (85.598)	L 1.9935 (1.2984)
 * Test on T training set - Prec@1 67.093, Prec@5 85.091
Train - epoch [25/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.0874 (10.0874)
Train - epoch [25/200]	BT 1.129 (1.129)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 11.1762 (11.1762)
Test on T test set - [18][0/45]	Time 0.523 (0.523)	Loss 0.6831 (0.6831)	Prec@1 87.302 (87.302)	Prec@5 98.413 (98.413)
Test on T test set - [18][10/45]	Time 0.341 (0.349)	Loss 2.6260 (0.9012)	Prec@1 30.159 (78.932)	Prec@5 61.905 (91.775)
Test on T test set - [18][20/45]	Time 0.326 (0.342)	Loss 0.5537 (1.0457)	Prec@1 87.302 (75.359)	Prec@5 100.000 (90.401)
Test on T test set - [18][30/45]	Time 0.360 (0.341)	Loss 1.0181 (1.0913)	Prec@1 76.190 (73.886)	Prec@5 95.238 (89.862)
Test on T test set - [18][40/45]	Time 0.332 (0.355)	Loss 1.9935 (1.2984)	Prec@1 42.857 (69.570)	Prec@5 80.952 (85.598)
 * Test on T test set - Prec@1 67.093, Prec@5 85.091
Epoch 18, K-means clustering 0, Average clustering time 0.027, Prec@1 73.021
Epoch 18, K-means clustering 1, Average clustering time 0.089, Prec@1 74.157
Epoch 18, K-means clustering 2, Average clustering time 0.096, Prec@1 74.157
Epoch 18, K-means clustering 3, Average clustering time 0.101, Prec@1 74.157
Epoch 18, K-means clustering 4, Average clustering time 0.104, Prec@1 74.015
Epoch 18, K-means clustering 0, Average clustering time 0.003, Prec@1 71.601
Epoch 18, K-means clustering 1, Average clustering time 0.056, Prec@1 72.595
Epoch 18, K-means clustering 2, Average clustering time 0.069, Prec@1 72.879
Epoch 18, K-means clustering 3, Average clustering time 0.077, Prec@1 72.985
Epoch 18, K-means clustering 4, Average clustering time 0.082, Prec@1 73.021
Train - epoch [25/200]	BT 1.245 (1.245)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 10.3451 (10.3451)
The penalty weight is 0.442230
Train - epoch [19/200]	BT 1.523 (1.523)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.8273 (8.8273)
Train - epoch [25/200]	BT 1.056 (1.056)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 9.9055 (9.9055)
Train - epoch [25/200]	BT 1.070 (1.070)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 10.8638 (10.8638)
Train - epoch [19/200]	BT 1.635 (1.635)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.7940 (8.7940)
Train - epoch [19/200]	BT 1.517 (1.517)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.9202 (8.9202)
Test on T training set - [25][0/13]	T 0.735 (0.735)	D 0.619 (0.619)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1357 (0.1357)
Test on T training set - [25][10/13]	T 0.503 (0.540)	D 0.386 (0.417)	T@1 66.667 (84.416)	T@5 98.413 (96.970)	L 0.8901 (0.6304)
 * Test on T training set - Prec@1 84.151, Prec@5 97.107
Test on T test set - [25][0/13]	Time 0.733 (0.733)	Loss 0.1357 (0.1357)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [25][10/13]	Time 0.520 (0.517)	Loss 0.8901 (0.6304)	Prec@1 66.667 (84.416)	Prec@5 98.413 (96.970)
 * Test on T test set - Prec@1 84.151, Prec@5 97.107
Epoch 25, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 25, K-means clustering 1, Average clustering time 0.080, Prec@1 88.553
Epoch 25, K-means clustering 2, Average clustering time 0.083, Prec@1 88.302
Epoch 25, K-means clustering 3, Average clustering time 0.084, Prec@1 88.302
Epoch 25, K-means clustering 4, Average clustering time 0.085, Prec@1 88.302
Epoch 25, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 25, K-means clustering 1, Average clustering time 0.037, Prec@1 88.302
Epoch 25, K-means clustering 2, Average clustering time 0.048, Prec@1 88.302
Epoch 25, K-means clustering 3, Average clustering time 0.053, Prec@1 88.050
Epoch 25, K-means clustering 4, Average clustering time 0.056, Prec@1 88.050
Train - epoch [19/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.7701 (8.7701)
The penalty weight is 0.571670
Train - epoch [26/200]	BT 1.153 (1.153)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 10.5256 (10.5256)
Train - epoch [19/200]	BT 1.509 (1.509)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.0470 (8.0470)
Train - epoch [19/200]	BT 1.478 (1.478)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.8189 (8.8189)
Train - epoch [26/200]	BT 1.711 (1.711)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 10.6913 (10.6913)
Train - epoch [26/200]	BT 1.202 (1.202)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 11.2148 (11.2148)
Train - epoch [26/200]	BT 1.151 (1.151)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 10.7661 (10.7661)
Train - epoch [26/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 11.4361 (11.4361)
Test on T training set - [19][0/45]	T 0.518 (0.518)	D 0.397 (0.397)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7661 (0.7661)
Test on T training set - [19][10/45]	T 0.323 (0.348)	D 0.206 (0.230)	T@1 30.159 (78.932)	T@5 63.492 (91.775)	L 2.6260 (0.8845)
Test on T training set - [19][20/45]	T 0.335 (0.344)	D 0.213 (0.227)	T@1 87.302 (75.435)	T@5 100.000 (90.098)	L 0.5754 (1.0468)
Test on T training set - [19][30/45]	T 0.325 (0.341)	D 0.212 (0.222)	T@1 76.190 (73.272)	T@5 95.238 (89.196)	L 1.0102 (1.1033)
Test on T training set - [19][40/45]	T 0.371 (0.341)	D 0.240 (0.222)	T@1 41.270 (69.067)	T@5 80.952 (85.095)	L 2.0130 (1.3006)
 * Test on T training set - Prec@1 66.773, Prec@5 84.594
Train - epoch [26/200]	BT 1.204 (1.204)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 11.4320 (11.4320)
Test on T test set - [19][0/45]	Time 0.502 (0.502)	Loss 0.7661 (0.7661)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [19][10/45]	Time 0.321 (0.348)	Loss 2.6260 (0.8845)	Prec@1 30.159 (78.932)	Prec@5 63.492 (91.775)
Test on T test set - [19][20/45]	Time 0.323 (0.354)	Loss 0.5754 (1.0468)	Prec@1 87.302 (75.435)	Prec@5 100.000 (90.098)
Test on T test set - [19][30/45]	Time 0.612 (0.358)	Loss 1.0102 (1.1033)	Prec@1 76.190 (73.272)	Prec@5 95.238 (89.196)
Test on T test set - [19][40/45]	Time 0.336 (0.352)	Loss 2.0130 (1.3006)	Prec@1 41.270 (69.067)	Prec@5 80.952 (85.095)
 * Test on T test set - Prec@1 66.773, Prec@5 84.594
Epoch 19, K-means clustering 0, Average clustering time 0.027, Prec@1 72.985
Epoch 19, K-means clustering 1, Average clustering time 0.089, Prec@1 73.979
Epoch 19, K-means clustering 2, Average clustering time 0.102, Prec@1 74.228
Epoch 19, K-means clustering 3, Average clustering time 0.102, Prec@1 74.121
Epoch 19, K-means clustering 4, Average clustering time 0.102, Prec@1 73.731
Epoch 19, K-means clustering 0, Average clustering time 0.003, Prec@1 71.530
Epoch 19, K-means clustering 1, Average clustering time 0.047, Prec@1 72.133
Epoch 19, K-means clustering 2, Average clustering time 0.060, Prec@1 72.453
Epoch 19, K-means clustering 3, Average clustering time 0.069, Prec@1 72.559
Epoch 19, K-means clustering 4, Average clustering time 0.077, Prec@1 72.524
Test on T training set - [26][0/13]	T 0.771 (0.771)	D 0.641 (0.641)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1330 (0.1330)
Test on T training set - [26][10/13]	T 0.520 (0.526)	D 0.398 (0.404)	T@1 69.841 (84.704)	T@5 98.413 (96.970)	L 0.8930 (0.6213)
 * Test on T training set - Prec@1 84.277, Prec@5 97.107
Train - epoch [20/200]	BT 1.670 (1.670)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.9096 (8.9096)
The penalty weight is 0.462117
Train - epoch [20/200]	BT 1.468 (1.468)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.0053 (9.0053)
Test on T test set - [26][0/13]	Time 0.761 (0.761)	Loss 0.1330 (0.1330)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [26][10/13]	Time 0.530 (0.520)	Loss 0.8930 (0.6213)	Prec@1 69.841 (84.704)	Prec@5 98.413 (96.970)
 * Test on T test set - Prec@1 84.277, Prec@5 97.107
Epoch 26, K-means clustering 0, Average clustering time 0.018, Prec@1 88.679
Epoch 26, K-means clustering 1, Average clustering time 0.080, Prec@1 88.176
Epoch 26, K-means clustering 2, Average clustering time 0.083, Prec@1 88.176
Epoch 26, K-means clustering 3, Average clustering time 0.084, Prec@1 88.176
Epoch 26, K-means clustering 4, Average clustering time 0.084, Prec@1 88.176
Epoch 26, K-means clustering 0, Average clustering time 0.001, Prec@1 88.176
Epoch 26, K-means clustering 1, Average clustering time 0.101, Prec@1 87.925
Epoch 26, K-means clustering 2, Average clustering time 0.098, Prec@1 87.673
Epoch 26, K-means clustering 3, Average clustering time 0.096, Prec@1 87.673
Epoch 26, K-means clustering 4, Average clustering time 0.095, Prec@1 87.673
Train - epoch [20/200]	BT 1.469 (1.469)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.0781 (9.0781)
The penalty weight is 0.588259
Train - epoch [27/200]	BT 1.238 (1.238)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 11.0542 (11.0542)
Train - epoch [27/200]	BT 1.077 (1.077)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 11.5292 (11.5292)
Train - epoch [20/200]	BT 1.820 (1.820)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.6289 (8.6289)
Train - epoch [27/200]	BT 0.963 (0.963)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 11.7368 (11.7368)
Train - epoch [27/200]	BT 1.101 (1.101)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 11.6386 (11.6386)
Train - epoch [20/200]	BT 1.478 (1.478)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.1221 (9.1221)
Train - epoch [20/200]	BT 1.591 (1.591)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.5134 (8.5134)
Train - epoch [27/200]	BT 1.189 (1.189)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 11.8207 (11.8207)
Train - epoch [27/200]	BT 1.104 (1.104)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 11.0168 (11.0168)
Train - epoch [27/200]	BT 1.079 (1.079)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 11.5947 (11.5947)
Train - epoch [20/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 8.2438 (8.2438)
Test on T training set - [27][0/13]	T 0.756 (0.756)	D 0.626 (0.626)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1212 (0.1212)
Test on T training set - [27][10/13]	T 0.526 (0.530)	D 0.410 (0.411)	T@1 60.317 (83.550)	T@5 98.413 (96.970)	L 1.0549 (0.6516)
 * Test on T training set - Prec@1 83.145, Prec@5 97.107
Test on T training set - [20][0/45]	T 0.509 (0.509)	D 0.386 (0.386)	T@1 84.127 (84.127)	T@5 98.413 (98.413)	L 0.7530 (0.7530)
Test on T training set - [20][10/45]	T 0.331 (0.356)	D 0.209 (0.238)	T@1 26.984 (77.778)	T@5 63.492 (91.631)	L 2.6884 (0.9028)
Test on T training set - [20][20/45]	T 0.343 (0.348)	D 0.221 (0.230)	T@1 87.302 (74.981)	T@5 100.000 (89.872)	L 0.5217 (1.0460)
Test on T training set - [20][30/45]	T 0.337 (0.344)	D 0.224 (0.227)	T@1 74.603 (73.630)	T@5 95.238 (89.606)	L 1.0576 (1.0882)
Test on T training set - [20][40/45]	T 0.329 (0.342)	D 0.216 (0.224)	T@1 44.444 (69.261)	T@5 80.952 (85.443)	L 2.0033 (1.2977)
 * Test on T training set - Prec@1 66.702, Prec@5 84.665
Test on T test set - [27][0/13]	Time 0.736 (0.736)	Loss 0.1212 (0.1212)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [27][10/13]	Time 0.512 (0.522)	Loss 1.0549 (0.6516)	Prec@1 60.317 (83.550)	Prec@5 98.413 (96.970)
 * Test on T test set - Prec@1 83.145, Prec@5 97.107
Epoch 27, K-means clustering 0, Average clustering time 0.018, Prec@1 87.925
Epoch 27, K-means clustering 1, Average clustering time 0.072, Prec@1 88.050
Epoch 27, K-means clustering 2, Average clustering time 0.076, Prec@1 87.547
Epoch 27, K-means clustering 3, Average clustering time 0.078, Prec@1 87.421
Epoch 27, K-means clustering 4, Average clustering time 0.078, Prec@1 87.421
Epoch 27, K-means clustering 0, Average clustering time 0.001, Prec@1 86.918
Epoch 27, K-means clustering 1, Average clustering time 0.039, Prec@1 87.799
Epoch 27, K-means clustering 2, Average clustering time 0.049, Prec@1 87.421
Epoch 27, K-means clustering 3, Average clustering time 0.055, Prec@1 87.421
Epoch 27, K-means clustering 4, Average clustering time 0.058, Prec@1 87.296
Test on T test set - [20][0/45]	Time 0.505 (0.505)	Loss 0.7530 (0.7530)	Prec@1 84.127 (84.127)	Prec@5 98.413 (98.413)
Test on T test set - [20][10/45]	Time 0.327 (0.365)	Loss 2.6884 (0.9028)	Prec@1 26.984 (77.778)	Prec@5 63.492 (91.631)
Test on T test set - [20][20/45]	Time 0.645 (0.367)	Loss 0.5217 (1.0460)	Prec@1 87.302 (74.981)	Prec@5 100.000 (89.872)
Test on T test set - [20][30/45]	Time 0.329 (0.366)	Loss 1.0576 (1.0882)	Prec@1 74.603 (73.630)	Prec@5 95.238 (89.606)
Test on T test set - [20][40/45]	Time 0.320 (0.358)	Loss 2.0033 (1.2977)	Prec@1 44.444 (69.261)	Prec@5 80.952 (85.443)
 * Test on T test set - Prec@1 66.702, Prec@5 84.665
Epoch 20, K-means clustering 0, Average clustering time 0.027, Prec@1 72.985
Epoch 20, K-means clustering 1, Average clustering time 0.091, Prec@1 74.405
Epoch 20, K-means clustering 2, Average clustering time 0.094, Prec@1 74.192
Epoch 20, K-means clustering 3, Average clustering time 0.095, Prec@1 74.050
Epoch 20, K-means clustering 4, Average clustering time 0.096, Prec@1 73.766
Epoch 20, K-means clustering 0, Average clustering time 0.007, Prec@1 71.459
Epoch 20, K-means clustering 1, Average clustering time 0.040, Prec@1 72.275
Epoch 20, K-means clustering 2, Average clustering time 0.059, Prec@1 72.275
Epoch 20, K-means clustering 3, Average clustering time 0.065, Prec@1 72.417
Epoch 20, K-means clustering 4, Average clustering time 0.068, Prec@1 72.453
The penalty weight is 0.604368
Train - epoch [28/200]	BT 1.429 (1.429)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 11.7340 (11.7340)
Train - epoch [28/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.8035 (11.8035)
The penalty weight is 0.481550
Train - epoch [21/200]	BT 1.547 (1.547)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.6994 (9.6994)
Train - epoch [28/200]	BT 1.211 (1.211)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 11.8502 (11.8502)
Train - epoch [28/200]	BT 1.113 (1.113)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 10.9983 (10.9983)
Train - epoch [21/200]	BT 1.532 (1.532)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.6379 (9.6379)
Train - epoch [28/200]	BT 1.166 (1.166)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 11.9838 (11.9838)
Train - epoch [21/200]	BT 1.447 (1.447)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.7863 (9.7863)
Train - epoch [28/200]	BT 1.646 (1.646)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 12.3134 (12.3134)
Train - epoch [28/200]	BT 1.135 (1.135)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 12.1049 (12.1049)
Train - epoch [21/200]	BT 2.022 (2.022)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.6059 (9.6059)
Train - epoch [21/200]	BT 1.399 (1.399)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.7698 (9.7698)
Train - epoch [21/200]	BT 1.522 (1.522)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.5925 (9.5925)
Test on T training set - [28][0/13]	T 0.800 (0.800)	D 0.676 (0.676)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1534 (0.1534)
Test on T training set - [28][10/13]	T 0.522 (0.537)	D 0.395 (0.416)	T@1 61.905 (83.838)	T@5 100.000 (96.392)	L 0.9414 (0.6396)
 * Test on T training set - Prec@1 83.648, Prec@5 96.604
Test on T test set - [28][0/13]	Time 0.753 (0.753)	Loss 0.1534 (0.1534)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [28][10/13]	Time 0.509 (0.531)	Loss 0.9414 (0.6396)	Prec@1 61.905 (83.838)	Prec@5 100.000 (96.392)
 * Test on T test set - Prec@1 83.648, Prec@5 96.604
Epoch 28, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 28, K-means clustering 1, Average clustering time 0.073, Prec@1 88.553
Epoch 28, K-means clustering 2, Average clustering time 0.074, Prec@1 87.925
Epoch 28, K-means clustering 3, Average clustering time 0.075, Prec@1 87.799
Epoch 28, K-means clustering 4, Average clustering time 0.095, Prec@1 87.799
Epoch 28, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 28, K-means clustering 1, Average clustering time 0.037, Prec@1 88.302
Epoch 28, K-means clustering 2, Average clustering time 0.050, Prec@1 87.799
Epoch 28, K-means clustering 3, Average clustering time 0.056, Prec@1 87.799
Epoch 28, K-means clustering 4, Average clustering time 0.063, Prec@1 87.799
Train - epoch [21/200]	BT 1.555 (1.555)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.3171 (9.3171)
The penalty weight is 0.619997
Train - epoch [29/200]	BT 1.029 (1.029)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 11.0479 (11.0479)
Train - epoch [29/200]	BT 1.026 (1.026)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 12.1970 (12.1970)
Test on T training set - [21][0/45]	T 0.530 (0.530)	D 0.404 (0.404)	T@1 87.302 (87.302)	T@5 98.413 (98.413)	L 0.6280 (0.6280)
Test on T training set - [21][10/45]	T 0.331 (0.349)	D 0.209 (0.230)	T@1 30.159 (79.798)	T@5 63.492 (91.919)	L 2.7466 (0.8752)
Test on T training set - [21][20/45]	T 0.331 (0.340)	D 0.214 (0.222)	T@1 80.952 (76.115)	T@5 100.000 (90.023)	L 0.6660 (1.0283)
Test on T training set - [21][30/45]	T 0.329 (0.339)	D 0.210 (0.220)	T@1 79.365 (74.808)	T@5 95.238 (89.452)	L 0.8887 (1.0637)
Test on T training set - [21][40/45]	T 0.335 (0.337)	D 0.219 (0.218)	T@1 39.683 (70.538)	T@5 77.778 (85.095)	L 2.1088 (1.2724)
 * Test on T training set - Prec@1 68.016, Prec@5 84.381
Train - epoch [29/200]	BT 1.153 (1.153)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 12.5904 (12.5904)
Test on T test set - [21][0/45]	Time 0.506 (0.506)	Loss 0.6280 (0.6280)	Prec@1 87.302 (87.302)	Prec@5 98.413 (98.413)
Test on T test set - [21][10/45]	Time 0.332 (0.342)	Loss 2.7466 (0.8752)	Prec@1 30.159 (79.798)	Prec@5 63.492 (91.919)
Test on T test set - [21][20/45]	Time 0.332 (0.343)	Loss 0.6660 (1.0283)	Prec@1 80.952 (76.115)	Prec@5 100.000 (90.023)
Test on T test set - [21][30/45]	Time 0.323 (0.340)	Loss 0.8887 (1.0637)	Prec@1 79.365 (74.808)	Prec@5 95.238 (89.452)
Test on T test set - [21][40/45]	Time 0.361 (0.347)	Loss 2.1088 (1.2724)	Prec@1 39.683 (70.538)	Prec@5 77.778 (85.095)
 * Test on T test set - Prec@1 68.016, Prec@5 84.381
Epoch 21, K-means clustering 0, Average clustering time 0.029, Prec@1 73.802
Epoch 21, K-means clustering 1, Average clustering time 0.115, Prec@1 74.405
Epoch 21, K-means clustering 2, Average clustering time 0.119, Prec@1 74.228
Epoch 21, K-means clustering 3, Average clustering time 0.117, Prec@1 74.015
Epoch 21, K-means clustering 4, Average clustering time 0.114, Prec@1 73.873
Epoch 21, K-means clustering 0, Average clustering time 0.003, Prec@1 72.240
Epoch 21, K-means clustering 1, Average clustering time 0.047, Prec@1 72.701
Epoch 21, K-means clustering 2, Average clustering time 0.064, Prec@1 72.950
Epoch 21, K-means clustering 3, Average clustering time 0.069, Prec@1 72.950
Epoch 21, K-means clustering 4, Average clustering time 0.072, Prec@1 72.985
Train - epoch [29/200]	BT 1.050 (1.050)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 12.1905 (12.1905)
Train - epoch [29/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 11.8364 (11.8364)
The penalty weight is 0.500520
Train - epoch [22/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.1075 (9.1075)
Train - epoch [29/200]	BT 1.109 (1.109)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 12.1126 (12.1126)
Train - epoch [22/200]	BT 1.771 (1.771)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.8491 (9.8491)
Test on T training set - [29][0/13]	T 0.735 (0.735)	D 0.615 (0.615)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1360 (0.1360)
Test on T training set - [29][10/13]	T 0.543 (0.524)	D 0.413 (0.404)	T@1 66.667 (84.127)	T@5 98.413 (97.114)	L 0.9489 (0.6345)
 * Test on T training set - Prec@1 83.774, Prec@5 97.233
Train - epoch [22/200]	BT 1.455 (1.455)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.7295 (9.7295)
Test on T test set - [29][0/13]	Time 0.743 (0.743)	Loss 0.1360 (0.1360)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [29][10/13]	Time 0.525 (0.528)	Loss 0.9489 (0.6345)	Prec@1 66.667 (84.127)	Prec@5 98.413 (97.114)
 * Test on T test set - Prec@1 83.774, Prec@5 97.233
Epoch 29, K-means clustering 0, Average clustering time 0.018, Prec@1 88.679
Epoch 29, K-means clustering 1, Average clustering time 0.081, Prec@1 88.302
Epoch 29, K-means clustering 2, Average clustering time 0.088, Prec@1 88.050
Epoch 29, K-means clustering 3, Average clustering time 0.091, Prec@1 88.050
Epoch 29, K-means clustering 4, Average clustering time 0.092, Prec@1 88.050
Epoch 29, K-means clustering 0, Average clustering time 0.001, Prec@1 87.925
Epoch 29, K-means clustering 1, Average clustering time 0.038, Prec@1 88.176
Epoch 29, K-means clustering 2, Average clustering time 0.049, Prec@1 87.799
Epoch 29, K-means clustering 3, Average clustering time 0.055, Prec@1 87.673
Epoch 29, K-means clustering 4, Average clustering time 0.059, Prec@1 87.673
Train - epoch [22/200]	BT 1.570 (1.570)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.7779 (9.7779)
Train - epoch [30/200]	BT 1.640 (1.640)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 12.6964 (12.6964)
The penalty weight is 0.635149
Train - epoch [30/200]	BT 1.070 (1.070)	DT 0.000 (0.000)	S@1 83.333 (83.333)	Loss 12.7926 (12.7926)
Train - epoch [22/200]	BT 1.541 (1.541)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.8969 (9.8969)
Train - epoch [30/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.1983 (13.1983)
Train - epoch [30/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 12.8658 (12.8658)
Train - epoch [22/200]	BT 1.459 (1.459)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.9379 (9.9379)
Train - epoch [22/200]	BT 1.865 (1.865)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.1671 (10.1671)
Train - epoch [30/200]	BT 1.317 (1.317)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 11.6692 (11.6692)
Train - epoch [30/200]	BT 1.099 (1.099)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 11.3971 (11.3971)
Test on T training set - [22][0/45]	T 0.506 (0.506)	D 0.391 (0.391)	T@1 85.714 (85.714)	T@5 98.413 (98.413)	L 0.6947 (0.6947)
Test on T training set - [22][10/45]	T 0.330 (0.354)	D 0.206 (0.234)	T@1 26.984 (79.221)	T@5 63.492 (91.486)	L 2.7138 (0.8981)
Test on T training set - [22][20/45]	T 0.344 (0.351)	D 0.221 (0.233)	T@1 84.127 (75.510)	T@5 100.000 (89.796)	L 0.6131 (1.0419)
Test on T training set - [22][30/45]	T 0.337 (0.347)	D 0.224 (0.228)	T@1 74.603 (74.142)	T@5 95.238 (89.811)	L 1.0912 (1.0794)
Test on T training set - [22][40/45]	T 0.322 (0.344)	D 0.208 (0.225)	T@1 39.683 (69.454)	T@5 79.365 (85.559)	L 2.0912 (1.2959)
 * Test on T training set - Prec@1 66.986, Prec@5 85.055
Train - epoch [30/200]	BT 1.166 (1.166)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 12.2711 (12.2711)
Test on T test set - [22][0/45]	Time 0.523 (0.523)	Loss 0.6947 (0.6947)	Prec@1 85.714 (85.714)	Prec@5 98.413 (98.413)
Test on T test set - [22][10/45]	Time 0.348 (0.387)	Loss 2.7138 (0.8981)	Prec@1 26.984 (79.221)	Prec@5 63.492 (91.486)
Test on T test set - [22][20/45]	Time 0.325 (0.360)	Loss 0.6131 (1.0419)	Prec@1 84.127 (75.510)	Prec@5 100.000 (89.796)
Test on T test set - [22][30/45]	Time 0.325 (0.350)	Loss 1.0912 (1.0794)	Prec@1 74.603 (74.142)	Prec@5 95.238 (89.811)
Test on T test set - [22][40/45]	Time 0.335 (0.348)	Loss 2.0912 (1.2959)	Prec@1 39.683 (69.454)	Prec@5 79.365 (85.559)
 * Test on T test set - Prec@1 66.986, Prec@5 85.055
Epoch 22, K-means clustering 0, Average clustering time 0.027, Prec@1 73.269
Epoch 22, K-means clustering 1, Average clustering time 0.093, Prec@1 74.334
Epoch 22, K-means clustering 2, Average clustering time 0.105, Prec@1 74.370
Epoch 22, K-means clustering 3, Average clustering time 0.104, Prec@1 74.086
Epoch 22, K-means clustering 4, Average clustering time 0.104, Prec@1 73.802
Epoch 22, K-means clustering 0, Average clustering time 0.003, Prec@1 71.991
Epoch 22, K-means clustering 1, Average clustering time 0.045, Prec@1 72.772
Epoch 22, K-means clustering 2, Average clustering time 0.064, Prec@1 72.843
Epoch 22, K-means clustering 3, Average clustering time 0.072, Prec@1 72.737
Epoch 22, K-means clustering 4, Average clustering time 0.074, Prec@1 72.808
Test on T training set - [30][0/13]	T 0.750 (0.750)	D 0.620 (0.620)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1185 (0.1185)
Test on T training set - [30][10/13]	T 0.527 (0.528)	D 0.399 (0.406)	T@1 65.079 (83.983)	T@5 98.413 (96.392)	L 0.9500 (0.6332)
 * Test on T training set - Prec@1 84.025, Prec@5 96.604
Test on T test set - [30][0/13]	Time 0.757 (0.757)	Loss 0.1185 (0.1185)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [30][10/13]	Time 0.527 (0.567)	Loss 0.9500 (0.6332)	Prec@1 65.079 (83.983)	Prec@5 98.413 (96.392)
 * Test on T test set - Prec@1 84.025, Prec@5 96.604
Epoch 30, K-means clustering 0, Average clustering time 0.018, Prec@1 88.931
Epoch 30, K-means clustering 1, Average clustering time 0.084, Prec@1 88.302
Epoch 30, K-means clustering 2, Average clustering time 0.088, Prec@1 88.050
Epoch 30, K-means clustering 3, Average clustering time 0.091, Prec@1 88.050
Epoch 30, K-means clustering 4, Average clustering time 0.093, Prec@1 88.050
Epoch 30, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 30, K-means clustering 1, Average clustering time 0.046, Prec@1 88.428
Epoch 30, K-means clustering 2, Average clustering time 0.056, Prec@1 88.050
Epoch 30, K-means clustering 3, Average clustering time 0.065, Prec@1 88.050
Epoch 30, K-means clustering 4, Average clustering time 0.065, Prec@1 88.050
The penalty weight is 0.519022
Train - epoch [23/200]	BT 1.671 (1.671)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.8064 (9.8064)
Train - epoch [23/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.2370 (9.2370)
The penalty weight is 0.649827
Train - epoch [31/200]	BT 1.207 (1.207)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 13.1572 (13.1572)
Train - epoch [31/200]	BT 1.205 (1.205)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 12.6026 (12.6026)
Train - epoch [23/200]	BT 1.486 (1.486)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.1769 (10.1769)
Train - epoch [31/200]	BT 1.090 (1.090)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 12.3594 (12.3594)
Train - epoch [31/200]	BT 1.162 (1.162)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.9497 (12.9497)
Train - epoch [23/200]	BT 1.722 (1.722)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.8537 (9.8537)
Train - epoch [31/200]	BT 1.152 (1.152)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 12.1660 (12.1660)
Train - epoch [31/200]	BT 1.089 (1.089)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.0381 (13.0381)
Train - epoch [23/200]	BT 1.531 (1.531)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.4588 (10.4588)
Train - epoch [31/200]	BT 1.168 (1.168)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 13.0710 (13.0710)
Train - epoch [23/200]	BT 1.555 (1.555)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.4894 (9.4894)
Test on T training set - [31][0/13]	T 0.770 (0.770)	D 0.646 (0.646)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1440 (0.1440)
Test on T training set - [31][10/13]	T 0.543 (0.529)	D 0.416 (0.407)	T@1 65.079 (84.704)	T@5 100.000 (96.825)	L 0.9059 (0.6210)
 * Test on T training set - Prec@1 84.654, Prec@5 96.855
Test on T test set - [31][0/13]	Time 0.728 (0.728)	Loss 0.1440 (0.1440)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [31][10/13]	Time 0.526 (0.522)	Loss 0.9059 (0.6210)	Prec@1 65.079 (84.704)	Prec@5 100.000 (96.825)
 * Test on T test set - Prec@1 84.654, Prec@5 96.855
Epoch 31, K-means clustering 0, Average clustering time 0.018, Prec@1 88.931
Epoch 31, K-means clustering 1, Average clustering time 0.080, Prec@1 88.302
Epoch 31, K-means clustering 2, Average clustering time 0.091, Prec@1 87.925
Epoch 31, K-means clustering 3, Average clustering time 0.091, Prec@1 87.925
Epoch 31, K-means clustering 4, Average clustering time 0.093, Prec@1 87.925
Epoch 31, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 31, K-means clustering 1, Average clustering time 0.039, Prec@1 88.428
Epoch 31, K-means clustering 2, Average clustering time 0.054, Prec@1 88.050
Epoch 31, K-means clustering 3, Average clustering time 0.060, Prec@1 88.050
Epoch 31, K-means clustering 4, Average clustering time 0.066, Prec@1 88.050
Test on T training set - [23][0/45]	T 0.545 (0.545)	D 0.423 (0.423)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7304 (0.7304)
Test on T training set - [23][10/45]	T 0.359 (0.350)	D 0.238 (0.231)	T@1 26.984 (78.355)	T@5 60.317 (91.198)	L 2.7756 (0.9047)
Test on T training set - [23][20/45]	T 0.328 (0.344)	D 0.202 (0.224)	T@1 85.714 (74.906)	T@5 100.000 (89.342)	L 0.5829 (1.0669)
Test on T training set - [23][30/45]	T 0.324 (0.340)	D 0.201 (0.220)	T@1 76.190 (73.528)	T@5 95.238 (89.350)	L 0.9992 (1.0944)
Test on T training set - [23][40/45]	T 0.312 (0.339)	D 0.195 (0.219)	T@1 39.683 (68.990)	T@5 80.952 (85.405)	L 2.0746 (1.3031)
 * Test on T training set - Prec@1 66.631, Prec@5 84.878
Test on T test set - [23][0/45]	Time 0.747 (0.747)	Loss 0.7304 (0.7304)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [23][10/45]	Time 0.325 (0.371)	Loss 2.7756 (0.9047)	Prec@1 26.984 (78.355)	Prec@5 60.317 (91.198)
Test on T test set - [23][20/45]	Time 0.342 (0.354)	Loss 0.5829 (1.0669)	Prec@1 85.714 (74.906)	Prec@5 100.000 (89.342)
Test on T test set - [23][30/45]	Time 0.343 (0.350)	Loss 0.9992 (1.0944)	Prec@1 76.190 (73.528)	Prec@5 95.238 (89.350)
Test on T test set - [23][40/45]	Time 0.335 (0.346)	Loss 2.0746 (1.3031)	Prec@1 39.683 (68.990)	Prec@5 80.952 (85.405)
 * Test on T test set - Prec@1 66.631, Prec@5 84.878
Epoch 23, K-means clustering 0, Average clustering time 0.027, Prec@1 72.985
Epoch 23, K-means clustering 1, Average clustering time 0.107, Prec@1 74.299
Epoch 23, K-means clustering 2, Average clustering time 0.120, Prec@1 74.157
Epoch 23, K-means clustering 3, Average clustering time 0.122, Prec@1 74.157
Epoch 23, K-means clustering 4, Average clustering time 0.120, Prec@1 74.121
Epoch 23, K-means clustering 0, Average clustering time 0.003, Prec@1 71.494
Epoch 23, K-means clustering 1, Average clustering time 0.045, Prec@1 72.346
Epoch 23, K-means clustering 2, Average clustering time 0.066, Prec@1 72.524
Epoch 23, K-means clustering 3, Average clustering time 0.073, Prec@1 72.630
Epoch 23, K-means clustering 4, Average clustering time 0.077, Prec@1 72.666
The penalty weight is 0.664037
Train - epoch [32/200]	BT 1.168 (1.168)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 12.5345 (12.5345)
Train - epoch [32/200]	BT 1.311 (1.311)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 12.0029 (12.0029)
The penalty weight is 0.537050
Train - epoch [24/200]	BT 1.479 (1.479)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.2285 (10.2285)
Train - epoch [32/200]	BT 1.090 (1.090)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 13.3308 (13.3308)
Train - epoch [24/200]	BT 1.488 (1.488)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.6054 (10.6054)
Train - epoch [32/200]	BT 1.637 (1.637)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 13.4216 (13.4216)
Train - epoch [32/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.3004 (13.3004)
Train - epoch [24/200]	BT 2.077 (2.077)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 9.8494 (9.8494)
Train - epoch [24/200]	BT 1.459 (1.459)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.5454 (10.5454)
Train - epoch [32/200]	BT 1.126 (1.126)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 12.2220 (12.2220)
Train - epoch [32/200]	BT 1.039 (1.039)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 12.9542 (12.9542)
Train - epoch [24/200]	BT 1.765 (1.765)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.4027 (10.4027)
Test on T training set - [32][0/13]	T 0.779 (0.779)	D 0.653 (0.653)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1108 (0.1108)
Test on T training set - [32][10/13]	T 0.506 (0.524)	D 0.387 (0.403)	T@1 63.492 (84.704)	T@5 98.413 (96.681)	L 0.9399 (0.6314)
 * Test on T training set - Prec@1 84.277, Prec@5 96.855
Train - epoch [24/200]	BT 1.496 (1.496)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.8885 (10.8885)
Test on T test set - [32][0/13]	Time 0.740 (0.740)	Loss 0.1108 (0.1108)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [32][10/13]	Time 0.529 (0.525)	Loss 0.9399 (0.6314)	Prec@1 63.492 (84.704)	Prec@5 98.413 (96.681)
 * Test on T test set - Prec@1 84.277, Prec@5 96.855
Epoch 32, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 32, K-means clustering 1, Average clustering time 0.092, Prec@1 87.925
Epoch 32, K-means clustering 2, Average clustering time 0.101, Prec@1 87.799
Epoch 32, K-means clustering 3, Average clustering time 0.110, Prec@1 87.799
Epoch 32, K-means clustering 4, Average clustering time 0.106, Prec@1 87.799
Epoch 32, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 32, K-means clustering 1, Average clustering time 0.043, Prec@1 88.805
Epoch 32, K-means clustering 2, Average clustering time 0.056, Prec@1 88.302
Epoch 32, K-means clustering 3, Average clustering time 0.074, Prec@1 88.176
Epoch 32, K-means clustering 4, Average clustering time 0.077, Prec@1 88.176
Train - epoch [24/200]	BT 1.484 (1.484)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.8536 (10.8536)
The penalty weight is 0.677782
Train - epoch [33/200]	BT 1.122 (1.122)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.2677 (13.2677)
Test on T training set - [24][0/45]	T 0.531 (0.531)	D 0.411 (0.411)	T@1 87.302 (87.302)	T@5 98.413 (98.413)	L 0.7118 (0.7118)
Test on T training set - [24][10/45]	T 0.329 (0.383)	D 0.217 (0.267)	T@1 28.571 (78.644)	T@5 63.492 (91.198)	L 2.6898 (0.9151)
Test on T training set - [24][20/45]	T 0.337 (0.365)	D 0.212 (0.247)	T@1 87.302 (75.586)	T@5 100.000 (89.796)	L 0.5261 (1.0544)
Test on T training set - [24][30/45]	T 0.352 (0.356)	D 0.230 (0.237)	T@1 76.190 (74.040)	T@5 95.238 (89.401)	L 1.0034 (1.0970)
Test on T training set - [24][40/45]	T 0.325 (0.361)	D 0.203 (0.241)	T@1 41.270 (69.299)	T@5 80.952 (85.056)	L 1.9640 (1.3118)
 * Test on T training set - Prec@1 66.915, Prec@5 84.629
Train - epoch [33/200]	BT 0.987 (0.987)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 13.4936 (13.4936)
Train - epoch [33/200]	BT 1.665 (1.665)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 12.5965 (12.5965)
Test on T test set - [24][0/45]	Time 0.529 (0.529)	Loss 0.7118 (0.7118)	Prec@1 87.302 (87.302)	Prec@5 98.413 (98.413)
Test on T test set - [24][10/45]	Time 0.317 (0.351)	Loss 2.6898 (0.9151)	Prec@1 28.571 (78.644)	Prec@5 63.492 (91.198)
Test on T test set - [24][20/45]	Time 0.354 (0.343)	Loss 0.5261 (1.0544)	Prec@1 87.302 (75.586)	Prec@5 100.000 (89.796)
Test on T test set - [24][30/45]	Time 0.357 (0.344)	Loss 1.0034 (1.0970)	Prec@1 76.190 (74.040)	Prec@5 95.238 (89.401)
Test on T test set - [24][40/45]	Time 0.319 (0.359)	Loss 1.9640 (1.3118)	Prec@1 41.270 (69.299)	Prec@5 80.952 (85.056)
 * Test on T test set - Prec@1 66.915, Prec@5 84.629
Epoch 24, K-means clustering 0, Average clustering time 0.027, Prec@1 73.518
Epoch 24, K-means clustering 1, Average clustering time 0.100, Prec@1 74.370
Epoch 24, K-means clustering 2, Average clustering time 0.108, Prec@1 74.263
Epoch 24, K-means clustering 3, Average clustering time 0.113, Prec@1 74.405
Epoch 24, K-means clustering 4, Average clustering time 0.111, Prec@1 74.334
Epoch 24, K-means clustering 0, Average clustering time 0.003, Prec@1 72.062
Epoch 24, K-means clustering 1, Average clustering time 0.046, Prec@1 73.092
Epoch 24, K-means clustering 2, Average clustering time 0.061, Prec@1 73.092
Epoch 24, K-means clustering 3, Average clustering time 0.073, Prec@1 73.198
Epoch 24, K-means clustering 4, Average clustering time 0.077, Prec@1 73.269
Train - epoch [33/200]	BT 1.217 (1.217)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.5662 (13.5662)
Train - epoch [33/200]	BT 1.105 (1.105)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 13.4636 (13.4636)
The penalty weight is 0.554600
Train - epoch [25/200]	BT 1.471 (1.471)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.1229 (11.1229)
Train - epoch [33/200]	BT 1.184 (1.184)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 13.3711 (13.3711)
Train - epoch [25/200]	BT 1.567 (1.567)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.6677 (10.6677)
Test on T training set - [33][0/13]	T 0.740 (0.740)	D 0.624 (0.624)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1344 (0.1344)
Test on T training set - [33][10/13]	T 0.537 (0.528)	D 0.422 (0.405)	T@1 65.079 (84.416)	T@5 98.413 (96.970)	L 1.0343 (0.6346)
 * Test on T training set - Prec@1 84.403, Prec@5 97.107
Train - epoch [25/200]	BT 1.555 (1.555)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.6352 (10.6352)
Test on T test set - [33][0/13]	Time 0.762 (0.762)	Loss 0.1344 (0.1344)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [33][10/13]	Time 0.533 (0.529)	Loss 1.0343 (0.6346)	Prec@1 65.079 (84.416)	Prec@5 98.413 (96.970)
 * Test on T test set - Prec@1 84.403, Prec@5 97.107
Epoch 33, K-means clustering 0, Average clustering time 0.018, Prec@1 88.302
Epoch 33, K-means clustering 1, Average clustering time 0.079, Prec@1 88.050
Epoch 33, K-means clustering 2, Average clustering time 0.077, Prec@1 87.925
Epoch 33, K-means clustering 3, Average clustering time 0.076, Prec@1 87.925
Epoch 33, K-means clustering 4, Average clustering time 0.075, Prec@1 87.925
Epoch 33, K-means clustering 0, Average clustering time 0.001, Prec@1 88.050
Epoch 33, K-means clustering 1, Average clustering time 0.034, Prec@1 88.428
Epoch 33, K-means clustering 2, Average clustering time 0.050, Prec@1 87.799
Epoch 33, K-means clustering 3, Average clustering time 0.058, Prec@1 87.673
Epoch 33, K-means clustering 4, Average clustering time 0.064, Prec@1 87.673
Train - epoch [25/200]	BT 1.609 (1.609)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.3011 (11.3011)
The penalty weight is 0.691069
Train - epoch [34/200]	BT 1.170 (1.170)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 13.5613 (13.5613)
Train - epoch [34/200]	BT 1.148 (1.148)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 12.7814 (12.7814)
Train - epoch [25/200]	BT 1.510 (1.510)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.1385 (11.1385)
Train - epoch [34/200]	BT 1.056 (1.056)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.7940 (13.7940)
Train - epoch [34/200]	BT 1.230 (1.230)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.2982 (13.2982)
Train - epoch [25/200]	BT 2.083 (2.083)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.2448 (11.2448)
Train - epoch [25/200]	BT 1.144 (1.144)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.0747 (10.0747)
Train - epoch [34/200]	BT 1.015 (1.015)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.6619 (13.6619)
Train - epoch [34/200]	BT 1.215 (1.215)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 13.6542 (13.6542)
Train - epoch [34/200]	BT 1.354 (1.354)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.5183 (13.5183)
Test on T training set - [25][0/45]	T 0.517 (0.517)	D 0.403 (0.403)	T@1 87.302 (87.302)	T@5 98.413 (98.413)	L 0.6556 (0.6556)
Test on T training set - [25][10/45]	T 0.338 (0.351)	D 0.214 (0.232)	T@1 28.571 (79.509)	T@5 63.492 (92.063)	L 2.6895 (0.8773)
Test on T training set - [25][20/45]	T 0.333 (0.344)	D 0.217 (0.225)	T@1 84.127 (75.283)	T@5 100.000 (90.098)	L 0.6073 (1.0494)
Test on T training set - [25][30/45]	T 0.329 (0.365)	D 0.210 (0.245)	T@1 77.778 (73.938)	T@5 95.238 (89.964)	L 1.0444 (1.0831)
Test on T training set - [25][40/45]	T 0.351 (0.359)	D 0.233 (0.240)	T@1 41.270 (69.144)	T@5 80.952 (85.714)	L 1.9967 (1.2987)
 * Test on T training set - Prec@1 66.809, Prec@5 85.233
Test on T test set - [25][0/45]	Time 0.516 (0.516)	Loss 0.6556 (0.6556)	Prec@1 87.302 (87.302)	Prec@5 98.413 (98.413)
Test on T test set - [25][10/45]	Time 0.328 (0.341)	Loss 2.6895 (0.8773)	Prec@1 28.571 (79.509)	Prec@5 63.492 (92.063)
Test on T test set - [25][20/45]	Time 0.319 (0.334)	Loss 0.6073 (1.0494)	Prec@1 84.127 (75.283)	Prec@5 100.000 (90.098)
Test on T test set - [25][30/45]	Time 0.336 (0.332)	Loss 1.0444 (1.0831)	Prec@1 77.778 (73.938)	Prec@5 95.238 (89.964)
Test on T test set - [25][40/45]	Time 0.330 (0.329)	Loss 1.9967 (1.2987)	Prec@1 41.270 (69.144)	Prec@5 80.952 (85.714)
 * Test on T test set - Prec@1 66.809, Prec@5 85.233
Epoch 25, K-means clustering 0, Average clustering time 0.027, Prec@1 72.595
Epoch 25, K-means clustering 1, Average clustering time 0.093, Prec@1 74.050
Epoch 25, K-means clustering 2, Average clustering time 0.098, Prec@1 74.228
Epoch 25, K-means clustering 3, Average clustering time 0.098, Prec@1 74.086
Epoch 25, K-means clustering 4, Average clustering time 0.100, Prec@1 74.015
Epoch 25, K-means clustering 0, Average clustering time 0.003, Prec@1 71.778
Epoch 25, K-means clustering 1, Average clustering time 0.049, Prec@1 72.453
Epoch 25, K-means clustering 2, Average clustering time 0.061, Prec@1 72.701
Epoch 25, K-means clustering 3, Average clustering time 0.080, Prec@1 73.234
Epoch 25, K-means clustering 4, Average clustering time 0.082, Prec@1 73.340
Test on T training set - [34][0/13]	T 0.734 (0.734)	D 0.605 (0.605)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1262 (0.1262)
Test on T training set - [34][10/13]	T 0.518 (0.539)	D 0.391 (0.416)	T@1 66.667 (84.416)	T@5 100.000 (96.825)	L 0.9225 (0.6296)
 * Test on T training set - Prec@1 84.403, Prec@5 96.981
Test on T test set - [34][0/13]	Time 0.991 (0.991)	Loss 0.1262 (0.1262)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [34][10/13]	Time 0.507 (0.573)	Loss 0.9225 (0.6296)	Prec@1 66.667 (84.416)	Prec@5 100.000 (96.825)
 * Test on T test set - Prec@1 84.403, Prec@5 96.981
Epoch 34, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 34, K-means clustering 1, Average clustering time 0.077, Prec@1 88.428
Epoch 34, K-means clustering 2, Average clustering time 0.080, Prec@1 88.302
Epoch 34, K-means clustering 3, Average clustering time 0.117, Prec@1 88.302
Epoch 34, K-means clustering 4, Average clustering time 0.112, Prec@1 88.302
Epoch 34, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 34, K-means clustering 1, Average clustering time 0.043, Prec@1 88.428
Epoch 34, K-means clustering 2, Average clustering time 0.056, Prec@1 88.176
Epoch 34, K-means clustering 3, Average clustering time 0.064, Prec@1 88.176
Epoch 34, K-means clustering 4, Average clustering time 0.068, Prec@1 88.176
The penalty weight is 0.571670
Train - epoch [26/200]	BT 2.296 (2.296)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.9637 (10.9637)
The penalty weight is 0.703906
Train - epoch [35/200]	BT 1.193 (1.193)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.2664 (14.2664)
Train - epoch [35/200]	BT 1.081 (1.081)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 13.8068 (13.8068)
Train - epoch [26/200]	BT 1.492 (1.492)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.7329 (10.7329)
Train - epoch [26/200]	BT 1.503 (1.503)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.0116 (11.0116)
Train - epoch [35/200]	BT 1.096 (1.096)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 12.9304 (12.9304)
Train - epoch [35/200]	BT 0.997 (0.997)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.3737 (14.3737)
Train - epoch [26/200]	BT 1.506 (1.506)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.1560 (10.1560)
Train - epoch [35/200]	BT 1.086 (1.086)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 12.6588 (12.6588)
Train - epoch [26/200]	BT 1.565 (1.565)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.6059 (11.6059)
Train - epoch [35/200]	BT 1.115 (1.115)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 12.8484 (12.8484)
Train - epoch [35/200]	BT 1.134 (1.134)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 14.2762 (14.2762)
Train - epoch [26/200]	BT 1.522 (1.522)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.4439 (11.4439)
Test on T training set - [35][0/13]	T 0.745 (0.745)	D 0.624 (0.624)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1406 (0.1406)
Test on T training set - [35][10/13]	T 0.517 (0.517)	D 0.402 (0.397)	T@1 69.841 (84.993)	T@5 100.000 (97.403)	L 0.8543 (0.6151)
 * Test on T training set - Prec@1 84.906, Prec@5 97.484
Test on T test set - [35][0/13]	Time 0.730 (0.730)	Loss 0.1406 (0.1406)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [35][10/13]	Time 0.533 (0.521)	Loss 0.8543 (0.6151)	Prec@1 69.841 (84.993)	Prec@5 100.000 (97.403)
 * Test on T test set - Prec@1 84.906, Prec@5 97.484
Epoch 35, K-means clustering 0, Average clustering time 0.018, Prec@1 89.182
Epoch 35, K-means clustering 1, Average clustering time 0.091, Prec@1 88.302
Epoch 35, K-means clustering 2, Average clustering time 0.088, Prec@1 87.799
Epoch 35, K-means clustering 3, Average clustering time 0.087, Prec@1 87.799
Epoch 35, K-means clustering 4, Average clustering time 0.087, Prec@1 87.799
Epoch 35, K-means clustering 0, Average clustering time 0.001, Prec@1 88.931
Epoch 35, K-means clustering 1, Average clustering time 0.038, Prec@1 88.679
Epoch 35, K-means clustering 2, Average clustering time 0.051, Prec@1 88.050
Epoch 35, K-means clustering 3, Average clustering time 0.062, Prec@1 88.050
Epoch 35, K-means clustering 4, Average clustering time 0.065, Prec@1 88.050
Test on T training set - [26][0/45]	T 0.499 (0.499)	D 0.379 (0.379)	T@1 88.889 (88.889)	T@5 98.413 (98.413)	L 0.6756 (0.6756)
Test on T training set - [26][10/45]	T 0.322 (0.344)	D 0.201 (0.223)	T@1 26.984 (78.499)	T@5 60.317 (91.631)	L 2.7146 (0.9044)
Test on T training set - [26][20/45]	T 0.331 (0.397)	D 0.218 (0.277)	T@1 88.889 (75.435)	T@5 100.000 (90.098)	L 0.5855 (1.0569)
Test on T training set - [26][30/45]	T 0.340 (0.379)	D 0.218 (0.259)	T@1 71.429 (73.784)	T@5 92.063 (89.708)	L 1.2404 (1.0982)
Test on T training set - [26][40/45]	T 0.347 (0.369)	D 0.222 (0.249)	T@1 39.683 (69.299)	T@5 80.952 (85.676)	L 2.1319 (1.3060)
 * Test on T training set - Prec@1 66.951, Prec@5 85.020
The penalty weight is 0.716298
Train - epoch [36/200]	BT 1.654 (1.654)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 13.7007 (13.7007)
Test on T test set - [26][0/45]	Time 0.772 (0.772)	Loss 0.6756 (0.6756)	Prec@1 88.889 (88.889)	Prec@5 98.413 (98.413)
Test on T test set - [26][10/45]	Time 0.324 (0.364)	Loss 2.7146 (0.9044)	Prec@1 26.984 (78.499)	Prec@5 60.317 (91.631)
Test on T test set - [26][20/45]	Time 0.326 (0.352)	Loss 0.5855 (1.0569)	Prec@1 88.889 (75.435)	Prec@5 100.000 (90.098)
Test on T test set - [26][30/45]	Time 0.339 (0.346)	Loss 1.2404 (1.0982)	Prec@1 71.429 (73.784)	Prec@5 92.063 (89.708)
Test on T test set - [26][40/45]	Time 0.341 (0.344)	Loss 2.1319 (1.3060)	Prec@1 39.683 (69.299)	Prec@5 80.952 (85.676)
 * Test on T test set - Prec@1 66.951, Prec@5 85.020
Epoch 26, K-means clustering 0, Average clustering time 0.029, Prec@1 73.340
Epoch 26, K-means clustering 1, Average clustering time 0.098, Prec@1 74.015
Epoch 26, K-means clustering 2, Average clustering time 0.113, Prec@1 74.334
Epoch 26, K-means clustering 3, Average clustering time 0.112, Prec@1 74.121
Epoch 26, K-means clustering 4, Average clustering time 0.114, Prec@1 73.802
Epoch 26, K-means clustering 0, Average clustering time 0.003, Prec@1 71.530
Epoch 26, K-means clustering 1, Average clustering time 0.058, Prec@1 71.956
Epoch 26, K-means clustering 2, Average clustering time 0.069, Prec@1 72.488
Epoch 26, K-means clustering 3, Average clustering time 0.072, Prec@1 72.559
Epoch 26, K-means clustering 4, Average clustering time 0.083, Prec@1 72.595
Train - epoch [36/200]	BT 1.588 (1.588)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 13.2770 (13.2770)
Train - epoch [36/200]	BT 1.153 (1.153)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 13.2569 (13.2569)
The penalty weight is 0.588259
Train - epoch [27/200]	BT 1.478 (1.478)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.8467 (10.8467)
Train - epoch [36/200]	BT 1.074 (1.074)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.0449 (14.0449)
Train - epoch [36/200]	BT 1.108 (1.108)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.0691 (14.0691)
Train - epoch [27/200]	BT 2.101 (2.101)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.5442 (10.5442)
Train - epoch [27/200]	BT 1.447 (1.447)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.2968 (10.2968)
Train - epoch [36/200]	BT 1.200 (1.200)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.3853 (14.3853)
Train - epoch [27/200]	BT 1.558 (1.558)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.4499 (11.4499)
Train - epoch [27/200]	BT 1.577 (1.577)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.8256 (11.8256)
Test on T training set - [36][0/13]	T 0.757 (0.757)	D 0.633 (0.633)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1679 (0.1679)
Test on T training set - [36][10/13]	T 0.491 (0.547)	D 0.370 (0.426)	T@1 60.317 (84.416)	T@5 100.000 (97.403)	L 0.9792 (0.6335)
 * Test on T training set - Prec@1 84.654, Prec@5 97.484
Test on T test set - [36][0/13]	Time 0.789 (0.789)	Loss 0.1679 (0.1679)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [36][10/13]	Time 0.524 (0.553)	Loss 0.9792 (0.6335)	Prec@1 60.317 (84.416)	Prec@5 100.000 (97.403)
 * Test on T test set - Prec@1 84.654, Prec@5 97.484
Epoch 36, K-means clustering 0, Average clustering time 0.018, Prec@1 88.553
Epoch 36, K-means clustering 1, Average clustering time 0.081, Prec@1 88.176
Epoch 36, K-means clustering 2, Average clustering time 0.088, Prec@1 87.799
Epoch 36, K-means clustering 3, Average clustering time 0.090, Prec@1 87.799
Epoch 36, K-means clustering 4, Average clustering time 0.092, Prec@1 87.799
Epoch 36, K-means clustering 0, Average clustering time 0.001, Prec@1 88.176
Epoch 36, K-means clustering 1, Average clustering time 0.043, Prec@1 88.302
Epoch 36, K-means clustering 2, Average clustering time 0.056, Prec@1 88.050
Epoch 36, K-means clustering 3, Average clustering time 0.067, Prec@1 88.050
Epoch 36, K-means clustering 4, Average clustering time 0.070, Prec@1 88.050
Train - epoch [27/200]	BT 1.548 (1.548)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 10.8161 (10.8161)
The penalty weight is 0.728254
Train - epoch [37/200]	BT 0.973 (0.973)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.7133 (14.7133)
Train - epoch [37/200]	BT 1.217 (1.217)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.6692 (12.6692)
Train - epoch [27/200]	BT 1.519 (1.519)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.3361 (11.3361)
Train - epoch [37/200]	BT 1.156 (1.156)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.2553 (14.2553)
Train - epoch [37/200]	BT 1.070 (1.070)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 13.2123 (13.2123)
Test on T training set - [27][0/45]	T 0.583 (0.583)	D 0.450 (0.450)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6994 (0.6994)
Test on T training set - [27][10/45]	T 0.672 (0.386)	D 0.550 (0.266)	T@1 26.984 (79.365)	T@5 61.905 (91.631)	L 2.6830 (0.8997)
Test on T training set - [27][20/45]	T 0.329 (0.365)	D 0.214 (0.246)	T@1 90.476 (75.435)	T@5 100.000 (89.418)	L 0.5214 (1.0648)
Test on T training set - [27][30/45]	T 0.349 (0.356)	D 0.225 (0.236)	T@1 74.603 (74.296)	T@5 95.238 (89.452)	L 1.1157 (1.0901)
Test on T training set - [27][40/45]	T 0.338 (0.361)	D 0.218 (0.241)	T@1 39.683 (69.493)	T@5 80.952 (85.288)	L 2.1232 (1.3036)
 * Test on T training set - Prec@1 67.022, Prec@5 84.771
Train - epoch [37/200]	BT 0.996 (0.996)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 14.7091 (14.7091)
Train - epoch [37/200]	BT 1.384 (1.384)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.5118 (14.5118)
Test on T test set - [27][0/45]	Time 0.729 (0.729)	Loss 0.6994 (0.6994)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [27][10/45]	Time 0.320 (0.366)	Loss 2.6830 (0.8997)	Prec@1 26.984 (79.365)	Prec@5 61.905 (91.631)
Test on T test set - [27][20/45]	Time 0.325 (0.366)	Loss 0.5214 (1.0648)	Prec@1 90.476 (75.435)	Prec@5 100.000 (89.418)
Test on T test set - [27][30/45]	Time 0.344 (0.361)	Loss 1.1157 (1.0901)	Prec@1 74.603 (74.296)	Prec@5 95.238 (89.452)
Test on T test set - [27][40/45]	Time 0.325 (0.354)	Loss 2.1232 (1.3036)	Prec@1 39.683 (69.493)	Prec@5 80.952 (85.288)
 * Test on T test set - Prec@1 67.022, Prec@5 84.771
Epoch 27, K-means clustering 0, Average clustering time 0.027, Prec@1 73.198
Epoch 27, K-means clustering 1, Average clustering time 0.093, Prec@1 74.086
Epoch 27, K-means clustering 2, Average clustering time 0.104, Prec@1 74.441
Epoch 27, K-means clustering 3, Average clustering time 0.102, Prec@1 74.121
Epoch 27, K-means clustering 4, Average clustering time 0.103, Prec@1 73.979
Epoch 27, K-means clustering 0, Average clustering time 0.003, Prec@1 71.778
Epoch 27, K-means clustering 1, Average clustering time 0.040, Prec@1 72.701
Epoch 27, K-means clustering 2, Average clustering time 0.061, Prec@1 72.879
Epoch 27, K-means clustering 3, Average clustering time 0.070, Prec@1 73.056
Epoch 27, K-means clustering 4, Average clustering time 0.074, Prec@1 73.234
Train - epoch [37/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 12.9948 (12.9948)
The penalty weight is 0.604368
Train - epoch [28/200]	BT 1.473 (1.473)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.0214 (12.0214)
Test on T training set - [37][0/13]	T 0.769 (0.769)	D 0.640 (0.640)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1580 (0.1580)
Test on T training set - [37][10/13]	T 0.524 (0.536)	D 0.409 (0.414)	T@1 68.254 (84.704)	T@5 98.413 (96.970)	L 0.9292 (0.6421)
 * Test on T training set - Prec@1 84.528, Prec@5 97.107
Train - epoch [28/200]	BT 1.558 (1.558)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.6408 (11.6408)
Test on T test set - [37][0/13]	Time 0.936 (0.936)	Loss 0.1580 (0.1580)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [37][10/13]	Time 0.523 (0.559)	Loss 0.9292 (0.6421)	Prec@1 68.254 (84.704)	Prec@5 98.413 (96.970)
 * Test on T test set - Prec@1 84.528, Prec@5 97.107
Epoch 37, K-means clustering 0, Average clustering time 0.019, Prec@1 88.428
Epoch 37, K-means clustering 1, Average clustering time 0.076, Prec@1 87.799
Epoch 37, K-means clustering 2, Average clustering time 0.081, Prec@1 87.547
Epoch 37, K-means clustering 3, Average clustering time 0.084, Prec@1 87.673
Epoch 37, K-means clustering 4, Average clustering time 0.086, Prec@1 87.673
Epoch 37, K-means clustering 0, Average clustering time 0.001, Prec@1 88.805
Epoch 37, K-means clustering 1, Average clustering time 0.042, Prec@1 88.302
Epoch 37, K-means clustering 2, Average clustering time 0.056, Prec@1 88.176
Epoch 37, K-means clustering 3, Average clustering time 0.065, Prec@1 88.302
Epoch 37, K-means clustering 4, Average clustering time 0.070, Prec@1 88.302
Train - epoch [28/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.0181 (12.0181)
The penalty weight is 0.739783
Train - epoch [38/200]	BT 1.159 (1.159)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.2037 (15.2037)
Train - epoch [38/200]	BT 1.089 (1.089)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 13.4007 (13.4007)
Train - epoch [28/200]	BT 1.517 (1.517)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.2122 (12.2122)
Train - epoch [38/200]	BT 1.177 (1.177)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 12.9661 (12.9661)
Train - epoch [38/200]	BT 1.181 (1.181)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 14.8992 (14.8992)
Train - epoch [28/200]	BT 2.078 (2.078)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.9203 (11.9203)
Train - epoch [28/200]	BT 1.471 (1.471)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.9096 (11.9096)
Train - epoch [28/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.8855 (11.8855)
Train - epoch [38/200]	BT 1.313 (1.313)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.5399 (14.5399)
Train - epoch [38/200]	BT 1.650 (1.650)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.1200 (14.1200)
Train - epoch [38/200]	BT 1.098 (1.098)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.9906 (13.9906)
Test on T training set - [28][0/45]	T 0.529 (0.529)	D 0.412 (0.412)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6797 (0.6797)
Test on T training set - [28][10/45]	T 0.352 (0.365)	D 0.240 (0.245)	T@1 30.159 (79.221)	T@5 63.492 (91.631)	L 2.6400 (0.9023)
Test on T training set - [28][20/45]	T 0.323 (0.350)	D 0.211 (0.231)	T@1 87.302 (76.342)	T@5 100.000 (90.023)	L 0.5572 (1.0298)
Test on T training set - [28][30/45]	T 0.348 (0.345)	D 0.232 (0.226)	T@1 77.778 (74.962)	T@5 93.651 (89.657)	L 1.0349 (1.0693)
Test on T training set - [28][40/45]	T 0.306 (0.347)	D 0.193 (0.229)	T@1 41.270 (70.151)	T@5 79.365 (85.443)	L 2.1106 (1.2864)
 * Test on T training set - Prec@1 67.661, Prec@5 84.771
Test on T training set - [38][0/13]	T 0.754 (0.754)	D 0.639 (0.639)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1305 (0.1305)
Test on T training set - [38][10/13]	T 0.500 (0.521)	D 0.382 (0.404)	T@1 65.079 (85.281)	T@5 98.413 (97.547)	L 0.9111 (0.6072)
 * Test on T training set - Prec@1 85.157, Prec@5 97.610
Test on T test set - [28][0/45]	Time 0.508 (0.508)	Loss 0.6797 (0.6797)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [28][10/45]	Time 0.318 (0.343)	Loss 2.6400 (0.9023)	Prec@1 30.159 (79.221)	Prec@5 63.492 (91.631)
Test on T test set - [28][20/45]	Time 0.339 (0.336)	Loss 0.5572 (1.0298)	Prec@1 87.302 (76.342)	Prec@5 100.000 (90.023)
Test on T test set - [28][30/45]	Time 0.332 (0.335)	Loss 1.0349 (1.0693)	Prec@1 77.778 (74.962)	Prec@5 93.651 (89.657)
Test on T test set - [28][40/45]	Time 0.321 (0.334)	Loss 2.1106 (1.2864)	Prec@1 41.270 (70.151)	Prec@5 79.365 (85.443)
 * Test on T test set - Prec@1 67.661, Prec@5 84.771
Epoch 28, K-means clustering 0, Average clustering time 0.027, Prec@1 73.092
Epoch 28, K-means clustering 1, Average clustering time 0.093, Prec@1 73.944
Epoch 28, K-means clustering 2, Average clustering time 0.096, Prec@1 74.121
Epoch 28, K-means clustering 3, Average clustering time 0.099, Prec@1 74.015
Epoch 28, K-means clustering 4, Average clustering time 0.098, Prec@1 73.873
Epoch 28, K-means clustering 0, Average clustering time 0.003, Prec@1 71.778
Epoch 28, K-means clustering 1, Average clustering time 0.056, Prec@1 72.346
Epoch 28, K-means clustering 2, Average clustering time 0.066, Prec@1 72.737
Epoch 28, K-means clustering 3, Average clustering time 0.079, Prec@1 72.772
Epoch 28, K-means clustering 4, Average clustering time 0.080, Prec@1 72.524
Test on T test set - [38][0/13]	Time 0.786 (0.786)	Loss 0.1305 (0.1305)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [38][10/13]	Time 0.520 (0.549)	Loss 0.9111 (0.6072)	Prec@1 65.079 (85.281)	Prec@5 98.413 (97.547)
 * Test on T test set - Prec@1 85.157, Prec@5 97.610
Epoch 38, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 38, K-means clustering 1, Average clustering time 0.086, Prec@1 88.428
Epoch 38, K-means clustering 2, Average clustering time 0.094, Prec@1 88.176
Epoch 38, K-means clustering 3, Average clustering time 0.102, Prec@1 88.176
Epoch 38, K-means clustering 4, Average clustering time 0.104, Prec@1 88.176
Epoch 38, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 38, K-means clustering 1, Average clustering time 0.039, Prec@1 88.302
Epoch 38, K-means clustering 2, Average clustering time 0.052, Prec@1 88.302
Epoch 38, K-means clustering 3, Average clustering time 0.059, Prec@1 88.302
Epoch 38, K-means clustering 4, Average clustering time 0.063, Prec@1 88.302
The penalty weight is 0.619997
Train - epoch [29/200]	BT 1.481 (1.481)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.4907 (12.4907)
The penalty weight is 0.750893
Train - epoch [39/200]	BT 1.118 (1.118)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 14.4602 (14.4602)
Train - epoch [39/200]	BT 1.038 (1.038)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 14.5646 (14.5646)
Train - epoch [29/200]	BT 1.538 (1.538)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.3475 (12.3475)
Train - epoch [39/200]	BT 1.174 (1.174)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.0458 (15.0458)
Train - epoch [29/200]	BT 1.471 (1.471)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.5071 (12.5071)
Train - epoch [39/200]	BT 1.030 (1.030)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.7811 (14.7811)
Train - epoch [39/200]	BT 1.171 (1.171)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.1698 (14.1698)
Train - epoch [29/200]	BT 1.527 (1.527)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.4240 (12.4240)
Train - epoch [39/200]	BT 1.069 (1.069)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 15.3536 (15.3536)
Train - epoch [29/200]	BT 1.525 (1.525)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.1428 (11.1428)
Train - epoch [29/200]	BT 1.495 (1.495)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.4841 (12.4841)
Test on T training set - [39][0/13]	T 0.763 (0.763)	D 0.632 (0.632)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1280 (0.1280)
Test on T training set - [39][10/13]	T 0.528 (0.522)	D 0.402 (0.400)	T@1 63.492 (84.704)	T@5 98.413 (96.970)	L 0.9242 (0.6295)
 * Test on T training set - Prec@1 84.906, Prec@5 97.107
Test on T test set - [39][0/13]	Time 0.749 (0.749)	Loss 0.1280 (0.1280)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [39][10/13]	Time 0.521 (0.521)	Loss 0.9242 (0.6295)	Prec@1 63.492 (84.704)	Prec@5 98.413 (96.970)
 * Test on T test set - Prec@1 84.906, Prec@5 97.107
Epoch 39, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 39, K-means clustering 1, Average clustering time 0.081, Prec@1 88.050
Epoch 39, K-means clustering 2, Average clustering time 0.084, Prec@1 88.050
Epoch 39, K-means clustering 3, Average clustering time 0.085, Prec@1 88.050
Epoch 39, K-means clustering 4, Average clustering time 0.092, Prec@1 88.050
Epoch 39, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 39, K-means clustering 1, Average clustering time 0.044, Prec@1 88.176
Epoch 39, K-means clustering 2, Average clustering time 0.058, Prec@1 87.799
Epoch 39, K-means clustering 3, Average clustering time 0.066, Prec@1 87.799
Epoch 39, K-means clustering 4, Average clustering time 0.071, Prec@1 87.925
Test on T training set - [29][0/45]	T 0.503 (0.503)	D 0.386 (0.386)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6721 (0.6721)
Test on T training set - [29][10/45]	T 0.322 (0.347)	D 0.209 (0.229)	T@1 26.984 (78.355)	T@5 61.905 (91.342)	L 2.7247 (0.9100)
Test on T training set - [29][20/45]	T 0.356 (0.348)	D 0.237 (0.230)	T@1 88.889 (75.283)	T@5 100.000 (89.796)	L 0.5276 (1.0725)
Test on T training set - [29][30/45]	T 0.321 (0.343)	D 0.209 (0.225)	T@1 74.603 (74.552)	T@5 95.238 (89.964)	L 1.1174 (1.0859)
Test on T training set - [29][40/45]	T 0.344 (0.342)	D 0.228 (0.224)	T@1 39.683 (69.686)	T@5 82.540 (85.908)	L 2.0693 (1.3011)
 * Test on T training set - Prec@1 67.199, Prec@5 85.162
Train - epoch [40/200]	BT 1.236 (1.236)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 13.8061 (13.8061)
The penalty weight is 0.761594
Train - epoch [40/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.3462 (15.3462)
Test on T test set - [29][0/45]	Time 0.505 (0.505)	Loss 0.6721 (0.6721)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [29][10/45]	Time 0.315 (0.346)	Loss 2.7247 (0.9100)	Prec@1 26.984 (78.355)	Prec@5 61.905 (91.342)
Test on T test set - [29][20/45]	Time 0.349 (0.345)	Loss 0.5276 (1.0725)	Prec@1 88.889 (75.283)	Prec@5 100.000 (89.796)
Test on T test set - [29][30/45]	Time 0.350 (0.342)	Loss 1.1174 (1.0859)	Prec@1 74.603 (74.552)	Prec@5 95.238 (89.964)
Test on T test set - [29][40/45]	Time 0.334 (0.342)	Loss 2.0693 (1.3011)	Prec@1 39.683 (69.686)	Prec@5 82.540 (85.908)
 * Test on T test set - Prec@1 67.199, Prec@5 85.162
Epoch 29, K-means clustering 0, Average clustering time 0.027, Prec@1 73.198
Epoch 29, K-means clustering 1, Average clustering time 0.101, Prec@1 73.873
Epoch 29, K-means clustering 2, Average clustering time 0.105, Prec@1 73.873
Epoch 29, K-means clustering 3, Average clustering time 0.110, Prec@1 74.050
Epoch 29, K-means clustering 4, Average clustering time 0.109, Prec@1 73.802
Epoch 29, K-means clustering 0, Average clustering time 0.003, Prec@1 72.062
Epoch 29, K-means clustering 1, Average clustering time 0.049, Prec@1 72.737
Epoch 29, K-means clustering 2, Average clustering time 0.068, Prec@1 72.772
Epoch 29, K-means clustering 3, Average clustering time 0.078, Prec@1 72.808
Epoch 29, K-means clustering 4, Average clustering time 0.087, Prec@1 73.092
Train - epoch [40/200]	BT 1.027 (1.027)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.7796 (14.7796)
Train - epoch [40/200]	BT 1.089 (1.089)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.3526 (14.3526)
Train - epoch [30/200]	BT 1.669 (1.669)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.3377 (12.3377)
The penalty weight is 0.635149
Train - epoch [30/200]	BT 1.431 (1.431)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.7161 (11.7161)
Train - epoch [40/200]	BT 1.335 (1.335)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 14.3300 (14.3300)
Train - epoch [40/200]	BT 1.024 (1.024)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.1325 (15.1325)
Train - epoch [30/200]	BT 1.469 (1.469)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.3986 (11.3986)
Train - epoch [40/200]	BT 1.113 (1.113)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 14.9859 (14.9859)
Train - epoch [30/200]	BT 1.496 (1.496)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.2884 (12.2884)
Test on T training set - [40][0/13]	T 0.754 (0.754)	D 0.624 (0.624)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1154 (0.1154)
Test on T training set - [40][10/13]	T 0.533 (0.521)	D 0.406 (0.398)	T@1 63.492 (84.993)	T@5 100.000 (97.547)	L 0.9220 (0.6116)
 * Test on T training set - Prec@1 85.157, Prec@5 97.610
Train - epoch [30/200]	BT 1.507 (1.507)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.4950 (11.4950)
Test on T test set - [40][0/13]	Time 0.747 (0.747)	Loss 0.1154 (0.1154)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [40][10/13]	Time 0.511 (0.521)	Loss 0.9220 (0.6116)	Prec@1 63.492 (84.993)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 85.157, Prec@5 97.610
Epoch 40, K-means clustering 0, Average clustering time 0.018, Prec@1 88.553
Epoch 40, K-means clustering 1, Average clustering time 0.090, Prec@1 88.050
Epoch 40, K-means clustering 2, Average clustering time 0.089, Prec@1 88.050
Epoch 40, K-means clustering 3, Average clustering time 0.095, Prec@1 88.050
Epoch 40, K-means clustering 4, Average clustering time 0.094, Prec@1 88.050
Epoch 40, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 40, K-means clustering 1, Average clustering time 0.038, Prec@1 88.176
Epoch 40, K-means clustering 2, Average clustering time 0.051, Prec@1 88.428
Epoch 40, K-means clustering 3, Average clustering time 0.057, Prec@1 88.428
Epoch 40, K-means clustering 4, Average clustering time 0.061, Prec@1 88.302
Train - epoch [30/200]	BT 1.523 (1.523)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.5387 (12.5387)
The penalty weight is 0.771895
Train - epoch [41/200]	BT 1.352 (1.352)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.5376 (14.5376)
Train - epoch [41/200]	BT 1.103 (1.103)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 14.3444 (14.3444)
Train - epoch [30/200]	BT 1.482 (1.482)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 11.5525 (11.5525)
Train - epoch [41/200]	BT 1.157 (1.157)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 13.9252 (13.9252)
Train - epoch [41/200]	BT 1.306 (1.306)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 13.9975 (13.9975)
Test on T training set - [30][0/45]	T 0.532 (0.532)	D 0.409 (0.409)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6691 (0.6691)
Test on T training set - [30][10/45]	T 0.336 (0.350)	D 0.212 (0.230)	T@1 28.571 (78.499)	T@5 57.143 (90.765)	L 2.7771 (0.9212)
Test on T training set - [30][20/45]	T 0.332 (0.341)	D 0.215 (0.222)	T@1 87.302 (75.510)	T@5 100.000 (89.191)	L 0.5701 (1.0704)
Test on T training set - [30][30/45]	T 0.366 (0.354)	D 0.245 (0.235)	T@1 74.603 (74.552)	T@5 92.063 (89.503)	L 1.2029 (1.0857)
Test on T training set - [30][40/45]	T 0.323 (0.349)	D 0.198 (0.230)	T@1 42.857 (70.267)	T@5 79.365 (85.172)	L 2.0475 (1.3021)
 * Test on T training set - Prec@1 67.732, Prec@5 84.487
Train - epoch [41/200]	BT 1.113 (1.113)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 13.6789 (13.6789)
Train - epoch [41/200]	BT 1.062 (1.062)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.6419 (14.6419)
Test on T test set - [30][0/45]	Time 0.529 (0.529)	Loss 0.6691 (0.6691)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [30][10/45]	Time 0.316 (0.346)	Loss 2.7771 (0.9212)	Prec@1 28.571 (78.499)	Prec@5 57.143 (90.765)
Test on T test set - [30][20/45]	Time 0.342 (0.340)	Loss 0.5701 (1.0704)	Prec@1 87.302 (75.510)	Prec@5 100.000 (89.191)
Test on T test set - [30][30/45]	Time 0.348 (0.340)	Loss 1.2029 (1.0857)	Prec@1 74.603 (74.552)	Prec@5 92.063 (89.503)
Test on T test set - [30][40/45]	Time 0.322 (0.338)	Loss 2.0475 (1.3021)	Prec@1 42.857 (70.267)	Prec@5 79.365 (85.172)
 * Test on T test set - Prec@1 67.732, Prec@5 84.487
Epoch 30, K-means clustering 0, Average clustering time 0.027, Prec@1 73.340
Epoch 30, K-means clustering 1, Average clustering time 0.087, Prec@1 73.979
Epoch 30, K-means clustering 2, Average clustering time 0.090, Prec@1 74.050
Epoch 30, K-means clustering 3, Average clustering time 0.092, Prec@1 73.979
Epoch 30, K-means clustering 4, Average clustering time 0.097, Prec@1 73.802
Epoch 30, K-means clustering 0, Average clustering time 0.003, Prec@1 72.595
Epoch 30, K-means clustering 1, Average clustering time 0.060, Prec@1 73.127
Epoch 30, K-means clustering 2, Average clustering time 0.069, Prec@1 73.269
Epoch 30, K-means clustering 3, Average clustering time 0.080, Prec@1 73.447
Epoch 30, K-means clustering 4, Average clustering time 0.083, Prec@1 73.482
Train - epoch [41/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.0100 (15.0100)
The penalty weight is 0.649827
Train - epoch [31/200]	BT 1.605 (1.605)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.6688 (12.6688)
Test on T training set - [41][0/13]	T 0.773 (0.773)	D 0.643 (0.643)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1602 (0.1602)
Test on T training set - [41][10/13]	T 0.529 (0.525)	D 0.408 (0.404)	T@1 68.254 (85.281)	T@5 100.000 (97.258)	L 0.8760 (0.6184)
 * Test on T training set - Prec@1 85.535, Prec@5 97.358
Train - epoch [31/200]	BT 1.536 (1.536)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.1997 (13.1997)
Test on T test set - [41][0/13]	Time 0.737 (0.737)	Loss 0.1602 (0.1602)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [41][10/13]	Time 0.540 (0.529)	Loss 0.8760 (0.6184)	Prec@1 68.254 (85.281)	Prec@5 100.000 (97.258)
 * Test on T test set - Prec@1 85.535, Prec@5 97.358
Epoch 41, K-means clustering 0, Average clustering time 0.018, Prec@1 89.182
Epoch 41, K-means clustering 1, Average clustering time 0.080, Prec@1 88.302
Epoch 41, K-means clustering 2, Average clustering time 0.084, Prec@1 87.799
Epoch 41, K-means clustering 3, Average clustering time 0.085, Prec@1 87.673
Epoch 41, K-means clustering 4, Average clustering time 0.087, Prec@1 87.547
Epoch 41, K-means clustering 0, Average clustering time 0.001, Prec@1 88.679
Epoch 41, K-means clustering 1, Average clustering time 0.046, Prec@1 88.428
Epoch 41, K-means clustering 2, Average clustering time 0.061, Prec@1 88.176
Epoch 41, K-means clustering 3, Average clustering time 0.070, Prec@1 88.176
Epoch 41, K-means clustering 4, Average clustering time 0.072, Prec@1 88.176
Train - epoch [31/200]	BT 1.432 (1.432)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.4213 (12.4213)
The penalty weight is 0.781806
Train - epoch [42/200]	BT 1.037 (1.037)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.2485 (15.2485)
Train - epoch [42/200]	BT 1.100 (1.100)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.6290 (15.6290)
Train - epoch [31/200]	BT 1.994 (1.994)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.8171 (12.8171)
Train - epoch [31/200]	BT 1.481 (1.481)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.6959 (12.6959)
Train - epoch [42/200]	BT 1.143 (1.143)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 15.1768 (15.1768)
Train - epoch [31/200]	BT 1.515 (1.515)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.3197 (12.3197)
Train - epoch [42/200]	BT 1.687 (1.687)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.5485 (15.5485)
Train - epoch [42/200]	BT 1.197 (1.197)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.5545 (15.5545)
Train - epoch [31/200]	BT 1.511 (1.511)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.6928 (12.6928)
Train - epoch [42/200]	BT 1.103 (1.103)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.0228 (15.0228)
Train - epoch [42/200]	BT 1.039 (1.039)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.9001 (14.9001)
Test on T training set - [31][0/45]	T 0.507 (0.507)	D 0.392 (0.392)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6575 (0.6575)
Test on T training set - [31][10/45]	T 0.341 (0.374)	D 0.229 (0.256)	T@1 26.984 (79.509)	T@5 63.492 (91.342)	L 2.6718 (0.8997)
Test on T training set - [31][20/45]	T 0.336 (0.374)	D 0.214 (0.255)	T@1 87.302 (76.190)	T@5 100.000 (90.023)	L 0.5893 (1.0418)
Test on T training set - [31][30/45]	T 0.341 (0.364)	D 0.228 (0.245)	T@1 79.365 (75.013)	T@5 95.238 (90.169)	L 0.9685 (1.0654)
Test on T training set - [31][40/45]	T 0.348 (0.360)	D 0.224 (0.241)	T@1 42.857 (70.383)	T@5 80.952 (85.676)	L 2.0163 (1.2867)
 * Test on T training set - Prec@1 67.767, Prec@5 84.984
Test on T training set - [42][0/13]	T 0.753 (0.753)	D 0.637 (0.637)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1435 (0.1435)
Test on T training set - [42][10/13]	T 0.542 (0.546)	D 0.416 (0.426)	T@1 68.254 (85.137)	T@5 100.000 (97.258)	L 0.8726 (0.6138)
 * Test on T training set - Prec@1 85.409, Prec@5 97.358
Test on T test set - [42][0/13]	Time 0.772 (0.772)	Loss 0.1435 (0.1435)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [42][10/13]	Time 0.535 (0.534)	Loss 0.8726 (0.6138)	Prec@1 68.254 (85.137)	Prec@5 100.000 (97.258)
 * Test on T test set - Prec@1 85.409, Prec@5 97.358
Epoch 42, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 42, K-means clustering 1, Average clustering time 0.091, Prec@1 88.176
Epoch 42, K-means clustering 2, Average clustering time 0.097, Prec@1 87.925
Epoch 42, K-means clustering 3, Average clustering time 0.093, Prec@1 87.925
Epoch 42, K-means clustering 4, Average clustering time 0.095, Prec@1 87.925
Epoch 42, K-means clustering 0, Average clustering time 0.001, Prec@1 88.679
Epoch 42, K-means clustering 1, Average clustering time 0.052, Prec@1 88.302
Epoch 42, K-means clustering 2, Average clustering time 0.065, Prec@1 87.925
Epoch 42, K-means clustering 3, Average clustering time 0.068, Prec@1 88.050
Epoch 42, K-means clustering 4, Average clustering time 0.073, Prec@1 88.176
Test on T test set - [31][0/45]	Time 0.499 (0.499)	Loss 0.6575 (0.6575)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [31][10/45]	Time 0.326 (0.349)	Loss 2.6718 (0.8997)	Prec@1 26.984 (79.509)	Prec@5 63.492 (91.342)
Test on T test set - [31][20/45]	Time 0.325 (0.351)	Loss 0.5893 (1.0418)	Prec@1 87.302 (76.190)	Prec@5 100.000 (90.023)
Test on T test set - [31][30/45]	Time 0.385 (0.348)	Loss 0.9685 (1.0654)	Prec@1 79.365 (75.013)	Prec@5 95.238 (90.169)
Test on T test set - [31][40/45]	Time 0.324 (0.346)	Loss 2.0163 (1.2867)	Prec@1 42.857 (70.383)	Prec@5 80.952 (85.676)
 * Test on T test set - Prec@1 67.767, Prec@5 84.984
Epoch 31, K-means clustering 0, Average clustering time 0.028, Prec@1 73.553
Epoch 31, K-means clustering 1, Average clustering time 0.087, Prec@1 74.370
Epoch 31, K-means clustering 2, Average clustering time 0.100, Prec@1 74.228
Epoch 31, K-means clustering 3, Average clustering time 0.104, Prec@1 74.015
Epoch 31, K-means clustering 4, Average clustering time 0.106, Prec@1 73.802
Epoch 31, K-means clustering 0, Average clustering time 0.003, Prec@1 72.240
Epoch 31, K-means clustering 1, Average clustering time 0.051, Prec@1 72.985
Epoch 31, K-means clustering 2, Average clustering time 0.068, Prec@1 73.092
Epoch 31, K-means clustering 3, Average clustering time 0.087, Prec@1 73.163
Epoch 31, K-means clustering 4, Average clustering time 0.092, Prec@1 73.198
The penalty weight is 0.664037
Train - epoch [32/200]	BT 1.482 (1.482)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.0171 (13.0171)
The penalty weight is 0.791338
Train - epoch [43/200]	BT 1.114 (1.114)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.6477 (15.6477)
Train - epoch [32/200]	BT 1.544 (1.544)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.2181 (12.2181)
Train - epoch [43/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 15.5356 (15.5356)
Train - epoch [43/200]	BT 1.038 (1.038)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.0252 (16.0252)
Train - epoch [32/200]	BT 1.478 (1.478)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.0008 (13.0008)
Train - epoch [43/200]	BT 1.108 (1.108)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.1584 (15.1584)
Train - epoch [43/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.4958 (15.4958)
Train - epoch [32/200]	BT 1.461 (1.461)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.1907 (12.1907)
Train - epoch [43/200]	BT 1.063 (1.063)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.1704 (16.1704)
Train - epoch [32/200]	BT 1.521 (1.521)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.0060 (13.0060)
Test on T training set - [43][0/13]	T 0.740 (0.740)	D 0.624 (0.624)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1522 (0.1522)
Test on T training set - [43][10/13]	T 0.526 (0.522)	D 0.407 (0.401)	T@1 68.254 (84.560)	T@5 100.000 (97.403)	L 0.8852 (0.6248)
 * Test on T training set - Prec@1 84.654, Prec@5 97.484
Train - epoch [32/200]	BT 1.437 (1.437)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.0151 (13.0151)
Train - epoch [32/200]	BT 1.784 (1.784)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.0669 (12.0669)
Test on T test set - [43][0/13]	Time 0.753 (0.753)	Loss 0.1522 (0.1522)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [43][10/13]	Time 0.530 (0.526)	Loss 0.8852 (0.6248)	Prec@1 68.254 (84.560)	Prec@5 100.000 (97.403)
 * Test on T test set - Prec@1 84.654, Prec@5 97.484
Epoch 43, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 43, K-means clustering 1, Average clustering time 0.082, Prec@1 88.176
Epoch 43, K-means clustering 2, Average clustering time 0.086, Prec@1 87.799
Epoch 43, K-means clustering 3, Average clustering time 0.088, Prec@1 87.799
Epoch 43, K-means clustering 4, Average clustering time 0.089, Prec@1 87.799
Epoch 43, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 43, K-means clustering 1, Average clustering time 0.039, Prec@1 88.428
Epoch 43, K-means clustering 2, Average clustering time 0.053, Prec@1 88.302
Epoch 43, K-means clustering 3, Average clustering time 0.061, Prec@1 88.176
Epoch 43, K-means clustering 4, Average clustering time 0.065, Prec@1 88.176
The penalty weight is 0.800499
Train - epoch [44/200]	BT 1.094 (1.094)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.9684 (15.9684)
Train - epoch [44/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.0592 (16.0592)
Test on T training set - [32][0/45]	T 0.549 (0.549)	D 0.423 (0.423)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7261 (0.7261)
Test on T training set - [32][10/45]	T 0.322 (0.357)	D 0.198 (0.235)	T@1 31.746 (79.654)	T@5 61.905 (91.342)	L 2.6928 (0.9070)
Test on T training set - [32][20/45]	T 0.343 (0.346)	D 0.221 (0.224)	T@1 85.714 (76.568)	T@5 100.000 (90.174)	L 0.6971 (1.0384)
Test on T training set - [32][30/45]	T 0.329 (0.344)	D 0.204 (0.223)	T@1 80.952 (75.371)	T@5 95.238 (90.425)	L 0.9384 (1.0619)
Test on T training set - [32][40/45]	T 0.335 (0.350)	D 0.211 (0.229)	T@1 39.683 (70.732)	T@5 80.952 (86.063)	L 2.0794 (1.2757)
 * Test on T training set - Prec@1 68.193, Prec@5 85.304
Test on T test set - [32][0/45]	Time 0.526 (0.526)	Loss 0.7261 (0.7261)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [32][10/45]	Time 0.335 (0.346)	Loss 2.6928 (0.9070)	Prec@1 31.746 (79.654)	Prec@5 61.905 (91.342)
Test on T test set - [32][20/45]	Time 0.329 (0.338)	Loss 0.6971 (1.0384)	Prec@1 85.714 (76.568)	Prec@5 100.000 (90.174)
Test on T test set - [32][30/45]	Time 0.331 (0.337)	Loss 0.9384 (1.0619)	Prec@1 80.952 (75.371)	Prec@5 95.238 (90.425)
Test on T test set - [32][40/45]	Time 0.327 (0.334)	Loss 2.0794 (1.2757)	Prec@1 39.683 (70.732)	Prec@5 80.952 (86.063)
 * Test on T test set - Prec@1 68.193, Prec@5 85.304
Epoch 32, K-means clustering 0, Average clustering time 0.027, Prec@1 73.624
Epoch 32, K-means clustering 1, Average clustering time 0.093, Prec@1 73.979
Epoch 32, K-means clustering 2, Average clustering time 0.096, Prec@1 73.944
Epoch 32, K-means clustering 3, Average clustering time 0.097, Prec@1 74.015
Epoch 32, K-means clustering 4, Average clustering time 0.097, Prec@1 73.731
Epoch 32, K-means clustering 0, Average clustering time 0.003, Prec@1 72.701
Epoch 32, K-means clustering 1, Average clustering time 0.045, Prec@1 73.340
Epoch 32, K-means clustering 2, Average clustering time 0.056, Prec@1 73.127
Epoch 32, K-means clustering 3, Average clustering time 0.069, Prec@1 73.305
Epoch 32, K-means clustering 4, Average clustering time 0.074, Prec@1 73.234
Train - epoch [44/200]	BT 1.224 (1.224)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.9173 (14.9173)
Train - epoch [44/200]	BT 1.150 (1.150)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.8610 (15.8610)
The penalty weight is 0.677782
Train - epoch [33/200]	BT 1.554 (1.554)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.0899 (12.0899)
Train - epoch [44/200]	BT 1.147 (1.147)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.3416 (16.3416)
Train - epoch [44/200]	BT 1.121 (1.121)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 14.6706 (14.6706)
Train - epoch [33/200]	BT 1.558 (1.558)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.5506 (12.5506)
Train - epoch [44/200]	BT 1.125 (1.125)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.6119 (15.6119)
Train - epoch [33/200]	BT 1.534 (1.534)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.5162 (13.5162)
Test on T training set - [44][0/13]	T 0.751 (0.751)	D 0.621 (0.621)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1426 (0.1426)
Test on T training set - [44][10/13]	T 0.521 (0.519)	D 0.405 (0.395)	T@1 66.667 (85.426)	T@5 100.000 (97.403)	L 0.8996 (0.6167)
 * Test on T training set - Prec@1 85.535, Prec@5 97.484
Test on T test set - [44][0/13]	Time 0.761 (0.761)	Loss 0.1426 (0.1426)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [44][10/13]	Time 0.529 (0.525)	Loss 0.8996 (0.6167)	Prec@1 66.667 (85.426)	Prec@5 100.000 (97.403)
 * Test on T test set - Prec@1 85.535, Prec@5 97.484
Epoch 44, K-means clustering 0, Average clustering time 0.020, Prec@1 88.805
Epoch 44, K-means clustering 1, Average clustering time 0.083, Prec@1 88.176
Epoch 44, K-means clustering 2, Average clustering time 0.088, Prec@1 88.050
Epoch 44, K-means clustering 3, Average clustering time 0.092, Prec@1 88.050
Epoch 44, K-means clustering 4, Average clustering time 0.092, Prec@1 88.050
Epoch 44, K-means clustering 0, Average clustering time 0.001, Prec@1 88.931
Epoch 44, K-means clustering 1, Average clustering time 0.045, Prec@1 88.428
Epoch 44, K-means clustering 2, Average clustering time 0.051, Prec@1 88.050
Epoch 44, K-means clustering 3, Average clustering time 0.054, Prec@1 88.050
Epoch 44, K-means clustering 4, Average clustering time 0.055, Prec@1 88.050
Train - epoch [33/200]	BT 1.533 (1.533)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.2356 (13.2356)
Train - epoch [33/200]	BT 1.543 (1.543)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.0671 (12.0671)
The penalty weight is 0.809301
Train - epoch [45/200]	BT 1.200 (1.200)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 14.9855 (14.9855)
Train - epoch [45/200]	BT 1.227 (1.227)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 14.9474 (14.9474)
Train - epoch [33/200]	BT 1.496 (1.496)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.3150 (13.3150)
Train - epoch [45/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.9486 (15.9486)
Train - epoch [45/200]	BT 1.061 (1.061)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.1080 (16.1080)
Test on T training set - [33][0/45]	T 0.507 (0.507)	D 0.393 (0.393)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7230 (0.7230)
Test on T training set - [33][10/45]	T 0.337 (0.389)	D 0.220 (0.270)	T@1 30.159 (78.355)	T@5 61.905 (91.342)	L 2.6330 (0.9370)
Test on T training set - [33][20/45]	T 0.321 (0.368)	D 0.199 (0.247)	T@1 88.889 (76.266)	T@5 100.000 (90.023)	L 0.5591 (1.0578)
Test on T training set - [33][30/45]	T 0.343 (0.358)	D 0.220 (0.238)	T@1 74.603 (75.064)	T@5 93.651 (89.964)	L 1.0953 (1.0797)
Test on T training set - [33][40/45]	T 0.330 (0.354)	D 0.212 (0.233)	T@1 41.270 (70.074)	T@5 80.952 (85.830)	L 1.9964 (1.2919)
 * Test on T training set - Prec@1 67.625, Prec@5 85.375
Train - epoch [45/200]	BT 1.331 (1.331)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.0378 (16.0378)
Test on T test set - [33][0/45]	Time 0.510 (0.510)	Loss 0.7230 (0.7230)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [33][10/45]	Time 0.295 (0.357)	Loss 2.6330 (0.9370)	Prec@1 30.159 (78.355)	Prec@5 61.905 (91.342)
Test on T test set - [33][20/45]	Time 0.332 (0.344)	Loss 0.5591 (1.0578)	Prec@1 88.889 (76.266)	Prec@5 100.000 (90.023)
Test on T test set - [33][30/45]	Time 0.341 (0.340)	Loss 1.0953 (1.0797)	Prec@1 74.603 (75.064)	Prec@5 93.651 (89.964)
Test on T test set - [33][40/45]	Time 0.317 (0.338)	Loss 1.9964 (1.2919)	Prec@1 41.270 (70.074)	Prec@5 80.952 (85.830)
 * Test on T test set - Prec@1 67.625, Prec@5 85.375
Epoch 33, K-means clustering 0, Average clustering time 0.027, Prec@1 73.340
Epoch 33, K-means clustering 1, Average clustering time 0.089, Prec@1 73.802
Epoch 33, K-means clustering 2, Average clustering time 0.094, Prec@1 73.979
Epoch 33, K-means clustering 3, Average clustering time 0.097, Prec@1 74.086
Epoch 33, K-means clustering 4, Average clustering time 0.102, Prec@1 73.944
Epoch 33, K-means clustering 0, Average clustering time 0.003, Prec@1 72.524
Epoch 33, K-means clustering 1, Average clustering time 0.054, Prec@1 73.269
Epoch 33, K-means clustering 2, Average clustering time 0.072, Prec@1 73.802
Epoch 33, K-means clustering 3, Average clustering time 0.080, Prec@1 73.731
Epoch 33, K-means clustering 4, Average clustering time 0.086, Prec@1 73.695
Train - epoch [45/200]	BT 1.091 (1.091)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.1909 (16.1909)
Train - epoch [45/200]	BT 1.115 (1.115)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.1815 (16.1815)
The penalty weight is 0.691069
Train - epoch [34/200]	BT 1.539 (1.539)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.9762 (13.9762)
Test on T training set - [45][0/13]	T 0.745 (0.745)	D 0.615 (0.615)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1237 (0.1237)
Test on T training set - [45][10/13]	T 0.514 (0.534)	D 0.400 (0.412)	T@1 68.254 (85.714)	T@5 100.000 (97.403)	L 0.9170 (0.5967)
 * Test on T training set - Prec@1 85.786, Prec@5 97.484
Test on T test set - [45][0/13]	Time 0.722 (0.722)	Loss 0.1237 (0.1237)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [45][10/13]	Time 0.679 (0.544)	Loss 0.9170 (0.5967)	Prec@1 68.254 (85.714)	Prec@5 100.000 (97.403)
 * Test on T test set - Prec@1 85.786, Prec@5 97.484
Epoch 45, K-means clustering 0, Average clustering time 0.021, Prec@1 89.308
Epoch 45, K-means clustering 1, Average clustering time 0.083, Prec@1 88.176
Epoch 45, K-means clustering 2, Average clustering time 0.089, Prec@1 87.925
Epoch 45, K-means clustering 3, Average clustering time 0.091, Prec@1 87.925
Epoch 45, K-means clustering 4, Average clustering time 0.099, Prec@1 87.925
Epoch 45, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 45, K-means clustering 1, Average clustering time 0.046, Prec@1 88.176
Epoch 45, K-means clustering 2, Average clustering time 0.055, Prec@1 88.302
Epoch 45, K-means clustering 3, Average clustering time 0.062, Prec@1 88.176
Epoch 45, K-means clustering 4, Average clustering time 0.063, Prec@1 88.176
Train - epoch [34/200]	BT 1.497 (1.497)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.4145 (13.4145)
Train - epoch [34/200]	BT 2.428 (2.428)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.0751 (13.0751)
Train - epoch [34/200]	BT 1.449 (1.449)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.0389 (13.0389)
The penalty weight is 0.817754
Train - epoch [46/200]	BT 1.011 (1.011)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.4679 (15.4679)
Train - epoch [34/200]	BT 1.546 (1.546)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.7553 (13.7553)
Train - epoch [46/200]	BT 1.886 (1.886)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.9349 (14.9349)
Train - epoch [46/200]	BT 1.135 (1.135)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 15.7556 (15.7556)
Train - epoch [34/200]	BT 1.436 (1.436)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.9108 (12.9108)
Train - epoch [46/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 14.6648 (14.6648)
Train - epoch [46/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.1834 (15.1834)
Train - epoch [34/200]	BT 1.572 (1.572)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 12.0117 (12.0117)
Train - epoch [46/200]	BT 1.115 (1.115)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.1907 (16.1907)
Test on T training set - [34][0/45]	T 0.519 (0.519)	D 0.402 (0.402)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6668 (0.6668)
Test on T training set - [34][10/45]	T 0.338 (0.356)	D 0.214 (0.237)	T@1 31.746 (79.221)	T@5 63.492 (91.198)	L 2.6643 (0.9056)
Test on T training set - [34][20/45]	T 0.327 (0.346)	D 0.214 (0.226)	T@1 85.714 (76.342)	T@5 100.000 (89.796)	L 0.6094 (1.0451)
Test on T training set - [34][30/45]	T 0.321 (0.349)	D 0.202 (0.229)	T@1 76.190 (75.422)	T@5 95.238 (90.118)	L 0.9705 (1.0607)
Test on T training set - [34][40/45]	T 0.328 (0.344)	D 0.207 (0.224)	T@1 42.857 (71.158)	T@5 80.952 (85.753)	L 1.9852 (1.2742)
 * Test on T training set - Prec@1 68.832, Prec@5 85.410
Test on T training set - [46][0/13]	T 0.795 (0.795)	D 0.665 (0.665)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1422 (0.1422)
Test on T training set - [46][10/13]	T 0.568 (0.532)	D 0.441 (0.408)	T@1 61.905 (85.714)	T@5 100.000 (97.547)	L 1.0122 (0.6208)
 * Test on T training set - Prec@1 85.912, Prec@5 97.610
Test on T test set - [46][0/13]	Time 0.863 (0.863)	Loss 0.1422 (0.1422)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [46][10/13]	Time 0.523 (0.538)	Loss 1.0122 (0.6208)	Prec@1 61.905 (85.714)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 85.912, Prec@5 97.610
Epoch 46, K-means clustering 0, Average clustering time 0.018, Prec@1 88.679
Epoch 46, K-means clustering 1, Average clustering time 0.093, Prec@1 88.050
Epoch 46, K-means clustering 2, Average clustering time 0.090, Prec@1 87.925
Epoch 46, K-means clustering 3, Average clustering time 0.089, Prec@1 87.799
Epoch 46, K-means clustering 4, Average clustering time 0.091, Prec@1 87.673
Epoch 46, K-means clustering 0, Average clustering time 0.001, Prec@1 88.176
Epoch 46, K-means clustering 1, Average clustering time 0.041, Prec@1 87.925
Epoch 46, K-means clustering 2, Average clustering time 0.056, Prec@1 87.925
Epoch 46, K-means clustering 3, Average clustering time 0.066, Prec@1 87.925
Epoch 46, K-means clustering 4, Average clustering time 0.068, Prec@1 87.799
Test on T test set - [34][0/45]	Time 0.527 (0.527)	Loss 0.6668 (0.6668)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [34][10/45]	Time 0.344 (0.349)	Loss 2.6643 (0.9056)	Prec@1 31.746 (79.221)	Prec@5 63.492 (91.198)
Test on T test set - [34][20/45]	Time 0.318 (0.342)	Loss 0.6094 (1.0451)	Prec@1 85.714 (76.342)	Prec@5 100.000 (89.796)
Test on T test set - [34][30/45]	Time 0.322 (0.341)	Loss 0.9705 (1.0607)	Prec@1 76.190 (75.422)	Prec@5 95.238 (90.118)
Test on T test set - [34][40/45]	Time 0.328 (0.338)	Loss 1.9852 (1.2742)	Prec@1 42.857 (71.158)	Prec@5 80.952 (85.753)
 * Test on T test set - Prec@1 68.832, Prec@5 85.410
Epoch 34, K-means clustering 0, Average clustering time 0.028, Prec@1 73.731
Epoch 34, K-means clustering 1, Average clustering time 0.093, Prec@1 74.512
Epoch 34, K-means clustering 2, Average clustering time 0.101, Prec@1 74.512
Epoch 34, K-means clustering 3, Average clustering time 0.104, Prec@1 74.441
Epoch 34, K-means clustering 4, Average clustering time 0.105, Prec@1 74.015
Epoch 34, K-means clustering 0, Average clustering time 0.003, Prec@1 72.701
Epoch 34, K-means clustering 1, Average clustering time 0.050, Prec@1 73.482
Epoch 34, K-means clustering 2, Average clustering time 0.064, Prec@1 73.553
Epoch 34, K-means clustering 3, Average clustering time 0.073, Prec@1 73.553
Epoch 34, K-means clustering 4, Average clustering time 0.078, Prec@1 73.447
The penalty weight is 0.703906
Train - epoch [35/200]	BT 1.481 (1.481)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.7283 (13.7283)
The penalty weight is 0.825868
Train - epoch [47/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.0042 (16.0042)
Train - epoch [47/200]	BT 1.130 (1.130)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 14.3945 (14.3945)
Train - epoch [35/200]	BT 1.496 (1.496)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.6082 (13.6082)
Train - epoch [47/200]	BT 1.170 (1.170)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.4208 (15.4208)
Train - epoch [47/200]	BT 1.395 (1.395)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.1381 (16.1381)
Train - epoch [35/200]	BT 1.509 (1.509)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.9617 (13.9617)
Train - epoch [47/200]	BT 1.208 (1.208)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.9421 (15.9421)
Train - epoch [47/200]	BT 1.121 (1.121)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.4965 (15.4965)
Train - epoch [35/200]	BT 1.953 (1.953)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.7283 (13.7283)
Train - epoch [47/200]	BT 1.123 (1.123)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.7719 (15.7719)
Train - epoch [35/200]	BT 1.488 (1.488)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.2181 (14.2181)
Test on T training set - [47][0/13]	T 0.758 (0.758)	D 0.628 (0.628)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1179 (0.1179)
Test on T training set - [47][10/13]	T 0.500 (0.565)	D 0.383 (0.444)	T@1 60.317 (85.137)	T@5 98.413 (97.258)	L 0.9719 (0.6079)
 * Test on T training set - Prec@1 85.157, Prec@5 97.358
Train - epoch [35/200]	BT 2.026 (2.026)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.5845 (13.5845)
Train - epoch [35/200]	BT 1.052 (1.052)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.1682 (13.1682)
Test on T test set - [47][0/13]	Time 0.835 (0.835)	Loss 0.1179 (0.1179)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [47][10/13]	Time 0.529 (0.575)	Loss 0.9719 (0.6079)	Prec@1 60.317 (85.137)	Prec@5 98.413 (97.258)
 * Test on T test set - Prec@1 85.157, Prec@5 97.358
Epoch 47, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 47, K-means clustering 1, Average clustering time 0.082, Prec@1 87.925
Epoch 47, K-means clustering 2, Average clustering time 0.083, Prec@1 87.925
Epoch 47, K-means clustering 3, Average clustering time 0.084, Prec@1 87.925
Epoch 47, K-means clustering 4, Average clustering time 0.084, Prec@1 87.925
Epoch 47, K-means clustering 0, Average clustering time 0.001, Prec@1 88.050
Epoch 47, K-means clustering 1, Average clustering time 0.038, Prec@1 88.050
Epoch 47, K-means clustering 2, Average clustering time 0.049, Prec@1 88.176
Epoch 47, K-means clustering 3, Average clustering time 0.056, Prec@1 88.050
Epoch 47, K-means clustering 4, Average clustering time 0.059, Prec@1 88.050
The penalty weight is 0.833655
Train - epoch [48/200]	BT 1.232 (1.232)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.0672 (16.0672)
Train - epoch [48/200]	BT 1.226 (1.226)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.6828 (16.6828)
Test on T training set - [35][0/45]	T 0.509 (0.509)	D 0.391 (0.391)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6591 (0.6591)
Test on T training set - [35][10/45]	T 0.333 (0.360)	D 0.221 (0.240)	T@1 28.571 (79.221)	T@5 58.730 (91.342)	L 2.6975 (0.9148)
Test on T training set - [35][20/45]	T 0.324 (0.352)	D 0.206 (0.233)	T@1 95.238 (76.342)	T@5 100.000 (89.645)	L 0.5091 (1.0678)
Test on T training set - [35][30/45]	T 0.323 (0.356)	D 0.208 (0.236)	T@1 77.778 (74.962)	T@5 95.238 (89.811)	L 1.0743 (1.0911)
Test on T training set - [35][40/45]	T 0.336 (0.352)	D 0.214 (0.232)	T@1 41.270 (70.345)	T@5 80.952 (85.637)	L 2.0968 (1.3079)
 * Test on T training set - Prec@1 67.838, Prec@5 85.055
Test on T test set - [35][0/45]	Time 0.512 (0.512)	Loss 0.6591 (0.6591)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [35][10/45]	Time 0.348 (0.345)	Loss 2.6975 (0.9148)	Prec@1 28.571 (79.221)	Prec@5 58.730 (91.342)
Test on T test set - [35][20/45]	Time 0.354 (0.371)	Loss 0.5091 (1.0678)	Prec@1 95.238 (76.342)	Prec@5 100.000 (89.645)
Test on T test set - [35][30/45]	Time 0.336 (0.369)	Loss 1.0743 (1.0911)	Prec@1 77.778 (74.962)	Prec@5 95.238 (89.811)
Test on T test set - [35][40/45]	Time 0.340 (0.362)	Loss 2.0968 (1.3079)	Prec@1 41.270 (70.345)	Prec@5 80.952 (85.637)
 * Test on T test set - Prec@1 67.838, Prec@5 85.055
Epoch 35, K-means clustering 0, Average clustering time 0.027, Prec@1 73.376
Epoch 35, K-means clustering 1, Average clustering time 0.091, Prec@1 73.979
Epoch 35, K-means clustering 2, Average clustering time 0.094, Prec@1 73.979
Epoch 35, K-means clustering 3, Average clustering time 0.096, Prec@1 73.837
Epoch 35, K-means clustering 4, Average clustering time 0.097, Prec@1 73.589
Epoch 35, K-means clustering 0, Average clustering time 0.003, Prec@1 72.559
Epoch 35, K-means clustering 1, Average clustering time 0.066, Prec@1 73.198
Epoch 35, K-means clustering 2, Average clustering time 0.076, Prec@1 73.447
Epoch 35, K-means clustering 3, Average clustering time 0.087, Prec@1 73.411
Epoch 35, K-means clustering 4, Average clustering time 0.091, Prec@1 73.305
Train - epoch [48/200]	BT 1.326 (1.326)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.8198 (15.8198)
Train - epoch [48/200]	BT 1.300 (1.300)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.3881 (16.3881)
The penalty weight is 0.716298
Train - epoch [36/200]	BT 1.767 (1.767)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.2106 (14.2106)
Train - epoch [48/200]	BT 1.463 (1.463)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.3266 (16.3266)
Train - epoch [36/200]	BT 1.356 (1.356)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.1150 (14.1150)
Train - epoch [48/200]	BT 1.688 (1.688)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 14.7966 (14.7966)
Train - epoch [48/200]	BT 1.105 (1.105)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.4183 (16.4183)
Train - epoch [36/200]	BT 1.467 (1.467)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.7322 (13.7322)
Test on T training set - [48][0/13]	T 0.748 (0.748)	D 0.619 (0.619)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1388 (0.1388)
Test on T training set - [48][10/13]	T 0.502 (0.523)	D 0.374 (0.399)	T@1 63.492 (85.137)	T@5 100.000 (97.547)	L 0.9418 (0.6167)
 * Test on T training set - Prec@1 85.283, Prec@5 97.610
Train - epoch [36/200]	BT 1.509 (1.509)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.4160 (13.4160)
Test on T test set - [48][0/13]	Time 0.746 (0.746)	Loss 0.1388 (0.1388)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [48][10/13]	Time 0.523 (0.526)	Loss 0.9418 (0.6167)	Prec@1 63.492 (85.137)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 85.283, Prec@5 97.610
Epoch 48, K-means clustering 0, Average clustering time 0.018, Prec@1 88.679
Epoch 48, K-means clustering 1, Average clustering time 0.090, Prec@1 87.799
Epoch 48, K-means clustering 2, Average clustering time 0.094, Prec@1 87.673
Epoch 48, K-means clustering 3, Average clustering time 0.094, Prec@1 87.673
Epoch 48, K-means clustering 4, Average clustering time 0.096, Prec@1 87.673
Epoch 48, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 48, K-means clustering 1, Average clustering time 0.041, Prec@1 88.428
Epoch 48, K-means clustering 2, Average clustering time 0.054, Prec@1 88.176
Epoch 48, K-means clustering 3, Average clustering time 0.060, Prec@1 88.176
Epoch 48, K-means clustering 4, Average clustering time 0.064, Prec@1 88.176
Train - epoch [36/200]	BT 1.578 (1.578)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.4574 (14.4574)
The penalty weight is 0.841123
Train - epoch [49/200]	BT 1.148 (1.148)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.6656 (16.6656)
Train - epoch [49/200]	BT 1.170 (1.170)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.6945 (16.6945)
Train - epoch [36/200]	BT 1.506 (1.506)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.3365 (14.3365)
Train - epoch [49/200]	BT 1.237 (1.237)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.6884 (16.6884)
Test on T training set - [36][0/45]	T 0.522 (0.522)	D 0.398 (0.398)	T@1 84.127 (84.127)	T@5 96.825 (96.825)	L 0.7407 (0.7407)
Test on T training set - [36][10/45]	T 0.313 (0.348)	D 0.201 (0.228)	T@1 28.571 (78.066)	T@5 60.317 (91.486)	L 2.6712 (0.9392)
Test on T training set - [36][20/45]	T 0.357 (0.344)	D 0.235 (0.224)	T@1 92.063 (75.888)	T@5 100.000 (89.720)	L 0.6132 (1.0849)
Test on T training set - [36][30/45]	T 0.345 (0.341)	D 0.220 (0.222)	T@1 74.603 (74.706)	T@5 95.238 (90.015)	L 1.0511 (1.0969)
Test on T training set - [36][40/45]	T 0.339 (0.340)	D 0.216 (0.221)	T@1 42.857 (70.151)	T@5 80.952 (85.637)	L 2.0765 (1.3123)
 * Test on T training set - Prec@1 67.696, Prec@5 85.162
Train - epoch [49/200]	BT 1.070 (1.070)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 17.0973 (17.0973)
Train - epoch [49/200]	BT 1.207 (1.207)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.8323 (16.8323)
Test on T test set - [36][0/45]	Time 0.537 (0.537)	Loss 0.7407 (0.7407)	Prec@1 84.127 (84.127)	Prec@5 96.825 (96.825)
Test on T test set - [36][10/45]	Time 0.324 (0.348)	Loss 2.6712 (0.9392)	Prec@1 28.571 (78.066)	Prec@5 60.317 (91.486)
Test on T test set - [36][20/45]	Time 0.364 (0.344)	Loss 0.6132 (1.0849)	Prec@1 92.063 (75.888)	Prec@5 100.000 (89.720)
Test on T test set - [36][30/45]	Time 0.324 (0.345)	Loss 1.0511 (1.0969)	Prec@1 74.603 (74.706)	Prec@5 95.238 (90.015)
Test on T test set - [36][40/45]	Time 0.331 (0.342)	Loss 2.0765 (1.3123)	Prec@1 42.857 (70.151)	Prec@5 80.952 (85.637)
 * Test on T test set - Prec@1 67.696, Prec@5 85.162
Epoch 36, K-means clustering 0, Average clustering time 0.027, Prec@1 73.269
Epoch 36, K-means clustering 1, Average clustering time 0.093, Prec@1 74.086
Epoch 36, K-means clustering 2, Average clustering time 0.094, Prec@1 73.944
Epoch 36, K-means clustering 3, Average clustering time 0.094, Prec@1 73.660
Epoch 36, K-means clustering 4, Average clustering time 0.095, Prec@1 73.340
Epoch 36, K-means clustering 0, Average clustering time 0.003, Prec@1 72.808
Epoch 36, K-means clustering 1, Average clustering time 0.051, Prec@1 73.553
Epoch 36, K-means clustering 2, Average clustering time 0.064, Prec@1 73.340
Epoch 36, K-means clustering 3, Average clustering time 0.069, Prec@1 73.163
Epoch 36, K-means clustering 4, Average clustering time 0.075, Prec@1 73.163
Train - epoch [49/200]	BT 1.145 (1.145)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.4620 (16.4620)
The penalty weight is 0.728254
Train - epoch [37/200]	BT 1.461 (1.461)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.6100 (14.6100)
Test on T training set - [49][0/13]	T 0.744 (0.744)	D 0.627 (0.627)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1328 (0.1328)
Test on T training set - [49][10/13]	T 0.529 (0.521)	D 0.400 (0.400)	T@1 57.143 (84.271)	T@5 98.413 (97.547)	L 1.1067 (0.6058)
 * Test on T training set - Prec@1 84.528, Prec@5 97.610
Test on T test set - [49][0/13]	Time 0.772 (0.772)	Loss 0.1328 (0.1328)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [49][10/13]	Time 0.537 (0.523)	Loss 1.1067 (0.6058)	Prec@1 57.143 (84.271)	Prec@5 98.413 (97.547)
 * Test on T test set - Prec@1 84.528, Prec@5 97.610
Epoch 49, K-means clustering 0, Average clustering time 0.018, Prec@1 87.925
Epoch 49, K-means clustering 1, Average clustering time 0.078, Prec@1 87.673
Epoch 49, K-means clustering 2, Average clustering time 0.079, Prec@1 87.547
Epoch 49, K-means clustering 3, Average clustering time 0.083, Prec@1 87.547
Epoch 49, K-means clustering 4, Average clustering time 0.083, Prec@1 87.547
Epoch 49, K-means clustering 0, Average clustering time 0.001, Prec@1 87.421
Epoch 49, K-means clustering 1, Average clustering time 0.047, Prec@1 87.925
Epoch 49, K-means clustering 2, Average clustering time 0.062, Prec@1 87.799
Epoch 49, K-means clustering 3, Average clustering time 0.069, Prec@1 87.799
Epoch 49, K-means clustering 4, Average clustering time 0.075, Prec@1 87.799
Train - epoch [37/200]	BT 1.981 (1.981)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.6337 (14.6337)
Train - epoch [37/200]	BT 1.541 (1.541)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.1819 (13.1819)
Train - epoch [37/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.1340 (14.1340)
Train - epoch [50/200]	BT 1.042 (1.042)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.6119 (16.6119)
The penalty weight is 0.848284
Train - epoch [50/200]	BT 1.146 (1.146)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.7849 (15.7849)
Train - epoch [37/200]	BT 1.495 (1.495)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.2483 (14.2483)
Train - epoch [50/200]	BT 1.054 (1.054)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.7772 (16.7772)
Train - epoch [50/200]	BT 1.171 (1.171)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.3414 (16.3414)
Train - epoch [37/200]	BT 1.567 (1.567)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.4720 (14.4720)
Train - epoch [50/200]	BT 1.149 (1.149)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 16.1397 (16.1397)
Train - epoch [50/200]	BT 1.140 (1.140)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.5694 (16.5694)
Train - epoch [37/200]	BT 1.509 (1.509)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.8219 (13.8219)
Train - epoch [50/200]	BT 1.157 (1.157)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.6720 (16.6720)
Test on T training set - [37][0/45]	T 0.510 (0.510)	D 0.390 (0.390)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.6415 (0.6415)
Test on T training set - [37][10/45]	T 0.319 (0.341)	D 0.195 (0.221)	T@1 28.571 (79.365)	T@5 60.317 (90.909)	L 2.6574 (0.9124)
Test on T training set - [37][20/45]	T 0.314 (0.334)	D 0.202 (0.214)	T@1 85.714 (76.342)	T@5 100.000 (89.720)	L 0.6585 (1.0586)
Test on T training set - [37][30/45]	T 0.341 (0.337)	D 0.219 (0.217)	T@1 79.365 (75.115)	T@5 95.238 (89.913)	L 0.9506 (1.0766)
Test on T training set - [37][40/45]	T 0.346 (0.337)	D 0.228 (0.217)	T@1 42.857 (70.964)	T@5 80.952 (85.753)	L 1.9901 (1.2857)
 * Test on T training set - Prec@1 68.619, Prec@5 85.268
Test on T training set - [50][0/13]	T 0.738 (0.738)	D 0.615 (0.615)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1120 (0.1120)
Test on T training set - [50][10/13]	T 0.768 (0.554)	D 0.640 (0.434)	T@1 68.254 (86.580)	T@5 100.000 (97.691)	L 0.8734 (0.5859)
 * Test on T training set - Prec@1 86.541, Prec@5 97.736
Test on T test set - [50][0/13]	Time 0.732 (0.732)	Loss 0.1120 (0.1120)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [50][10/13]	Time 0.522 (0.542)	Loss 0.8734 (0.5859)	Prec@1 68.254 (86.580)	Prec@5 100.000 (97.691)
 * Test on T test set - Prec@1 86.541, Prec@5 97.736
Epoch 50, K-means clustering 0, Average clustering time 0.018, Prec@1 89.308
Epoch 50, K-means clustering 1, Average clustering time 0.092, Prec@1 88.302
Epoch 50, K-means clustering 2, Average clustering time 0.089, Prec@1 87.799
Epoch 50, K-means clustering 3, Average clustering time 0.087, Prec@1 87.799
Epoch 50, K-means clustering 4, Average clustering time 0.086, Prec@1 87.799
Epoch 50, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 50, K-means clustering 1, Average clustering time 0.037, Prec@1 88.553
Epoch 50, K-means clustering 2, Average clustering time 0.050, Prec@1 88.302
Epoch 50, K-means clustering 3, Average clustering time 0.062, Prec@1 88.176
Epoch 50, K-means clustering 4, Average clustering time 0.065, Prec@1 88.176
Test on T test set - [37][0/45]	Time 0.586 (0.586)	Loss 0.6415 (0.6415)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [37][10/45]	Time 0.540 (0.371)	Loss 2.6574 (0.9124)	Prec@1 28.571 (79.365)	Prec@5 60.317 (90.909)
Test on T test set - [37][20/45]	Time 0.346 (0.352)	Loss 0.6585 (1.0586)	Prec@1 85.714 (76.342)	Prec@5 100.000 (89.720)
Test on T test set - [37][30/45]	Time 0.332 (0.351)	Loss 0.9506 (1.0766)	Prec@1 79.365 (75.115)	Prec@5 95.238 (89.913)
Test on T test set - [37][40/45]	Time 0.330 (0.347)	Loss 1.9901 (1.2857)	Prec@1 42.857 (70.964)	Prec@5 80.952 (85.753)
 * Test on T test set - Prec@1 68.619, Prec@5 85.268
Epoch 37, K-means clustering 0, Average clustering time 0.027, Prec@1 73.731
Epoch 37, K-means clustering 1, Average clustering time 0.098, Prec@1 74.334
Epoch 37, K-means clustering 2, Average clustering time 0.102, Prec@1 74.121
Epoch 37, K-means clustering 3, Average clustering time 0.100, Prec@1 73.944
Epoch 37, K-means clustering 4, Average clustering time 0.102, Prec@1 73.553
Epoch 37, K-means clustering 0, Average clustering time 0.003, Prec@1 72.630
Epoch 37, K-means clustering 1, Average clustering time 0.051, Prec@1 73.340
Epoch 37, K-means clustering 2, Average clustering time 0.068, Prec@1 73.482
Epoch 37, K-means clustering 3, Average clustering time 0.072, Prec@1 73.482
Epoch 37, K-means clustering 4, Average clustering time 0.076, Prec@1 73.411
The penalty weight is 0.739783
Train - epoch [38/200]	BT 1.531 (1.531)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.6708 (14.6708)
The penalty weight is 0.855147
Train - epoch [51/200]	BT 1.934 (1.934)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.7098 (16.7098)
Train - epoch [51/200]	BT 1.231 (1.231)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.8621 (16.8621)
Train - epoch [38/200]	BT 1.536 (1.536)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.6411 (14.6411)
Train - epoch [51/200]	BT 1.196 (1.196)	DT 0.000 (0.000)	S@1 83.333 (83.333)	Loss 17.3085 (17.3085)
Train - epoch [51/200]	BT 1.086 (1.086)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.8263 (16.8263)
Train - epoch [38/200]	BT 1.899 (1.899)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.8620 (14.8620)
Train - epoch [51/200]	BT 1.203 (1.203)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.3301 (16.3301)
Train - epoch [51/200]	BT 1.244 (1.244)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.2088 (17.2088)
Train - epoch [38/200]	BT 1.445 (1.445)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.4309 (13.4309)
Train - epoch [51/200]	BT 1.143 (1.143)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.3604 (16.3604)
Train - epoch [38/200]	BT 2.007 (2.007)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.1305 (13.1305)
Train - epoch [38/200]	BT 1.436 (1.436)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.3256 (14.3256)
Test on T training set - [51][0/13]	T 0.766 (0.766)	D 0.637 (0.637)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1406 (0.1406)
Test on T training set - [51][10/13]	T 0.534 (0.530)	D 0.406 (0.405)	T@1 58.730 (85.426)	T@5 100.000 (97.691)	L 0.9518 (0.6079)
 * Test on T training set - Prec@1 85.786, Prec@5 97.736
Train - epoch [38/200]	BT 1.802 (1.802)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.5109 (14.5109)
Test on T test set - [51][0/13]	Time 0.766 (0.766)	Loss 0.1406 (0.1406)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [51][10/13]	Time 0.537 (0.598)	Loss 0.9518 (0.6079)	Prec@1 58.730 (85.426)	Prec@5 100.000 (97.691)
 * Test on T test set - Prec@1 85.786, Prec@5 97.736
Epoch 51, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 51, K-means clustering 1, Average clustering time 0.075, Prec@1 87.673
Epoch 51, K-means clustering 2, Average clustering time 0.084, Prec@1 87.421
Epoch 51, K-means clustering 3, Average clustering time 0.087, Prec@1 87.296
Epoch 51, K-means clustering 4, Average clustering time 0.088, Prec@1 87.296
Epoch 51, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 51, K-means clustering 1, Average clustering time 0.038, Prec@1 88.176
Epoch 51, K-means clustering 2, Average clustering time 0.051, Prec@1 88.050
Epoch 51, K-means clustering 3, Average clustering time 0.056, Prec@1 88.050
Epoch 51, K-means clustering 4, Average clustering time 0.060, Prec@1 88.050
The penalty weight is 0.861723
Train - epoch [52/200]	BT 1.028 (1.028)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.3446 (17.3446)
Train - epoch [52/200]	BT 1.227 (1.227)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.5835 (16.5835)
Test on T training set - [38][0/45]	T 0.512 (0.512)	D 0.375 (0.375)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7340 (0.7340)
Test on T training set - [38][10/45]	T 0.339 (0.348)	D 0.217 (0.227)	T@1 28.571 (79.076)	T@5 57.143 (90.909)	L 2.6827 (0.9251)
Test on T training set - [38][20/45]	T 0.328 (0.367)	D 0.216 (0.247)	T@1 92.063 (75.888)	T@5 100.000 (89.342)	L 0.6088 (1.0885)
Test on T training set - [38][30/45]	T 0.332 (0.380)	D 0.210 (0.261)	T@1 76.190 (74.603)	T@5 93.651 (89.657)	L 1.1157 (1.1062)
Test on T training set - [38][40/45]	T 0.361 (0.373)	D 0.238 (0.254)	T@1 41.270 (70.228)	T@5 80.952 (85.559)	L 2.0541 (1.3209)
 * Test on T training set - Prec@1 67.874, Prec@5 85.162
Test on T test set - [38][0/45]	Time 0.513 (0.513)	Loss 0.7340 (0.7340)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [38][10/45]	Time 0.322 (0.349)	Loss 2.6827 (0.9251)	Prec@1 28.571 (79.076)	Prec@5 57.143 (90.909)
Test on T test set - [38][20/45]	Time 0.341 (0.344)	Loss 0.6088 (1.0885)	Prec@1 92.063 (75.888)	Prec@5 100.000 (89.342)
Test on T test set - [38][30/45]	Time 0.324 (0.352)	Loss 1.1157 (1.1062)	Prec@1 76.190 (74.603)	Prec@5 93.651 (89.657)
Test on T test set - [38][40/45]	Time 0.370 (0.348)	Loss 2.0541 (1.3209)	Prec@1 41.270 (70.228)	Prec@5 80.952 (85.559)
 * Test on T test set - Prec@1 67.874, Prec@5 85.162
Epoch 38, K-means clustering 0, Average clustering time 0.028, Prec@1 73.340
Epoch 38, K-means clustering 1, Average clustering time 0.089, Prec@1 73.908
Epoch 38, K-means clustering 2, Average clustering time 0.100, Prec@1 73.979
Epoch 38, K-means clustering 3, Average clustering time 0.106, Prec@1 73.553
Epoch 38, K-means clustering 4, Average clustering time 0.107, Prec@1 73.234
Epoch 38, K-means clustering 0, Average clustering time 0.003, Prec@1 72.453
Epoch 38, K-means clustering 1, Average clustering time 0.052, Prec@1 73.269
Epoch 38, K-means clustering 2, Average clustering time 0.062, Prec@1 73.447
Epoch 38, K-means clustering 3, Average clustering time 0.073, Prec@1 73.482
Epoch 38, K-means clustering 4, Average clustering time 0.077, Prec@1 73.269
Train - epoch [52/200]	BT 1.200 (1.200)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.3490 (16.3490)
The penalty weight is 0.750893
Train - epoch [39/200]	BT 1.522 (1.522)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.4634 (14.4634)
Train - epoch [52/200]	BT 1.734 (1.734)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.9925 (16.9925)
Train - epoch [52/200]	BT 1.105 (1.105)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.3460 (15.3460)
Train - epoch [39/200]	BT 1.714 (1.714)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.7139 (14.7139)
Train - epoch [52/200]	BT 1.121 (1.121)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.1706 (16.1706)
Train - epoch [52/200]	BT 1.020 (1.020)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.9582 (15.9582)
Train - epoch [39/200]	BT 1.497 (1.497)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.6168 (13.6168)
Test on T training set - [52][0/13]	T 0.753 (0.753)	D 0.623 (0.623)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1325 (0.1325)
Test on T training set - [52][10/13]	T 0.520 (0.546)	D 0.398 (0.425)	T@1 63.492 (85.137)	T@5 100.000 (98.124)	L 0.9348 (0.5930)
 * Test on T training set - Prec@1 85.409, Prec@5 98.113
Train - epoch [39/200]	BT 1.449 (1.449)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.4830 (13.4830)
Test on T test set - [52][0/13]	Time 0.811 (0.811)	Loss 0.1325 (0.1325)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [52][10/13]	Time 0.537 (0.535)	Loss 0.9348 (0.5930)	Prec@1 63.492 (85.137)	Prec@5 100.000 (98.124)
 * Test on T test set - Prec@1 85.409, Prec@5 98.113
Epoch 52, K-means clustering 0, Average clustering time 0.018, Prec@1 89.182
Epoch 52, K-means clustering 1, Average clustering time 0.077, Prec@1 88.679
Epoch 52, K-means clustering 2, Average clustering time 0.079, Prec@1 88.428
Epoch 52, K-means clustering 3, Average clustering time 0.084, Prec@1 88.428
Epoch 52, K-means clustering 4, Average clustering time 0.153, Prec@1 88.428
Epoch 52, K-means clustering 0, Average clustering time 0.001, Prec@1 88.931
Epoch 52, K-means clustering 1, Average clustering time 0.045, Prec@1 88.553
Epoch 52, K-means clustering 2, Average clustering time 0.065, Prec@1 88.302
Epoch 52, K-means clustering 3, Average clustering time 0.070, Prec@1 88.176
Epoch 52, K-means clustering 4, Average clustering time 0.073, Prec@1 88.176
Train - epoch [39/200]	BT 1.713 (1.713)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.7999 (14.7999)
The penalty weight is 0.868022
Train - epoch [53/200]	BT 1.194 (1.194)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.9889 (16.9889)
Train - epoch [39/200]	BT 1.510 (1.510)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.5208 (14.5208)
Train - epoch [53/200]	BT 1.124 (1.124)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.1999 (17.1999)
Train - epoch [53/200]	BT 1.066 (1.066)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.3270 (17.3270)
Test on T training set - [39][0/45]	T 0.502 (0.502)	D 0.384 (0.384)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.6672 (0.6672)
Test on T training set - [39][10/45]	T 0.316 (0.349)	D 0.204 (0.229)	T@1 28.571 (78.644)	T@5 61.905 (91.198)	L 2.6474 (0.9292)
Test on T training set - [39][20/45]	T 0.329 (0.344)	D 0.207 (0.225)	T@1 92.063 (76.493)	T@5 100.000 (89.796)	L 0.5035 (1.0595)
Test on T training set - [39][30/45]	T 0.340 (0.343)	D 0.225 (0.225)	T@1 74.603 (75.064)	T@5 95.238 (89.964)	L 1.0228 (1.0842)
Test on T training set - [39][40/45]	T 0.350 (0.342)	D 0.229 (0.224)	T@1 39.683 (70.461)	T@5 80.952 (85.753)	L 2.0706 (1.3013)
 * Test on T training set - Prec@1 68.016, Prec@5 85.339
Train - epoch [53/200]	BT 1.183 (1.183)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.4291 (16.4291)
Train - epoch [53/200]	BT 1.121 (1.121)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.2107 (17.2107)
Test on T test set - [39][0/45]	Time 0.512 (0.512)	Loss 0.6672 (0.6672)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [39][10/45]	Time 0.318 (0.347)	Loss 2.6474 (0.9292)	Prec@1 28.571 (78.644)	Prec@5 61.905 (91.198)
Test on T test set - [39][20/45]	Time 0.344 (0.345)	Loss 0.5035 (1.0595)	Prec@1 92.063 (76.493)	Prec@5 100.000 (89.796)
Test on T test set - [39][30/45]	Time 0.361 (0.343)	Loss 1.0228 (1.0842)	Prec@1 74.603 (75.064)	Prec@5 95.238 (89.964)
Test on T test set - [39][40/45]	Time 0.336 (0.340)	Loss 2.0706 (1.3013)	Prec@1 39.683 (70.461)	Prec@5 80.952 (85.753)
 * Test on T test set - Prec@1 68.016, Prec@5 85.339
Epoch 39, K-means clustering 0, Average clustering time 0.027, Prec@1 73.518
Epoch 39, K-means clustering 1, Average clustering time 0.087, Prec@1 74.015
Epoch 39, K-means clustering 2, Average clustering time 0.095, Prec@1 74.228
Epoch 39, K-means clustering 3, Average clustering time 0.099, Prec@1 73.944
Epoch 39, K-means clustering 4, Average clustering time 0.102, Prec@1 73.589
Epoch 39, K-means clustering 0, Average clustering time 0.003, Prec@1 72.737
Epoch 39, K-means clustering 1, Average clustering time 0.046, Prec@1 73.553
Epoch 39, K-means clustering 2, Average clustering time 0.058, Prec@1 73.837
Epoch 39, K-means clustering 3, Average clustering time 0.069, Prec@1 73.802
Epoch 39, K-means clustering 4, Average clustering time 0.073, Prec@1 73.766
Train - epoch [53/200]	BT 1.157 (1.157)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.1619 (17.1619)
Train - epoch [40/200]	BT 1.582 (1.582)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.7029 (14.7029)
The penalty weight is 0.761594
Train - epoch [40/200]	BT 1.421 (1.421)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.1240 (14.1240)
Test on T training set - [53][0/13]	T 0.744 (0.744)	D 0.622 (0.622)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1436 (0.1436)
Test on T training set - [53][10/13]	T 0.512 (0.532)	D 0.392 (0.411)	T@1 65.079 (85.426)	T@5 100.000 (97.691)	L 0.9215 (0.6066)
 * Test on T training set - Prec@1 85.786, Prec@5 97.736
Test on T test set - [53][0/13]	Time 0.732 (0.732)	Loss 0.1436 (0.1436)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [53][10/13]	Time 0.512 (0.528)	Loss 0.9215 (0.6066)	Prec@1 65.079 (85.426)	Prec@5 100.000 (97.691)
 * Test on T test set - Prec@1 85.786, Prec@5 97.736
Epoch 53, K-means clustering 0, Average clustering time 0.018, Prec@1 88.553
Epoch 53, K-means clustering 1, Average clustering time 0.089, Prec@1 88.302
Epoch 53, K-means clustering 2, Average clustering time 0.093, Prec@1 88.176
Epoch 53, K-means clustering 3, Average clustering time 0.096, Prec@1 88.050
Epoch 53, K-means clustering 4, Average clustering time 0.096, Prec@1 88.050
Epoch 53, K-means clustering 0, Average clustering time 0.001, Prec@1 89.057
Epoch 53, K-means clustering 1, Average clustering time 0.049, Prec@1 88.805
Epoch 53, K-means clustering 2, Average clustering time 0.060, Prec@1 88.805
Epoch 53, K-means clustering 3, Average clustering time 0.065, Prec@1 88.428
Epoch 53, K-means clustering 4, Average clustering time 0.067, Prec@1 88.428
Train - epoch [40/200]	BT 1.537 (1.537)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.3087 (15.3087)
Train - epoch [40/200]	BT 1.540 (1.540)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.0092 (15.0092)
The penalty weight is 0.874053
Train - epoch [54/200]	BT 1.180 (1.180)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.2893 (17.2893)
Train - epoch [54/200]	BT 1.397 (1.397)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 15.9468 (15.9468)
Train - epoch [40/200]	BT 1.514 (1.514)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.5197 (15.5197)
Train - epoch [54/200]	BT 1.164 (1.164)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.2773 (17.2773)
Train - epoch [54/200]	BT 1.126 (1.126)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1130 (17.1130)
Train - epoch [40/200]	BT 1.717 (1.717)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2263 (15.2263)
Train - epoch [54/200]	BT 1.301 (1.301)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.8899 (15.8899)
Train - epoch [54/200]	BT 1.146 (1.146)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.0533 (17.0533)
Train - epoch [40/200]	BT 1.504 (1.504)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2889 (15.2889)
Train - epoch [54/200]	BT 1.175 (1.175)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.7914 (16.7914)
Test on T training set - [40][0/45]	T 0.521 (0.521)	D 0.402 (0.402)	T@1 88.889 (88.889)	T@5 98.413 (98.413)	L 0.6033 (0.6033)
Test on T training set - [40][10/45]	T 0.331 (0.361)	D 0.218 (0.244)	T@1 28.571 (79.365)	T@5 55.556 (91.198)	L 2.7495 (0.9240)
Test on T training set - [40][20/45]	T 0.346 (0.372)	D 0.234 (0.255)	T@1 90.476 (76.039)	T@5 100.000 (89.342)	L 0.5775 (1.0789)
Test on T training set - [40][30/45]	T 0.341 (0.366)	D 0.216 (0.249)	T@1 73.016 (74.654)	T@5 93.651 (89.708)	L 1.1633 (1.1006)
Test on T training set - [40][40/45]	T 0.323 (0.357)	D 0.210 (0.240)	T@1 39.683 (70.190)	T@5 80.952 (85.753)	L 2.0954 (1.3121)
 * Test on T training set - Prec@1 67.980, Prec@5 85.339
Test on T training set - [54][0/13]	T 0.736 (0.736)	D 0.606 (0.606)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1371 (0.1371)
Test on T training set - [54][10/13]	T 0.523 (0.524)	D 0.405 (0.403)	T@1 66.667 (86.147)	T@5 98.413 (97.403)	L 0.9304 (0.5934)
 * Test on T training set - Prec@1 86.415, Prec@5 97.484
Test on T test set - [54][0/13]	Time 0.761 (0.761)	Loss 0.1371 (0.1371)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [54][10/13]	Time 0.521 (0.528)	Loss 0.9304 (0.5934)	Prec@1 66.667 (86.147)	Prec@5 98.413 (97.403)
 * Test on T test set - Prec@1 86.415, Prec@5 97.484
Epoch 54, K-means clustering 0, Average clustering time 0.018, Prec@1 89.182
Epoch 54, K-means clustering 1, Average clustering time 0.081, Prec@1 88.302
Epoch 54, K-means clustering 2, Average clustering time 0.084, Prec@1 88.050
Epoch 54, K-means clustering 3, Average clustering time 0.088, Prec@1 88.050
Epoch 54, K-means clustering 4, Average clustering time 0.089, Prec@1 88.050
Epoch 54, K-means clustering 0, Average clustering time 0.001, Prec@1 88.805
Epoch 54, K-means clustering 1, Average clustering time 0.051, Prec@1 88.679
Epoch 54, K-means clustering 2, Average clustering time 0.062, Prec@1 88.679
Epoch 54, K-means clustering 3, Average clustering time 0.065, Prec@1 88.679
Epoch 54, K-means clustering 4, Average clustering time 0.068, Prec@1 88.553
Test on T test set - [40][0/45]	Time 0.532 (0.532)	Loss 0.6033 (0.6033)	Prec@1 88.889 (88.889)	Prec@5 98.413 (98.413)
Test on T test set - [40][10/45]	Time 0.347 (0.353)	Loss 2.7495 (0.9240)	Prec@1 28.571 (79.365)	Prec@5 55.556 (91.198)
Test on T test set - [40][20/45]	Time 0.339 (0.344)	Loss 0.5775 (1.0789)	Prec@1 90.476 (76.039)	Prec@5 100.000 (89.342)
Test on T test set - [40][30/45]	Time 0.329 (0.341)	Loss 1.1633 (1.1006)	Prec@1 73.016 (74.654)	Prec@5 93.651 (89.708)
Test on T test set - [40][40/45]	Time 0.340 (0.347)	Loss 2.0954 (1.3121)	Prec@1 39.683 (70.190)	Prec@5 80.952 (85.753)
 * Test on T test set - Prec@1 67.980, Prec@5 85.339
Epoch 40, K-means clustering 0, Average clustering time 0.026, Prec@1 73.021
Epoch 40, K-means clustering 1, Average clustering time 0.097, Prec@1 73.518
Epoch 40, K-means clustering 2, Average clustering time 0.099, Prec@1 73.589
Epoch 40, K-means clustering 3, Average clustering time 0.100, Prec@1 73.589
Epoch 40, K-means clustering 4, Average clustering time 0.106, Prec@1 73.269
Epoch 40, K-means clustering 0, Average clustering time 0.003, Prec@1 72.772
Epoch 40, K-means clustering 1, Average clustering time 0.046, Prec@1 73.518
Epoch 40, K-means clustering 2, Average clustering time 0.057, Prec@1 73.944
Epoch 40, K-means clustering 3, Average clustering time 0.064, Prec@1 73.766
Epoch 40, K-means clustering 4, Average clustering time 0.071, Prec@1 73.695
The penalty weight is 0.879827
Train - epoch [55/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.7139 (16.7139)
Train - epoch [55/200]	BT 1.180 (1.180)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.3097 (17.3097)
The penalty weight is 0.771895
Train - epoch [41/200]	BT 1.582 (1.582)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.4960 (13.4960)
Train - epoch [41/200]	BT 1.516 (1.516)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.5983 (13.5983)
Train - epoch [55/200]	BT 1.160 (1.160)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 15.9961 (15.9961)
Train - epoch [55/200]	BT 1.029 (1.029)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 17.8740 (17.8740)
Train - epoch [41/200]	BT 1.429 (1.429)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.7510 (13.7510)
Train - epoch [55/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1869 (17.1869)
Train - epoch [41/200]	BT 2.050 (2.050)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.3528 (15.3528)
Train - epoch [41/200]	BT 1.444 (1.444)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.3209 (15.3209)
Train - epoch [55/200]	BT 1.096 (1.096)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.7257 (15.7257)
Train - epoch [55/200]	BT 0.952 (0.952)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.3977 (15.3977)
Train - epoch [41/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.6713 (14.6713)
Test on T training set - [55][0/13]	T 0.749 (0.749)	D 0.619 (0.619)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1417 (0.1417)
Test on T training set - [55][10/13]	T 0.487 (0.549)	D 0.372 (0.425)	T@1 65.079 (86.003)	T@5 98.413 (97.114)	L 0.9294 (0.5938)
 * Test on T training set - Prec@1 86.289, Prec@5 97.233
Train - epoch [41/200]	BT 1.481 (1.481)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.3707 (15.3707)
Test on T test set - [55][0/13]	Time 0.723 (0.723)	Loss 0.1417 (0.1417)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [55][10/13]	Time 0.577 (0.535)	Loss 0.9294 (0.5938)	Prec@1 65.079 (86.003)	Prec@5 98.413 (97.114)
 * Test on T test set - Prec@1 86.289, Prec@5 97.233
Epoch 55, K-means clustering 0, Average clustering time 0.018, Prec@1 88.679
Epoch 55, K-means clustering 1, Average clustering time 0.074, Prec@1 88.050
Epoch 55, K-means clustering 2, Average clustering time 0.072, Prec@1 88.176
Epoch 55, K-means clustering 3, Average clustering time 0.081, Prec@1 88.176
Epoch 55, K-means clustering 4, Average clustering time 0.084, Prec@1 88.176
Epoch 55, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 55, K-means clustering 1, Average clustering time 0.041, Prec@1 88.302
Epoch 55, K-means clustering 2, Average clustering time 0.054, Prec@1 88.050
Epoch 55, K-means clustering 3, Average clustering time 0.101, Prec@1 87.925
Epoch 55, K-means clustering 4, Average clustering time 0.097, Prec@1 87.925
The penalty weight is 0.885352
Train - epoch [56/200]	BT 1.137 (1.137)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.1168 (17.1168)
Test on T training set - [41][0/45]	T 0.542 (0.542)	D 0.412 (0.412)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.6373 (0.6373)
Test on T training set - [41][10/45]	T 0.333 (0.351)	D 0.217 (0.231)	T@1 26.984 (79.076)	T@5 58.730 (90.620)	L 2.7655 (0.9455)
Test on T training set - [41][20/45]	T 0.354 (0.374)	D 0.232 (0.256)	T@1 88.889 (76.039)	T@5 100.000 (89.116)	L 0.6167 (1.0870)
Test on T training set - [41][30/45]	T 0.399 (0.385)	D 0.274 (0.266)	T@1 74.603 (74.757)	T@5 95.238 (89.555)	L 1.1163 (1.1031)
Test on T training set - [41][40/45]	T 0.322 (0.379)	D 0.199 (0.260)	T@1 42.857 (70.383)	T@5 80.952 (85.405)	L 1.9379 (1.3143)
 * Test on T training set - Prec@1 68.087, Prec@5 85.162
Train - epoch [56/200]	BT 1.740 (1.740)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.2618 (17.2618)
Train - epoch [56/200]	BT 1.159 (1.159)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.2414 (17.2414)
Test on T test set - [41][0/45]	Time 0.540 (0.540)	Loss 0.6373 (0.6373)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [41][10/45]	Time 0.322 (0.360)	Loss 2.7655 (0.9455)	Prec@1 26.984 (79.076)	Prec@5 58.730 (90.620)
Test on T test set - [41][20/45]	Time 0.362 (0.351)	Loss 0.6167 (1.0870)	Prec@1 88.889 (76.039)	Prec@5 100.000 (89.116)
Test on T test set - [41][30/45]	Time 0.343 (0.346)	Loss 1.1163 (1.1031)	Prec@1 74.603 (74.757)	Prec@5 95.238 (89.555)
Test on T test set - [41][40/45]	Time 0.336 (0.343)	Loss 1.9379 (1.3143)	Prec@1 42.857 (70.383)	Prec@5 80.952 (85.405)
 * Test on T test set - Prec@1 68.087, Prec@5 85.162
Epoch 41, K-means clustering 0, Average clustering time 0.029, Prec@1 73.518
Epoch 41, K-means clustering 1, Average clustering time 0.097, Prec@1 74.121
Epoch 41, K-means clustering 2, Average clustering time 0.099, Prec@1 74.157
Epoch 41, K-means clustering 3, Average clustering time 0.103, Prec@1 74.086
Epoch 41, K-means clustering 4, Average clustering time 0.107, Prec@1 73.482
Epoch 41, K-means clustering 0, Average clustering time 0.003, Prec@1 72.630
Epoch 41, K-means clustering 1, Average clustering time 0.043, Prec@1 73.198
Epoch 41, K-means clustering 2, Average clustering time 0.066, Prec@1 73.269
Epoch 41, K-means clustering 3, Average clustering time 0.072, Prec@1 72.985
Epoch 41, K-means clustering 4, Average clustering time 0.074, Prec@1 72.843
The penalty weight is 0.781806
Train - epoch [42/200]	BT 1.704 (1.704)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.5013 (14.5013)
Train - epoch [56/200]	BT 1.642 (1.642)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.7379 (15.7379)
Train - epoch [56/200]	BT 1.188 (1.188)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.7100 (15.7100)
Train - epoch [56/200]	BT 1.238 (1.238)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.6989 (17.6989)
Train - epoch [42/200]	BT 1.488 (1.488)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.4221 (14.4221)
Train - epoch [42/200]	BT 1.535 (1.535)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2683 (15.2683)
Test on T training set - [56][0/13]	T 0.767 (0.767)	D 0.644 (0.644)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1627 (0.1627)
Test on T training set - [56][10/13]	T 0.534 (0.528)	D 0.409 (0.407)	T@1 66.667 (86.147)	T@5 98.413 (97.403)	L 0.9467 (0.6010)
 * Test on T training set - Prec@1 86.541, Prec@5 97.484
Test on T test set - [56][0/13]	Time 0.750 (0.750)	Loss 0.1627 (0.1627)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [56][10/13]	Time 0.500 (0.525)	Loss 0.9467 (0.6010)	Prec@1 66.667 (86.147)	Prec@5 98.413 (97.403)
 * Test on T test set - Prec@1 86.541, Prec@5 97.484
Epoch 56, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 56, K-means clustering 1, Average clustering time 0.086, Prec@1 88.176
Epoch 56, K-means clustering 2, Average clustering time 0.085, Prec@1 88.050
Epoch 56, K-means clustering 3, Average clustering time 0.084, Prec@1 87.925
Epoch 56, K-means clustering 4, Average clustering time 0.084, Prec@1 87.925
Epoch 56, K-means clustering 0, Average clustering time 0.001, Prec@1 88.679
Epoch 56, K-means clustering 1, Average clustering time 0.037, Prec@1 88.176
Epoch 56, K-means clustering 2, Average clustering time 0.052, Prec@1 87.673
Epoch 56, K-means clustering 3, Average clustering time 0.058, Prec@1 87.673
Epoch 56, K-means clustering 4, Average clustering time 0.068, Prec@1 87.673
Train - epoch [42/200]	BT 1.545 (1.545)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.4172 (14.4172)
Train - epoch [42/200]	BT 1.592 (1.592)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 13.8678 (13.8678)
The penalty weight is 0.890637
Train - epoch [57/200]	BT 0.939 (0.939)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 16.6667 (16.6667)
Train - epoch [57/200]	BT 1.019 (1.019)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.1146 (17.1146)
Train - epoch [42/200]	BT 1.459 (1.459)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2573 (15.2573)
Train - epoch [42/200]	BT 1.806 (1.806)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.7430 (14.7430)
Train - epoch [57/200]	BT 1.142 (1.142)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.0132 (17.0132)
Train - epoch [57/200]	BT 1.112 (1.112)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.0247 (17.0247)
Train - epoch [57/200]	BT 1.111 (1.111)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.1697 (16.1697)
Train - epoch [57/200]	BT 1.244 (1.244)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 17.6044 (17.6044)
Test on T training set - [42][0/45]	T 0.492 (0.492)	D 0.378 (0.378)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7354 (0.7354)
Test on T training set - [42][10/45]	T 0.324 (0.346)	D 0.203 (0.227)	T@1 28.571 (78.788)	T@5 61.905 (91.342)	L 2.6529 (0.9447)
Test on T training set - [42][20/45]	T 0.356 (0.343)	D 0.234 (0.224)	T@1 90.476 (76.946)	T@5 100.000 (90.249)	L 0.6090 (1.0607)
Test on T training set - [42][30/45]	T 0.347 (0.351)	D 0.216 (0.231)	T@1 77.778 (75.832)	T@5 93.651 (90.271)	L 1.0323 (1.0843)
Test on T training set - [42][40/45]	T 0.517 (0.351)	D 0.400 (0.231)	T@1 41.270 (71.390)	T@5 80.952 (85.985)	L 2.0034 (1.2962)
 * Test on T training set - Prec@1 68.868, Prec@5 85.552
Train - epoch [57/200]	BT 1.111 (1.111)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.9212 (16.9212)
Test on T test set - [42][0/45]	Time 0.519 (0.519)	Loss 0.7354 (0.7354)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [42][10/45]	Time 0.342 (0.351)	Loss 2.6529 (0.9447)	Prec@1 28.571 (78.788)	Prec@5 61.905 (91.342)
Test on T test set - [42][20/45]	Time 0.320 (0.344)	Loss 0.6090 (1.0607)	Prec@1 90.476 (76.946)	Prec@5 100.000 (90.249)
Test on T test set - [42][30/45]	Time 0.350 (0.342)	Loss 1.0323 (1.0843)	Prec@1 77.778 (75.832)	Prec@5 93.651 (90.271)
Test on T test set - [42][40/45]	Time 0.318 (0.339)	Loss 2.0034 (1.2962)	Prec@1 41.270 (71.390)	Prec@5 80.952 (85.985)
 * Test on T test set - Prec@1 68.868, Prec@5 85.552
Epoch 42, K-means clustering 0, Average clustering time 0.026, Prec@1 73.624
Epoch 42, K-means clustering 1, Average clustering time 0.094, Prec@1 73.766
Epoch 42, K-means clustering 2, Average clustering time 0.101, Prec@1 74.050
Epoch 42, K-means clustering 3, Average clustering time 0.103, Prec@1 73.908
Epoch 42, K-means clustering 4, Average clustering time 0.105, Prec@1 73.518
Epoch 42, K-means clustering 0, Average clustering time 0.003, Prec@1 73.056
Epoch 42, K-means clustering 1, Average clustering time 0.042, Prec@1 73.766
Epoch 42, K-means clustering 2, Average clustering time 0.056, Prec@1 73.766
Epoch 42, K-means clustering 3, Average clustering time 0.066, Prec@1 73.482
Epoch 42, K-means clustering 4, Average clustering time 0.068, Prec@1 73.269
The penalty weight is 0.791338
Train - epoch [43/200]	BT 1.469 (1.469)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.8314 (14.8314)
Test on T training set - [57][0/13]	T 0.747 (0.747)	D 0.621 (0.621)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1440 (0.1440)
Test on T training set - [57][10/13]	T 0.527 (0.550)	D 0.394 (0.427)	T@1 66.667 (86.003)	T@5 100.000 (97.547)	L 0.8779 (0.5886)
 * Test on T training set - Prec@1 86.541, Prec@5 97.610
Test on T test set - [57][0/13]	Time 0.717 (0.717)	Loss 0.1440 (0.1440)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [57][10/13]	Time 0.524 (0.571)	Loss 0.8779 (0.5886)	Prec@1 66.667 (86.003)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 86.541, Prec@5 97.610
Epoch 57, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 57, K-means clustering 1, Average clustering time 0.082, Prec@1 88.050
Epoch 57, K-means clustering 2, Average clustering time 0.097, Prec@1 87.925
Epoch 57, K-means clustering 3, Average clustering time 0.096, Prec@1 87.925
Epoch 57, K-means clustering 4, Average clustering time 0.096, Prec@1 87.925
Epoch 57, K-means clustering 0, Average clustering time 0.001, Prec@1 88.805
Epoch 57, K-means clustering 1, Average clustering time 0.050, Prec@1 88.428
Epoch 57, K-means clustering 2, Average clustering time 0.061, Prec@1 88.176
Epoch 57, K-means clustering 3, Average clustering time 0.071, Prec@1 88.050
Epoch 57, K-means clustering 4, Average clustering time 0.073, Prec@1 88.050
Train - epoch [43/200]	BT 1.506 (1.506)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.6331 (15.6331)
The penalty weight is 0.895693
Train - epoch [58/200]	BT 1.129 (1.129)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.1827 (17.1827)
Train - epoch [58/200]	BT 1.203 (1.203)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 17.0951 (17.0951)
Train - epoch [43/200]	BT 1.516 (1.516)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.5599 (14.5599)
Train - epoch [43/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2578 (15.2578)
Train - epoch [58/200]	BT 1.180 (1.180)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.7795 (17.7795)
Train - epoch [58/200]	BT 1.222 (1.222)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.9544 (16.9544)
Train - epoch [43/200]	BT 1.501 (1.501)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.4103 (15.4103)
Train - epoch [58/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.0653 (17.0653)
Train - epoch [43/200]	BT 1.695 (1.695)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.9240 (15.9240)
Train - epoch [58/200]	BT 1.658 (1.658)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.4368 (17.4368)
Train - epoch [58/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 17.8300 (17.8300)
Test on T training set - [58][0/13]	T 0.742 (0.742)	D 0.613 (0.613)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1482 (0.1482)
Test on T training set - [58][10/13]	T 0.504 (0.528)	D 0.389 (0.406)	T@1 61.905 (85.426)	T@5 100.000 (98.124)	L 0.9758 (0.6011)
 * Test on T training set - Prec@1 85.786, Prec@5 98.113
Test on T training set - [43][0/45]	T 0.505 (0.505)	D 0.383 (0.383)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7326 (0.7326)
Test on T training set - [43][10/45]	T 0.326 (0.343)	D 0.209 (0.223)	T@1 26.984 (78.644)	T@5 57.143 (90.188)	L 2.7170 (0.9670)
Test on T training set - [43][20/45]	T 0.338 (0.342)	D 0.217 (0.222)	T@1 92.063 (76.190)	T@5 100.000 (89.040)	L 0.5288 (1.0874)
Test on T training set - [43][30/45]	T 0.313 (0.337)	D 0.197 (0.219)	T@1 73.016 (74.859)	T@5 93.651 (89.555)	L 1.1800 (1.1083)
Test on T training set - [43][40/45]	T 0.340 (0.337)	D 0.217 (0.218)	T@1 42.857 (70.732)	T@5 80.952 (85.405)	L 1.9501 (1.3178)
 * Test on T training set - Prec@1 68.193, Prec@5 84.878
Test on T test set - [58][0/13]	Time 0.752 (0.752)	Loss 0.1482 (0.1482)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [58][10/13]	Time 0.501 (0.536)	Loss 0.9758 (0.6011)	Prec@1 61.905 (85.426)	Prec@5 100.000 (98.124)
 * Test on T test set - Prec@1 85.786, Prec@5 98.113
Epoch 58, K-means clustering 0, Average clustering time 0.018, Prec@1 88.553
Epoch 58, K-means clustering 1, Average clustering time 0.082, Prec@1 87.925
Epoch 58, K-means clustering 2, Average clustering time 0.083, Prec@1 87.799
Epoch 58, K-means clustering 3, Average clustering time 0.084, Prec@1 87.799
Epoch 58, K-means clustering 4, Average clustering time 0.090, Prec@1 87.799
Epoch 58, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 58, K-means clustering 1, Average clustering time 0.043, Prec@1 88.428
Epoch 58, K-means clustering 2, Average clustering time 0.062, Prec@1 88.302
Epoch 58, K-means clustering 3, Average clustering time 0.065, Prec@1 88.176
Epoch 58, K-means clustering 4, Average clustering time 0.068, Prec@1 88.428
Test on T test set - [43][0/45]	Time 0.542 (0.542)	Loss 0.7326 (0.7326)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [43][10/45]	Time 0.320 (0.345)	Loss 2.7170 (0.9670)	Prec@1 26.984 (78.644)	Prec@5 57.143 (90.188)
Test on T test set - [43][20/45]	Time 0.395 (0.343)	Loss 0.5288 (1.0874)	Prec@1 92.063 (76.190)	Prec@5 100.000 (89.040)
Test on T test set - [43][30/45]	Time 0.333 (0.347)	Loss 1.1800 (1.1083)	Prec@1 73.016 (74.859)	Prec@5 93.651 (89.555)
Test on T test set - [43][40/45]	Time 0.352 (0.347)	Loss 1.9501 (1.3178)	Prec@1 42.857 (70.732)	Prec@5 80.952 (85.405)
 * Test on T test set - Prec@1 68.193, Prec@5 84.878
Epoch 43, K-means clustering 0, Average clustering time 0.026, Prec@1 73.553
Epoch 43, K-means clustering 1, Average clustering time 0.087, Prec@1 74.192
Epoch 43, K-means clustering 2, Average clustering time 0.096, Prec@1 74.086
Epoch 43, K-means clustering 3, Average clustering time 0.095, Prec@1 74.157
Epoch 43, K-means clustering 4, Average clustering time 0.095, Prec@1 73.802
Epoch 43, K-means clustering 0, Average clustering time 0.004, Prec@1 72.559
Epoch 43, K-means clustering 1, Average clustering time 0.045, Prec@1 73.340
Epoch 43, K-means clustering 2, Average clustering time 0.069, Prec@1 73.553
Epoch 43, K-means clustering 3, Average clustering time 0.074, Prec@1 73.411
Epoch 43, K-means clustering 4, Average clustering time 0.074, Prec@1 73.127
The penalty weight is 0.900527
Train - epoch [59/200]	BT 1.456 (1.456)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 17.7025 (17.7025)
Train - epoch [59/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 15.9125 (15.9125)
The penalty weight is 0.800499
Train - epoch [44/200]	BT 1.470 (1.470)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.3091 (15.3091)
Train - epoch [59/200]	BT 1.029 (1.029)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.7023 (17.7023)
Train - epoch [44/200]	BT 1.485 (1.485)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.0156 (16.0156)
Train - epoch [44/200]	BT 2.064 (2.064)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.4789 (15.4789)
Train - epoch [44/200]	BT 1.431 (1.431)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.9743 (14.9743)
Train - epoch [59/200]	BT 1.093 (1.093)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.1341 (18.1341)
Train - epoch [59/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.0432 (17.0432)
Train - epoch [44/200]	BT 1.545 (1.545)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.7520 (15.7520)
Train - epoch [59/200]	BT 1.063 (1.063)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.2587 (18.2587)
Train - epoch [44/200]	BT 1.483 (1.483)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.2855 (16.2855)
Test on T training set - [59][0/13]	T 0.716 (0.716)	D 0.589 (0.589)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1181 (0.1181)
Test on T training set - [59][10/13]	T 0.742 (0.547)	D 0.627 (0.427)	T@1 61.905 (86.003)	T@5 100.000 (97.835)	L 0.9348 (0.5804)
 * Test on T training set - Prec@1 86.164, Prec@5 97.862
Test on T test set - [59][0/13]	Time 0.740 (0.740)	Loss 0.1181 (0.1181)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [59][10/13]	Time 0.525 (0.527)	Loss 0.9348 (0.5804)	Prec@1 61.905 (86.003)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 86.164, Prec@5 97.862
Epoch 59, K-means clustering 0, Average clustering time 0.018, Prec@1 88.050
Epoch 59, K-means clustering 1, Average clustering time 0.089, Prec@1 87.925
Epoch 59, K-means clustering 2, Average clustering time 0.093, Prec@1 87.673
Epoch 59, K-means clustering 3, Average clustering time 0.095, Prec@1 87.547
Epoch 59, K-means clustering 4, Average clustering time 0.096, Prec@1 87.547
Epoch 59, K-means clustering 0, Average clustering time 0.001, Prec@1 88.050
Epoch 59, K-means clustering 1, Average clustering time 0.051, Prec@1 88.428
Epoch 59, K-means clustering 2, Average clustering time 0.063, Prec@1 88.302
Epoch 59, K-means clustering 3, Average clustering time 0.073, Prec@1 88.176
Epoch 59, K-means clustering 4, Average clustering time 0.076, Prec@1 88.176
Train - epoch [44/200]	BT 1.479 (1.479)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.8105 (15.8105)
Train - epoch [60/200]	BT 1.095 (1.095)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.8936 (17.8936)
The penalty weight is 0.905148
Train - epoch [60/200]	BT 1.199 (1.199)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.5767 (17.5767)
Test on T training set - [44][0/45]	T 0.502 (0.502)	D 0.389 (0.389)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.8188 (0.8188)
Test on T training set - [44][10/45]	T 0.342 (0.376)	D 0.220 (0.258)	T@1 30.159 (78.788)	T@5 60.317 (91.198)	L 2.6384 (0.9452)
Test on T training set - [44][20/45]	T 0.338 (0.372)	D 0.216 (0.254)	T@1 88.889 (76.190)	T@5 100.000 (90.023)	L 0.6127 (1.0848)
Test on T training set - [44][30/45]	T 0.345 (0.364)	D 0.223 (0.245)	T@1 74.603 (74.808)	T@5 95.238 (90.220)	L 1.0656 (1.1077)
Test on T training set - [44][40/45]	T 0.346 (0.357)	D 0.232 (0.239)	T@1 41.270 (70.499)	T@5 80.952 (85.908)	L 1.9868 (1.3169)
 * Test on T training set - Prec@1 68.229, Prec@5 85.552
Train - epoch [60/200]	BT 1.074 (1.074)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 15.8699 (15.8699)
Train - epoch [60/200]	BT 1.199 (1.199)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.4909 (17.4909)
Test on T test set - [44][0/45]	Time 0.546 (0.546)	Loss 0.8188 (0.8188)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [44][10/45]	Time 0.341 (0.354)	Loss 2.6384 (0.9452)	Prec@1 30.159 (78.788)	Prec@5 60.317 (91.198)
Test on T test set - [44][20/45]	Time 0.347 (0.357)	Loss 0.6127 (1.0848)	Prec@1 88.889 (76.190)	Prec@5 100.000 (90.023)
Test on T test set - [44][30/45]	Time 0.336 (0.349)	Loss 1.0656 (1.1077)	Prec@1 74.603 (74.808)	Prec@5 95.238 (90.220)
Test on T test set - [44][40/45]	Time 0.357 (0.347)	Loss 1.9868 (1.3169)	Prec@1 41.270 (70.499)	Prec@5 80.952 (85.908)
 * Test on T test set - Prec@1 68.229, Prec@5 85.552
Epoch 44, K-means clustering 0, Average clustering time 0.026, Prec@1 73.589
Epoch 44, K-means clustering 1, Average clustering time 0.085, Prec@1 74.086
Epoch 44, K-means clustering 2, Average clustering time 0.095, Prec@1 74.086
Epoch 44, K-means clustering 3, Average clustering time 0.096, Prec@1 73.873
Epoch 44, K-means clustering 4, Average clustering time 0.097, Prec@1 73.340
Epoch 44, K-means clustering 0, Average clustering time 0.005, Prec@1 72.524
Epoch 44, K-means clustering 1, Average clustering time 0.055, Prec@1 73.163
Epoch 44, K-means clustering 2, Average clustering time 0.062, Prec@1 73.269
Epoch 44, K-means clustering 3, Average clustering time 0.067, Prec@1 73.234
Epoch 44, K-means clustering 4, Average clustering time 0.068, Prec@1 73.021
Train - epoch [60/200]	BT 1.109 (1.109)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.8253 (17.8253)
Train - epoch [60/200]	BT 1.049 (1.049)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 16.4893 (16.4893)
The penalty weight is 0.809301
Train - epoch [45/200]	BT 1.481 (1.481)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.1050 (15.1050)
Train - epoch [60/200]	BT 1.092 (1.092)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.8181 (17.8181)
Train - epoch [45/200]	BT 1.497 (1.497)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.5314 (15.5314)
Train - epoch [45/200]	BT 1.615 (1.615)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.3223 (16.3223)
Test on T training set - [60][0/13]	T 0.754 (0.754)	D 0.633 (0.633)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1387 (0.1387)
Test on T training set - [60][10/13]	T 0.507 (0.548)	D 0.392 (0.427)	T@1 65.079 (85.859)	T@5 100.000 (97.691)	L 0.9137 (0.5872)
 * Test on T training set - Prec@1 86.038, Prec@5 97.862
Test on T test set - [60][0/13]	Time 0.726 (0.726)	Loss 0.1387 (0.1387)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [60][10/13]	Time 0.536 (0.522)	Loss 0.9137 (0.5872)	Prec@1 65.079 (85.859)	Prec@5 100.000 (97.691)
 * Test on T test set - Prec@1 86.038, Prec@5 97.862
Epoch 60, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 60, K-means clustering 1, Average clustering time 0.081, Prec@1 87.799
Epoch 60, K-means clustering 2, Average clustering time 0.082, Prec@1 87.925
Epoch 60, K-means clustering 3, Average clustering time 0.082, Prec@1 87.925
Epoch 60, K-means clustering 4, Average clustering time 0.082, Prec@1 87.925
Epoch 60, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 60, K-means clustering 1, Average clustering time 0.037, Prec@1 88.050
Epoch 60, K-means clustering 2, Average clustering time 0.053, Prec@1 88.050
Epoch 60, K-means clustering 3, Average clustering time 0.061, Prec@1 88.050
Epoch 60, K-means clustering 4, Average clustering time 0.067, Prec@1 88.050
Train - epoch [45/200]	BT 1.461 (1.461)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.8826 (15.8826)
The penalty weight is 0.909565
Train - epoch [61/200]	BT 1.077 (1.077)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.2422 (16.2422)
Train - epoch [61/200]	BT 0.984 (0.984)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.0284 (18.0284)
Train - epoch [45/200]	BT 1.501 (1.501)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.8148 (15.8148)
Train - epoch [45/200]	BT 2.053 (2.053)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.0873 (15.0873)
Train - epoch [45/200]	BT 1.185 (1.185)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.1348 (15.1348)
Train - epoch [61/200]	BT 1.130 (1.130)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.1506 (17.1506)
Train - epoch [61/200]	BT 1.114 (1.114)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.6155 (18.6155)
Train - epoch [61/200]	BT 1.326 (1.326)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.2507 (16.2507)
Train - epoch [61/200]	BT 1.177 (1.177)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.5258 (17.5258)
Test on T training set - [45][0/45]	T 0.508 (0.508)	D 0.395 (0.395)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.6579 (0.6579)
Test on T training set - [45][10/45]	T 0.344 (0.376)	D 0.222 (0.258)	T@1 26.984 (79.654)	T@5 58.730 (91.198)	L 2.7387 (0.9235)
Test on T training set - [45][20/45]	T 0.322 (0.366)	D 0.205 (0.247)	T@1 88.889 (76.644)	T@5 100.000 (90.098)	L 0.6501 (1.0634)
Test on T training set - [45][30/45]	T 0.323 (0.357)	D 0.211 (0.238)	T@1 76.190 (75.627)	T@5 95.238 (90.579)	L 1.0806 (1.0808)
Test on T training set - [45][40/45]	T 0.327 (0.352)	D 0.205 (0.233)	T@1 42.857 (71.390)	T@5 77.778 (86.179)	L 2.0797 (1.2940)
 * Test on T training set - Prec@1 68.903, Prec@5 85.481
Train - epoch [61/200]	BT 1.209 (1.209)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.5479 (18.5479)
Test on T test set - [45][0/45]	Time 0.525 (0.525)	Loss 0.6579 (0.6579)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [45][10/45]	Time 0.322 (0.346)	Loss 2.7387 (0.9235)	Prec@1 26.984 (79.654)	Prec@5 58.730 (91.198)
Test on T test set - [45][20/45]	Time 0.331 (0.342)	Loss 0.6501 (1.0634)	Prec@1 88.889 (76.644)	Prec@5 100.000 (90.098)
Test on T test set - [45][30/45]	Time 0.320 (0.354)	Loss 1.0806 (1.0808)	Prec@1 76.190 (75.627)	Prec@5 95.238 (90.579)
Test on T test set - [45][40/45]	Time 0.332 (0.357)	Loss 2.0797 (1.2940)	Prec@1 42.857 (71.390)	Prec@5 77.778 (86.179)
 * Test on T test set - Prec@1 68.903, Prec@5 85.481
Epoch 45, K-means clustering 0, Average clustering time 0.026, Prec@1 73.766
Epoch 45, K-means clustering 1, Average clustering time 0.089, Prec@1 73.908
Epoch 45, K-means clustering 2, Average clustering time 0.118, Prec@1 73.979
Epoch 45, K-means clustering 3, Average clustering time 0.112, Prec@1 73.766
Epoch 45, K-means clustering 4, Average clustering time 0.117, Prec@1 73.411
Epoch 45, K-means clustering 0, Average clustering time 0.003, Prec@1 73.056
Epoch 45, K-means clustering 1, Average clustering time 0.040, Prec@1 73.731
Epoch 45, K-means clustering 2, Average clustering time 0.054, Prec@1 73.766
Epoch 45, K-means clustering 3, Average clustering time 0.061, Prec@1 73.624
Epoch 45, K-means clustering 4, Average clustering time 0.067, Prec@1 73.482
Test on T training set - [61][0/13]	T 0.768 (0.768)	D 0.645 (0.645)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1549 (0.1549)
Test on T training set - [61][10/13]	T 0.520 (0.522)	D 0.405 (0.401)	T@1 66.667 (86.580)	T@5 100.000 (98.124)	L 0.8478 (0.5858)
 * Test on T training set - Prec@1 86.918, Prec@5 98.113
The penalty weight is 0.817754
Train - epoch [46/200]	BT 1.471 (1.471)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2707 (15.2707)
Test on T test set - [61][0/13]	Time 0.741 (0.741)	Loss 0.1549 (0.1549)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [61][10/13]	Time 0.499 (0.527)	Loss 0.8478 (0.5858)	Prec@1 66.667 (86.580)	Prec@5 100.000 (98.124)
 * Test on T test set - Prec@1 86.918, Prec@5 98.113
Epoch 61, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 61, K-means clustering 1, Average clustering time 0.086, Prec@1 88.050
Epoch 61, K-means clustering 2, Average clustering time 0.087, Prec@1 87.673
Epoch 61, K-means clustering 3, Average clustering time 0.086, Prec@1 87.673
Epoch 61, K-means clustering 4, Average clustering time 0.087, Prec@1 87.673
Epoch 61, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 61, K-means clustering 1, Average clustering time 0.044, Prec@1 88.176
Epoch 61, K-means clustering 2, Average clustering time 0.059, Prec@1 87.925
Epoch 61, K-means clustering 3, Average clustering time 0.062, Prec@1 88.050
Epoch 61, K-means clustering 4, Average clustering time 0.063, Prec@1 88.050
Train - epoch [46/200]	BT 1.792 (1.792)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.6274 (15.6274)
The penalty weight is 0.913785
Train - epoch [62/200]	BT 1.127 (1.127)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.0286 (18.0286)
Train - epoch [62/200]	BT 1.234 (1.234)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 18.0459 (18.0459)
Train - epoch [46/200]	BT 1.440 (1.440)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.2199 (16.2199)
Train - epoch [62/200]	BT 1.109 (1.109)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.8596 (16.8596)
Train - epoch [46/200]	BT 1.455 (1.455)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.0111 (16.0111)
Train - epoch [46/200]	BT 1.566 (1.566)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.0613 (15.0613)
Train - epoch [62/200]	BT 1.754 (1.754)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.3933 (18.3933)
Train - epoch [62/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.5698 (16.5698)
Train - epoch [62/200]	BT 1.189 (1.189)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.9994 (16.9994)
Train - epoch [62/200]	BT 0.962 (0.962)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.1669 (18.1669)
Train - epoch [46/200]	BT 1.525 (1.525)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.1335 (16.1335)
Test on T training set - [62][0/13]	T 0.721 (0.721)	D 0.604 (0.604)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1706 (0.1706)
Test on T training set - [62][10/13]	T 0.520 (0.519)	D 0.392 (0.398)	T@1 68.254 (86.580)	T@5 100.000 (98.124)	L 0.8755 (0.5912)
 * Test on T training set - Prec@1 86.792, Prec@5 98.113
Test on T training set - [46][0/45]	T 0.645 (0.645)	D 0.522 (0.522)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7882 (0.7882)
Test on T training set - [46][10/45]	T 0.337 (0.360)	D 0.225 (0.241)	T@1 30.159 (78.355)	T@5 63.492 (91.631)	L 2.6728 (0.9546)
Test on T training set - [46][20/45]	T 0.320 (0.345)	D 0.198 (0.226)	T@1 90.476 (76.266)	T@5 100.000 (90.174)	L 0.6575 (1.0891)
Test on T training set - [46][30/45]	T 0.325 (0.341)	D 0.210 (0.221)	T@1 76.190 (75.064)	T@5 95.238 (90.374)	L 1.1227 (1.1090)
Test on T training set - [46][40/45]	T 0.345 (0.339)	D 0.224 (0.219)	T@1 44.444 (71.312)	T@5 80.952 (86.101)	L 2.0189 (1.3090)
 * Test on T training set - Prec@1 68.939, Prec@5 85.588
Test on T test set - [62][0/13]	Time 0.730 (0.730)	Loss 0.1706 (0.1706)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [62][10/13]	Time 0.497 (0.518)	Loss 0.8755 (0.5912)	Prec@1 68.254 (86.580)	Prec@5 100.000 (98.124)
 * Test on T test set - Prec@1 86.792, Prec@5 98.113
Epoch 62, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 62, K-means clustering 1, Average clustering time 0.084, Prec@1 88.428
Epoch 62, K-means clustering 2, Average clustering time 0.085, Prec@1 87.925
Epoch 62, K-means clustering 3, Average clustering time 0.091, Prec@1 87.925
Epoch 62, K-means clustering 4, Average clustering time 0.091, Prec@1 87.925
Epoch 62, K-means clustering 0, Average clustering time 0.001, Prec@1 89.057
Epoch 62, K-means clustering 1, Average clustering time 0.050, Prec@1 88.679
Epoch 62, K-means clustering 2, Average clustering time 0.059, Prec@1 88.428
Epoch 62, K-means clustering 3, Average clustering time 0.064, Prec@1 88.553
Epoch 62, K-means clustering 4, Average clustering time 0.067, Prec@1 88.553
Test on T test set - [46][0/45]	Time 0.531 (0.531)	Loss 0.7882 (0.7882)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [46][10/45]	Time 0.353 (0.385)	Loss 2.6728 (0.9546)	Prec@1 30.159 (78.355)	Prec@5 63.492 (91.631)
Test on T test set - [46][20/45]	Time 0.343 (0.362)	Loss 0.6575 (1.0891)	Prec@1 90.476 (76.266)	Prec@5 100.000 (90.174)
Test on T test set - [46][30/45]	Time 0.330 (0.357)	Loss 1.1227 (1.1090)	Prec@1 76.190 (75.064)	Prec@5 95.238 (90.374)
Test on T test set - [46][40/45]	Time 0.327 (0.352)	Loss 2.0189 (1.3090)	Prec@1 44.444 (71.312)	Prec@5 80.952 (86.101)
 * Test on T test set - Prec@1 68.939, Prec@5 85.588
Epoch 46, K-means clustering 0, Average clustering time 0.026, Prec@1 73.908
Epoch 46, K-means clustering 1, Average clustering time 0.112, Prec@1 74.015
Epoch 46, K-means clustering 2, Average clustering time 0.117, Prec@1 73.802
Epoch 46, K-means clustering 3, Average clustering time 0.114, Prec@1 73.305
Epoch 46, K-means clustering 4, Average clustering time 0.112, Prec@1 72.808
Epoch 46, K-means clustering 0, Average clustering time 0.003, Prec@1 73.021
Epoch 46, K-means clustering 1, Average clustering time 0.049, Prec@1 73.447
Epoch 46, K-means clustering 2, Average clustering time 0.062, Prec@1 73.411
Epoch 46, K-means clustering 3, Average clustering time 0.066, Prec@1 73.305
Epoch 46, K-means clustering 4, Average clustering time 0.070, Prec@1 72.985
The penalty weight is 0.917817
Train - epoch [63/200]	BT 1.102 (1.102)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.0894 (17.0894)
The penalty weight is 0.825868
Train - epoch [47/200]	BT 1.478 (1.478)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.4657 (16.4657)
Train - epoch [63/200]	BT 1.123 (1.123)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.1559 (18.1559)
Train - epoch [63/200]	BT 1.109 (1.109)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.4389 (17.4389)
Train - epoch [47/200]	BT 2.002 (2.002)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.2937 (16.2937)
Train - epoch [47/200]	BT 1.448 (1.448)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2848 (15.2848)
Train - epoch [63/200]	BT 1.073 (1.073)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.2160 (17.2160)
Train - epoch [63/200]	BT 1.055 (1.055)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.2370 (18.2370)
Train - epoch [47/200]	BT 1.494 (1.494)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8069 (16.8069)
Train - epoch [63/200]	BT 1.149 (1.149)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.7943 (16.7943)
Train - epoch [47/200]	BT 1.560 (1.560)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.4143 (16.4143)
Test on T training set - [63][0/13]	T 0.745 (0.745)	D 0.625 (0.625)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1399 (0.1399)
Test on T training set - [63][10/13]	T 0.529 (0.523)	D 0.407 (0.398)	T@1 63.492 (86.580)	T@5 100.000 (97.547)	L 0.8862 (0.5934)
 * Test on T training set - Prec@1 86.918, Prec@5 97.610
Train - epoch [47/200]	BT 1.491 (1.491)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.9940 (15.9940)
Test on T test set - [63][0/13]	Time 0.753 (0.753)	Loss 0.1399 (0.1399)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [63][10/13]	Time 0.538 (0.523)	Loss 0.8862 (0.5934)	Prec@1 63.492 (86.580)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 86.918, Prec@5 97.610
Epoch 63, K-means clustering 0, Average clustering time 0.018, Prec@1 88.553
Epoch 63, K-means clustering 1, Average clustering time 0.083, Prec@1 87.925
Epoch 63, K-means clustering 2, Average clustering time 0.087, Prec@1 87.799
Epoch 63, K-means clustering 3, Average clustering time 0.089, Prec@1 87.799
Epoch 63, K-means clustering 4, Average clustering time 0.091, Prec@1 87.799
Epoch 63, K-means clustering 0, Average clustering time 0.001, Prec@1 88.428
Epoch 63, K-means clustering 1, Average clustering time 0.040, Prec@1 88.302
Epoch 63, K-means clustering 2, Average clustering time 0.051, Prec@1 88.428
Epoch 63, K-means clustering 3, Average clustering time 0.060, Prec@1 88.428
Epoch 63, K-means clustering 4, Average clustering time 0.063, Prec@1 88.302
Train - epoch [47/200]	BT 1.980 (1.980)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.3145 (16.3145)
The penalty weight is 0.921669
Train - epoch [64/200]	BT 1.158 (1.158)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.5392 (18.5392)
Train - epoch [64/200]	BT 1.103 (1.103)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.0343 (18.0343)
Test on T training set - [47][0/45]	T 0.505 (0.505)	D 0.389 (0.389)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7531 (0.7531)
Test on T training set - [47][10/45]	T 0.333 (0.351)	D 0.217 (0.231)	T@1 28.571 (78.932)	T@5 60.317 (90.620)	L 2.6683 (0.9669)
Test on T training set - [47][20/45]	T 0.356 (0.345)	D 0.236 (0.225)	T@1 90.476 (76.342)	T@5 100.000 (89.569)	L 0.5937 (1.0995)
Test on T training set - [47][30/45]	T 0.334 (0.344)	D 0.212 (0.225)	T@1 76.190 (75.013)	T@5 95.238 (90.118)	L 1.0761 (1.1150)
Test on T training set - [47][40/45]	T 0.330 (0.343)	D 0.210 (0.223)	T@1 39.683 (70.461)	T@5 79.365 (85.792)	L 2.0646 (1.3267)
 * Test on T training set - Prec@1 68.122, Prec@5 85.304
Train - epoch [64/200]	BT 1.244 (1.244)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.5887 (17.5887)
Train - epoch [64/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.0441 (17.0441)
Test on T test set - [47][0/45]	Time 0.559 (0.559)	Loss 0.7531 (0.7531)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [47][10/45]	Time 0.319 (0.348)	Loss 2.6683 (0.9669)	Prec@1 28.571 (78.932)	Prec@5 60.317 (90.620)
Test on T test set - [47][20/45]	Time 0.336 (0.342)	Loss 0.5937 (1.0995)	Prec@1 90.476 (76.342)	Prec@5 100.000 (89.569)
Test on T test set - [47][30/45]	Time 0.336 (0.340)	Loss 1.0761 (1.1150)	Prec@1 76.190 (75.013)	Prec@5 95.238 (90.118)
Test on T test set - [47][40/45]	Time 0.341 (0.339)	Loss 2.0646 (1.3267)	Prec@1 39.683 (70.461)	Prec@5 79.365 (85.792)
 * Test on T test set - Prec@1 68.122, Prec@5 85.304
Epoch 47, K-means clustering 0, Average clustering time 0.026, Prec@1 73.340
Epoch 47, K-means clustering 1, Average clustering time 0.103, Prec@1 74.121
Epoch 47, K-means clustering 2, Average clustering time 0.108, Prec@1 73.908
Epoch 47, K-means clustering 3, Average clustering time 0.112, Prec@1 73.305
Epoch 47, K-means clustering 4, Average clustering time 0.112, Prec@1 72.843
Epoch 47, K-means clustering 0, Average clustering time 0.003, Prec@1 72.914
Epoch 47, K-means clustering 1, Average clustering time 0.052, Prec@1 73.269
Epoch 47, K-means clustering 2, Average clustering time 0.069, Prec@1 73.340
Epoch 47, K-means clustering 3, Average clustering time 0.074, Prec@1 73.163
Epoch 47, K-means clustering 4, Average clustering time 0.077, Prec@1 73.092
Train - epoch [64/200]	BT 1.196 (1.196)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.3880 (18.3880)
Train - epoch [64/200]	BT 1.231 (1.231)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.5681 (17.5681)
The penalty weight is 0.833655
Train - epoch [48/200]	BT 1.521 (1.521)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 14.9485 (14.9485)
Train - epoch [64/200]	BT 1.179 (1.179)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.4240 (18.4240)
Train - epoch [48/200]	BT 1.516 (1.516)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.0421 (17.0421)
Test on T training set - [64][0/13]	T 0.737 (0.737)	D 0.611 (0.611)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1322 (0.1322)
Test on T training set - [64][10/13]	T 0.534 (0.533)	D 0.417 (0.411)	T@1 61.905 (86.147)	T@5 100.000 (98.124)	L 0.8875 (0.5867)
 * Test on T training set - Prec@1 86.541, Prec@5 98.113
Train - epoch [48/200]	BT 1.480 (1.480)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.2128 (15.2128)
Test on T test set - [64][0/13]	Time 0.722 (0.722)	Loss 0.1322 (0.1322)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [64][10/13]	Time 0.513 (0.534)	Loss 0.8875 (0.5867)	Prec@1 61.905 (86.147)	Prec@5 100.000 (98.124)
 * Test on T test set - Prec@1 86.541, Prec@5 98.113
Epoch 64, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 64, K-means clustering 1, Average clustering time 0.083, Prec@1 87.799
Epoch 64, K-means clustering 2, Average clustering time 0.086, Prec@1 87.799
Epoch 64, K-means clustering 3, Average clustering time 0.087, Prec@1 87.799
Epoch 64, K-means clustering 4, Average clustering time 0.089, Prec@1 87.799
Epoch 64, K-means clustering 0, Average clustering time 0.001, Prec@1 88.176
Epoch 64, K-means clustering 1, Average clustering time 0.039, Prec@1 88.428
Epoch 64, K-means clustering 2, Average clustering time 0.053, Prec@1 88.302
Epoch 64, K-means clustering 3, Average clustering time 0.056, Prec@1 88.302
Epoch 64, K-means clustering 4, Average clustering time 0.063, Prec@1 88.302
Train - epoch [48/200]	BT 1.468 (1.468)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.5344 (16.5344)
The penalty weight is 0.925346
Train - epoch [65/200]	BT 1.160 (1.160)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.0752 (18.0752)
Train - epoch [65/200]	BT 1.174 (1.174)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.0078 (18.0078)
Train - epoch [48/200]	BT 2.181 (2.181)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.3238 (15.3238)
Train - epoch [48/200]	BT 1.440 (1.440)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.6273 (15.6273)
Train - epoch [65/200]	BT 1.182 (1.182)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.5446 (18.5446)
Train - epoch [65/200]	BT 1.098 (1.098)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 17.1201 (17.1201)
Train - epoch [48/200]	BT 1.618 (1.618)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.0931 (16.0931)
Train - epoch [65/200]	BT 1.203 (1.203)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.9309 (16.9309)
Test on T training set - [48][0/45]	T 0.510 (0.510)	D 0.388 (0.388)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7797 (0.7797)
Test on T training set - [48][10/45]	T 0.327 (0.351)	D 0.208 (0.230)	T@1 28.571 (79.365)	T@5 57.143 (90.765)	L 2.7096 (0.9610)
Test on T training set - [48][20/45]	T 0.341 (0.340)	D 0.219 (0.221)	T@1 90.476 (76.795)	T@5 100.000 (89.947)	L 0.5929 (1.0869)
Test on T training set - [48][30/45]	T 0.341 (0.337)	D 0.219 (0.218)	T@1 76.190 (75.320)	T@5 95.238 (90.220)	L 1.0685 (1.1027)
Test on T training set - [48][40/45]	T 0.324 (0.336)	D 0.202 (0.217)	T@1 41.270 (71.119)	T@5 80.952 (85.908)	L 2.0241 (1.3149)
 * Test on T training set - Prec@1 68.690, Prec@5 85.552
Train - epoch [65/200]	BT 1.004 (1.004)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.8028 (17.8028)
Train - epoch [65/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.8836 (17.8836)
Test on T test set - [48][0/45]	Time 0.544 (0.544)	Loss 0.7797 (0.7797)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [48][10/45]	Time 0.310 (0.349)	Loss 2.7096 (0.9610)	Prec@1 28.571 (79.365)	Prec@5 57.143 (90.765)
Test on T test set - [48][20/45]	Time 0.347 (0.338)	Loss 0.5929 (1.0869)	Prec@1 90.476 (76.795)	Prec@5 100.000 (89.947)
Test on T test set - [48][30/45]	Time 0.349 (0.338)	Loss 1.0685 (1.1027)	Prec@1 76.190 (75.320)	Prec@5 95.238 (90.220)
Test on T test set - [48][40/45]	Time 0.330 (0.335)	Loss 2.0241 (1.3149)	Prec@1 41.270 (71.119)	Prec@5 80.952 (85.908)
 * Test on T test set - Prec@1 68.690, Prec@5 85.552
Epoch 48, K-means clustering 0, Average clustering time 0.026, Prec@1 73.518
Epoch 48, K-means clustering 1, Average clustering time 0.090, Prec@1 73.944
Epoch 48, K-means clustering 2, Average clustering time 0.100, Prec@1 73.802
Epoch 48, K-means clustering 3, Average clustering time 0.099, Prec@1 73.553
Epoch 48, K-means clustering 4, Average clustering time 0.100, Prec@1 73.163
Epoch 48, K-means clustering 0, Average clustering time 0.004, Prec@1 72.879
Epoch 48, K-means clustering 1, Average clustering time 0.041, Prec@1 73.695
Epoch 48, K-means clustering 2, Average clustering time 0.068, Prec@1 73.695
Epoch 48, K-means clustering 3, Average clustering time 0.072, Prec@1 73.660
Epoch 48, K-means clustering 4, Average clustering time 0.073, Prec@1 73.624
Test on T training set - [65][0/13]	T 0.728 (0.728)	D 0.612 (0.612)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1350 (0.1350)
Test on T training set - [65][10/13]	T 0.529 (0.533)	D 0.405 (0.410)	T@1 58.730 (86.147)	T@5 100.000 (97.547)	L 0.9086 (0.5910)
 * Test on T training set - Prec@1 86.415, Prec@5 97.610
The penalty weight is 0.841123
Train - epoch [49/200]	BT 1.459 (1.459)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.8002 (15.8002)
Test on T test set - [65][0/13]	Time 0.743 (0.743)	Loss 0.1350 (0.1350)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [65][10/13]	Time 0.524 (0.522)	Loss 0.9086 (0.5910)	Prec@1 58.730 (86.147)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 86.415, Prec@5 97.610
Epoch 65, K-means clustering 0, Average clustering time 0.018, Prec@1 88.302
Epoch 65, K-means clustering 1, Average clustering time 0.077, Prec@1 87.799
Epoch 65, K-means clustering 2, Average clustering time 0.081, Prec@1 87.799
Epoch 65, K-means clustering 3, Average clustering time 0.083, Prec@1 87.799
Epoch 65, K-means clustering 4, Average clustering time 0.085, Prec@1 87.799
Epoch 65, K-means clustering 0, Average clustering time 0.001, Prec@1 87.421
Epoch 65, K-means clustering 1, Average clustering time 0.046, Prec@1 87.421
Epoch 65, K-means clustering 2, Average clustering time 0.055, Prec@1 87.547
Epoch 65, K-means clustering 3, Average clustering time 0.060, Prec@1 87.421
Epoch 65, K-means clustering 4, Average clustering time 0.062, Prec@1 87.547
Train - epoch [49/200]	BT 1.495 (1.495)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.5629 (16.5629)
The penalty weight is 0.928858
Train - epoch [66/200]	BT 1.187 (1.187)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.8860 (17.8860)
Train - epoch [49/200]	BT 1.401 (1.401)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.9666 (16.9666)
Train - epoch [66/200]	BT 1.701 (1.701)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.6741 (17.6741)
Train - epoch [66/200]	BT 1.227 (1.227)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1315 (17.1315)
Train - epoch [49/200]	BT 1.476 (1.476)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.0793 (17.0793)
Train - epoch [49/200]	BT 1.495 (1.495)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.7311 (16.7311)
Train - epoch [66/200]	BT 1.216 (1.216)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.7048 (18.7048)
Train - epoch [66/200]	BT 1.190 (1.190)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.9637 (17.9637)
Train - epoch [49/200]	BT 1.498 (1.498)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.1221 (15.1221)
Train - epoch [66/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.0826 (18.0826)
Test on T training set - [66][0/13]	T 0.735 (0.735)	D 0.614 (0.614)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1241 (0.1241)
Test on T training set - [66][10/13]	T 0.532 (0.533)	D 0.416 (0.413)	T@1 61.905 (85.859)	T@5 100.000 (98.124)	L 0.9230 (0.5865)
 * Test on T training set - Prec@1 86.289, Prec@5 98.113
Test on T training set - [49][0/45]	T 0.513 (0.513)	D 0.399 (0.399)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7388 (0.7388)
Test on T training set - [49][10/45]	T 0.326 (0.353)	D 0.207 (0.233)	T@1 26.984 (79.654)	T@5 60.317 (90.620)	L 2.6824 (0.9632)
Test on T training set - [49][20/45]	T 0.357 (0.348)	D 0.233 (0.229)	T@1 88.889 (76.871)	T@5 100.000 (89.569)	L 0.6157 (1.0880)
Test on T training set - [49][30/45]	T 0.336 (0.345)	D 0.224 (0.225)	T@1 77.778 (75.371)	T@5 95.238 (89.964)	L 0.9993 (1.1069)
Test on T training set - [49][40/45]	T 0.335 (0.345)	D 0.213 (0.225)	T@1 42.857 (71.158)	T@5 79.365 (85.676)	L 2.0074 (1.3189)
 * Test on T training set - Prec@1 68.761, Prec@5 85.233
Test on T test set - [66][0/13]	Time 0.738 (0.738)	Loss 0.1241 (0.1241)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [66][10/13]	Time 0.531 (0.538)	Loss 0.9230 (0.5865)	Prec@1 61.905 (85.859)	Prec@5 100.000 (98.124)
 * Test on T test set - Prec@1 86.289, Prec@5 98.113
Epoch 66, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 66, K-means clustering 1, Average clustering time 0.084, Prec@1 87.925
Epoch 66, K-means clustering 2, Average clustering time 0.085, Prec@1 87.799
Epoch 66, K-means clustering 3, Average clustering time 0.089, Prec@1 87.799
Epoch 66, K-means clustering 4, Average clustering time 0.088, Prec@1 87.799
Epoch 66, K-means clustering 0, Average clustering time 0.001, Prec@1 88.050
Epoch 66, K-means clustering 1, Average clustering time 0.043, Prec@1 88.050
Epoch 66, K-means clustering 2, Average clustering time 0.053, Prec@1 88.302
Epoch 66, K-means clustering 3, Average clustering time 0.059, Prec@1 88.302
Epoch 66, K-means clustering 4, Average clustering time 0.066, Prec@1 88.302
Test on T test set - [49][0/45]	Time 0.509 (0.509)	Loss 0.7388 (0.7388)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [49][10/45]	Time 0.325 (0.344)	Loss 2.6824 (0.9632)	Prec@1 26.984 (79.654)	Prec@5 60.317 (90.620)
Test on T test set - [49][20/45]	Time 0.330 (0.365)	Loss 0.6157 (1.0880)	Prec@1 88.889 (76.871)	Prec@5 100.000 (89.569)
Test on T test set - [49][30/45]	Time 0.330 (0.357)	Loss 0.9993 (1.1069)	Prec@1 77.778 (75.371)	Prec@5 95.238 (89.964)
Test on T test set - [49][40/45]	Time 0.337 (0.352)	Loss 2.0074 (1.3189)	Prec@1 42.857 (71.158)	Prec@5 79.365 (85.676)
 * Test on T test set - Prec@1 68.761, Prec@5 85.233
Epoch 49, K-means clustering 0, Average clustering time 0.026, Prec@1 73.340
Epoch 49, K-means clustering 1, Average clustering time 0.108, Prec@1 74.050
Epoch 49, K-means clustering 2, Average clustering time 0.106, Prec@1 73.766
Epoch 49, K-means clustering 3, Average clustering time 0.149, Prec@1 73.376
Epoch 49, K-means clustering 4, Average clustering time 0.141, Prec@1 73.305
Epoch 49, K-means clustering 0, Average clustering time 0.003, Prec@1 72.914
Epoch 49, K-means clustering 1, Average clustering time 0.055, Prec@1 73.269
Epoch 49, K-means clustering 2, Average clustering time 0.067, Prec@1 73.340
Epoch 49, K-means clustering 3, Average clustering time 0.075, Prec@1 73.198
Epoch 49, K-means clustering 4, Average clustering time 0.079, Prec@1 73.376
The penalty weight is 0.932210
Train - epoch [67/200]	BT 1.117 (1.117)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.5695 (16.5695)
Train - epoch [67/200]	BT 1.051 (1.051)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 16.9957 (16.9957)
Train - epoch [50/200]	BT 1.697 (1.697)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.9599 (16.9599)
The penalty weight is 0.848284
Train - epoch [50/200]	BT 1.464 (1.464)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.2323 (16.2323)
Train - epoch [67/200]	BT 1.100 (1.100)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.6822 (17.6822)
Train - epoch [67/200]	BT 1.124 (1.124)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.3488 (18.3488)
Train - epoch [50/200]	BT 1.524 (1.524)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.2868 (16.2868)
Train - epoch [67/200]	BT 1.034 (1.034)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.6038 (17.6038)
Train - epoch [67/200]	BT 1.237 (1.237)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.5108 (18.5108)
Train - epoch [50/200]	BT 1.514 (1.514)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.1093 (16.1093)
Train - epoch [67/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.7600 (17.7600)
Train - epoch [50/200]	BT 1.503 (1.503)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.0389 (16.0389)
Train - epoch [50/200]	BT 1.578 (1.578)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.9126 (16.9126)
Test on T training set - [67][0/13]	T 0.807 (0.807)	D 0.675 (0.675)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1409 (0.1409)
Test on T training set - [67][10/13]	T 0.623 (0.544)	D 0.502 (0.422)	T@1 60.317 (85.570)	T@5 100.000 (97.691)	L 0.9211 (0.5853)
 * Test on T training set - Prec@1 86.038, Prec@5 97.736
Test on T test set - [67][0/13]	Time 0.752 (0.752)	Loss 0.1409 (0.1409)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [67][10/13]	Time 0.531 (0.537)	Loss 0.9211 (0.5853)	Prec@1 60.317 (85.570)	Prec@5 100.000 (97.691)
 * Test on T test set - Prec@1 86.038, Prec@5 97.736
Epoch 67, K-means clustering 0, Average clustering time 0.018, Prec@1 88.302
Epoch 67, K-means clustering 1, Average clustering time 0.081, Prec@1 88.176
Epoch 67, K-means clustering 2, Average clustering time 0.082, Prec@1 88.050
Epoch 67, K-means clustering 3, Average clustering time 0.084, Prec@1 88.050
Epoch 67, K-means clustering 4, Average clustering time 0.084, Prec@1 88.050
Epoch 67, K-means clustering 0, Average clustering time 0.001, Prec@1 88.176
Epoch 67, K-means clustering 1, Average clustering time 0.041, Prec@1 88.428
Epoch 67, K-means clustering 2, Average clustering time 0.059, Prec@1 88.302
Epoch 67, K-means clustering 3, Average clustering time 0.067, Prec@1 88.302
Epoch 67, K-means clustering 4, Average clustering time 0.072, Prec@1 88.302
Train - epoch [50/200]	BT 1.546 (1.546)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.3772 (16.3772)
The penalty weight is 0.935409
Train - epoch [68/200]	BT 1.032 (1.032)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.3739 (16.3739)
Train - epoch [68/200]	BT 1.125 (1.125)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 18.9704 (18.9704)
Test on T training set - [50][0/45]	T 0.507 (0.507)	D 0.382 (0.382)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7101 (0.7101)
Test on T training set - [50][10/45]	T 0.338 (0.345)	D 0.216 (0.224)	T@1 28.571 (79.365)	T@5 57.143 (90.620)	L 2.6931 (0.9303)
Test on T training set - [50][20/45]	T 0.325 (0.340)	D 0.212 (0.221)	T@1 90.476 (76.568)	T@5 100.000 (90.023)	L 0.5861 (1.0729)
Test on T training set - [50][30/45]	T 0.323 (0.346)	D 0.211 (0.226)	T@1 80.952 (75.678)	T@5 93.651 (90.425)	L 1.0033 (1.0869)
Test on T training set - [50][40/45]	T 0.340 (0.343)	D 0.216 (0.224)	T@1 42.857 (71.274)	T@5 82.540 (86.101)	L 1.9577 (1.3016)
 * Test on T training set - Prec@1 68.974, Prec@5 85.623
Train - epoch [68/200]	BT 1.572 (1.572)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.2306 (18.2306)
Train - epoch [68/200]	BT 1.381 (1.381)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.5102 (18.5102)
Test on T test set - [50][0/45]	Time 0.516 (0.516)	Loss 0.7101 (0.7101)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [50][10/45]	Time 0.328 (0.348)	Loss 2.6931 (0.9303)	Prec@1 28.571 (79.365)	Prec@5 57.143 (90.620)
Test on T test set - [50][20/45]	Time 0.336 (0.344)	Loss 0.5861 (1.0729)	Prec@1 90.476 (76.568)	Prec@5 100.000 (90.023)
Test on T test set - [50][30/45]	Time 0.349 (0.343)	Loss 1.0033 (1.0869)	Prec@1 80.952 (75.678)	Prec@5 93.651 (90.425)
Test on T test set - [50][40/45]	Time 0.334 (0.342)	Loss 1.9577 (1.3016)	Prec@1 42.857 (71.274)	Prec@5 82.540 (86.101)
 * Test on T test set - Prec@1 68.974, Prec@5 85.623
Epoch 50, K-means clustering 0, Average clustering time 0.026, Prec@1 73.482
Epoch 50, K-means clustering 1, Average clustering time 0.101, Prec@1 73.731
Epoch 50, K-means clustering 2, Average clustering time 0.106, Prec@1 73.695
Epoch 50, K-means clustering 3, Average clustering time 0.105, Prec@1 73.269
Epoch 50, K-means clustering 4, Average clustering time 0.108, Prec@1 73.163
Epoch 50, K-means clustering 0, Average clustering time 0.003, Prec@1 72.914
Epoch 50, K-means clustering 1, Average clustering time 0.059, Prec@1 73.624
Epoch 50, K-means clustering 2, Average clustering time 0.069, Prec@1 73.802
Epoch 50, K-means clustering 3, Average clustering time 0.072, Prec@1 73.695
Epoch 50, K-means clustering 4, Average clustering time 0.076, Prec@1 73.589
Train - epoch [68/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.2510 (18.2510)
The penalty weight is 0.855147
Train - epoch [51/200]	BT 1.475 (1.475)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8957 (16.8957)
Train - epoch [68/200]	BT 1.707 (1.707)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4593 (17.4593)
Train - epoch [68/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.1391 (17.1391)
Train - epoch [51/200]	BT 1.744 (1.744)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1564 (17.1564)
Test on T training set - [68][0/13]	T 0.747 (0.747)	D 0.623 (0.623)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1136 (0.1136)
Test on T training set - [68][10/13]	T 0.542 (0.522)	D 0.416 (0.401)	T@1 63.492 (86.724)	T@5 100.000 (97.691)	L 0.8281 (0.5781)
 * Test on T training set - Prec@1 86.918, Prec@5 97.736
Train - epoch [51/200]	BT 1.493 (1.493)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.5554 (17.5554)
Test on T test set - [68][0/13]	Time 0.733 (0.733)	Loss 0.1136 (0.1136)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [68][10/13]	Time 0.511 (0.539)	Loss 0.8281 (0.5781)	Prec@1 63.492 (86.724)	Prec@5 100.000 (97.691)
 * Test on T test set - Prec@1 86.918, Prec@5 97.736
Epoch 68, K-means clustering 0, Average clustering time 0.018, Prec@1 88.050
Epoch 68, K-means clustering 1, Average clustering time 0.090, Prec@1 87.547
Epoch 68, K-means clustering 2, Average clustering time 0.092, Prec@1 87.547
Epoch 68, K-means clustering 3, Average clustering time 0.092, Prec@1 87.547
Epoch 68, K-means clustering 4, Average clustering time 0.095, Prec@1 87.547
Epoch 68, K-means clustering 0, Average clustering time 0.001, Prec@1 87.925
Epoch 68, K-means clustering 1, Average clustering time 0.039, Prec@1 87.673
Epoch 68, K-means clustering 2, Average clustering time 0.051, Prec@1 87.547
Epoch 68, K-means clustering 3, Average clustering time 0.057, Prec@1 87.547
Epoch 68, K-means clustering 4, Average clustering time 0.061, Prec@1 87.547
Train - epoch [51/200]	BT 2.371 (2.371)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.0319 (17.0319)
Train - epoch [51/200]	BT 1.502 (1.502)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8605 (16.8605)
The penalty weight is 0.938462
Train - epoch [69/200]	BT 1.136 (1.136)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.4167 (18.4167)
Train - epoch [69/200]	BT 1.098 (1.098)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.3271 (18.3271)
Train - epoch [51/200]	BT 1.508 (1.508)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4205 (17.4205)
Train - epoch [69/200]	BT 1.112 (1.112)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.5921 (18.5921)
Train - epoch [51/200]	BT 1.602 (1.602)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.2151 (17.2151)
Train - epoch [69/200]	BT 1.018 (1.018)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.6037 (18.6037)
Train - epoch [69/200]	BT 1.207 (1.207)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.1982 (18.1982)
Test on T training set - [51][0/45]	T 0.519 (0.519)	D 0.406 (0.406)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.6650 (0.6650)
Test on T training set - [51][10/45]	T 0.340 (0.353)	D 0.227 (0.233)	T@1 28.571 (79.798)	T@5 58.730 (91.198)	L 2.7351 (0.9411)
Test on T training set - [51][20/45]	T 0.342 (0.346)	D 0.220 (0.226)	T@1 88.889 (76.795)	T@5 100.000 (90.098)	L 0.6138 (1.0776)
Test on T training set - [51][30/45]	T 0.321 (0.342)	D 0.209 (0.223)	T@1 74.603 (75.422)	T@5 93.651 (90.476)	L 1.1188 (1.0950)
Test on T training set - [51][40/45]	T 0.328 (0.341)	D 0.205 (0.222)	T@1 39.683 (71.119)	T@5 79.365 (86.218)	L 2.1014 (1.3110)
 * Test on T training set - Prec@1 68.726, Prec@5 85.481
Train - epoch [69/200]	BT 1.338 (1.338)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.6993 (16.6993)
Test on T test set - [51][0/45]	Time 0.526 (0.526)	Loss 0.6650 (0.6650)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [51][10/45]	Time 0.314 (0.348)	Loss 2.7351 (0.9411)	Prec@1 28.571 (79.798)	Prec@5 58.730 (91.198)
Test on T test set - [51][20/45]	Time 0.335 (0.339)	Loss 0.6138 (1.0776)	Prec@1 88.889 (76.795)	Prec@5 100.000 (90.098)
Test on T test set - [51][30/45]	Time 0.340 (0.341)	Loss 1.1188 (1.0950)	Prec@1 74.603 (75.422)	Prec@5 93.651 (90.476)
Test on T test set - [51][40/45]	Time 0.347 (0.363)	Loss 2.1014 (1.3110)	Prec@1 39.683 (71.119)	Prec@5 79.365 (86.218)
 * Test on T test set - Prec@1 68.726, Prec@5 85.481
Epoch 51, K-means clustering 0, Average clustering time 0.026, Prec@1 73.269
Epoch 51, K-means clustering 1, Average clustering time 0.090, Prec@1 73.589
Epoch 51, K-means clustering 2, Average clustering time 0.100, Prec@1 73.376
Epoch 51, K-means clustering 3, Average clustering time 0.099, Prec@1 73.021
Epoch 51, K-means clustering 4, Average clustering time 0.100, Prec@1 72.488
Epoch 51, K-means clustering 0, Average clustering time 0.003, Prec@1 72.843
Epoch 51, K-means clustering 1, Average clustering time 0.042, Prec@1 73.553
Epoch 51, K-means clustering 2, Average clustering time 0.070, Prec@1 73.269
Epoch 51, K-means clustering 3, Average clustering time 0.075, Prec@1 73.234
Epoch 51, K-means clustering 4, Average clustering time 0.076, Prec@1 73.340
Test on T training set - [69][0/13]	T 0.752 (0.752)	D 0.629 (0.629)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1422 (0.1422)
Test on T training set - [69][10/13]	T 0.527 (0.545)	D 0.400 (0.421)	T@1 68.254 (87.157)	T@5 100.000 (97.835)	L 0.8403 (0.5768)
 * Test on T training set - Prec@1 87.547, Prec@5 97.862
Test on T test set - [69][0/13]	Time 0.898 (0.898)	Loss 0.1422 (0.1422)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [69][10/13]	Time 0.533 (0.547)	Loss 0.8403 (0.5768)	Prec@1 68.254 (87.157)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 87.547, Prec@5 97.862
Epoch 69, K-means clustering 0, Average clustering time 0.018, Prec@1 88.805
Epoch 69, K-means clustering 1, Average clustering time 0.080, Prec@1 87.925
Epoch 69, K-means clustering 2, Average clustering time 0.085, Prec@1 87.925
Epoch 69, K-means clustering 3, Average clustering time 0.086, Prec@1 87.925
Epoch 69, K-means clustering 4, Average clustering time 0.088, Prec@1 87.925
Epoch 69, K-means clustering 0, Average clustering time 0.001, Prec@1 88.679
Epoch 69, K-means clustering 1, Average clustering time 0.043, Prec@1 88.302
Epoch 69, K-means clustering 2, Average clustering time 0.057, Prec@1 88.176
Epoch 69, K-means clustering 3, Average clustering time 0.065, Prec@1 88.302
Epoch 69, K-means clustering 4, Average clustering time 0.069, Prec@1 88.302
The penalty weight is 0.861723
Train - epoch [52/200]	BT 1.535 (1.535)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8181 (16.8181)
Train - epoch [52/200]	BT 1.553 (1.553)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3132 (17.3132)
Train - epoch [70/200]	BT 1.002 (1.002)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.7265 (18.7265)
The penalty weight is 0.941376
Train - epoch [70/200]	BT 1.125 (1.125)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.2000 (18.2000)
Train - epoch [52/200]	BT 1.488 (1.488)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.2356 (17.2356)
Train - epoch [70/200]	BT 1.086 (1.086)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.6750 (17.6750)
Train - epoch [70/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.8362 (17.8362)
Train - epoch [52/200]	BT 1.506 (1.506)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.3015 (15.3015)
Train - epoch [70/200]	BT 1.118 (1.118)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.4399 (18.4399)
Train - epoch [70/200]	BT 1.030 (1.030)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.7953 (18.7953)
Train - epoch [52/200]	BT 1.773 (1.773)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.8345 (15.8345)
Train - epoch [70/200]	BT 1.153 (1.153)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.3840 (17.3840)
Train - epoch [52/200]	BT 1.423 (1.423)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8007 (16.8007)
Train - epoch [52/200]	BT 1.813 (1.813)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8211 (16.8211)
Test on T training set - [70][0/13]	T 0.730 (0.730)	D 0.614 (0.614)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1488 (0.1488)
Test on T training set - [70][10/13]	T 0.534 (0.528)	D 0.419 (0.407)	T@1 66.667 (87.013)	T@5 100.000 (98.268)	L 0.8558 (0.5625)
 * Test on T training set - Prec@1 87.296, Prec@5 98.239
Test on T test set - [70][0/13]	Time 0.733 (0.733)	Loss 0.1488 (0.1488)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [70][10/13]	Time 0.515 (0.540)	Loss 0.8558 (0.5625)	Prec@1 66.667 (87.013)	Prec@5 100.000 (98.268)
 * Test on T test set - Prec@1 87.296, Prec@5 98.239
Epoch 70, K-means clustering 0, Average clustering time 0.018, Prec@1 89.057
Epoch 70, K-means clustering 1, Average clustering time 0.082, Prec@1 88.176
Epoch 70, K-means clustering 2, Average clustering time 0.090, Prec@1 87.925
Epoch 70, K-means clustering 3, Average clustering time 0.088, Prec@1 88.050
Epoch 70, K-means clustering 4, Average clustering time 0.089, Prec@1 88.050
Epoch 70, K-means clustering 0, Average clustering time 0.001, Prec@1 89.057
Epoch 70, K-means clustering 1, Average clustering time 0.038, Prec@1 88.931
Epoch 70, K-means clustering 2, Average clustering time 0.050, Prec@1 88.679
Epoch 70, K-means clustering 3, Average clustering time 0.057, Prec@1 88.931
Epoch 70, K-means clustering 4, Average clustering time 0.065, Prec@1 88.931
Test on T training set - [52][0/45]	T 0.529 (0.529)	D 0.403 (0.403)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7355 (0.7355)
Test on T training set - [52][10/45]	T 0.329 (0.358)	D 0.207 (0.237)	T@1 30.159 (80.087)	T@5 60.317 (91.342)	L 2.6940 (0.9394)
Test on T training set - [52][20/45]	T 0.319 (0.347)	D 0.205 (0.228)	T@1 88.889 (77.324)	T@5 100.000 (90.249)	L 0.6937 (1.0810)
Test on T training set - [52][30/45]	T 0.357 (0.347)	D 0.233 (0.227)	T@1 77.778 (75.986)	T@5 93.651 (90.476)	L 1.0731 (1.1073)
Test on T training set - [52][40/45]	T 0.425 (0.368)	D 0.301 (0.248)	T@1 44.444 (71.738)	T@5 82.540 (86.101)	L 1.9440 (1.3219)
 * Test on T training set - Prec@1 69.400, Prec@5 85.730
Test on T test set - [52][0/45]	Time 0.547 (0.547)	Loss 0.7355 (0.7355)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [52][10/45]	Time 0.327 (0.353)	Loss 2.6940 (0.9394)	Prec@1 30.159 (80.087)	Prec@5 60.317 (91.342)
Test on T test set - [52][20/45]	Time 0.330 (0.343)	Loss 0.6937 (1.0810)	Prec@1 88.889 (77.324)	Prec@5 100.000 (90.249)
Test on T test set - [52][30/45]	Time 0.325 (0.341)	Loss 1.0731 (1.1073)	Prec@1 77.778 (75.986)	Prec@5 93.651 (90.476)
Test on T test set - [52][40/45]	Time 0.322 (0.340)	Loss 1.9440 (1.3219)	Prec@1 44.444 (71.738)	Prec@5 82.540 (86.101)
 * Test on T test set - Prec@1 69.400, Prec@5 85.730
Epoch 52, K-means clustering 0, Average clustering time 0.026, Prec@1 73.695
Epoch 52, K-means clustering 1, Average clustering time 0.100, Prec@1 73.908
Epoch 52, K-means clustering 2, Average clustering time 0.109, Prec@1 73.482
Epoch 52, K-means clustering 3, Average clustering time 0.107, Prec@1 73.340
Epoch 52, K-means clustering 4, Average clustering time 0.119, Prec@1 72.950
Epoch 52, K-means clustering 0, Average clustering time 0.003, Prec@1 72.985
Epoch 52, K-means clustering 1, Average clustering time 0.052, Prec@1 73.553
Epoch 52, K-means clustering 2, Average clustering time 0.060, Prec@1 73.447
Epoch 52, K-means clustering 3, Average clustering time 0.066, Prec@1 73.305
Epoch 52, K-means clustering 4, Average clustering time 0.070, Prec@1 73.092
The penalty weight is 0.944155
Train - epoch [71/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.9915 (17.9915)
Train - epoch [71/200]	BT 1.193 (1.193)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.5046 (16.5046)
The penalty weight is 0.868022
Train - epoch [53/200]	BT 1.484 (1.484)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.6334 (16.6334)
Train - epoch [71/200]	BT 1.117 (1.117)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.9940 (17.9940)
Train - epoch [71/200]	BT 1.100 (1.100)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.5335 (18.5335)
Train - epoch [53/200]	BT 1.527 (1.527)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.0713 (16.0713)
Train - epoch [71/200]	BT 1.200 (1.200)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.0623 (18.0623)
Train - epoch [71/200]	BT 1.243 (1.243)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.2118 (18.2118)
Train - epoch [53/200]	BT 1.502 (1.502)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.3136 (16.3136)
Train - epoch [71/200]	BT 1.187 (1.187)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.9962 (17.9962)
Train - epoch [53/200]	BT 1.799 (1.799)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8610 (16.8610)
Test on T training set - [71][0/13]	T 0.759 (0.759)	D 0.629 (0.629)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1336 (0.1336)
Test on T training set - [71][10/13]	T 0.756 (0.540)	D 0.641 (0.420)	T@1 65.079 (86.724)	T@5 100.000 (97.835)	L 0.8599 (0.5827)
 * Test on T training set - Prec@1 87.044, Prec@5 97.862
Train - epoch [53/200]	BT 1.449 (1.449)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.0365 (16.0365)
Test on T test set - [71][0/13]	Time 0.752 (0.752)	Loss 0.1336 (0.1336)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [71][10/13]	Time 0.514 (0.520)	Loss 0.8599 (0.5827)	Prec@1 65.079 (86.724)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 87.044, Prec@5 97.862
Epoch 71, K-means clustering 0, Average clustering time 0.019, Prec@1 89.057
Epoch 71, K-means clustering 1, Average clustering time 0.087, Prec@1 88.050
Epoch 71, K-means clustering 2, Average clustering time 0.091, Prec@1 87.925
Epoch 71, K-means clustering 3, Average clustering time 0.093, Prec@1 87.925
Epoch 71, K-means clustering 4, Average clustering time 0.094, Prec@1 87.925
Epoch 71, K-means clustering 0, Average clustering time 0.001, Prec@1 88.805
Epoch 71, K-means clustering 1, Average clustering time 0.052, Prec@1 88.428
Epoch 71, K-means clustering 2, Average clustering time 0.067, Prec@1 88.428
Epoch 71, K-means clustering 3, Average clustering time 0.069, Prec@1 88.428
Epoch 71, K-means clustering 4, Average clustering time 0.073, Prec@1 88.553
Train - epoch [53/200]	BT 1.524 (1.524)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3317 (17.3317)
The penalty weight is 0.946806
Train - epoch [72/200]	BT 1.143 (1.143)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.6470 (16.6470)
Train - epoch [72/200]	BT 1.070 (1.070)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.7663 (18.7663)
Test on T training set - [53][0/45]	T 0.851 (0.851)	D 0.731 (0.731)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7863 (0.7863)
Test on T training set - [53][10/45]	T 0.319 (0.385)	D 0.195 (0.265)	T@1 31.746 (79.654)	T@5 58.730 (91.053)	L 2.7158 (0.9532)
Test on T training set - [53][20/45]	T 0.323 (0.364)	D 0.201 (0.245)	T@1 88.889 (77.324)	T@5 100.000 (89.947)	L 0.6916 (1.0867)
Test on T training set - [53][30/45]	T 0.326 (0.354)	D 0.212 (0.235)	T@1 76.190 (76.344)	T@5 95.238 (90.425)	L 1.0332 (1.0947)
Test on T training set - [53][40/45]	T 0.365 (0.349)	D 0.243 (0.230)	T@1 42.857 (72.203)	T@5 80.952 (86.140)	L 2.0362 (1.2968)
 * Test on T training set - Prec@1 70.004, Prec@5 85.800
Train - epoch [72/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.8676 (18.8676)
Test on T test set - [53][0/45]	Time 0.538 (0.538)	Loss 0.7863 (0.7863)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [53][10/45]	Time 0.344 (0.352)	Loss 2.7158 (0.9532)	Prec@1 31.746 (79.654)	Prec@5 58.730 (91.053)
Test on T test set - [53][20/45]	Time 0.318 (0.344)	Loss 0.6916 (1.0867)	Prec@1 88.889 (77.324)	Prec@5 100.000 (89.947)
Test on T test set - [53][30/45]	Time 0.320 (0.340)	Loss 1.0332 (1.0947)	Prec@1 76.190 (76.344)	Prec@5 95.238 (90.425)
Test on T test set - [53][40/45]	Time 0.343 (0.339)	Loss 2.0362 (1.2968)	Prec@1 42.857 (72.203)	Prec@5 80.952 (86.140)
 * Test on T test set - Prec@1 70.004, Prec@5 85.800
Epoch 53, K-means clustering 0, Average clustering time 0.027, Prec@1 73.979
Epoch 53, K-means clustering 1, Average clustering time 0.097, Prec@1 74.050
Epoch 53, K-means clustering 2, Average clustering time 0.100, Prec@1 73.873
Epoch 53, K-means clustering 3, Average clustering time 0.099, Prec@1 73.660
Epoch 53, K-means clustering 4, Average clustering time 0.103, Prec@1 73.376
Epoch 53, K-means clustering 0, Average clustering time 0.003, Prec@1 73.482
Epoch 53, K-means clustering 1, Average clustering time 0.062, Prec@1 73.695
Epoch 53, K-means clustering 2, Average clustering time 0.071, Prec@1 73.482
Epoch 53, K-means clustering 3, Average clustering time 0.084, Prec@1 73.127
Epoch 53, K-means clustering 4, Average clustering time 0.088, Prec@1 73.305
Train - epoch [72/200]	BT 1.568 (1.568)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.7112 (17.7112)
Train - epoch [72/200]	BT 1.182 (1.182)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.5525 (18.5525)
The penalty weight is 0.874053
Train - epoch [54/200]	BT 1.492 (1.492)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3094 (17.3094)
Train - epoch [72/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.1745 (18.1745)
Train - epoch [72/200]	BT 1.095 (1.095)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.1168 (18.1168)
Train - epoch [54/200]	BT 1.538 (1.538)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4162 (17.4162)
Test on T training set - [72][0/13]	T 0.720 (0.720)	D 0.601 (0.601)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1373 (0.1373)
Test on T training set - [72][10/13]	T 0.500 (0.528)	D 0.385 (0.408)	T@1 65.079 (86.580)	T@5 100.000 (98.124)	L 0.8498 (0.5788)
 * Test on T training set - Prec@1 86.792, Prec@5 98.113
Test on T test set - [72][0/13]	Time 0.735 (0.735)	Loss 0.1373 (0.1373)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [72][10/13]	Time 0.516 (0.523)	Loss 0.8498 (0.5788)	Prec@1 65.079 (86.580)	Prec@5 100.000 (98.124)
 * Test on T test set - Prec@1 86.792, Prec@5 98.113
Epoch 72, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 72, K-means clustering 1, Average clustering time 0.086, Prec@1 88.050
Epoch 72, K-means clustering 2, Average clustering time 0.089, Prec@1 88.050
Epoch 72, K-means clustering 3, Average clustering time 0.094, Prec@1 88.050
Epoch 72, K-means clustering 4, Average clustering time 0.094, Prec@1 88.050
Epoch 72, K-means clustering 0, Average clustering time 0.001, Prec@1 88.679
Epoch 72, K-means clustering 1, Average clustering time 0.036, Prec@1 88.679
Epoch 72, K-means clustering 2, Average clustering time 0.053, Prec@1 88.302
Epoch 72, K-means clustering 3, Average clustering time 0.058, Prec@1 88.302
Epoch 72, K-means clustering 4, Average clustering time 0.062, Prec@1 88.302
Train - epoch [54/200]	BT 2.053 (2.053)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.5636 (16.5636)
Train - epoch [54/200]	BT 1.495 (1.495)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.6811 (17.6811)
Train - epoch [54/200]	BT 1.486 (1.486)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.4783 (15.4783)
The penalty weight is 0.949335
Train - epoch [73/200]	BT 1.130 (1.130)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.3374 (18.3374)
Train - epoch [54/200]	BT 1.582 (1.582)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.0342 (17.0342)
Train - epoch [73/200]	BT 1.085 (1.085)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.0527 (17.0527)
Train - epoch [73/200]	BT 1.096 (1.096)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 17.2843 (17.2843)
Train - epoch [54/200]	BT 1.553 (1.553)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1876 (17.1876)
Train - epoch [73/200]	BT 1.105 (1.105)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.2426 (18.2426)
Train - epoch [73/200]	BT 1.162 (1.162)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 16.9093 (16.9093)
Train - epoch [73/200]	BT 1.229 (1.229)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 19.0521 (19.0521)
Test on T training set - [54][0/45]	T 0.504 (0.504)	D 0.385 (0.385)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.7082 (0.7082)
Test on T training set - [54][10/45]	T 0.334 (0.348)	D 0.208 (0.228)	T@1 30.159 (79.509)	T@5 58.730 (91.631)	L 2.6419 (0.9528)
Test on T training set - [54][20/45]	T 0.321 (0.343)	D 0.209 (0.223)	T@1 92.063 (77.324)	T@5 100.000 (90.703)	L 0.6074 (1.0822)
Test on T training set - [54][30/45]	T 0.352 (0.341)	D 0.230 (0.222)	T@1 76.190 (75.781)	T@5 95.238 (90.835)	L 1.0436 (1.1028)
Test on T training set - [54][40/45]	T 0.330 (0.338)	D 0.208 (0.218)	T@1 44.444 (71.661)	T@5 80.952 (86.489)	L 1.9573 (1.3111)
 * Test on T training set - Prec@1 69.507, Prec@5 86.155
Test on T test set - [54][0/45]	Time 0.575 (0.575)	Loss 0.7082 (0.7082)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [54][10/45]	Time 0.337 (0.362)	Loss 2.6419 (0.9528)	Prec@1 30.159 (79.509)	Prec@5 58.730 (91.631)
Test on T test set - [54][20/45]	Time 0.326 (0.348)	Loss 0.6074 (1.0822)	Prec@1 92.063 (77.324)	Prec@5 100.000 (90.703)
Test on T test set - [54][30/45]	Time 0.332 (0.344)	Loss 1.0436 (1.1028)	Prec@1 76.190 (75.781)	Prec@5 95.238 (90.835)
Test on T test set - [54][40/45]	Time 0.343 (0.341)	Loss 1.9573 (1.3111)	Prec@1 44.444 (71.661)	Prec@5 80.952 (86.489)
 * Test on T test set - Prec@1 69.507, Prec@5 86.155
Epoch 54, K-means clustering 0, Average clustering time 0.026, Prec@1 74.086
Epoch 54, K-means clustering 1, Average clustering time 0.096, Prec@1 74.263
Epoch 54, K-means clustering 2, Average clustering time 0.100, Prec@1 73.731
Epoch 54, K-means clustering 3, Average clustering time 0.098, Prec@1 73.340
Epoch 54, K-means clustering 4, Average clustering time 0.098, Prec@1 72.950
Epoch 54, K-means clustering 0, Average clustering time 0.003, Prec@1 73.163
Epoch 54, K-means clustering 1, Average clustering time 0.053, Prec@1 73.589
Epoch 54, K-means clustering 2, Average clustering time 0.062, Prec@1 73.518
Epoch 54, K-means clustering 3, Average clustering time 0.067, Prec@1 73.305
Epoch 54, K-means clustering 4, Average clustering time 0.069, Prec@1 73.411
Test on T training set - [73][0/13]	T 0.744 (0.744)	D 0.624 (0.624)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1447 (0.1447)
Test on T training set - [73][10/13]	T 0.523 (0.552)	D 0.402 (0.431)	T@1 65.079 (86.869)	T@5 100.000 (97.980)	L 0.8594 (0.5769)
 * Test on T training set - Prec@1 87.296, Prec@5 97.987
Test on T test set - [73][0/13]	Time 0.765 (0.765)	Loss 0.1447 (0.1447)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [73][10/13]	Time 0.507 (0.526)	Loss 0.8594 (0.5769)	Prec@1 65.079 (86.869)	Prec@5 100.000 (97.980)
 * Test on T test set - Prec@1 87.296, Prec@5 97.987
Epoch 73, K-means clustering 0, Average clustering time 0.018, Prec@1 88.302
Epoch 73, K-means clustering 1, Average clustering time 0.088, Prec@1 87.925
Epoch 73, K-means clustering 2, Average clustering time 0.089, Prec@1 87.925
Epoch 73, K-means clustering 3, Average clustering time 0.093, Prec@1 87.925
Epoch 73, K-means clustering 4, Average clustering time 0.093, Prec@1 87.925
Epoch 73, K-means clustering 0, Average clustering time 0.001, Prec@1 88.302
Epoch 73, K-means clustering 1, Average clustering time 0.038, Prec@1 88.176
Epoch 73, K-means clustering 2, Average clustering time 0.050, Prec@1 87.925
Epoch 73, K-means clustering 3, Average clustering time 0.056, Prec@1 87.799
Epoch 73, K-means clustering 4, Average clustering time 0.060, Prec@1 87.673
The penalty weight is 0.879827
Train - epoch [55/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1546 (17.1546)
The penalty weight is 0.951746
Train - epoch [74/200]	BT 1.126 (1.126)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.8664 (18.8664)
Train - epoch [74/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.3166 (18.3166)
Train - epoch [55/200]	BT 1.392 (1.392)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3750 (17.3750)
Train - epoch [55/200]	BT 1.487 (1.487)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.6919 (16.6919)
Train - epoch [74/200]	BT 1.169 (1.169)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.1145 (17.1145)
Train - epoch [74/200]	BT 1.113 (1.113)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.5371 (18.5371)
Train - epoch [55/200]	BT 1.496 (1.496)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4632 (17.4632)
Train - epoch [74/200]	BT 1.101 (1.101)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.4821 (18.4821)
Train - epoch [74/200]	BT 1.121 (1.121)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 19.2294 (19.2294)
Train - epoch [55/200]	BT 1.309 (1.309)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.9247 (15.9247)
Train - epoch [74/200]	BT 1.185 (1.185)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.2968 (18.2968)
Train - epoch [55/200]	BT 2.095 (2.095)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4575 (17.4575)
Train - epoch [55/200]	BT 1.166 (1.166)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.5492 (17.5492)
Test on T training set - [74][0/13]	T 0.721 (0.721)	D 0.601 (0.601)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1417 (0.1417)
Test on T training set - [74][10/13]	T 0.525 (0.522)	D 0.390 (0.400)	T@1 65.079 (86.724)	T@5 100.000 (97.835)	L 0.8828 (0.5869)
 * Test on T training set - Prec@1 87.044, Prec@5 97.862
Test on T test set - [74][0/13]	Time 0.732 (0.732)	Loss 0.1417 (0.1417)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [74][10/13]	Time 0.508 (0.520)	Loss 0.8828 (0.5869)	Prec@1 65.079 (86.724)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 87.044, Prec@5 97.862
Epoch 74, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 74, K-means clustering 1, Average clustering time 0.084, Prec@1 88.050
Epoch 74, K-means clustering 2, Average clustering time 0.087, Prec@1 87.799
Epoch 74, K-means clustering 3, Average clustering time 0.088, Prec@1 87.799
Epoch 74, K-means clustering 4, Average clustering time 0.087, Prec@1 87.799
Epoch 74, K-means clustering 0, Average clustering time 0.001, Prec@1 88.931
Epoch 74, K-means clustering 1, Average clustering time 0.043, Prec@1 88.931
Epoch 74, K-means clustering 2, Average clustering time 0.054, Prec@1 89.057
Epoch 74, K-means clustering 3, Average clustering time 0.060, Prec@1 88.805
Epoch 74, K-means clustering 4, Average clustering time 0.066, Prec@1 88.805
Test on T training set - [55][0/45]	T 0.530 (0.530)	D 0.414 (0.414)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.6879 (0.6879)
Test on T training set - [55][10/45]	T 0.339 (0.349)	D 0.219 (0.231)	T@1 31.746 (79.798)	T@5 63.492 (91.919)	L 2.6920 (0.9389)
Test on T training set - [55][20/45]	T 0.346 (0.344)	D 0.219 (0.224)	T@1 88.889 (77.400)	T@5 100.000 (90.627)	L 0.6228 (1.0660)
Test on T training set - [55][30/45]	T 0.326 (0.346)	D 0.208 (0.227)	T@1 76.190 (76.088)	T@5 95.238 (90.732)	L 1.0303 (1.0917)
Test on T training set - [55][40/45]	T 0.340 (0.344)	D 0.219 (0.225)	T@1 39.683 (71.893)	T@5 79.365 (86.411)	L 2.1071 (1.3026)
 * Test on T training set - Prec@1 69.613, Prec@5 85.942
The penalty weight is 0.954045
Train - epoch [75/200]	BT 1.146 (1.146)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.5814 (17.5814)
Train - epoch [75/200]	BT 1.059 (1.059)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 19.2603 (19.2603)
Test on T test set - [55][0/45]	Time 0.566 (0.566)	Loss 0.6879 (0.6879)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [55][10/45]	Time 0.342 (0.355)	Loss 2.6920 (0.9389)	Prec@1 31.746 (79.798)	Prec@5 63.492 (91.919)
Test on T test set - [55][20/45]	Time 0.337 (0.346)	Loss 0.6228 (1.0660)	Prec@1 88.889 (77.400)	Prec@5 100.000 (90.627)
Test on T test set - [55][30/45]	Time 0.322 (0.342)	Loss 1.0303 (1.0917)	Prec@1 76.190 (76.088)	Prec@5 95.238 (90.732)
Test on T test set - [55][40/45]	Time 0.324 (0.340)	Loss 2.1071 (1.3026)	Prec@1 39.683 (71.893)	Prec@5 79.365 (86.411)
 * Test on T test set - Prec@1 69.613, Prec@5 85.942
Epoch 55, K-means clustering 0, Average clustering time 0.026, Prec@1 73.731
Epoch 55, K-means clustering 1, Average clustering time 0.090, Prec@1 73.837
Epoch 55, K-means clustering 2, Average clustering time 0.091, Prec@1 73.411
Epoch 55, K-means clustering 3, Average clustering time 0.092, Prec@1 72.950
Epoch 55, K-means clustering 4, Average clustering time 0.096, Prec@1 72.630
Epoch 55, K-means clustering 0, Average clustering time 0.003, Prec@1 73.411
Epoch 55, K-means clustering 1, Average clustering time 0.045, Prec@1 73.589
Epoch 55, K-means clustering 2, Average clustering time 0.057, Prec@1 73.340
Epoch 55, K-means clustering 3, Average clustering time 0.070, Prec@1 73.021
Epoch 55, K-means clustering 4, Average clustering time 0.077, Prec@1 73.127
Train - epoch [75/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 19.0183 (19.0183)
Train - epoch [75/200]	BT 1.138 (1.138)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.3071 (18.3071)
The penalty weight is 0.885352
Train - epoch [56/200]	BT 1.561 (1.561)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3801 (17.3801)
Train - epoch [56/200]	BT 1.464 (1.464)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.3712 (16.3712)
Train - epoch [75/200]	BT 1.202 (1.202)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.2230 (18.2230)
Train - epoch [56/200]	BT 1.506 (1.506)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3483 (17.3483)
Train - epoch [75/200]	BT 1.122 (1.122)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.0142 (18.0142)
Train - epoch [75/200]	BT 1.056 (1.056)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.6699 (18.6699)
Train - epoch [56/200]	BT 1.491 (1.491)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.2808 (16.2808)
Test on T training set - [75][0/13]	T 0.729 (0.729)	D 0.600 (0.600)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1568 (0.1568)
Test on T training set - [75][10/13]	T 0.547 (0.519)	D 0.432 (0.398)	T@1 65.079 (87.013)	T@5 100.000 (98.268)	L 0.8414 (0.5821)
 * Test on T training set - Prec@1 87.421, Prec@5 98.239
Test on T test set - [75][0/13]	Time 0.750 (0.750)	Loss 0.1568 (0.1568)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [75][10/13]	Time 0.522 (0.520)	Loss 0.8414 (0.5821)	Prec@1 65.079 (87.013)	Prec@5 100.000 (98.268)
 * Test on T test set - Prec@1 87.421, Prec@5 98.239
Epoch 75, K-means clustering 0, Average clustering time 0.018, Prec@1 88.302
Epoch 75, K-means clustering 1, Average clustering time 0.078, Prec@1 87.925
Epoch 75, K-means clustering 2, Average clustering time 0.080, Prec@1 87.925
Epoch 75, K-means clustering 3, Average clustering time 0.080, Prec@1 87.925
Epoch 75, K-means clustering 4, Average clustering time 0.080, Prec@1 87.925
Epoch 75, K-means clustering 0, Average clustering time 0.001, Prec@1 88.805
Epoch 75, K-means clustering 1, Average clustering time 0.047, Prec@1 88.679
Epoch 75, K-means clustering 2, Average clustering time 0.059, Prec@1 88.428
Epoch 75, K-means clustering 3, Average clustering time 0.066, Prec@1 88.428
Epoch 75, K-means clustering 4, Average clustering time 0.070, Prec@1 88.553
Train - epoch [56/200]	BT 1.561 (1.561)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.3976 (16.3976)
Train - epoch [56/200]	BT 1.490 (1.490)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.2752 (17.2752)
The penalty weight is 0.956237
Train - epoch [76/200]	BT 1.160 (1.160)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.2319 (17.2319)
Train - epoch [76/200]	BT 1.651 (1.651)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.6706 (18.6706)
Train - epoch [76/200]	BT 0.948 (0.948)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.2190 (18.2190)
Test on T training set - [56][0/45]	T 0.496 (0.496)	D 0.381 (0.381)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.6679 (0.6679)
Test on T training set - [56][10/45]	T 0.318 (0.375)	D 0.199 (0.256)	T@1 26.984 (79.076)	T@5 57.143 (90.765)	L 2.7727 (0.9422)
Test on T training set - [56][20/45]	T 0.367 (0.358)	D 0.245 (0.239)	T@1 88.889 (76.342)	T@5 100.000 (89.796)	L 0.6239 (1.0893)
Test on T training set - [56][30/45]	T 0.340 (0.353)	D 0.214 (0.233)	T@1 71.429 (74.962)	T@5 93.651 (90.271)	L 1.2849 (1.1169)
Test on T training set - [56][40/45]	T 0.344 (0.350)	D 0.227 (0.230)	T@1 41.270 (70.616)	T@5 80.952 (86.101)	L 2.0657 (1.3294)
 * Test on T training set - Prec@1 68.477, Prec@5 85.659
Test on T test set - [56][0/45]	Time 0.516 (0.516)	Loss 0.6679 (0.6679)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [56][10/45]	Time 0.321 (0.348)	Loss 2.7727 (0.9422)	Prec@1 26.984 (79.076)	Prec@5 57.143 (90.765)
Test on T test set - [56][20/45]	Time 0.330 (0.350)	Loss 0.6239 (1.0893)	Prec@1 88.889 (76.342)	Prec@5 100.000 (89.796)
Test on T test set - [56][30/45]	Time 0.345 (0.346)	Loss 1.2849 (1.1169)	Prec@1 71.429 (74.962)	Prec@5 93.651 (90.271)
Test on T test set - [56][40/45]	Time 0.340 (0.344)	Loss 2.0657 (1.3294)	Prec@1 41.270 (70.616)	Prec@5 80.952 (86.101)
 * Test on T test set - Prec@1 68.477, Prec@5 85.659
Epoch 56, K-means clustering 0, Average clustering time 0.027, Prec@1 73.127
Epoch 56, K-means clustering 1, Average clustering time 0.104, Prec@1 73.518
Epoch 56, K-means clustering 2, Average clustering time 0.104, Prec@1 73.269
Epoch 56, K-means clustering 3, Average clustering time 0.102, Prec@1 72.808
Epoch 56, K-means clustering 4, Average clustering time 0.102, Prec@1 72.630
Epoch 56, K-means clustering 0, Average clustering time 0.003, Prec@1 72.772
Epoch 56, K-means clustering 1, Average clustering time 0.046, Prec@1 73.447
Epoch 56, K-means clustering 2, Average clustering time 0.059, Prec@1 73.376
Epoch 56, K-means clustering 3, Average clustering time 0.064, Prec@1 73.376
Epoch 56, K-means clustering 4, Average clustering time 0.072, Prec@1 73.518
Train - epoch [76/200]	BT 1.206 (1.206)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.2164 (18.2164)
Train - epoch [76/200]	BT 1.158 (1.158)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.9722 (18.9722)
Train - epoch [76/200]	BT 1.219 (1.219)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.8984 (17.8984)
The penalty weight is 0.890637
Train - epoch [57/200]	BT 1.454 (1.454)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.2310 (16.2310)
Train - epoch [57/200]	BT 2.080 (2.080)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1615 (17.1615)
Train - epoch [57/200]	BT 1.430 (1.430)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.2692 (17.2692)
Test on T training set - [76][0/13]	T 0.738 (0.738)	D 0.617 (0.617)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1571 (0.1571)
Test on T training set - [76][10/13]	T 0.646 (0.556)	D 0.531 (0.436)	T@1 63.492 (86.291)	T@5 100.000 (97.547)	L 0.8674 (0.5792)
 * Test on T training set - Prec@1 86.918, Prec@5 97.610
Test on T test set - [76][0/13]	Time 0.736 (0.736)	Loss 0.1571 (0.1571)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [76][10/13]	Time 0.522 (0.526)	Loss 0.8674 (0.5792)	Prec@1 63.492 (86.291)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 86.918, Prec@5 97.610
Epoch 76, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 76, K-means clustering 1, Average clustering time 0.088, Prec@1 87.925
Epoch 76, K-means clustering 2, Average clustering time 0.087, Prec@1 87.799
Epoch 76, K-means clustering 3, Average clustering time 0.089, Prec@1 87.673
Epoch 76, K-means clustering 4, Average clustering time 0.091, Prec@1 87.673
Epoch 76, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 76, K-means clustering 1, Average clustering time 0.036, Prec@1 88.553
Epoch 76, K-means clustering 2, Average clustering time 0.047, Prec@1 88.553
Epoch 76, K-means clustering 3, Average clustering time 0.054, Prec@1 88.428
Epoch 76, K-means clustering 4, Average clustering time 0.057, Prec@1 88.302
Train - epoch [57/200]	BT 2.086 (2.086)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.8251 (16.8251)
Train - epoch [57/200]	BT 1.499 (1.499)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.0208 (17.0208)
The penalty weight is 0.958327
Train - epoch [77/200]	BT 1.089 (1.089)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.6427 (18.6427)
Train - epoch [77/200]	BT 1.116 (1.116)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.3097 (17.3097)
Train - epoch [57/200]	BT 1.483 (1.483)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.0114 (18.0114)
Train - epoch [77/200]	BT 1.203 (1.203)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.7778 (18.7778)
Train - epoch [77/200]	BT 1.213 (1.213)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.1116 (18.1116)
Train - epoch [57/200]	BT 1.583 (1.583)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.6579 (17.6579)
Train - epoch [77/200]	BT 1.215 (1.215)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.9003 (18.9003)
Train - epoch [77/200]	BT 1.190 (1.190)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 19.4195 (19.4195)
Train - epoch [77/200]	BT 1.133 (1.133)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.3336 (18.3336)
Test on T training set - [57][0/45]	T 0.499 (0.499)	D 0.373 (0.373)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7685 (0.7685)
Test on T training set - [57][10/45]	T 0.335 (0.356)	D 0.216 (0.237)	T@1 33.333 (79.654)	T@5 60.317 (91.486)	L 2.6316 (0.9647)
Test on T training set - [57][20/45]	T 0.341 (0.359)	D 0.225 (0.241)	T@1 88.889 (77.249)	T@5 100.000 (90.476)	L 0.6141 (1.0933)
Test on T training set - [57][30/45]	T 0.335 (0.351)	D 0.217 (0.233)	T@1 77.778 (75.730)	T@5 95.238 (90.476)	L 1.0319 (1.1184)
Test on T training set - [57][40/45]	T 0.326 (0.346)	D 0.203 (0.228)	T@1 42.857 (71.777)	T@5 80.952 (86.295)	L 1.9930 (1.3175)
 * Test on T training set - Prec@1 69.862, Prec@5 86.013
Test on T test set - [57][0/45]	Time 0.521 (0.521)	Loss 0.7685 (0.7685)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [57][10/45]	Time 0.334 (0.348)	Loss 2.6316 (0.9647)	Prec@1 33.333 (79.654)	Prec@5 60.317 (91.486)
Test on T test set - [57][20/45]	Time 0.348 (0.344)	Loss 0.6141 (1.0933)	Prec@1 88.889 (77.249)	Prec@5 100.000 (90.476)
Test on T test set - [57][30/45]	Time 0.330 (0.341)	Loss 1.0319 (1.1184)	Prec@1 77.778 (75.730)	Prec@5 95.238 (90.476)
Test on T test set - [57][40/45]	Time 0.331 (0.339)	Loss 1.9930 (1.3175)	Prec@1 42.857 (71.777)	Prec@5 80.952 (86.295)
 * Test on T test set - Prec@1 69.862, Prec@5 86.013
Epoch 57, K-means clustering 0, Average clustering time 0.028, Prec@1 73.624
Epoch 57, K-means clustering 1, Average clustering time 0.089, Prec@1 73.411
Epoch 57, K-means clustering 2, Average clustering time 0.092, Prec@1 73.411
Epoch 57, K-means clustering 3, Average clustering time 0.093, Prec@1 72.950
Epoch 57, K-means clustering 4, Average clustering time 0.096, Prec@1 72.985
Epoch 57, K-means clustering 0, Average clustering time 0.003, Prec@1 73.376
Epoch 57, K-means clustering 1, Average clustering time 0.042, Prec@1 73.518
Epoch 57, K-means clustering 2, Average clustering time 0.058, Prec@1 73.553
Epoch 57, K-means clustering 3, Average clustering time 0.065, Prec@1 73.269
Epoch 57, K-means clustering 4, Average clustering time 0.072, Prec@1 73.163
Test on T training set - [77][0/13]	T 0.738 (0.738)	D 0.608 (0.608)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1484 (0.1484)
Test on T training set - [77][10/13]	T 0.495 (0.537)	D 0.380 (0.415)	T@1 65.079 (86.869)	T@5 100.000 (97.835)	L 0.8391 (0.5714)
 * Test on T training set - Prec@1 87.170, Prec@5 97.862
Test on T test set - [77][0/13]	Time 0.726 (0.726)	Loss 0.1484 (0.1484)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [77][10/13]	Time 0.499 (0.517)	Loss 0.8391 (0.5714)	Prec@1 65.079 (86.869)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 87.170, Prec@5 97.862
Epoch 77, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 77, K-means clustering 1, Average clustering time 0.080, Prec@1 87.547
Epoch 77, K-means clustering 2, Average clustering time 0.083, Prec@1 87.547
Epoch 77, K-means clustering 3, Average clustering time 0.084, Prec@1 87.547
Epoch 77, K-means clustering 4, Average clustering time 0.087, Prec@1 87.547
Epoch 77, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 77, K-means clustering 1, Average clustering time 0.043, Prec@1 88.553
Epoch 77, K-means clustering 2, Average clustering time 0.055, Prec@1 88.428
Epoch 77, K-means clustering 3, Average clustering time 0.061, Prec@1 88.302
Epoch 77, K-means clustering 4, Average clustering time 0.067, Prec@1 88.302
The penalty weight is 0.895693
Train - epoch [58/200]	BT 1.486 (1.486)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.9970 (17.9970)
The penalty weight is 0.960319
Train - epoch [78/200]	BT 1.148 (1.148)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.4627 (17.4627)
Train - epoch [78/200]	BT 1.094 (1.094)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.9228 (17.9228)
Train - epoch [58/200]	BT 1.464 (1.464)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4376 (17.4376)
Train - epoch [58/200]	BT 1.444 (1.444)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.2603 (18.2603)
Train - epoch [78/200]	BT 0.995 (0.995)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.2746 (18.2746)
Train - epoch [78/200]	BT 1.111 (1.111)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.9537 (16.9537)
Train - epoch [58/200]	BT 1.461 (1.461)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.7414 (17.7414)
Train - epoch [78/200]	BT 1.115 (1.115)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.3824 (17.3824)
Train - epoch [58/200]	BT 2.014 (2.014)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.8162 (15.8162)
Train - epoch [58/200]	BT 1.448 (1.448)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4005 (17.4005)
Train - epoch [78/200]	BT 1.702 (1.702)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 19.1507 (19.1507)
Train - epoch [78/200]	BT 1.106 (1.106)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 17.9728 (17.9728)
Train - epoch [58/200]	BT 1.508 (1.508)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 15.6832 (15.6832)
Test on T training set - [78][0/13]	T 0.740 (0.740)	D 0.622 (0.622)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1342 (0.1342)
Test on T training set - [78][10/13]	T 0.523 (0.524)	D 0.400 (0.404)	T@1 65.079 (86.291)	T@5 100.000 (97.547)	L 0.8940 (0.5782)
 * Test on T training set - Prec@1 86.541, Prec@5 97.610
Test on T test set - [78][0/13]	Time 0.747 (0.747)	Loss 0.1342 (0.1342)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [78][10/13]	Time 0.517 (0.519)	Loss 0.8940 (0.5782)	Prec@1 65.079 (86.291)	Prec@5 100.000 (97.547)
 * Test on T test set - Prec@1 86.541, Prec@5 97.610
Epoch 78, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 78, K-means clustering 1, Average clustering time 0.089, Prec@1 87.673
Epoch 78, K-means clustering 2, Average clustering time 0.086, Prec@1 87.673
Epoch 78, K-means clustering 3, Average clustering time 0.085, Prec@1 87.673
Epoch 78, K-means clustering 4, Average clustering time 0.084, Prec@1 87.673
Epoch 78, K-means clustering 0, Average clustering time 0.001, Prec@1 87.673
Epoch 78, K-means clustering 1, Average clustering time 0.036, Prec@1 87.547
Epoch 78, K-means clustering 2, Average clustering time 0.049, Prec@1 87.421
Epoch 78, K-means clustering 3, Average clustering time 0.060, Prec@1 87.421
Epoch 78, K-means clustering 4, Average clustering time 0.064, Prec@1 87.421
Test on T training set - [58][0/45]	T 0.505 (0.505)	D 0.380 (0.380)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7375 (0.7375)
Test on T training set - [58][10/45]	T 0.606 (0.375)	D 0.483 (0.256)	T@1 30.159 (80.087)	T@5 60.317 (91.486)	L 2.6696 (0.9189)
Test on T training set - [58][20/45]	T 0.342 (0.361)	D 0.222 (0.243)	T@1 88.889 (77.551)	T@5 100.000 (90.627)	L 0.6452 (1.0500)
Test on T training set - [58][30/45]	T 0.323 (0.364)	D 0.208 (0.246)	T@1 76.190 (75.883)	T@5 93.651 (90.783)	L 1.0943 (1.0777)
Test on T training set - [58][40/45]	T 0.325 (0.357)	D 0.203 (0.239)	T@1 42.857 (71.429)	T@5 80.952 (86.295)	L 1.9659 (1.3024)
 * Test on T training set - Prec@1 69.045, Prec@5 85.978
The penalty weight is 0.962218
Train - epoch [79/200]	BT 1.143 (1.143)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.2156 (18.2156)
Train - epoch [79/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.8249 (18.8249)
Test on T test set - [58][0/45]	Time 0.518 (0.518)	Loss 0.7375 (0.7375)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [58][10/45]	Time 0.348 (0.363)	Loss 2.6696 (0.9189)	Prec@1 30.159 (80.087)	Prec@5 60.317 (91.486)
Test on T test set - [58][20/45]	Time 0.326 (0.349)	Loss 0.6452 (1.0500)	Prec@1 88.889 (77.551)	Prec@5 100.000 (90.627)
Test on T test set - [58][30/45]	Time 0.355 (0.348)	Loss 1.0943 (1.0777)	Prec@1 76.190 (75.883)	Prec@5 93.651 (90.783)
Test on T test set - [58][40/45]	Time 0.347 (0.347)	Loss 1.9659 (1.3024)	Prec@1 42.857 (71.429)	Prec@5 80.952 (86.295)
 * Test on T test set - Prec@1 69.045, Prec@5 85.978
Epoch 58, K-means clustering 0, Average clustering time 0.026, Prec@1 73.518
Epoch 58, K-means clustering 1, Average clustering time 0.113, Prec@1 73.766
Epoch 58, K-means clustering 2, Average clustering time 0.114, Prec@1 73.553
Epoch 58, K-means clustering 3, Average clustering time 0.112, Prec@1 73.092
Epoch 58, K-means clustering 4, Average clustering time 0.111, Prec@1 72.737
Epoch 58, K-means clustering 0, Average clustering time 0.003, Prec@1 72.914
Epoch 58, K-means clustering 1, Average clustering time 0.046, Prec@1 73.589
Epoch 58, K-means clustering 2, Average clustering time 0.067, Prec@1 73.305
Epoch 58, K-means clustering 3, Average clustering time 0.074, Prec@1 73.305
Epoch 58, K-means clustering 4, Average clustering time 0.075, Prec@1 73.127
Train - epoch [79/200]	BT 1.124 (1.124)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.3550 (18.3550)
The penalty weight is 0.900527
Train - epoch [59/200]	BT 1.459 (1.459)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.4399 (16.4399)
Train - epoch [59/200]	BT 1.534 (1.534)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.8076 (17.8076)
Train - epoch [79/200]	BT 1.058 (1.058)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.9316 (18.9316)
Train - epoch [79/200]	BT 1.336 (1.336)	DT 0.000 (0.000)	S@1 85.714 (85.714)	Loss 18.2969 (18.2969)
Train - epoch [79/200]	BT 1.221 (1.221)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 19.0153 (19.0153)
Train - epoch [59/200]	BT 1.578 (1.578)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.2800 (18.2800)
Train - epoch [59/200]	BT 1.468 (1.468)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3335 (17.3335)
Test on T training set - [79][0/13]	T 0.745 (0.745)	D 0.622 (0.622)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1510 (0.1510)
Test on T training set - [79][10/13]	T 0.529 (0.533)	D 0.406 (0.409)	T@1 65.079 (86.580)	T@5 100.000 (97.691)	L 0.8828 (0.5845)
 * Test on T training set - Prec@1 87.044, Prec@5 97.736
Test on T test set - [79][0/13]	Time 0.744 (0.744)	Loss 0.1510 (0.1510)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [79][10/13]	Time 0.533 (0.527)	Loss 0.8828 (0.5845)	Prec@1 65.079 (86.580)	Prec@5 100.000 (97.691)
 * Test on T test set - Prec@1 87.044, Prec@5 97.736
Epoch 79, K-means clustering 0, Average clustering time 0.018, Prec@1 88.428
Epoch 79, K-means clustering 1, Average clustering time 0.084, Prec@1 87.925
Epoch 79, K-means clustering 2, Average clustering time 0.091, Prec@1 87.673
Epoch 79, K-means clustering 3, Average clustering time 0.092, Prec@1 87.673
Epoch 79, K-means clustering 4, Average clustering time 0.095, Prec@1 87.673
Epoch 79, K-means clustering 0, Average clustering time 0.001, Prec@1 88.805
Epoch 79, K-means clustering 1, Average clustering time 0.040, Prec@1 88.931
Epoch 79, K-means clustering 2, Average clustering time 0.052, Prec@1 88.805
Epoch 79, K-means clustering 3, Average clustering time 0.058, Prec@1 88.679
Epoch 79, K-means clustering 4, Average clustering time 0.061, Prec@1 88.679
Train - epoch [59/200]	BT 1.517 (1.517)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.9663 (17.9663)
Train - epoch [59/200]	BT 1.480 (1.480)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.7403 (17.7403)
Train - epoch [80/200]	BT 1.087 (1.087)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 19.3517 (19.3517)
The penalty weight is 0.964028
Train - epoch [80/200]	BT 1.097 (1.097)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.9169 (18.9169)
Train - epoch [80/200]	BT 1.318 (1.318)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.7778 (17.7778)
Train - epoch [80/200]	BT 1.134 (1.134)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 16.7322 (16.7322)
Test on T training set - [59][0/45]	T 0.511 (0.511)	D 0.388 (0.388)	T@1 88.889 (88.889)	T@5 96.825 (96.825)	L 0.7399 (0.7399)
Test on T training set - [59][10/45]	T 0.353 (0.360)	D 0.231 (0.240)	T@1 30.159 (79.798)	T@5 60.317 (91.053)	L 2.6977 (0.9627)
Test on T training set - [59][20/45]	T 0.389 (0.360)	D 0.266 (0.241)	T@1 88.889 (77.627)	T@5 100.000 (90.174)	L 0.6885 (1.0754)
Test on T training set - [59][30/45]	T 0.351 (0.356)	D 0.229 (0.237)	T@1 77.778 (75.986)	T@5 95.238 (90.579)	L 1.0637 (1.1011)
Test on T training set - [59][40/45]	T 0.335 (0.352)	D 0.210 (0.232)	T@1 44.444 (71.893)	T@5 79.365 (86.218)	L 1.9619 (1.3122)
 * Test on T training set - Prec@1 69.649, Prec@5 85.765
Train - epoch [80/200]	BT 1.115 (1.115)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.7339 (18.7339)
Train - epoch [80/200]	BT 1.077 (1.077)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.6030 (18.6030)
Test on T test set - [59][0/45]	Time 0.563 (0.563)	Loss 0.7399 (0.7399)	Prec@1 88.889 (88.889)	Prec@5 96.825 (96.825)
Test on T test set - [59][10/45]	Time 0.339 (0.351)	Loss 2.6977 (0.9627)	Prec@1 30.159 (79.798)	Prec@5 60.317 (91.053)
Test on T test set - [59][20/45]	Time 0.326 (0.344)	Loss 0.6885 (1.0754)	Prec@1 88.889 (77.627)	Prec@5 100.000 (90.174)
Test on T test set - [59][30/45]	Time 0.335 (0.340)	Loss 1.0637 (1.1011)	Prec@1 77.778 (75.986)	Prec@5 95.238 (90.579)
Test on T test set - [59][40/45]	Time 0.335 (0.346)	Loss 1.9619 (1.3122)	Prec@1 44.444 (71.893)	Prec@5 79.365 (86.218)
 * Test on T test set - Prec@1 69.649, Prec@5 85.765
Epoch 59, K-means clustering 0, Average clustering time 0.026, Prec@1 73.589
Epoch 59, K-means clustering 1, Average clustering time 0.098, Prec@1 73.660
Epoch 59, K-means clustering 2, Average clustering time 0.100, Prec@1 73.376
Epoch 59, K-means clustering 3, Average clustering time 0.100, Prec@1 73.021
Epoch 59, K-means clustering 4, Average clustering time 0.101, Prec@1 72.666
Epoch 59, K-means clustering 0, Average clustering time 0.005, Prec@1 73.021
Epoch 59, K-means clustering 1, Average clustering time 0.041, Prec@1 73.163
Epoch 59, K-means clustering 2, Average clustering time 0.054, Prec@1 72.950
Epoch 59, K-means clustering 3, Average clustering time 0.061, Prec@1 72.914
Epoch 59, K-means clustering 4, Average clustering time 0.064, Prec@1 72.985
Train - epoch [80/200]	BT 1.122 (1.122)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.9908 (18.9908)
Train - epoch [60/200]	BT 1.636 (1.636)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.1817 (18.1817)
The penalty weight is 0.905148
Train - epoch [60/200]	BT 1.493 (1.493)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.7359 (17.7359)
Test on T training set - [80][0/13]	T 0.748 (0.748)	D 0.625 (0.625)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1308 (0.1308)
Test on T training set - [80][10/13]	T 0.517 (0.619)	D 0.391 (0.498)	T@1 65.079 (86.291)	T@5 100.000 (97.835)	L 0.8450 (0.5823)
 * Test on T training set - Prec@1 86.918, Prec@5 97.862
Train - epoch [60/200]	BT 1.465 (1.465)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.1083 (18.1083)
Test on T test set - [80][0/13]	Time 0.744 (0.744)	Loss 0.1308 (0.1308)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [80][10/13]	Time 0.512 (0.554)	Loss 0.8450 (0.5823)	Prec@1 65.079 (86.291)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 86.918, Prec@5 97.862
Epoch 80, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 80, K-means clustering 1, Average clustering time 0.078, Prec@1 87.925
Epoch 80, K-means clustering 2, Average clustering time 0.083, Prec@1 87.925
Epoch 80, K-means clustering 3, Average clustering time 0.084, Prec@1 87.925
Epoch 80, K-means clustering 4, Average clustering time 0.084, Prec@1 87.925
Epoch 80, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 80, K-means clustering 1, Average clustering time 0.036, Prec@1 88.428
Epoch 80, K-means clustering 2, Average clustering time 0.049, Prec@1 88.050
Epoch 80, K-means clustering 3, Average clustering time 0.055, Prec@1 88.050
Epoch 80, K-means clustering 4, Average clustering time 0.061, Prec@1 88.050
Train - epoch [60/200]	BT 1.577 (1.577)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.2395 (18.2395)
The penalty weight is 0.965752
Train - epoch [81/200]	BT 1.123 (1.123)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.7107 (18.7107)
Train - epoch [81/200]	BT 1.237 (1.237)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 19.1327 (19.1327)
Train - epoch [60/200]	BT 1.469 (1.469)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.6707 (17.6707)
Train - epoch [81/200]	BT 1.140 (1.140)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.6942 (18.6942)
Train - epoch [81/200]	BT 1.112 (1.112)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.6136 (18.6136)
Train - epoch [60/200]	BT 1.961 (1.961)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.6247 (16.6247)
Train - epoch [60/200]	BT 1.484 (1.484)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4133 (17.4133)
Train - epoch [81/200]	BT 1.203 (1.203)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 17.8448 (17.8448)
Train - epoch [81/200]	BT 1.100 (1.100)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 18.8815 (18.8815)
Train - epoch [81/200]	BT 1.005 (1.005)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.8632 (18.8632)
Test on T training set - [60][0/45]	T 0.510 (0.510)	D 0.387 (0.387)	T@1 85.714 (85.714)	T@5 96.825 (96.825)	L 0.7554 (0.7554)
Test on T training set - [60][10/45]	T 0.329 (0.351)	D 0.207 (0.230)	T@1 31.746 (79.942)	T@5 60.317 (91.342)	L 2.6346 (0.9646)
Test on T training set - [60][20/45]	T 0.360 (0.343)	D 0.238 (0.224)	T@1 88.889 (77.475)	T@5 100.000 (90.325)	L 0.6293 (1.0831)
Test on T training set - [60][30/45]	T 0.344 (0.341)	D 0.220 (0.222)	T@1 79.365 (76.037)	T@5 95.238 (90.527)	L 1.0211 (1.1089)
Test on T training set - [60][40/45]	T 0.335 (0.338)	D 0.218 (0.219)	T@1 41.270 (72.125)	T@5 79.365 (86.140)	L 1.9380 (1.3110)
 * Test on T training set - Prec@1 69.862, Prec@5 85.659
Test on T training set - [81][0/13]	T 0.763 (0.763)	D 0.647 (0.647)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1448 (0.1448)
Test on T training set - [81][10/13]	T 0.543 (0.537)	D 0.421 (0.417)	T@1 63.492 (86.291)	T@5 100.000 (97.835)	L 0.9649 (0.5830)
 * Test on T training set - Prec@1 86.792, Prec@5 97.862
Test on T test set - [60][0/45]	Time 0.518 (0.518)	Loss 0.7554 (0.7554)	Prec@1 85.714 (85.714)	Prec@5 96.825 (96.825)
Test on T test set - [60][10/45]	Time 0.331 (0.347)	Loss 2.6346 (0.9646)	Prec@1 31.746 (79.942)	Prec@5 60.317 (91.342)
Test on T test set - [60][20/45]	Time 0.389 (0.385)	Loss 0.6293 (1.0831)	Prec@1 88.889 (77.475)	Prec@5 100.000 (90.325)
Test on T test set - [60][30/45]	Time 0.321 (0.369)	Loss 1.0211 (1.1089)	Prec@1 79.365 (76.037)	Prec@5 95.238 (90.527)
Test on T test set - [60][40/45]	Time 0.336 (0.361)	Loss 1.9380 (1.3110)	Prec@1 41.270 (72.125)	Prec@5 79.365 (86.140)
 * Test on T test set - Prec@1 69.862, Prec@5 85.659
Epoch 60, K-means clustering 0, Average clustering time 0.026, Prec@1 73.766
Epoch 60, K-means clustering 1, Average clustering time 0.091, Prec@1 73.802
Epoch 60, K-means clustering 2, Average clustering time 0.095, Prec@1 73.660
Epoch 60, K-means clustering 3, Average clustering time 0.096, Prec@1 73.269
Epoch 60, K-means clustering 4, Average clustering time 0.098, Prec@1 72.843
Epoch 60, K-means clustering 0, Average clustering time 0.003, Prec@1 73.340
Epoch 60, K-means clustering 1, Average clustering time 0.045, Prec@1 73.447
Epoch 60, K-means clustering 2, Average clustering time 0.056, Prec@1 73.553
Epoch 60, K-means clustering 3, Average clustering time 0.063, Prec@1 73.411
Epoch 60, K-means clustering 4, Average clustering time 0.067, Prec@1 73.234
Test on T test set - [81][0/13]	Time 0.744 (0.744)	Loss 0.1448 (0.1448)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [81][10/13]	Time 0.537 (0.548)	Loss 0.9649 (0.5830)	Prec@1 63.492 (86.291)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 86.792, Prec@5 97.862
Epoch 81, K-means clustering 0, Average clustering time 0.018, Prec@1 87.799
Epoch 81, K-means clustering 1, Average clustering time 0.083, Prec@1 87.421
Epoch 81, K-means clustering 2, Average clustering time 0.086, Prec@1 87.421
Epoch 81, K-means clustering 3, Average clustering time 0.088, Prec@1 87.421
Epoch 81, K-means clustering 4, Average clustering time 0.092, Prec@1 87.421
Epoch 81, K-means clustering 0, Average clustering time 0.001, Prec@1 87.799
Epoch 81, K-means clustering 1, Average clustering time 0.048, Prec@1 88.050
Epoch 81, K-means clustering 2, Average clustering time 0.057, Prec@1 88.302
Epoch 81, K-means clustering 3, Average clustering time 0.062, Prec@1 88.176
Epoch 81, K-means clustering 4, Average clustering time 0.065, Prec@1 88.176
The penalty weight is 0.909565
Train - epoch [61/200]	BT 1.777 (1.777)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.3529 (17.3529)
The penalty weight is 0.967395
Train - epoch [82/200]	BT 1.219 (1.219)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.4245 (18.4245)
Train - epoch [82/200]	BT 1.125 (1.125)	DT 0.000 (0.000)	S@1 83.333 (83.333)	Loss 19.7786 (19.7786)
Train - epoch [61/200]	BT 1.519 (1.519)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.1434 (16.1434)
Train - epoch [82/200]	BT 1.244 (1.244)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 17.6745 (17.6745)
Train - epoch [61/200]	BT 1.450 (1.450)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.4862 (17.4862)
Train - epoch [61/200]	BT 2.031 (2.031)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.6331 (17.6331)
Train - epoch [61/200]	BT 1.459 (1.459)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 16.4030 (16.4030)
Train - epoch [82/200]	BT 1.702 (1.702)	DT 0.000 (0.000)	S@1 97.619 (97.619)	Loss 19.3436 (19.3436)
Train - epoch [82/200]	BT 1.206 (1.206)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.5757 (18.5757)
Train - epoch [61/200]	BT 1.483 (1.483)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.8469 (17.8469)
Train - epoch [82/200]	BT 1.187 (1.187)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 17.5230 (17.5230)
Train - epoch [82/200]	BT 1.006 (1.006)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 19.0036 (19.0036)
Train - epoch [61/200]	BT 1.519 (1.519)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.1580 (17.1580)
Test on T training set - [82][0/13]	T 0.919 (0.919)	D 0.794 (0.794)	T@1 100.000 (100.000)	T@5 100.000 (100.000)	L 0.1450 (0.1450)
Test on T training set - [82][10/13]	T 0.516 (0.610)	D 0.396 (0.487)	T@1 63.492 (86.580)	T@5 100.000 (97.835)	L 0.8832 (0.5947)
 * Test on T training set - Prec@1 86.918, Prec@5 97.862
Test on T test set - [82][0/13]	Time 0.731 (0.731)	Loss 0.1450 (0.1450)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test on T test set - [82][10/13]	Time 0.508 (0.528)	Loss 0.8832 (0.5947)	Prec@1 63.492 (86.580)	Prec@5 100.000 (97.835)
 * Test on T test set - Prec@1 86.918, Prec@5 97.862
Epoch 82, K-means clustering 0, Average clustering time 0.018, Prec@1 88.176
Epoch 82, K-means clustering 1, Average clustering time 0.082, Prec@1 87.925
Epoch 82, K-means clustering 2, Average clustering time 0.083, Prec@1 87.925
Epoch 82, K-means clustering 3, Average clustering time 0.086, Prec@1 87.925
Epoch 82, K-means clustering 4, Average clustering time 0.106, Prec@1 87.925
Epoch 82, K-means clustering 0, Average clustering time 0.001, Prec@1 88.553
Epoch 82, K-means clustering 1, Average clustering time 0.042, Prec@1 88.302
Epoch 82, K-means clustering 2, Average clustering time 0.052, Prec@1 88.176
Epoch 82, K-means clustering 3, Average clustering time 0.058, Prec@1 88.176
Epoch 82, K-means clustering 4, Average clustering time 0.064, Prec@1 88.176
Test on T training set - [61][0/45]	T 0.522 (0.522)	D 0.402 (0.402)	T@1 87.302 (87.302)	T@5 96.825 (96.825)	L 0.7386 (0.7386)
Test on T training set - [61][10/45]	T 0.321 (0.400)	D 0.203 (0.281)	T@1 28.571 (79.509)	T@5 57.143 (91.198)	L 2.7230 (0.9561)
Test on T training set - [61][20/45]	T 0.334 (0.372)	D 0.218 (0.252)	T@1 90.476 (76.871)	T@5 100.000 (90.249)	L 0.5675 (1.0972)
Test on T training set - [61][30/45]	T 0.343 (0.368)	D 0.221 (0.249)	T@1 74.603 (75.576)	T@5 95.238 (90.630)	L 1.1353 (1.1191)
Test on T training set - [61][40/45]	T 0.335 (0.360)	D 0.222 (0.241)	T@1 41.270 (71.003)	T@5 80.952 (86.101)	L 1.9898 (1.3408)
 * Test on T training set - Prec@1 68.939, Prec@5 85.765
The penalty weight is 0.968960
Train - epoch [83/200]	BT 1.193 (1.193)	DT 0.000 (0.000)	S@1 90.476 (90.476)	Loss 18.8197 (18.8197)
Test on T test set - [61][0/45]	Time 0.524 (0.524)	Loss 0.7386 (0.7386)	Prec@1 87.302 (87.302)	Prec@5 96.825 (96.825)
Test on T test set - [61][10/45]	Time 0.316 (0.349)	Loss 2.7230 (0.9561)	Prec@1 28.571 (79.509)	Prec@5 57.143 (91.198)
Test on T test set - [61][20/45]	Time 0.338 (0.353)	Loss 0.5675 (1.0972)	Prec@1 90.476 (76.871)	Prec@5 100.000 (90.249)
Test on T test set - [61][30/45]	Time 0.357 (0.347)	Loss 1.1353 (1.1191)	Prec@1 74.603 (75.576)	Prec@5 95.238 (90.630)
Test on T test set - [61][40/45]	Time 0.557 (0.355)	Loss 1.9898 (1.3408)	Prec@1 41.270 (71.003)	Prec@5 80.952 (86.101)
 * Test on T test set - Prec@1 68.939, Prec@5 85.765
Epoch 61, K-means clustering 0, Average clustering time 0.026, Prec@1 73.376
Epoch 61, K-means clustering 1, Average clustering time 0.096, Prec@1 73.127
Epoch 61, K-means clustering 2, Average clustering time 0.103, Prec@1 72.843
Epoch 61, K-means clustering 3, Average clustering time 0.108, Prec@1 72.524
Epoch 61, K-means clustering 4, Average clustering time 0.112, Prec@1 72.275
Epoch 61, K-means clustering 0, Average clustering time 0.003, Prec@1 72.808
Epoch 61, K-means clustering 1, Average clustering time 0.051, Prec@1 73.376
Epoch 61, K-means clustering 2, Average clustering time 0.060, Prec@1 73.305
Epoch 61, K-means clustering 3, Average clustering time 0.065, Prec@1 73.802
Epoch 61, K-means clustering 4, Average clustering time 0.077, Prec@1 73.695
Train - epoch [83/200]	BT 1.307 (1.307)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.7778 (18.7778)
Train - epoch [83/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 88.095 (88.095)	Loss 19.1985 (19.1985)
The penalty weight is 0.913785
Train - epoch [62/200]	BT 1.501 (1.501)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 17.9907 (17.9907)
Train - epoch [62/200]	BT 1.500 (1.500)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 18.1921 (18.1921)
Train - epoch [83/200]	BT 1.149 (1.149)	DT 0.000 (0.000)	S@1 92.857 (92.857)	Loss 18.7361 (18.7361)
Train - epoch [83/200]	BT 1.205 (1.205)	DT 0.000 (0.000)	S@1 95.238 (95.238)	Loss 18.4295 (18.4295)
