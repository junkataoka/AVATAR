/data/home/jkataok1/alexnet_resnet_finetune/checkpoints/train_to_validation_resnet101_512.pkl
Source pre-trained model has been loaded!
https://app.neptune.ai/junkataoka/SRDC/e/SRDC-2136
Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.
begin training
Test on T training set - [0][0/1731]	T 0.605 (0.605)	D 0.202 (0.202)	T@1 25.000 (25.000)	T@5 78.125 (78.125)	L 2.3324 (2.3324)
Test on T training set - [0][10/1731]	T 0.211 (0.212)	D 0.115 (0.082)	T@1 56.250 (41.477)	T@5 90.625 (88.920)	L 1.5164 (1.8050)
Test on T training set - [0][20/1731]	T 0.224 (0.220)	D 0.118 (0.102)	T@1 46.875 (43.750)	T@5 93.750 (90.179)	L 1.4888 (1.6986)
Test on T training set - [0][30/1731]	T 0.206 (0.218)	D 0.105 (0.105)	T@1 56.250 (45.665)	T@5 90.625 (90.927)	L 1.4455 (1.6480)
Test on T training set - [0][40/1731]	T 0.223 (0.289)	D 0.126 (0.179)	T@1 31.250 (46.189)	T@5 90.625 (90.701)	L 1.9106 (1.6380)
Test on T training set - [0][50/1731]	T 0.211 (0.276)	D 0.111 (0.167)	T@1 43.750 (46.201)	T@5 100.000 (90.135)	L 1.4430 (1.6503)
Test on T training set - [0][60/1731]	T 0.224 (0.267)	D 0.118 (0.159)	T@1 34.375 (46.516)	T@5 78.125 (90.266)	L 1.8778 (1.6363)
Test on T training set - [0][70/1731]	T 0.207 (0.259)	D 0.105 (0.151)	T@1 43.750 (46.743)	T@5 96.875 (90.053)	L 1.6551 (1.6437)
Test on T training set - [0][80/1731]	T 0.198 (0.253)	D 0.093 (0.146)	T@1 43.750 (46.875)	T@5 100.000 (90.625)	L 1.6279 (1.6409)
Test on T training set - [0][90/1731]	T 0.181 (0.247)	D 0.085 (0.141)	T@1 50.000 (46.669)	T@5 90.625 (90.762)	L 1.7432 (1.6486)
Test on T training set - [0][100/1731]	T 0.194 (0.242)	D 0.093 (0.137)	T@1 40.625 (46.597)	T@5 93.750 (90.656)	L 1.8455 (1.6511)
Test on T training set - [0][110/1731]	T 0.196 (0.237)	D 0.100 (0.132)	T@1 31.250 (46.059)	T@5 78.125 (89.977)	L 2.1418 (1.6720)
Test on T training set - [0][120/1731]	T 0.203 (0.234)	D 0.099 (0.129)	T@1 71.875 (47.314)	T@5 96.875 (90.263)	L 0.9930 (1.6403)
Test on T training set - [0][130/1731]	T 0.199 (0.250)	D 0.092 (0.145)	T@1 71.875 (49.666)	T@5 100.000 (90.792)	L 0.8602 (1.5780)
Test on T training set - [0][140/1731]	T 0.181 (0.246)	D 0.084 (0.141)	T@1 78.125 (51.751)	T@5 100.000 (91.401)	L 0.7643 (1.5246)
Test on T training set - [0][150/1731]	T 0.194 (0.242)	D 0.095 (0.137)	T@1 87.500 (53.415)	T@5 100.000 (91.867)	L 0.8136 (1.4821)
Test on T training set - [0][160/1731]	T 0.183 (0.238)	D 0.082 (0.134)	T@1 81.250 (55.008)	T@5 100.000 (92.236)	L 0.7387 (1.4402)
Test on T training set - [0][170/1731]	T 0.172 (0.235)	D 0.071 (0.131)	T@1 71.875 (56.341)	T@5 93.750 (92.452)	L 1.0034 (1.4063)
Test on T training set - [0][180/1731]	T 0.171 (0.231)	D 0.063 (0.127)	T@1 50.000 (56.992)	T@5 87.500 (92.576)	L 1.4710 (1.3911)
Test on T training set - [0][190/1731]	T 0.180 (0.228)	D 0.084 (0.124)	T@1 65.625 (57.428)	T@5 90.625 (92.605)	L 1.2746 (1.3793)
Test on T training set - [0][200/1731]	T 0.163 (0.225)	D 0.065 (0.121)	T@1 56.250 (57.354)	T@5 90.625 (92.568)	L 1.6620 (1.3785)
Test on T training set - [0][210/1731]	T 0.177 (0.222)	D 0.078 (0.119)	T@1 62.500 (57.598)	T@5 96.875 (92.624)	L 1.2822 (1.3727)
Test on T training set - [0][220/1731]	T 0.232 (0.231)	D 0.130 (0.128)	T@1 68.750 (58.201)	T@5 96.875 (92.803)	L 1.0035 (1.3584)
Test on T training set - [0][230/1731]	T 0.173 (0.229)	D 0.070 (0.126)	T@1 43.750 (57.562)	T@5 100.000 (92.871)	L 1.6612 (1.3711)
Test on T training set - [0][240/1731]	T 0.233 (0.229)	D 0.130 (0.126)	T@1 90.625 (58.143)	T@5 100.000 (93.141)	L 0.4183 (1.3490)
Test on T training set - [0][250/1731]	T 0.208 (0.229)	D 0.105 (0.126)	T@1 62.500 (58.752)	T@5 96.875 (93.376)	L 0.8469 (1.3259)
Test on T training set - [0][260/1731]	T 0.232 (0.229)	D 0.136 (0.126)	T@1 68.750 (59.315)	T@5 96.875 (93.618)	L 0.8927 (1.3041)
Test on T training set - [0][270/1731]	T 0.231 (0.230)	D 0.135 (0.127)	T@1 78.125 (59.998)	T@5 100.000 (93.819)	L 0.7125 (1.2828)
Test on T training set - [0][280/1731]	T 0.227 (0.230)	D 0.131 (0.127)	T@1 71.875 (60.509)	T@5 96.875 (93.972)	L 0.7231 (1.2649)
Test on T training set - [0][290/1731]	T 0.231 (0.229)	D 0.135 (0.127)	T@1 84.375 (60.964)	T@5 100.000 (94.158)	L 0.5710 (1.2480)
Test on T training set - [0][300/1731]	T 0.213 (0.229)	D 0.117 (0.127)	T@1 78.125 (61.534)	T@5 100.000 (94.300)	L 0.7707 (1.2313)
Test on T training set - [0][310/1731]	T 0.238 (0.239)	D 0.142 (0.136)	T@1 71.875 (61.837)	T@5 96.875 (94.433)	L 0.8389 (1.2182)
Test on T training set - [0][320/1731]	T 0.193 (0.238)	D 0.097 (0.136)	T@1 75.000 (62.305)	T@5 100.000 (94.587)	L 0.7557 (1.2026)
Test on T training set - [0][330/1731]	T 0.208 (0.237)	D 0.101 (0.135)	T@1 84.375 (62.632)	T@5 100.000 (94.741)	L 0.6483 (1.1900)
Test on T training set - [0][340/1731]	T 0.196 (0.236)	D 0.094 (0.133)	T@1 53.125 (62.170)	T@5 96.875 (94.621)	L 1.3058 (1.2017)
Test on T training set - [0][350/1731]	T 0.207 (0.235)	D 0.111 (0.132)	T@1 50.000 (61.957)	T@5 96.875 (94.676)	L 1.1969 (1.2038)
Test on T training set - [0][360/1731]	T 0.238 (0.235)	D 0.142 (0.132)	T@1 68.750 (62.413)	T@5 96.875 (94.797)	L 0.7381 (1.1885)
Test on T training set - [0][370/1731]	T 0.184 (0.234)	D 0.088 (0.132)	T@1 62.500 (62.761)	T@5 90.625 (94.879)	L 1.2204 (1.1784)
Test on T training set - [0][380/1731]	T 0.186 (0.233)	D 0.081 (0.130)	T@1 87.500 (62.959)	T@5 100.000 (94.915)	L 0.4835 (1.1719)
Test on T training set - [0][390/1731]	T 0.170 (0.231)	D 0.065 (0.129)	T@1 71.875 (63.395)	T@5 90.625 (94.949)	L 0.9248 (1.1592)
Test on T training set - [0][400/1731]	T 0.160 (0.235)	D 0.057 (0.133)	T@1 65.625 (63.716)	T@5 93.750 (94.966)	L 0.9058 (1.1504)
Test on T training set - [0][410/1731]	T 0.167 (0.234)	D 0.062 (0.131)	T@1 84.375 (63.983)	T@5 96.875 (94.913)	L 0.6991 (1.1447)
Test on T training set - [0][420/1731]	T 0.167 (0.232)	D 0.067 (0.130)	T@1 68.750 (64.207)	T@5 87.500 (94.893)	L 1.0539 (1.1387)
Test on T training set - [0][430/1731]	T 0.172 (0.231)	D 0.076 (0.128)	T@1 78.125 (64.436)	T@5 93.750 (94.896)	L 0.8978 (1.1324)
Test on T training set - [0][440/1731]	T 0.160 (0.229)	D 0.055 (0.127)	T@1 81.250 (64.895)	T@5 100.000 (94.969)	L 0.5575 (1.1220)
Test on T training set - [0][450/1731]	T 0.161 (0.228)	D 0.060 (0.125)	T@1 84.375 (65.251)	T@5 100.000 (95.053)	L 0.5952 (1.1124)
Test on T training set - [0][460/1731]	T 0.166 (0.226)	D 0.070 (0.124)	T@1 87.500 (65.618)	T@5 100.000 (95.140)	L 0.4306 (1.1007)
Test on T training set - [0][470/1731]	T 0.158 (0.225)	D 0.054 (0.123)	T@1 81.250 (65.950)	T@5 100.000 (95.170)	L 0.5948 (1.0921)
Test on T training set - [0][480/1731]	T 0.160 (0.224)	D 0.055 (0.122)	T@1 75.000 (66.268)	T@5 96.875 (95.225)	L 0.8001 (1.0836)
Test on T training set - [0][490/1731]	T 0.166 (0.223)	D 0.064 (0.121)	T@1 81.250 (66.561)	T@5 96.875 (95.284)	L 0.6098 (1.0759)
Test on T training set - [0][500/1731]	T 0.170 (0.222)	D 0.065 (0.119)	T@1 93.750 (66.904)	T@5 100.000 (95.322)	L 0.4273 (1.0676)
Test on T training set - [0][510/1731]	T 0.180 (0.221)	D 0.074 (0.118)	T@1 68.750 (67.074)	T@5 96.875 (95.340)	L 0.9099 (1.0640)
Test on T training set - [0][520/1731]	T 0.158 (0.224)	D 0.056 (0.122)	T@1 68.750 (67.101)	T@5 93.750 (95.351)	L 1.2084 (1.0643)
Test on T training set - [0][530/1731]	T 0.161 (0.223)	D 0.065 (0.121)	T@1 68.750 (67.173)	T@5 96.875 (95.310)	L 1.0687 (1.0638)
Test on T training set - [0][540/1731]	T 0.160 (0.222)	D 0.060 (0.120)	T@1 87.500 (67.196)	T@5 100.000 (95.310)	L 0.6187 (1.0631)
Test on T training set - [0][550/1731]	T 0.148 (0.221)	D 0.052 (0.119)	T@1 71.875 (67.236)	T@5 90.625 (95.293)	L 1.1121 (1.0630)
Test on T training set - [0][560/1731]	T 0.172 (0.220)	D 0.070 (0.118)	T@1 43.750 (67.012)	T@5 87.500 (95.193)	L 1.6667 (1.0697)
Test on T training set - [0][570/1731]	T 0.186 (0.219)	D 0.090 (0.117)	T@1 75.000 (67.086)	T@5 100.000 (95.206)	L 0.8370 (1.0682)
Test on T training set - [0][580/1731]	T 0.173 (0.218)	D 0.069 (0.116)	T@1 87.500 (67.287)	T@5 96.875 (95.224)	L 0.5848 (1.0633)
Test on T training set - [0][590/1731]	T 0.189 (0.218)	D 0.082 (0.115)	T@1 90.625 (67.523)	T@5 100.000 (95.283)	L 0.4396 (1.0569)
Test on T training set - [0][600/1731]	T 0.169 (0.217)	D 0.070 (0.115)	T@1 84.375 (67.752)	T@5 96.875 (95.320)	L 0.6616 (1.0510)
Test on T training set - [0][610/1731]	T 0.164 (0.216)	D 0.058 (0.114)	T@1 84.375 (68.014)	T@5 100.000 (95.341)	L 0.5405 (1.0446)
Test on T training set - [0][620/1731]	T 0.192 (0.216)	D 0.087 (0.113)	T@1 87.500 (68.222)	T@5 100.000 (95.375)	L 0.6302 (1.0391)
Test on T training set - [0][630/1731]	T 0.193 (0.220)	D 0.096 (0.117)	T@1 78.125 (68.408)	T@5 100.000 (95.399)	L 0.7260 (1.0338)
Test on T training set - [0][640/1731]	T 0.159 (0.219)	D 0.058 (0.117)	T@1 84.375 (68.555)	T@5 96.875 (95.412)	L 0.6121 (1.0297)
Test on T training set - [0][650/1731]	T 0.160 (0.218)	D 0.059 (0.116)	T@1 75.000 (68.731)	T@5 93.750 (95.449)	L 0.9645 (1.0247)
Test on T training set - [0][660/1731]	T 0.170 (0.217)	D 0.073 (0.115)	T@1 78.125 (68.915)	T@5 93.750 (95.490)	L 0.7768 (1.0194)
Test on T training set - [0][670/1731]	T 0.169 (0.217)	D 0.072 (0.114)	T@1 71.875 (69.071)	T@5 93.750 (95.506)	L 0.9371 (1.0153)
Test on T training set - [0][680/1731]	T 0.155 (0.216)	D 0.059 (0.114)	T@1 68.750 (69.204)	T@5 96.875 (95.530)	L 0.9226 (1.0117)
Test on T training set - [0][690/1731]	T 0.237 (0.215)	D 0.132 (0.113)	T@1 3.125 (69.021)	T@5 53.125 (95.301)	L 2.9979 (1.0185)
Test on T training set - [0][700/1731]	T 0.164 (0.215)	D 0.059 (0.113)	T@1 40.625 (68.465)	T@5 65.625 (94.695)	L 1.8440 (1.0375)
Test on T training set - [0][710/1731]	T 0.175 (0.214)	D 0.070 (0.112)	T@1 56.250 (68.416)	T@5 78.125 (94.532)	L 1.5408 (1.0408)
Test on T training set - [0][720/1731]	T 0.170 (0.214)	D 0.072 (0.112)	T@1 78.125 (68.512)	T@5 93.750 (94.443)	L 0.8479 (1.0399)
Test on T training set - [0][730/1731]	T 0.217 (0.216)	D 0.118 (0.114)	T@1 87.500 (68.570)	T@5 100.000 (94.370)	L 0.4752 (1.0395)
Test on T training set - [0][740/1731]	T 0.220 (0.216)	D 0.118 (0.114)	T@1 81.250 (68.737)	T@5 93.750 (94.378)	L 0.8359 (1.0359)
Test on T training set - [0][750/1731]	T 0.200 (0.216)	D 0.093 (0.114)	T@1 84.375 (68.879)	T@5 90.625 (94.362)	L 0.7058 (1.0327)
Test on T training set - [0][760/1731]	T 0.240 (0.216)	D 0.135 (0.114)	T@1 90.625 (69.017)	T@5 96.875 (94.341)	L 0.5592 (1.0297)
Test on T training set - [0][770/1731]	T 0.201 (0.216)	D 0.105 (0.114)	T@1 71.875 (69.135)	T@5 93.750 (94.330)	L 0.8222 (1.0267)
Test on T training set - [0][780/1731]	T 0.232 (0.216)	D 0.130 (0.114)	T@1 81.250 (69.166)	T@5 100.000 (94.302)	L 0.7300 (1.0267)
Test on T training set - [0][790/1731]	T 0.218 (0.216)	D 0.111 (0.114)	T@1 90.625 (69.264)	T@5 96.875 (94.268)	L 0.5271 (1.0251)
Test on T training set - [0][800/1731]	T 0.201 (0.216)	D 0.104 (0.114)	T@1 78.125 (69.386)	T@5 96.875 (94.284)	L 0.8933 (1.0219)
Test on T training set - [0][810/1731]	T 0.206 (0.219)	D 0.098 (0.117)	T@1 75.000 (69.455)	T@5 84.375 (94.243)	L 0.9874 (1.0207)
Test on T training set - [0][820/1731]	T 0.224 (0.219)	D 0.118 (0.117)	T@1 75.000 (69.553)	T@5 90.625 (94.230)	L 0.9524 (1.0183)
Test on T training set - [0][830/1731]	T 0.196 (0.219)	D 0.090 (0.117)	T@1 84.375 (69.679)	T@5 90.625 (94.179)	L 0.6921 (1.0158)
Test on T training set - [0][840/1731]	T 0.178 (0.218)	D 0.074 (0.116)	T@1 46.875 (69.768)	T@5 84.375 (94.181)	L 1.5208 (1.0141)
Test on T training set - [0][850/1731]	T 0.148 (0.217)	D 0.052 (0.115)	T@1 6.250 (69.033)	T@5 46.875 (93.724)	L 2.7691 (1.0356)
Test on T training set - [0][860/1731]	T 0.164 (0.217)	D 0.067 (0.115)	T@1 9.375 (68.329)	T@5 65.625 (93.314)	L 2.6513 (1.0558)
Test on T training set - [0][870/1731]	T 0.158 (0.216)	D 0.063 (0.114)	T@1 3.125 (67.666)	T@5 56.250 (92.918)	L 2.8194 (1.0739)
Test on T training set - [0][880/1731]	T 0.168 (0.216)	D 0.066 (0.114)	T@1 21.875 (67.005)	T@5 59.375 (92.523)	L 2.5008 (1.0927)
Test on T training set - [0][890/1731]	T 0.168 (0.215)	D 0.068 (0.113)	T@1 6.250 (66.365)	T@5 59.375 (92.189)	L 2.9502 (1.1111)
Test on T training set - [0][900/1731]	T 0.168 (0.215)	D 0.067 (0.113)	T@1 12.500 (65.715)	T@5 59.375 (91.773)	L 2.7195 (1.1294)
Test on T training set - [0][910/1731]	T 0.168 (0.218)	D 0.066 (0.116)	T@1 46.875 (65.395)	T@5 87.500 (91.651)	L 1.6026 (1.1384)
Test on T training set - [0][920/1731]	T 0.162 (0.218)	D 0.064 (0.116)	T@1 53.125 (65.354)	T@5 90.625 (91.653)	L 1.5894 (1.1410)
Test on T training set - [0][930/1731]	T 0.231 (0.218)	D 0.129 (0.116)	T@1 71.875 (65.393)	T@5 93.750 (91.676)	L 1.0296 (1.1406)
Test on T training set - [0][940/1731]	T 0.234 (0.218)	D 0.138 (0.116)	T@1 71.875 (65.373)	T@5 96.875 (91.701)	L 0.9847 (1.1413)
Test on T training set - [0][950/1731]	T 0.237 (0.218)	D 0.137 (0.116)	T@1 65.625 (65.362)	T@5 96.875 (91.723)	L 1.2098 (1.1420)
Test on T training set - [0][960/1731]	T 0.219 (0.218)	D 0.122 (0.116)	T@1 59.375 (65.368)	T@5 96.875 (91.753)	L 1.0924 (1.1421)
Test on T training set - [0][970/1731]	T 0.230 (0.218)	D 0.125 (0.116)	T@1 78.125 (65.422)	T@5 100.000 (91.796)	L 0.8946 (1.1408)
Test on T training set - [0][980/1731]	T 0.201 (0.218)	D 0.104 (0.116)	T@1 71.875 (65.485)	T@5 90.625 (91.820)	L 1.0613 (1.1398)
Test on T training set - [0][990/1731]	T 0.222 (0.221)	D 0.126 (0.119)	T@1 68.750 (65.483)	T@5 96.875 (91.839)	L 1.0023 (1.1401)
Test on T training set - [0][1000/1731]	T 0.227 (0.221)	D 0.122 (0.119)	T@1 59.375 (65.500)	T@5 90.625 (91.858)	L 1.4276 (1.1401)
Test on T training set - [0][1010/1731]	T 0.198 (0.221)	D 0.099 (0.119)	T@1 65.625 (65.523)	T@5 93.750 (91.877)	L 1.3174 (1.1406)
Test on T training set - [0][1020/1731]	T 0.201 (0.220)	D 0.105 (0.119)	T@1 65.625 (65.506)	T@5 93.750 (91.892)	L 1.2312 (1.1411)
Test on T training set - [0][1030/1731]	T 0.170 (0.220)	D 0.070 (0.118)	T@1 59.375 (65.461)	T@5 96.875 (91.895)	L 1.3491 (1.1425)
Test on T training set - [0][1040/1731]	T 0.163 (0.220)	D 0.067 (0.118)	T@1 62.500 (65.415)	T@5 90.625 (91.880)	L 1.3089 (1.1445)
Test on T training set - [0][1050/1731]	T 0.174 (0.219)	D 0.071 (0.118)	T@1 25.000 (65.271)	T@5 84.375 (91.838)	L 1.8744 (1.1491)
Test on T training set - [0][1060/1731]	T 0.154 (0.219)	D 0.059 (0.117)	T@1 62.500 (65.154)	T@5 90.625 (91.791)	L 1.5574 (1.1538)
Test on T training set - [0][1070/1731]	T 0.206 (0.219)	D 0.099 (0.117)	T@1 50.000 (64.936)	T@5 96.875 (91.743)	L 1.4095 (1.1593)
Test on T training set - [0][1080/1731]	T 0.163 (0.218)	D 0.066 (0.116)	T@1 46.875 (64.784)	T@5 81.250 (91.732)	L 1.7924 (1.1629)
Test on T training set - [0][1090/1731]	T 0.181 (0.221)	D 0.085 (0.119)	T@1 3.125 (64.519)	T@5 56.250 (91.496)	L 2.6395 (1.1712)
Test on T training set - [0][1100/1731]	T 0.203 (0.221)	D 0.099 (0.119)	T@1 18.750 (64.146)	T@5 65.625 (91.215)	L 2.4408 (1.1827)
Test on T training set - [0][1110/1731]	T 0.214 (0.220)	D 0.113 (0.119)	T@1 28.125 (63.755)	T@5 75.000 (90.903)	L 2.3716 (1.1947)
Test on T training set - [0][1120/1731]	T 0.190 (0.220)	D 0.094 (0.118)	T@1 25.000 (63.373)	T@5 59.375 (90.605)	L 2.3115 (1.2065)
Test on T training set - [0][1130/1731]	T 0.177 (0.220)	D 0.081 (0.118)	T@1 12.500 (62.995)	T@5 50.000 (90.335)	L 2.6534 (1.2177)
Test on T training set - [0][1140/1731]	T 0.201 (0.220)	D 0.103 (0.118)	T@1 34.375 (62.626)	T@5 53.125 (90.061)	L 2.3439 (1.2288)
Test on T training set - [0][1150/1731]	T 0.176 (0.219)	D 0.080 (0.117)	T@1 21.875 (62.269)	T@5 59.375 (89.838)	L 2.3858 (1.2393)
Test on T training set - [0][1160/1731]	T 0.178 (0.219)	D 0.074 (0.117)	T@1 21.875 (61.924)	T@5 56.250 (89.589)	L 2.6261 (1.2499)
Test on T training set - [0][1170/1731]	T 0.178 (0.219)	D 0.079 (0.117)	T@1 25.000 (61.569)	T@5 71.875 (89.363)	L 2.3559 (1.2604)
Test on T training set - [0][1180/1731]	T 0.189 (0.221)	D 0.083 (0.119)	T@1 21.875 (61.222)	T@5 50.000 (89.143)	L 2.6156 (1.2704)
Test on T training set - [0][1190/1731]	T 0.191 (0.221)	D 0.090 (0.119)	T@1 28.125 (60.884)	T@5 56.250 (88.901)	L 2.5216 (1.2816)
Test on T training set - [0][1200/1731]	T 0.171 (0.220)	D 0.076 (0.119)	T@1 15.625 (60.538)	T@5 53.125 (88.608)	L 2.6478 (1.2921)
Test on T training set - [0][1210/1731]	T 0.206 (0.220)	D 0.104 (0.118)	T@1 28.125 (60.229)	T@5 59.375 (88.372)	L 2.3269 (1.3017)
Test on T training set - [0][1220/1731]	T 0.170 (0.220)	D 0.069 (0.118)	T@1 71.875 (60.191)	T@5 87.500 (88.386)	L 1.2015 (1.3031)
Test on T training set - [0][1230/1731]	T 0.161 (0.219)	D 0.055 (0.118)	T@1 59.375 (60.195)	T@5 93.750 (88.416)	L 1.3833 (1.3029)
Test on T training set - [0][1240/1731]	T 0.173 (0.219)	D 0.075 (0.117)	T@1 71.875 (60.234)	T@5 100.000 (88.490)	L 1.0037 (1.3019)
Test on T training set - [0][1250/1731]	T 0.177 (0.219)	D 0.080 (0.117)	T@1 81.250 (60.329)	T@5 93.750 (88.564)	L 0.9132 (1.2993)
Test on T training set - [0][1260/1731]	T 0.192 (0.218)	D 0.090 (0.117)	T@1 71.875 (60.411)	T@5 93.750 (88.628)	L 0.9872 (1.2972)
Test on T training set - [0][1270/1731]	T 0.204 (0.220)	D 0.105 (0.118)	T@1 71.875 (60.506)	T@5 96.875 (88.697)	L 0.9908 (1.2950)
Test on T training set - [0][1280/1731]	T 0.184 (0.220)	D 0.089 (0.118)	T@1 81.250 (60.648)	T@5 96.875 (88.778)	L 0.8374 (1.2914)
Test on T training set - [0][1290/1731]	T 0.181 (0.220)	D 0.070 (0.118)	T@1 59.375 (60.733)	T@5 96.875 (88.843)	L 1.2023 (1.2887)
Test on T training set - [0][1300/1731]	T 0.174 (0.219)	D 0.071 (0.118)	T@1 68.750 (60.811)	T@5 93.750 (88.905)	L 0.9140 (1.2862)
Test on T training set - [0][1310/1731]	T 0.186 (0.219)	D 0.081 (0.117)	T@1 71.875 (60.924)	T@5 93.750 (88.978)	L 0.9570 (1.2829)
Test on T training set - [0][1320/1731]	T 0.188 (0.219)	D 0.093 (0.117)	T@1 78.125 (61.057)	T@5 100.000 (89.054)	L 0.6990 (1.2790)
Test on T training set - [0][1330/1731]	T 0.177 (0.218)	D 0.072 (0.117)	T@1 78.125 (61.141)	T@5 96.875 (89.111)	L 0.8689 (1.2769)
Test on T training set - [0][1340/1731]	T 0.172 (0.218)	D 0.065 (0.116)	T@1 84.375 (61.232)	T@5 96.875 (89.171)	L 0.6630 (1.2744)
Test on T training set - [0][1350/1731]	T 0.172 (0.218)	D 0.073 (0.116)	T@1 81.250 (61.348)	T@5 100.000 (89.233)	L 0.6949 (1.2714)
Test on T training set - [0][1360/1731]	T 0.165 (0.217)	D 0.064 (0.116)	T@1 21.875 (61.113)	T@5 56.250 (89.038)	L 2.5516 (1.2787)
Test on T training set - [0][1370/1731]	T 0.158 (0.217)	D 0.058 (0.115)	T@1 31.250 (60.859)	T@5 53.125 (88.817)	L 2.3425 (1.2865)
Test on T training set - [0][1380/1731]	T 0.166 (0.219)	D 0.061 (0.117)	T@1 28.125 (60.624)	T@5 59.375 (88.625)	L 2.3711 (1.2937)
Test on T training set - [0][1390/1731]	T 0.172 (0.219)	D 0.066 (0.117)	T@1 25.000 (60.375)	T@5 62.500 (88.396)	L 2.4437 (1.3018)
Test on T training set - [0][1400/1731]	T 0.178 (0.218)	D 0.071 (0.116)	T@1 31.250 (60.136)	T@5 62.500 (88.220)	L 2.2363 (1.3095)
Test on T training set - [0][1410/1731]	T 0.179 (0.218)	D 0.077 (0.116)	T@1 18.750 (59.876)	T@5 56.250 (88.018)	L 2.6493 (1.3177)
Test on T training set - [0][1420/1731]	T 0.169 (0.217)	D 0.066 (0.116)	T@1 28.125 (59.639)	T@5 65.625 (87.803)	L 2.2107 (1.3254)
Test on T training set - [0][1430/1731]	T 0.215 (0.217)	D 0.113 (0.115)	T@1 84.375 (59.534)	T@5 100.000 (87.766)	L 0.5956 (1.3280)
Test on T training set - [0][1440/1731]	T 0.268 (0.217)	D 0.156 (0.116)	T@1 84.375 (59.731)	T@5 100.000 (87.851)	L 0.6011 (1.3221)
Test on T training set - [0][1450/1731]	T 0.235 (0.218)	D 0.130 (0.116)	T@1 81.250 (59.926)	T@5 100.000 (87.926)	L 0.6753 (1.3162)
Test on T training set - [0][1460/1731]	T 0.238 (0.218)	D 0.131 (0.116)	T@1 78.125 (60.087)	T@5 100.000 (88.001)	L 0.6850 (1.3111)
Test on T training set - [0][1470/1731]	T 0.248 (0.218)	D 0.141 (0.116)	T@1 81.250 (60.259)	T@5 100.000 (88.076)	L 0.7229 (1.3058)
Test on T training set - [0][1480/1731]	T 0.250 (0.220)	D 0.149 (0.118)	T@1 96.875 (60.436)	T@5 100.000 (88.150)	L 0.2958 (1.3001)
Test on T training set - [0][1490/1731]	T 0.229 (0.220)	D 0.133 (0.118)	T@1 87.500 (60.612)	T@5 100.000 (88.225)	L 0.5342 (1.2947)
Test on T training set - [0][1500/1731]	T 0.247 (0.220)	D 0.143 (0.118)	T@1 90.625 (60.782)	T@5 96.875 (88.293)	L 0.4275 (1.2898)
Test on T training set - [0][1510/1731]	T 0.238 (0.220)	D 0.138 (0.118)	T@1 90.625 (60.945)	T@5 96.875 (88.367)	L 0.6172 (1.2851)
Test on T training set - [0][1520/1731]	T 0.231 (0.220)	D 0.134 (0.119)	T@1 87.500 (61.082)	T@5 100.000 (88.441)	L 0.6614 (1.2805)
Test on T training set - [0][1530/1731]	T 0.226 (0.220)	D 0.121 (0.119)	T@1 90.625 (61.234)	T@5 100.000 (88.514)	L 0.4757 (1.2758)
Test on T training set - [0][1540/1731]	T 0.199 (0.220)	D 0.095 (0.119)	T@1 71.875 (61.314)	T@5 100.000 (88.581)	L 0.8950 (1.2732)
Test on T training set - [0][1550/1731]	T 2.915 (0.222)	D 2.813 (0.120)	T@1 78.125 (61.335)	T@5 100.000 (88.632)	L 0.6084 (1.2719)
Test on T training set - [0][1560/1731]	T 0.192 (0.222)	D 0.097 (0.120)	T@1 9.375 (61.315)	T@5 81.250 (88.667)	L 2.8856 (1.2723)
Test on T training set - [0][1570/1731]	T 0.189 (0.222)	D 0.078 (0.120)	T@1 18.750 (61.026)	T@5 96.875 (88.642)	L 2.8824 (1.2826)
Test on T training set - [0][1580/1731]	T 0.161 (0.222)	D 0.060 (0.120)	T@1 25.000 (60.737)	T@5 93.750 (88.654)	L 2.3684 (1.2924)
Test on T training set - [0][1590/1731]	T 0.177 (0.221)	D 0.078 (0.119)	T@1 9.375 (60.463)	T@5 90.625 (88.657)	L 2.6735 (1.3012)
Test on T training set - [0][1600/1731]	T 0.182 (0.221)	D 0.083 (0.119)	T@1 12.500 (60.162)	T@5 84.375 (88.681)	L 3.3184 (1.3113)
Test on T training set - [0][1610/1731]	T 0.174 (0.221)	D 0.073 (0.119)	T@1 15.625 (59.887)	T@5 84.375 (88.685)	L 3.1189 (1.3203)
Test on T training set - [0][1620/1731]	T 0.197 (0.220)	D 0.091 (0.119)	T@1 25.000 (59.612)	T@5 84.375 (88.670)	L 2.5915 (1.3292)
Test on T training set - [0][1630/1731]	T 0.173 (0.220)	D 0.072 (0.118)	T@1 18.750 (59.327)	T@5 87.500 (88.663)	L 3.0019 (1.3389)
Test on T training set - [0][1640/1731]	T 0.218 (0.220)	D 0.118 (0.118)	T@1 18.750 (59.055)	T@5 84.375 (88.665)	L 2.7173 (1.3478)
Test on T training set - [0][1650/1731]	T 0.221 (0.220)	D 0.125 (0.118)	T@1 28.125 (58.824)	T@5 90.625 (88.694)	L 2.4741 (1.3547)
Test on T training set - [0][1660/1731]	T 0.215 (0.221)	D 0.111 (0.120)	T@1 21.875 (58.621)	T@5 84.375 (88.717)	L 2.4618 (1.3612)
Test on T training set - [0][1670/1731]	T 0.208 (0.221)	D 0.099 (0.120)	T@1 15.625 (58.446)	T@5 93.750 (88.744)	L 2.7003 (1.3673)
Test on T training set - [0][1680/1731]	T 0.200 (0.221)	D 0.096 (0.120)	T@1 18.750 (58.243)	T@5 81.250 (88.759)	L 2.3513 (1.3733)
Test on T training set - [0][1690/1731]	T 0.218 (0.221)	D 0.113 (0.120)	T@1 25.000 (58.048)	T@5 93.750 (88.790)	L 2.2034 (1.3786)
Test on T training set - [0][1700/1731]	T 0.207 (0.221)	D 0.111 (0.120)	T@1 25.000 (57.846)	T@5 96.875 (88.814)	L 2.6909 (1.3853)
Test on T training set - [0][1710/1731]	T 0.222 (0.221)	D 0.125 (0.120)	T@1 25.000 (57.640)	T@5 90.625 (88.828)	L 2.0555 (1.3913)
Test on T training set - [0][1720/1731]	T 0.218 (0.221)	D 0.111 (0.120)	T@1 15.625 (57.436)	T@5 90.625 (88.851)	L 2.7101 (1.3974)
Test on T training set - [0][1730/1731]	T 0.462 (0.221)	D 0.082 (0.119)	T@1 21.429 (57.262)	T@5 75.000 (88.864)	L 2.7594 (1.4027)
 * Test on T training set - Prec@1 57.262, Prec@5 88.864
Test on T test set - [0][0/1731]	Time 0.292 (0.292)	Loss 2.3694 (2.3694)	Prec@1 21.875 (21.875)	Prec@5 81.250 (81.250)
Test on T test set - [0][10/1731]	Time 0.219 (0.201)	Loss 1.5825 (1.8332)	Prec@1 46.875 (40.625)	Prec@5 87.500 (88.920)
Test on T test set - [0][20/1731]	Time 0.222 (0.213)	Loss 1.5912 (1.7178)	Prec@1 46.875 (43.601)	Prec@5 93.750 (90.774)
Test on T test set - [0][30/1731]	Time 0.203 (0.213)	Loss 1.5280 (1.6572)	Prec@1 56.250 (45.363)	Prec@5 93.750 (91.532)
Test on T test set - [0][40/1731]	Time 0.225 (0.214)	Loss 1.9680 (1.6477)	Prec@1 31.250 (46.037)	Prec@5 81.250 (90.854)
Test on T test set - [0][50/1731]	Time 0.208 (0.215)	Loss 1.4795 (1.6530)	Prec@1 46.875 (45.650)	Prec@5 100.000 (90.625)
Test on T test set - [0][60/1731]	Time 0.224 (0.215)	Loss 1.8497 (1.6401)	Prec@1 40.625 (46.107)	Prec@5 75.000 (90.676)
Test on T test set - [0][70/1731]	Time 0.200 (0.214)	Loss 1.5873 (1.6456)	Prec@1 46.875 (45.995)	Prec@5 96.875 (90.757)
Test on T test set - [0][80/1731]	Time 0.197 (0.251)	Loss 1.5775 (1.6418)	Prec@1 46.875 (46.219)	Prec@5 96.875 (91.165)
Test on T test set - [0][90/1731]	Time 0.187 (0.246)	Loss 1.7902 (1.6412)	Prec@1 43.750 (46.154)	Prec@5 93.750 (91.312)
Test on T test set - [0][100/1731]	Time 0.179 (0.241)	Loss 1.9349 (1.6476)	Prec@1 31.250 (45.823)	Prec@5 90.625 (91.337)
Test on T test set - [0][110/1731]	Time 0.206 (0.235)	Loss 2.1880 (1.6689)	Prec@1 28.125 (45.101)	Prec@5 84.375 (90.653)
Test on T test set - [0][120/1731]	Time 0.198 (0.232)	Loss 0.8559 (1.6359)	Prec@1 75.000 (46.539)	Prec@5 100.000 (90.909)
Test on T test set - [0][130/1731]	Time 0.185 (0.229)	Loss 0.9674 (1.5737)	Prec@1 71.875 (48.831)	Prec@5 100.000 (91.484)
Test on T test set - [0][140/1731]	Time 0.168 (0.226)	Loss 0.8047 (1.5233)	Prec@1 75.000 (50.621)	Prec@5 100.000 (92.021)
Test on T test set - [0][150/1731]	Time 0.209 (0.223)	Loss 0.8077 (1.4786)	Prec@1 78.125 (52.339)	Prec@5 100.000 (92.488)
Test on T test set - [0][160/1731]	Time 0.185 (0.221)	Loss 0.6754 (1.4365)	Prec@1 78.125 (54.018)	Prec@5 100.000 (92.838)
Test on T test set - [0][170/1731]	Time 0.157 (0.235)	Loss 0.9822 (1.4036)	Prec@1 68.750 (55.300)	Prec@5 93.750 (93.074)
Test on T test set - [0][180/1731]	Time 0.160 (0.232)	Loss 1.5183 (1.3861)	Prec@1 46.875 (56.043)	Prec@5 84.375 (93.232)
Test on T test set - [0][190/1731]	Time 0.176 (0.228)	Loss 1.1546 (1.3744)	Prec@1 68.750 (56.610)	Prec@5 90.625 (93.325)
Test on T test set - [0][200/1731]	Time 0.166 (0.225)	Loss 1.6347 (1.3735)	Prec@1 50.000 (56.530)	Prec@5 93.750 (93.330)
Test on T test set - [0][210/1731]	Time 0.165 (0.222)	Loss 1.3288 (1.3681)	Prec@1 62.500 (56.872)	Prec@5 96.875 (93.335)
Test on T test set - [0][220/1731]	Time 0.197 (0.220)	Loss 0.9604 (1.3550)	Prec@1 68.750 (57.424)	Prec@5 100.000 (93.495)
Test on T test set - [0][230/1731]	Time 0.174 (0.218)	Loss 1.7905 (1.3711)	Prec@1 40.625 (56.588)	Prec@5 100.000 (93.506)
Test on T test set - [0][240/1731]	Time 0.224 (0.219)	Loss 0.4732 (1.3494)	Prec@1 84.375 (57.184)	Prec@5 100.000 (93.737)
Test on T test set - [0][250/1731]	Time 0.201 (0.219)	Loss 0.9188 (1.3277)	Prec@1 62.500 (57.806)	Prec@5 96.875 (93.937)
Test on T test set - [0][260/1731]	Time 2.785 (0.229)	Loss 1.0102 (1.3076)	Prec@1 65.625 (58.309)	Prec@5 93.750 (94.133)
Test on T test set - [0][270/1731]	Time 0.233 (0.229)	Loss 0.7698 (1.2874)	Prec@1 75.000 (58.960)	Prec@5 100.000 (94.304)
Test on T test set - [0][280/1731]	Time 0.232 (0.229)	Loss 0.7373 (1.2701)	Prec@1 75.000 (59.464)	Prec@5 96.875 (94.451)
Test on T test set - [0][290/1731]	Time 0.227 (0.229)	Loss 0.4651 (1.2524)	Prec@1 90.625 (59.933)	Prec@5 100.000 (94.609)
Test on T test set - [0][300/1731]	Time 0.218 (0.228)	Loss 0.7165 (1.2355)	Prec@1 78.125 (60.455)	Prec@5 100.000 (94.747)
Test on T test set - [0][310/1731]	Time 0.226 (0.228)	Loss 0.8693 (1.2215)	Prec@1 68.750 (60.772)	Prec@5 96.875 (94.875)
Test on T test set - [0][320/1731]	Time 0.199 (0.228)	Loss 0.7301 (1.2064)	Prec@1 78.125 (61.303)	Prec@5 100.000 (95.006)
Test on T test set - [0][330/1731]	Time 0.203 (0.227)	Loss 0.5680 (1.1933)	Prec@1 84.375 (61.660)	Prec@5 100.000 (95.147)
Test on T test set - [0][340/1731]	Time 0.236 (0.234)	Loss 1.3667 (1.2052)	Prec@1 50.000 (61.208)	Prec@5 100.000 (95.088)
Test on T test set - [0][350/1731]	Time 0.198 (0.233)	Loss 1.1703 (1.2076)	Prec@1 53.125 (61.040)	Prec@5 93.750 (95.112)
Test on T test set - [0][360/1731]	Time 0.237 (0.233)	Loss 0.7408 (1.1913)	Prec@1 68.750 (61.574)	Prec@5 100.000 (95.230)
Test on T test set - [0][370/1731]	Time 0.174 (0.232)	Loss 1.2548 (1.1814)	Prec@1 62.500 (61.927)	Prec@5 90.625 (95.317)
Test on T test set - [0][380/1731]	Time 0.175 (0.230)	Loss 0.5196 (1.1747)	Prec@1 78.125 (62.164)	Prec@5 100.000 (95.317)
Test on T test set - [0][390/1731]	Time 0.164 (0.229)	Loss 0.9113 (1.1619)	Prec@1 78.125 (62.628)	Prec@5 93.750 (95.356)
Test on T test set - [0][400/1731]	Time 0.155 (0.228)	Loss 0.8826 (1.1528)	Prec@1 71.875 (62.983)	Prec@5 96.875 (95.355)
Test on T test set - [0][410/1731]	Time 0.163 (0.226)	Loss 0.7308 (1.1466)	Prec@1 81.250 (63.260)	Prec@5 96.875 (95.324)
Test on T test set - [0][420/1731]	Time 0.161 (0.225)	Loss 1.1158 (1.1408)	Prec@1 62.500 (63.495)	Prec@5 87.500 (95.316)
Test on T test set - [0][430/1731]	Time 0.167 (0.223)	Loss 0.8216 (1.1346)	Prec@1 75.000 (63.725)	Prec@5 93.750 (95.360)
Test on T test set - [0][440/1731]	Time 0.172 (0.228)	Loss 0.5444 (1.1237)	Prec@1 81.250 (64.187)	Prec@5 100.000 (95.415)
Test on T test set - [0][450/1731]	Time 0.161 (0.226)	Loss 0.5686 (1.1140)	Prec@1 84.375 (64.606)	Prec@5 96.875 (95.503)
Test on T test set - [0][460/1731]	Time 0.168 (0.225)	Loss 0.5240 (1.1025)	Prec@1 81.250 (65.035)	Prec@5 100.000 (95.580)
Test on T test set - [0][470/1731]	Time 0.164 (0.224)	Loss 0.7008 (1.0939)	Prec@1 78.125 (65.373)	Prec@5 100.000 (95.634)
Test on T test set - [0][480/1731]	Time 0.154 (0.223)	Loss 0.7213 (1.0842)	Prec@1 78.125 (65.774)	Prec@5 93.750 (95.673)
Test on T test set - [0][490/1731]	Time 0.161 (0.222)	Loss 0.6906 (1.0762)	Prec@1 81.250 (66.077)	Prec@5 96.875 (95.723)
Test on T test set - [0][500/1731]	Time 0.166 (0.220)	Loss 0.5365 (1.0678)	Prec@1 87.500 (66.423)	Prec@5 100.000 (95.765)
Test on T test set - [0][510/1731]	Time 0.175 (0.219)	Loss 1.0171 (1.0633)	Prec@1 71.875 (66.634)	Prec@5 90.625 (95.811)
Test on T test set - [0][520/1731]	Time 0.164 (0.218)	Loss 1.3685 (1.0641)	Prec@1 56.250 (66.651)	Prec@5 87.500 (95.813)
Test on T test set - [0][530/1731]	Time 0.169 (0.217)	Loss 1.1303 (1.0642)	Prec@1 65.625 (66.684)	Prec@5 93.750 (95.716)
Test on T test set - [0][540/1731]	Time 0.165 (0.221)	Loss 0.5594 (1.0629)	Prec@1 87.500 (66.746)	Prec@5 100.000 (95.691)
Test on T test set - [0][550/1731]	Time 0.152 (0.220)	Loss 1.1627 (1.0624)	Prec@1 65.625 (66.805)	Prec@5 81.250 (95.644)
Test on T test set - [0][560/1731]	Time 0.168 (0.219)	Loss 1.6735 (1.0688)	Prec@1 46.875 (66.611)	Prec@5 87.500 (95.533)
Test on T test set - [0][570/1731]	Time 0.189 (0.218)	Loss 0.8142 (1.0672)	Prec@1 75.000 (66.665)	Prec@5 96.875 (95.534)
Test on T test set - [0][580/1731]	Time 0.171 (0.217)	Loss 0.6224 (1.0624)	Prec@1 84.375 (66.857)	Prec@5 96.875 (95.557)
Test on T test set - [0][590/1731]	Time 0.171 (0.216)	Loss 0.5802 (1.0563)	Prec@1 81.250 (67.074)	Prec@5 100.000 (95.601)
Test on T test set - [0][600/1731]	Time 0.162 (0.216)	Loss 0.6704 (1.0507)	Prec@1 81.250 (67.294)	Prec@5 93.750 (95.601)
Test on T test set - [0][610/1731]	Time 0.159 (0.215)	Loss 0.3994 (1.0433)	Prec@1 96.875 (67.609)	Prec@5 100.000 (95.622)
Test on T test set - [0][620/1731]	Time 0.186 (0.214)	Loss 0.5580 (1.0377)	Prec@1 84.375 (67.824)	Prec@5 100.000 (95.657)
Test on T test set - [0][630/1731]	Time 0.168 (0.214)	Loss 0.7837 (1.0322)	Prec@1 81.250 (68.042)	Prec@5 100.000 (95.691)
Test on T test set - [0][640/1731]	Time 0.160 (0.213)	Loss 0.6064 (1.0278)	Prec@1 84.375 (68.233)	Prec@5 100.000 (95.705)
Test on T test set - [0][650/1731]	Time 0.162 (0.212)	Loss 1.0314 (1.0229)	Prec@1 65.625 (68.404)	Prec@5 93.750 (95.742)
Test on T test set - [0][660/1731]	Time 0.164 (0.216)	Loss 0.7937 (1.0178)	Prec@1 78.125 (68.613)	Prec@5 93.750 (95.788)
Test on T test set - [0][670/1731]	Time 0.171 (0.215)	Loss 0.9850 (1.0140)	Prec@1 71.875 (68.755)	Prec@5 100.000 (95.813)
Test on T test set - [0][680/1731]	Time 0.160 (0.214)	Loss 0.8360 (1.0099)	Prec@1 71.875 (68.901)	Prec@5 96.875 (95.838)
Test on T test set - [0][690/1731]	Time 0.220 (0.214)	Loss 3.1638 (1.0165)	Prec@1 9.375 (68.764)	Prec@5 53.125 (95.595)
Test on T test set - [0][700/1731]	Time 0.158 (0.213)	Loss 1.8744 (1.0346)	Prec@1 37.500 (68.242)	Prec@5 62.500 (95.029)
Test on T test set - [0][710/1731]	Time 0.171 (0.213)	Loss 1.3302 (1.0382)	Prec@1 62.500 (68.179)	Prec@5 75.000 (94.844)
Test on T test set - [0][720/1731]	Time 0.166 (0.212)	Loss 0.8373 (1.0379)	Prec@1 75.000 (68.256)	Prec@5 93.750 (94.756)
Test on T test set - [0][730/1731]	Time 0.204 (0.212)	Loss 0.5085 (1.0375)	Prec@1 84.375 (68.297)	Prec@5 96.875 (94.665)
Test on T test set - [0][740/1731]	Time 0.221 (0.212)	Loss 0.8249 (1.0336)	Prec@1 78.125 (68.476)	Prec@5 93.750 (94.674)
Test on T test set - [0][750/1731]	Time 0.188 (0.212)	Loss 0.8032 (1.0305)	Prec@1 81.250 (68.621)	Prec@5 90.625 (94.674)
Test on T test set - [0][760/1731]	Time 0.236 (0.212)	Loss 0.5259 (1.0276)	Prec@1 90.625 (68.758)	Prec@5 96.875 (94.670)
Test on T test set - [0][770/1731]	Time 0.201 (0.216)	Loss 0.8855 (1.0245)	Prec@1 71.875 (68.896)	Prec@5 93.750 (94.638)
Test on T test set - [0][780/1731]	Time 0.236 (0.216)	Loss 0.8074 (1.0247)	Prec@1 81.250 (68.922)	Prec@5 96.875 (94.590)
Test on T test set - [0][790/1731]	Time 0.211 (0.216)	Loss 0.6288 (1.0234)	Prec@1 84.375 (68.999)	Prec@5 96.875 (94.568)
Test on T test set - [0][800/1731]	Time 0.211 (0.216)	Loss 1.0133 (1.0203)	Prec@1 68.750 (69.113)	Prec@5 84.375 (94.558)
Test on T test set - [0][810/1731]	Time 0.201 (0.216)	Loss 1.0735 (1.0196)	Prec@1 71.875 (69.147)	Prec@5 81.250 (94.501)
Test on T test set - [0][820/1731]	Time 0.215 (0.216)	Loss 0.9403 (1.0171)	Prec@1 75.000 (69.252)	Prec@5 90.625 (94.492)
Test on T test set - [0][830/1731]	Time 0.194 (0.215)	Loss 0.6125 (1.0145)	Prec@1 87.500 (69.393)	Prec@5 96.875 (94.461)
Test on T test set - [0][840/1731]	Time 0.182 (0.215)	Loss 1.4724 (1.0129)	Prec@1 46.875 (69.482)	Prec@5 81.250 (94.434)
Test on T test set - [0][850/1731]	Time 0.153 (0.217)	Loss 2.8413 (1.0345)	Prec@1 3.125 (68.743)	Prec@5 46.875 (93.959)
Test on T test set - [0][860/1731]	Time 0.162 (0.217)	Loss 2.6606 (1.0550)	Prec@1 9.375 (68.042)	Prec@5 56.250 (93.543)
Test on T test set - [0][870/1731]	Time 0.172 (0.216)	Loss 2.9102 (1.0734)	Prec@1 0.000 (67.383)	Prec@5 59.375 (93.144)
Test on T test set - [0][880/1731]	Time 0.169 (0.216)	Loss 2.5104 (1.0919)	Prec@1 12.500 (66.735)	Prec@5 59.375 (92.700)
Test on T test set - [0][890/1731]	Time 0.163 (0.215)	Loss 2.9236 (1.1104)	Prec@1 9.375 (66.105)	Prec@5 50.000 (92.354)
Test on T test set - [0][900/1731]	Time 0.159 (0.215)	Loss 2.7516 (1.1290)	Prec@1 12.500 (65.452)	Prec@5 50.000 (91.940)
Test on T test set - [0][910/1731]	Time 0.181 (0.214)	Loss 1.4481 (1.1379)	Prec@1 62.500 (65.203)	Prec@5 87.500 (91.760)
Test on T test set - [0][920/1731]	Time 0.165 (0.214)	Loss 1.4198 (1.1404)	Prec@1 59.375 (65.143)	Prec@5 90.625 (91.768)
Test on T test set - [0][930/1731]	Time 0.228 (0.214)	Loss 1.0005 (1.1397)	Prec@1 68.750 (65.192)	Prec@5 93.750 (91.800)
Test on T test set - [0][940/1731]	Time 0.247 (0.214)	Loss 0.9296 (1.1401)	Prec@1 78.125 (65.217)	Prec@5 100.000 (91.821)
Test on T test set - [0][950/1731]	Time 0.228 (0.216)	Loss 1.2054 (1.1402)	Prec@1 62.500 (65.218)	Prec@5 90.625 (91.838)
Test on T test set - [0][960/1731]	Time 0.224 (0.216)	Loss 1.0879 (1.1404)	Prec@1 65.625 (65.248)	Prec@5 100.000 (91.867)
Test on T test set - [0][970/1731]	Time 0.227 (0.216)	Loss 0.9404 (1.1392)	Prec@1 81.250 (65.326)	Prec@5 100.000 (91.903)
Test on T test set - [0][980/1731]	Time 0.202 (0.216)	Loss 1.0254 (1.1377)	Prec@1 71.875 (65.380)	Prec@5 90.625 (91.918)
Test on T test set - [0][990/1731]	Time 0.229 (0.216)	Loss 0.8953 (1.1384)	Prec@1 81.250 (65.379)	Prec@5 93.750 (91.918)
Test on T test set - [0][1000/1731]	Time 0.216 (0.216)	Loss 1.3224 (1.1384)	Prec@1 59.375 (65.397)	Prec@5 96.875 (91.955)
Test on T test set - [0][1010/1731]	Time 0.196 (0.216)	Loss 1.5601 (1.1391)	Prec@1 56.250 (65.399)	Prec@5 93.750 (91.973)
Test on T test set - [0][1020/1731]	Time 0.340 (0.216)	Loss 1.1797 (1.1398)	Prec@1 68.750 (65.392)	Prec@5 87.500 (91.975)
Test on T test set - [0][1030/1731]	Time 0.168 (0.216)	Loss 1.4092 (1.1412)	Prec@1 56.250 (65.367)	Prec@5 96.875 (91.986)
Test on T test set - [0][1040/1731]	Time 0.174 (0.217)	Loss 1.3531 (1.1433)	Prec@1 53.125 (65.325)	Prec@5 90.625 (91.991)
Test on T test set - [0][1050/1731]	Time 0.166 (0.217)	Loss 1.8323 (1.1475)	Prec@1 31.250 (65.200)	Prec@5 81.250 (91.930)
Test on T test set - [0][1060/1731]	Time 0.158 (0.217)	Loss 1.5582 (1.1516)	Prec@1 50.000 (65.074)	Prec@5 90.625 (91.903)
Test on T test set - [0][1070/1731]	Time 0.187 (0.216)	Loss 1.3658 (1.1570)	Prec@1 46.875 (64.890)	Prec@5 93.750 (91.862)
Test on T test set - [0][1080/1731]	Time 0.161 (0.216)	Loss 1.6866 (1.1604)	Prec@1 46.875 (64.743)	Prec@5 78.125 (91.845)
Test on T test set - [0][1090/1731]	Time 0.168 (0.215)	Loss 2.7064 (1.1689)	Prec@1 6.250 (64.453)	Prec@5 59.375 (91.622)
Test on T test set - [0][1100/1731]	Time 0.188 (0.215)	Loss 2.4709 (1.1805)	Prec@1 21.875 (64.081)	Prec@5 62.500 (91.352)
Test on T test set - [0][1110/1731]	Time 0.213 (0.215)	Loss 2.4061 (1.1926)	Prec@1 28.125 (63.676)	Prec@5 78.125 (91.072)
Test on T test set - [0][1120/1731]	Time 0.180 (0.215)	Loss 2.3539 (1.2042)	Prec@1 21.875 (63.308)	Prec@5 71.875 (90.776)
Test on T test set - [0][1130/1731]	Time 0.180 (0.214)	Loss 2.7321 (1.2155)	Prec@1 9.375 (62.926)	Prec@5 50.000 (90.498)
Test on T test set - [0][1140/1731]	Time 0.182 (0.214)	Loss 2.3862 (1.2268)	Prec@1 28.125 (62.547)	Prec@5 53.125 (90.203)
Test on T test set - [0][1150/1731]	Time 0.167 (0.216)	Loss 2.3683 (1.2374)	Prec@1 21.875 (62.182)	Prec@5 65.625 (89.968)
Test on T test set - [0][1160/1731]	Time 0.174 (0.216)	Loss 2.5116 (1.2483)	Prec@1 21.875 (61.806)	Prec@5 56.250 (89.713)
Test on T test set - [0][1170/1731]	Time 0.168 (0.216)	Loss 2.5185 (1.2591)	Prec@1 18.750 (61.462)	Prec@5 59.375 (89.448)
Test on T test set - [0][1180/1731]	Time 0.182 (0.215)	Loss 2.6285 (1.2691)	Prec@1 21.875 (61.106)	Prec@5 53.125 (89.241)
Test on T test set - [0][1190/1731]	Time 0.188 (0.215)	Loss 2.4974 (1.2798)	Prec@1 21.875 (60.766)	Prec@5 59.375 (88.988)
Test on T test set - [0][1200/1731]	Time 0.176 (0.215)	Loss 2.6326 (1.2901)	Prec@1 18.750 (60.434)	Prec@5 46.875 (88.694)
Test on T test set - [0][1210/1731]	Time 0.189 (0.215)	Loss 2.3812 (1.3001)	Prec@1 21.875 (60.090)	Prec@5 59.375 (88.463)
Test on T test set - [0][1220/1731]	Time 0.166 (0.214)	Loss 1.1693 (1.3010)	Prec@1 71.875 (60.081)	Prec@5 93.750 (88.470)
Test on T test set - [0][1230/1731]	Time 0.155 (0.214)	Loss 1.3028 (1.3008)	Prec@1 56.250 (60.081)	Prec@5 96.875 (88.510)
Test on T test set - [0][1240/1731]	Time 0.172 (0.214)	Loss 0.9973 (1.2995)	Prec@1 71.875 (60.130)	Prec@5 100.000 (88.580)
Test on T test set - [0][1250/1731]	Time 0.173 (0.213)	Loss 0.8559 (1.2969)	Prec@1 75.000 (60.227)	Prec@5 93.750 (88.644)
Test on T test set - [0][1260/1731]	Time 0.187 (0.213)	Loss 1.0230 (1.2948)	Prec@1 71.875 (60.304)	Prec@5 96.875 (88.707)
Test on T test set - [0][1270/1731]	Time 0.171 (0.214)	Loss 0.9905 (1.2928)	Prec@1 68.750 (60.376)	Prec@5 100.000 (88.779)
Test on T test set - [0][1280/1731]	Time 0.187 (0.214)	Loss 0.8933 (1.2892)	Prec@1 75.000 (60.512)	Prec@5 96.875 (88.859)
Test on T test set - [0][1290/1731]	Time 0.168 (0.213)	Loss 1.2971 (1.2867)	Prec@1 53.125 (60.600)	Prec@5 90.625 (88.916)
Test on T test set - [0][1300/1731]	Time 0.174 (0.213)	Loss 0.9164 (1.2843)	Prec@1 71.875 (60.689)	Prec@5 96.875 (88.982)
Test on T test set - [0][1310/1731]	Time 0.177 (0.213)	Loss 0.9062 (1.2808)	Prec@1 71.875 (60.831)	Prec@5 93.750 (89.054)
Test on T test set - [0][1320/1731]	Time 0.197 (0.213)	Loss 0.7365 (1.2768)	Prec@1 78.125 (60.988)	Prec@5 100.000 (89.130)
Test on T test set - [0][1330/1731]	Time 0.168 (0.212)	Loss 0.9223 (1.2745)	Prec@1 75.000 (61.087)	Prec@5 93.750 (89.190)
Test on T test set - [0][1340/1731]	Time 0.154 (0.212)	Loss 0.6207 (1.2719)	Prec@1 81.250 (61.188)	Prec@5 100.000 (89.245)
Test on T test set - [0][1350/1731]	Time 0.176 (0.212)	Loss 0.6368 (1.2692)	Prec@1 84.375 (61.281)	Prec@5 100.000 (89.304)
Test on T test set - [0][1360/1731]	Time 0.158 (0.211)	Loss 2.5851 (1.2766)	Prec@1 12.500 (61.051)	Prec@5 50.000 (89.110)
Test on T test set - [0][1370/1731]	Time 0.156 (0.211)	Loss 2.3590 (1.2842)	Prec@1 28.125 (60.816)	Prec@5 53.125 (88.906)
Test on T test set - [0][1380/1731]	Time 0.163 (0.213)	Loss 2.2127 (1.2915)	Prec@1 34.375 (60.592)	Prec@5 59.375 (88.729)
Test on T test set - [0][1390/1731]	Time 0.166 (0.212)	Loss 2.3608 (1.2991)	Prec@1 31.250 (60.350)	Prec@5 62.500 (88.531)
Test on T test set - [0][1400/1731]	Time 0.169 (0.212)	Loss 2.2588 (1.3070)	Prec@1 28.125 (60.102)	Prec@5 62.500 (88.343)
Test on T test set - [0][1410/1731]	Time 0.171 (0.212)	Loss 2.6285 (1.3153)	Prec@1 15.625 (59.840)	Prec@5 56.250 (88.136)
Test on T test set - [0][1420/1731]	Time 0.158 (0.211)	Loss 2.0585 (1.3227)	Prec@1 37.500 (59.608)	Prec@5 71.875 (87.929)
Test on T test set - [0][1430/1731]	Time 0.202 (0.211)	Loss 0.6781 (1.3253)	Prec@1 78.125 (59.508)	Prec@5 100.000 (87.880)
Test on T test set - [0][1440/1731]	Time 0.239 (0.211)	Loss 0.4741 (1.3191)	Prec@1 84.375 (59.711)	Prec@5 100.000 (87.964)
Test on T test set - [0][1450/1731]	Time 0.246 (0.211)	Loss 0.6579 (1.3131)	Prec@1 84.375 (59.909)	Prec@5 100.000 (88.041)
Test on T test set - [0][1460/1731]	Time 0.234 (0.211)	Loss 0.6200 (1.3082)	Prec@1 81.250 (60.064)	Prec@5 100.000 (88.118)
Test on T test set - [0][1470/1731]	Time 0.246 (0.212)	Loss 0.8472 (1.3030)	Prec@1 78.125 (60.233)	Prec@5 100.000 (88.193)
Test on T test set - [0][1480/1731]	Time 0.274 (0.214)	Loss 0.3335 (1.2973)	Prec@1 90.625 (60.409)	Prec@5 96.875 (88.266)
Test on T test set - [0][1490/1731]	Time 0.224 (0.214)	Loss 0.5436 (1.2918)	Prec@1 87.500 (60.591)	Prec@5 100.000 (88.340)
Test on T test set - [0][1500/1731]	Time 0.247 (0.214)	Loss 0.4747 (1.2870)	Prec@1 87.500 (60.747)	Prec@5 96.875 (88.408)
Test on T test set - [0][1510/1731]	Time 0.230 (0.214)	Loss 0.6695 (1.2823)	Prec@1 81.250 (60.908)	Prec@5 100.000 (88.482)
Test on T test set - [0][1520/1731]	Time 0.223 (0.214)	Loss 0.6051 (1.2778)	Prec@1 87.500 (61.049)	Prec@5 100.000 (88.552)
Test on T test set - [0][1530/1731]	Time 0.221 (0.214)	Loss 0.4860 (1.2733)	Prec@1 87.500 (61.179)	Prec@5 100.000 (88.627)
Test on T test set - [0][1540/1731]	Time 0.187 (0.214)	Loss 0.9716 (1.2707)	Prec@1 68.750 (61.267)	Prec@5 100.000 (88.686)
Test on T test set - [0][1550/1731]	Time 0.239 (0.214)	Loss 0.6553 (1.2691)	Prec@1 78.125 (61.313)	Prec@5 100.000 (88.733)
Test on T test set - [0][1560/1731]	Time 0.200 (0.216)	Loss 2.9390 (1.2695)	Prec@1 6.250 (61.293)	Prec@5 81.250 (88.769)
Test on T test set - [0][1570/1731]	Time 0.173 (0.216)	Loss 2.7647 (1.2793)	Prec@1 18.750 (60.998)	Prec@5 87.500 (88.757)
Test on T test set - [0][1580/1731]	Time 0.151 (0.215)	Loss 2.3310 (1.2889)	Prec@1 21.875 (60.719)	Prec@5 84.375 (88.753)
Test on T test set - [0][1590/1731]	Time 0.157 (0.215)	Loss 2.7529 (1.2981)	Prec@1 12.500 (60.432)	Prec@5 90.625 (88.751)
Test on T test set - [0][1600/1731]	Time 0.180 (0.215)	Loss 3.1334 (1.3080)	Prec@1 6.250 (60.136)	Prec@5 87.500 (88.757)
Test on T test set - [0][1610/1731]	Time 0.179 (0.215)	Loss 3.3536 (1.3174)	Prec@1 12.500 (59.844)	Prec@5 87.500 (88.751)
Test on T test set - [0][1620/1731]	Time 0.183 (0.214)	Loss 2.6948 (1.3264)	Prec@1 21.875 (59.566)	Prec@5 87.500 (88.736)
Test on T test set - [0][1630/1731]	Time 0.167 (0.214)	Loss 3.0213 (1.3366)	Prec@1 15.625 (59.268)	Prec@5 87.500 (88.701)
Test on T test set - [0][1640/1731]	Time 0.211 (0.214)	Loss 2.7910 (1.3457)	Prec@1 21.875 (59.007)	Prec@5 81.250 (88.694)
Test on T test set - [0][1650/1731]	Time 0.219 (0.216)	Loss 2.5274 (1.3521)	Prec@1 18.750 (58.790)	Prec@5 87.500 (88.713)
Test on T test set - [0][1660/1731]	Time 0.212 (0.216)	Loss 2.3874 (1.3588)	Prec@1 37.500 (58.587)	Prec@5 84.375 (88.736)
Test on T test set - [0][1670/1731]	Time 0.200 (0.216)	Loss 2.7245 (1.3648)	Prec@1 15.625 (58.408)	Prec@5 93.750 (88.759)
Test on T test set - [0][1680/1731]	Time 0.181 (0.216)	Loss 2.3709 (1.3708)	Prec@1 18.750 (58.200)	Prec@5 93.750 (88.768)
Test on T test set - [0][1690/1731]	Time 0.215 (0.216)	Loss 2.3957 (1.3764)	Prec@1 18.750 (58.019)	Prec@5 90.625 (88.805)
Test on T test set - [0][1700/1731]	Time 0.209 (0.216)	Loss 2.6067 (1.3828)	Prec@1 18.750 (57.823)	Prec@5 96.875 (88.839)
Test on T test set - [0][1710/1731]	Time 0.217 (0.216)	Loss 2.0078 (1.3887)	Prec@1 34.375 (57.631)	Prec@5 96.875 (88.846)
Test on T test set - [0][1720/1731]	Time 0.192 (0.215)	Loss 2.7051 (1.3947)	Prec@1 18.750 (57.434)	Prec@5 87.500 (88.862)
Test on T test set - [0][1730/1731]	Time 0.168 (0.215)	Loss 2.6235 (1.3999)	Prec@1 28.571 (57.260)	Prec@5 82.143 (88.878)
 * Test on T test set - Prec@1 57.260, Prec@5 88.878
Epoch 0 - Kernel K-means clustering 0: Clustering time 40.882, Prec@1 61.349
Epoch 0 - Kernel K-means clustering 1: Clustering time 39.713, Prec@1 62.100
Epoch 0 - Kernel K-means clustering 2: Clustering time 39.386, Prec@1 62.329
Epoch 0 - Kernel K-means clustering 3: Clustering time 39.270, Prec@1 62.306
Epoch 0 - Kernel K-means clustering 4: Clustering time 39.340, Prec@1 62.405
Epoch 0 - Kernel K-means clustering 5: Clustering time 38.826, Prec@1 62.362
Epoch 0 - Kernel K-means clustering 6: Clustering time 38.853, Prec@1 62.398
Epoch 0 - Kernel K-means clustering 7: Clustering time 38.983, Prec@1 62.344
Epoch 0 - Kernel K-means clustering 8: Clustering time 38.927, Prec@1 62.313
Epoch 0 - Kernel K-means clustering 9: Clustering time 39.335, Prec@1 62.297
Epoch 0 - Kernel K-means clustering 10: Clustering time 39.005, Prec@1 62.257
Epoch 0 - Kernel K-means clustering 11: Clustering time 39.256, Prec@1 62.228
Epoch 0 - Kernel K-means clustering 12: Clustering time 39.103, Prec@1 62.192
Epoch 0 - Kernel K-means clustering 13: Clustering time 39.067, Prec@1 62.158
Epoch 0 - Kernel K-means clustering 14: Clustering time 39.341, Prec@1 62.136
Epoch 0 - Kernel K-means clustering 15: Clustering time 39.058, Prec@1 62.089
Epoch 0 - Kernel K-means clustering 16: Clustering time 39.178, Prec@1 62.060
Epoch 0 - Kernel K-means clustering 17: Clustering time 39.201, Prec@1 62.035
Epoch 0 - Kernel K-means clustering 18: Clustering time 39.090, Prec@1 62.035
Epoch 0 - Kernel K-means clustering 19: Clustering time 41.130, Prec@1 62.030
Epoch 0 - Kernel K-means clustering 20: Clustering time 39.079, Prec@1 62.037
Epoch 0 - Kernel K-means clustering 21: Clustering time 39.272, Prec@1 62.030
Epoch 0 - Kernel K-means clustering 22: Clustering time 38.987, Prec@1 62.037
Epoch 0 - Kernel K-means clustering 23: Clustering time 39.288, Prec@1 62.039
Epoch 0 - Kernel K-means clustering 24: Clustering time 39.084, Prec@1 62.048
Epoch 0 - Kernel K-means clustering 25: Clustering time 39.175, Prec@1 62.046
Converged at iteration 26
Epoch 0 - Kernel K-means clustering 0: Clustering time 40.749, Prec@1 59.217
Epoch 0 - Kernel K-means clustering 1: Clustering time 40.572, Prec@1 59.421
Epoch 0 - Kernel K-means clustering 2: Clustering time 41.641, Prec@1 58.959
Epoch 0 - Kernel K-means clustering 3: Clustering time 41.872, Prec@1 58.278
Epoch 0 - Kernel K-means clustering 4: Clustering time 39.870, Prec@1 57.948
Epoch 0 - Kernel K-means clustering 5: Clustering time 40.030, Prec@1 57.722
Epoch 0 - Kernel K-means clustering 6: Clustering time 40.002, Prec@1 57.619
Epoch 0 - Kernel K-means clustering 7: Clustering time 39.917, Prec@1 57.545
Epoch 0 - Kernel K-means clustering 8: Clustering time 40.006, Prec@1 57.491
Epoch 0 - Kernel K-means clustering 9: Clustering time 39.855, Prec@1 57.466
Epoch 0 - Kernel K-means clustering 10: Clustering time 40.016, Prec@1 57.419
Epoch 0 - Kernel K-means clustering 11: Clustering time 39.971, Prec@1 57.346
Epoch 0 - Kernel K-means clustering 12: Clustering time 43.222, Prec@1 57.305
Epoch 0 - Kernel K-means clustering 13: Clustering time 39.766, Prec@1 57.247
Epoch 0 - Kernel K-means clustering 14: Clustering time 39.941, Prec@1 57.162
Epoch 0 - Kernel K-means clustering 15: Clustering time 39.885, Prec@1 57.077
Epoch 0 - Kernel K-means clustering 16: Clustering time 39.990, Prec@1 56.998
Epoch 0 - Kernel K-means clustering 17: Clustering time 39.759, Prec@1 56.940
Epoch 0 - Kernel K-means clustering 18: Clustering time 40.078, Prec@1 56.864
Epoch 0 - Kernel K-means clustering 19: Clustering time 39.716, Prec@1 56.729
Epoch 0 - Kernel K-means clustering 20: Clustering time 39.937, Prec@1 56.557
Epoch 0 - Kernel K-means clustering 21: Clustering time 40.032, Prec@1 56.400
Epoch 0 - Kernel K-means clustering 22: Clustering time 40.863, Prec@1 56.231
Epoch 0 - Kernel K-means clustering 23: Clustering time 42.090, Prec@1 56.054
Epoch 0 - Kernel K-means clustering 24: Clustering time 39.931, Prec@1 55.875
Epoch 0 - Kernel K-means clustering 25: Clustering time 42.101, Prec@1 55.727
Epoch 0 - Kernel K-means clustering 26: Clustering time 39.946, Prec@1 55.561
Epoch 0 - Kernel K-means clustering 27: Clustering time 40.261, Prec@1 55.404
Epoch 0 - Kernel K-means clustering 28: Clustering time 39.637, Prec@1 55.297
Epoch 0 - Kernel K-means clustering 29: Clustering time 39.921, Prec@1 55.187
Epoch 0 - Kernel K-means clustering 30: Clustering time 39.719, Prec@1 55.100
Epoch 0 - Kernel K-means clustering 31: Clustering time 39.892, Prec@1 55.039
Epoch 0 - Kernel K-means clustering 32: Clustering time 39.828, Prec@1 54.976
Epoch 0 - Kernel K-means clustering 33: Clustering time 39.352, Prec@1 54.931
Epoch 0 - Kernel K-means clustering 34: Clustering time 39.926, Prec@1 54.891
Epoch 0 - Kernel K-means clustering 35: Clustering time 39.820, Prec@1 54.875
Epoch 0 - Kernel K-means clustering 36: Clustering time 42.241, Prec@1 54.853
Epoch 0 - Kernel K-means clustering 37: Clustering time 42.561, Prec@1 54.830
Epoch 0 - Kernel K-means clustering 38: Clustering time 42.050, Prec@1 54.822
Epoch 0 - Kernel K-means clustering 39: Clustering time 39.961, Prec@1 54.806
Epoch 0 - Kernel K-means clustering 40: Clustering time 42.059, Prec@1 54.795
Epoch 0 - Kernel K-means clustering 41: Clustering time 43.079, Prec@1 54.777
Epoch 0 - Kernel K-means clustering 42: Clustering time 42.004, Prec@1 54.761
Epoch 0 - Kernel K-means clustering 43: Clustering time 42.751, Prec@1 54.747
Epoch 0 - Kernel K-means clustering 44: Clustering time 42.492, Prec@1 54.737
Epoch 0 - Kernel K-means clustering 45: Clustering time 42.503, Prec@1 54.728
Epoch 0 - Kernel K-means clustering 46: Clustering time 42.733, Prec@1 54.723
Epoch 0 - Kernel K-means clustering 47: Clustering time 42.907, Prec@1 54.705
Epoch 0 - Kernel K-means clustering 48: Clustering time 40.412, Prec@1 54.701
Epoch 0 - Kernel K-means clustering 49: Clustering time 42.559, Prec@1 54.692
Epoch 0 - Kernel K-means clustering 50: Clustering time 42.650, Prec@1 54.685
Epoch 0 - Kernel K-means clustering 51: Clustering time 42.535, Prec@1 54.682
Epoch 0 - Kernel K-means clustering 52: Clustering time 42.961, Prec@1 54.685
Epoch 0 - Kernel K-means clustering 53: Clustering time 42.680, Prec@1 54.683
Epoch 0 - Kernel K-means clustering 54: Clustering time 39.843, Prec@1 54.682
Epoch 0 - Kernel K-means clustering 55: Clustering time 39.696, Prec@1 54.683
Epoch 0 - Kernel K-means clustering 56: Clustering time 39.961, Prec@1 54.678
Epoch 0 - Kernel K-means clustering 57: Clustering time 39.697, Prec@1 54.674
Epoch 0 - Kernel K-means clustering 58: Clustering time 39.968, Prec@1 54.674
Epoch 0 - Kernel K-means clustering 59: Clustering time 39.762, Prec@1 54.671
Epoch 0 - Kernel K-means clustering 60: Clustering time 39.689, Prec@1 54.667
Epoch 0 - Kernel K-means clustering 61: Clustering time 39.907, Prec@1 54.660
Epoch 0 - Kernel K-means clustering 62: Clustering time 39.818, Prec@1 54.653
Epoch 0 - Kernel K-means clustering 63: Clustering time 39.968, Prec@1 54.653
Converged at iteration 64
Train - epoch [0/200]	BT 2.164 (2.164)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0422 (0.0422)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0740 (0.0740)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0639 (0.0639)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1072 (0.1072)
Train - epoch [0/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0590 (0.0590)
Train - epoch [0/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0868 (0.0868)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0681 (0.0681)
Train - epoch [0/200]	BT 4.797 (4.797)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1500 (0.1500)
Train - epoch [0/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.3624 (0.3624)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0570 (0.0570)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1619 (0.1619)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0824 (0.0824)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1031 (0.1031)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0769 (0.0769)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1100 (0.1100)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0664 (0.0664)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0458 (0.0458)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0411 (0.0411)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0449 (0.0449)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0594 (0.0594)
Train - epoch [0/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1605 (0.1605)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0999 (0.0999)
Train - epoch [0/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0734 (0.0734)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0456 (0.0456)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0469 (0.0469)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1595 (0.1595)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0939 (0.0939)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0539 (0.0539)
Train - epoch [0/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0995 (0.0995)
Train - epoch [0/200]	BT 4.530 (4.530)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0815 (0.0815)
Train - epoch [0/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0627 (0.0627)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0486 (0.0486)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0495 (0.0495)
Train - epoch [0/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1474 (0.1474)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0682 (0.0682)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0699 (0.0699)
Train - epoch [0/200]	BT 4.030 (4.030)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1095 (0.1095)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0772 (0.0772)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0371 (0.0371)
Train - epoch [0/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1195 (0.1195)
Train - epoch [0/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0546 (0.0546)
Train - epoch [0/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0660 (0.0660)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1527 (0.1527)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1727 (0.1727)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0622 (0.0622)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0758 (0.0758)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1656 (0.1656)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0438 (0.0438)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1211 (0.1211)
Train - epoch [0/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0892 (0.0892)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1868 (0.1868)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0589 (0.0589)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1944 (0.1944)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0435 (0.0435)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1412 (0.1412)
Train - epoch [0/200]	BT 4.636 (4.636)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0436 (0.0436)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0986 (0.0986)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0846 (0.0846)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0381 (0.0381)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0401 (0.0401)
Train - epoch [0/200]	BT 1.302 (1.302)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0458 (0.0458)
Train - epoch [0/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0742 (0.0742)
Train - epoch [0/200]	BT 4.220 (4.220)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0462 (0.0462)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0409 (0.0409)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0656 (0.0656)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0615 (0.0615)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0733 (0.0733)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0591 (0.0591)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1293 (0.1293)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0851 (0.0851)
Train - epoch [0/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1259 (0.1259)
Train - epoch [0/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0424 (0.0424)
Train - epoch [0/200]	BT 1.367 (1.367)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0754 (0.0754)
Train - epoch [0/200]	BT 4.453 (4.453)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0348 (0.0348)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0420 (0.0420)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.2095 (0.2095)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0477 (0.0477)
Train - epoch [0/200]	BT 1.300 (1.300)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0662 (0.0662)
Train - epoch [0/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0778 (0.0778)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0533 (0.0533)
Train - epoch [0/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1722 (0.1722)
Train - epoch [0/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1041 (0.1041)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0967 (0.0967)
Train - epoch [0/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0610 (0.0610)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0538 (0.0538)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1088 (0.1088)
Train - epoch [0/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1409 (0.1409)
Train - epoch [0/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1098 (0.1098)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0398 (0.0398)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0489 (0.0489)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0553 (0.0553)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0605 (0.0605)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1356 (0.1356)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.2409 (0.2409)
Train - epoch [0/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0644 (0.0644)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0370 (0.0370)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0991 (0.0991)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0375 (0.0375)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1468 (0.1468)
Train - epoch [0/200]	BT 3.962 (3.962)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0820 (0.0820)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0698 (0.0698)
Train - epoch [0/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0554 (0.0554)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0540 (0.0540)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1225 (0.1225)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0322 (0.0322)
Train - epoch [0/200]	BT 4.462 (4.462)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0648 (0.0648)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0903 (0.0903)
Train - epoch [0/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0408 (0.0408)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0905 (0.0905)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1729 (0.1729)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0627 (0.0627)
Train - epoch [0/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.2411 (0.2411)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.2350 (0.2350)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0496 (0.0496)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0640 (0.0640)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0582 (0.0582)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0791 (0.0791)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1810 (0.1810)
Train - epoch [0/200]	BT 1.468 (1.468)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1278 (0.1278)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0950 (0.0950)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0381 (0.0381)
Train - epoch [0/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0321 (0.0321)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0492 (0.0492)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0708 (0.0708)
Train - epoch [0/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0531 (0.0531)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0512 (0.0512)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0389 (0.0389)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0525 (0.0525)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0561 (0.0561)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0435 (0.0435)
Train - epoch [0/200]	BT 4.418 (4.418)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0455 (0.0455)
Train - epoch [0/200]	BT 1.340 (1.340)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0479 (0.0479)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0439 (0.0439)
Train - epoch [0/200]	BT 4.690 (4.690)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0584 (0.0584)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0411 (0.0411)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0835 (0.0835)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0388 (0.0388)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.2101 (0.2101)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0612 (0.0612)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0544 (0.0544)
Train - epoch [0/200]	BT 3.881 (3.881)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0520 (0.0520)
Train - epoch [0/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0299 (0.0299)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1372 (0.1372)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1245 (0.1245)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0700 (0.0700)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0652 (0.0652)
Train - epoch [0/200]	BT 1.302 (1.302)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1938 (0.1938)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0308 (0.0308)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0514 (0.0514)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0799 (0.0799)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0402 (0.0402)
Train - epoch [0/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0322 (0.0322)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0518 (0.0518)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0421 (0.0421)
Train - epoch [0/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0866 (0.0866)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0621 (0.0621)
Train - epoch [0/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1011 (0.1011)
Train - epoch [0/200]	BT 4.278 (4.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0841 (0.0841)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0518 (0.0518)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0505 (0.0505)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0358 (0.0358)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0312 (0.0312)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0527 (0.0527)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.0884 (0.0884)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0765 (0.0765)
Train - epoch [0/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0519 (0.0519)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0702 (0.0702)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0788 (0.0788)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0475 (0.0475)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0372 (0.0372)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0740 (0.0740)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0544 (0.0544)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0894 (0.0894)
Train - epoch [0/200]	BT 1.402 (1.402)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0435 (0.0435)
Train - epoch [0/200]	BT 4.552 (4.552)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0302 (0.0302)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0577 (0.0577)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0266 (0.0266)
Train - epoch [0/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0490 (0.0490)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1187 (0.1187)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1252 (0.1252)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1766 (0.1766)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0568 (0.0568)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0620 (0.0620)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0733 (0.0733)
Train - epoch [0/200]	BT 4.616 (4.616)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0399 (0.0399)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0862 (0.0862)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1124 (0.1124)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0723 (0.0723)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0451 (0.0451)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0843 (0.0843)
Train - epoch [0/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0925 (0.0925)
Train - epoch [0/200]	BT 4.293 (4.293)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0445 (0.0445)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0398 (0.0398)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0314 (0.0314)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1240 (0.1240)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0516 (0.0516)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0457 (0.0457)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0846 (0.0846)
Train - epoch [0/200]	BT 4.377 (4.377)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0706 (0.0706)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.2291 (0.2291)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0504 (0.0504)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0804 (0.0804)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0281 (0.0281)
Train - epoch [0/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0630 (0.0630)
Train - epoch [0/200]	BT 3.797 (3.797)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0543 (0.0543)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0617 (0.0617)
Train - epoch [0/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0648 (0.0648)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0923 (0.0923)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0795 (0.0795)
Train - epoch [0/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0463 (0.0463)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0480 (0.0480)
Train - epoch [0/200]	BT 3.493 (3.493)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1375 (0.1375)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0439 (0.0439)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0732 (0.0732)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0698 (0.0698)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0615 (0.0615)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0509 (0.0509)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1244 (0.1244)
Train - epoch [0/200]	BT 4.004 (4.004)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0344 (0.0344)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0801 (0.0801)
Train - epoch [0/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0431 (0.0431)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0597 (0.0597)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0429 (0.0429)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0497 (0.0497)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0422 (0.0422)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0573 (0.0573)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0909 (0.0909)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1071 (0.1071)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0447 (0.0447)
Train - epoch [0/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0428 (0.0428)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0664 (0.0664)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0576 (0.0576)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0787 (0.0787)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0626 (0.0626)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0425 (0.0425)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0439 (0.0439)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0504 (0.0504)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0439 (0.0439)
Train - epoch [0/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0498 (0.0498)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0342 (0.0342)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0327 (0.0327)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0379 (0.0379)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0732 (0.0732)
Train - epoch [0/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0581 (0.0581)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0616 (0.0616)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0669 (0.0669)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0459 (0.0459)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0479 (0.0479)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1068 (0.1068)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0434 (0.0434)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0448 (0.0448)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0555 (0.0555)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0670 (0.0670)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0343 (0.0343)
Train - epoch [0/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1623 (0.1623)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0308 (0.0308)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.2006 (0.2006)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0833 (0.0833)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0375 (0.0375)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0310 (0.0310)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0779 (0.0779)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0358 (0.0358)
Train - epoch [0/200]	BT 4.948 (4.948)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1193 (0.1193)
Train - epoch [0/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0437 (0.0437)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1360 (0.1360)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0875 (0.0875)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0452 (0.0452)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0687 (0.0687)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0374 (0.0374)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0449 (0.0449)
Train - epoch [0/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0627 (0.0627)
Train - epoch [0/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0584 (0.0584)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0948 (0.0948)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0746 (0.0746)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0445 (0.0445)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0487 (0.0487)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1458 (0.1458)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0757 (0.0757)
Train - epoch [0/200]	BT 4.405 (4.405)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0663 (0.0663)
Train - epoch [0/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0594 (0.0594)
Train - epoch [0/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0736 (0.0736)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0369 (0.0369)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0375 (0.0375)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0390 (0.0390)
Train - epoch [0/200]	BT 1.309 (1.309)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0470 (0.0470)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0319 (0.0319)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0474 (0.0474)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0342 (0.0342)
Train - epoch [0/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0607 (0.0607)
Train - epoch [0/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0887 (0.0887)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0488 (0.0488)
Train - epoch [0/200]	BT 4.135 (4.135)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0565 (0.0565)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0534 (0.0534)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0798 (0.0798)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0336 (0.0336)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0358 (0.0358)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1599 (0.1599)
Train - epoch [0/200]	BT 1.300 (1.300)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0404 (0.0404)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0456 (0.0456)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0395 (0.0395)
Train - epoch [0/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0498 (0.0498)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0393 (0.0393)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0282 (0.0282)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0576 (0.0576)
Train - epoch [0/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0381 (0.0381)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0321 (0.0321)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0588 (0.0588)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0480 (0.0480)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0421 (0.0421)
Train - epoch [0/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0317 (0.0317)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0554 (0.0554)
Train - epoch [0/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0762 (0.0762)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0375 (0.0375)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0624 (0.0624)
Train - epoch [0/200]	BT 4.328 (4.328)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0435 (0.0435)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0503 (0.0503)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0985 (0.0985)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0506 (0.0506)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0531 (0.0531)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0504 (0.0504)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1200 (0.1200)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.2500 (0.2500)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0951 (0.0951)
Train - epoch [0/200]	BT 4.161 (4.161)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0437 (0.0437)
Train - epoch [0/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0388 (0.0388)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0628 (0.0628)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0584 (0.0584)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0415 (0.0415)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0643 (0.0643)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0368 (0.0368)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0518 (0.0518)
Train - epoch [0/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0705 (0.0705)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.2050 (0.2050)
Train - epoch [0/200]	BT 4.466 (4.466)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0433 (0.0433)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0314 (0.0314)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0377 (0.0377)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0386 (0.0386)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0317 (0.0317)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0475 (0.0475)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0726 (0.0726)
Train - epoch [0/200]	BT 4.372 (4.372)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0988 (0.0988)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0440 (0.0440)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0361 (0.0361)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0382 (0.0382)
Train - epoch [0/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0857 (0.0857)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1770 (0.1770)
Train - epoch [0/200]	BT 1.431 (1.431)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1415 (0.1415)
Train - epoch [0/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0380 (0.0380)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0644 (0.0644)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0843 (0.0843)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0896 (0.0896)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0450 (0.0450)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1047 (0.1047)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0713 (0.0713)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0358 (0.0358)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0525 (0.0525)
Train - epoch [0/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0356 (0.0356)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0644 (0.0644)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0450 (0.0450)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0379 (0.0379)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0313 (0.0313)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0826 (0.0826)
Train - epoch [0/200]	BT 4.293 (4.293)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0721 (0.0721)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1723 (0.1723)
Train - epoch [0/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0437 (0.0437)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0405 (0.0405)
Train - epoch [0/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0617 (0.0617)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0758 (0.0758)
Train - epoch [0/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.2594 (0.2594)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1019 (0.1019)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0923 (0.0923)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1157 (0.1157)
Train - epoch [0/200]	BT 4.133 (4.133)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0367 (0.0367)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0873 (0.0873)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0628 (0.0628)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0738 (0.0738)
Train - epoch [0/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0488 (0.0488)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0396 (0.0396)
Train - epoch [0/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0860 (0.0860)
Train - epoch [0/200]	BT 4.231 (4.231)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0643 (0.0643)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0693 (0.0693)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0520 (0.0520)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0496 (0.0496)
Train - epoch [0/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0415 (0.0415)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0363 (0.0363)
Train - epoch [0/200]	BT 4.252 (4.252)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0303 (0.0303)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.2536 (0.2536)
Train - epoch [0/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0412 (0.0412)
Train - epoch [0/200]	BT 4.478 (4.478)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0449 (0.0449)
Train - epoch [0/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0400 (0.0400)
Train - epoch [0/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0718 (0.0718)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0386 (0.0386)
Train - epoch [0/200]	BT 1.324 (1.324)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0306 (0.0306)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0471 (0.0471)
Train - epoch [0/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0657 (0.0657)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0441 (0.0441)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0450 (0.0450)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0620 (0.0620)
Train - epoch [0/200]	BT 1.245 (1.245)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0537 (0.0537)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0383 (0.0383)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0423 (0.0423)
Train - epoch [0/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0650 (0.0650)
Train - epoch [0/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0795 (0.0795)
Train - epoch [0/200]	BT 1.307 (1.307)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0295 (0.0295)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0332 (0.0332)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0435 (0.0435)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0375 (0.0375)
Train - epoch [0/200]	BT 5.036 (5.036)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0532 (0.0532)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0648 (0.0648)
Train - epoch [0/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0635 (0.0635)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1065 (0.1065)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1031 (0.1031)
Train - epoch [0/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0750 (0.0750)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0730 (0.0730)
Train - epoch [0/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1032 (0.1032)
Train - epoch [0/200]	BT 3.997 (3.997)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0597 (0.0597)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0326 (0.0326)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0326 (0.0326)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0622 (0.0622)
Train - epoch [0/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0740 (0.0740)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1331 (0.1331)
Train - epoch [0/200]	BT 3.746 (3.746)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0746 (0.0746)
Train - epoch [0/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0521 (0.0521)
Train - epoch [0/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0466 (0.0466)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1606 (0.1606)
Train - epoch [0/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0886 (0.0886)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0453 (0.0453)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0506 (0.0506)
Train - epoch [0/200]	BT 4.507 (4.507)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0532 (0.0532)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1553 (0.1553)
Train - epoch [0/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0557 (0.0557)
Train - epoch [0/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1028 (0.1028)
Train - epoch [0/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0621 (0.0621)
Train - epoch [0/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0552 (0.0552)
Train - epoch [0/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0419 (0.0419)
Train - epoch [0/200]	BT 4.065 (4.065)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0402 (0.0402)
Train - epoch [0/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0530 (0.0530)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0528 (0.0528)
Train - epoch [0/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0409 (0.0409)
Train - epoch [0/200]	BT 3.776 (3.776)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0459 (0.0459)
Train - epoch [0/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0365 (0.0365)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0867 (0.0867)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0704 (0.0704)
Train - epoch [0/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.2561 (0.2561)
Train - epoch [0/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0379 (0.0379)
Train - epoch [0/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0400 (0.0400)
Train - epoch [0/200]	BT 4.020 (4.020)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0477 (0.0477)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1223 (0.1223)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0497 (0.0497)
Train - epoch [0/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1579 (0.1579)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0837 (0.0837)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0725 (0.0725)
Train - epoch [0/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0413 (0.0413)
Train - epoch [0/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0460 (0.0460)
Train - epoch [0/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0719 (0.0719)
Train - epoch [0/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1021 (0.1021)
Train - epoch [0/200]	BT 3.967 (3.967)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0359 (0.0359)
Train - epoch [0/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.1560 (0.1560)
Train - epoch [0/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0354 (0.0354)
Train - epoch [0/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1292 (0.1292)
Train - epoch [0/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0725 (0.0725)
Train - epoch [0/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0323 (0.0323)
Train - epoch [0/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0362 (0.0362)
Train - epoch [0/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.1136 (0.1136)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0860 (0.0860)
Train - epoch [0/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0519 (0.0519)
Train - epoch [0/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0445 (0.0445)
Train - epoch [0/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0949 (0.0949)
Train - epoch [0/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0499 (0.0499)
Train - epoch [0/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0584 (0.0584)
Train - epoch [0/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0406 (0.0406)
Train - epoch [0/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0431 (0.0431)
Train - epoch [0/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0540 (0.0540)
Train - epoch [0/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0622 (0.0622)
Train - epoch [0/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0640 (0.0640)
Train - epoch [0/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0601 (0.0601)
Train - epoch [0/200]	BT 4.622 (4.622)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.0500 (0.0500)
Test on T training set - [0][0/1731]	T 0.287 (0.287)	D 0.187 (0.187)	T@1 65.625 (65.625)	T@5 96.875 (96.875)	L 1.1538 (1.1538)
Test on T training set - [0][10/1731]	T 0.213 (0.199)	D 0.109 (0.098)	T@1 68.750 (69.602)	T@5 100.000 (97.727)	L 1.0098 (0.9635)
Test on T training set - [0][20/1731]	T 0.225 (0.211)	D 0.119 (0.110)	T@1 75.000 (71.131)	T@5 100.000 (98.661)	L 0.8327 (0.8664)
Test on T training set - [0][30/1731]	T 0.213 (0.212)	D 0.111 (0.110)	T@1 87.500 (72.681)	T@5 100.000 (98.690)	L 0.4858 (0.8020)
Test on T training set - [0][40/1731]	T 0.222 (0.213)	D 0.126 (0.112)	T@1 59.375 (72.637)	T@5 96.875 (98.704)	L 1.1711 (0.8189)
Test on T training set - [0][50/1731]	T 2.462 (0.258)	D 2.365 (0.157)	T@1 87.500 (72.243)	T@5 100.000 (98.958)	L 0.4881 (0.8421)
Test on T training set - [0][60/1731]	T 0.225 (0.253)	D 0.120 (0.151)	T@1 71.875 (72.746)	T@5 93.750 (98.924)	L 0.7928 (0.8277)
Test on T training set - [0][70/1731]	T 0.204 (0.247)	D 0.108 (0.145)	T@1 65.625 (72.403)	T@5 100.000 (98.856)	L 0.9581 (0.8356)
Test on T training set - [0][80/1731]	T 0.204 (0.243)	D 0.096 (0.141)	T@1 71.875 (72.647)	T@5 100.000 (98.804)	L 0.8055 (0.8342)
Test on T training set - [0][90/1731]	T 0.194 (0.239)	D 0.088 (0.137)	T@1 68.750 (72.493)	T@5 100.000 (98.901)	L 1.0504 (0.8464)
Test on T training set - [0][100/1731]	T 0.189 (0.234)	D 0.086 (0.133)	T@1 59.375 (72.525)	T@5 100.000 (98.886)	L 0.9672 (0.8464)
Test on T training set - [0][110/1731]	T 0.201 (0.230)	D 0.101 (0.128)	T@1 50.000 (71.706)	T@5 100.000 (98.818)	L 1.5157 (0.8701)
Test on T training set - [0][120/1731]	T 0.205 (0.227)	D 0.100 (0.125)	T@1 25.000 (68.440)	T@5 68.750 (97.624)	L 2.9641 (1.0058)
Test on T training set - [0][130/1731]	T 0.199 (0.225)	D 0.103 (0.123)	T@1 25.000 (65.029)	T@5 68.750 (95.969)	L 3.1257 (1.1543)
Test on T training set - [0][140/1731]	T 0.185 (0.222)	D 0.087 (0.121)	T@1 21.875 (61.813)	T@5 68.750 (94.504)	L 3.0145 (1.2876)
Test on T training set - [0][150/1731]	T 0.208 (0.238)	D 0.097 (0.136)	T@1 18.750 (58.982)	T@5 68.750 (92.964)	L 3.2106 (1.4173)
Test on T training set - [0][160/1731]	T 0.198 (0.235)	D 0.090 (0.133)	T@1 25.000 (56.813)	T@5 71.875 (91.751)	L 2.6679 (1.5153)
Test on T training set - [0][170/1731]	T 0.168 (0.232)	D 0.072 (0.130)	T@1 6.250 (54.349)	T@5 62.500 (90.461)	L 3.8195 (1.6204)
Test on T training set - [0][180/1731]	T 0.161 (0.230)	D 0.059 (0.128)	T@1 15.625 (51.951)	T@5 53.125 (88.691)	L 3.4083 (1.7269)
Test on T training set - [0][190/1731]	T 0.184 (0.226)	D 0.083 (0.124)	T@1 9.375 (49.624)	T@5 56.250 (87.058)	L 3.2483 (1.8290)
Test on T training set - [0][200/1731]	T 0.165 (0.224)	D 0.066 (0.122)	T@1 9.375 (47.606)	T@5 40.625 (85.152)	L 4.1922 (1.9229)
Test on T training set - [0][210/1731]	T 0.173 (0.221)	D 0.073 (0.119)	T@1 9.375 (45.661)	T@5 62.500 (83.753)	L 3.4055 (2.0081)
Test on T training set - [0][220/1731]	T 0.173 (0.219)	D 0.077 (0.118)	T@1 18.750 (44.202)	T@5 84.375 (82.890)	L 3.0045 (2.0727)
Test on T training set - [0][230/1731]	T 0.166 (0.218)	D 0.070 (0.116)	T@1 21.875 (43.344)	T@5 90.625 (82.576)	L 2.9807 (2.1028)
Test on T training set - [0][240/1731]	T 0.232 (0.229)	D 0.136 (0.128)	T@1 68.750 (43.698)	T@5 93.750 (83.104)	L 0.9693 (2.0804)
Test on T training set - [0][250/1731]	T 0.209 (0.230)	D 0.100 (0.128)	T@1 53.125 (44.024)	T@5 100.000 (83.553)	L 1.6571 (2.0619)
Test on T training set - [0][260/1731]	T 0.232 (0.230)	D 0.136 (0.128)	T@1 46.875 (44.313)	T@5 96.875 (83.980)	L 2.0795 (2.0448)
Test on T training set - [0][270/1731]	T 0.240 (0.230)	D 0.136 (0.128)	T@1 56.250 (44.696)	T@5 96.875 (84.375)	L 1.4324 (2.0246)
Test on T training set - [0][280/1731]	T 0.237 (0.230)	D 0.130 (0.128)	T@1 62.500 (45.018)	T@5 90.625 (84.720)	L 1.4193 (2.0043)
Test on T training set - [0][290/1731]	T 0.233 (0.230)	D 0.135 (0.128)	T@1 50.000 (45.114)	T@5 100.000 (85.105)	L 1.2174 (1.9923)
Test on T training set - [0][300/1731]	T 0.209 (0.229)	D 0.114 (0.128)	T@1 43.750 (45.494)	T@5 96.875 (85.403)	L 1.8007 (1.9747)
Test on T training set - [0][310/1731]	T 0.272 (0.237)	D 0.163 (0.136)	T@1 43.750 (45.679)	T@5 93.750 (85.691)	L 1.7367 (1.9625)
Test on T training set - [0][320/1731]	T 0.203 (0.237)	D 0.095 (0.135)	T@1 40.625 (45.921)	T@5 100.000 (86.011)	L 1.3517 (1.9506)
Test on T training set - [0][330/1731]	T 0.202 (0.236)	D 0.096 (0.134)	T@1 53.125 (46.148)	T@5 100.000 (86.339)	L 1.5766 (1.9395)
Test on T training set - [0][340/1731]	T 0.189 (0.234)	D 0.083 (0.133)	T@1 31.250 (45.748)	T@5 90.625 (86.263)	L 2.1868 (1.9529)
Test on T training set - [0][350/1731]	T 0.213 (0.233)	D 0.109 (0.131)	T@1 31.250 (45.513)	T@5 93.750 (86.360)	L 2.6140 (1.9595)
Test on T training set - [0][360/1731]	T 0.236 (0.233)	D 0.140 (0.131)	T@1 59.375 (45.871)	T@5 100.000 (86.634)	L 1.4235 (1.9442)
Test on T training set - [0][370/1731]	T 0.170 (0.233)	D 0.075 (0.131)	T@1 46.875 (46.159)	T@5 100.000 (86.885)	L 1.7686 (1.9293)
Test on T training set - [0][380/1731]	T 0.185 (0.231)	D 0.083 (0.129)	T@1 71.875 (46.432)	T@5 100.000 (87.082)	L 0.7811 (1.9156)
Test on T training set - [0][390/1731]	T 0.162 (0.230)	D 0.066 (0.128)	T@1 59.375 (47.075)	T@5 93.750 (87.340)	L 1.3091 (1.8906)
Test on T training set - [0][400/1731]	T 0.155 (0.234)	D 0.048 (0.132)	T@1 59.375 (47.491)	T@5 100.000 (87.601)	L 1.3563 (1.8720)
Test on T training set - [0][410/1731]	T 0.168 (0.232)	D 0.064 (0.131)	T@1 65.625 (47.795)	T@5 96.875 (87.827)	L 1.0799 (1.8562)
Test on T training set - [0][420/1731]	T 0.165 (0.231)	D 0.060 (0.129)	T@1 53.125 (48.085)	T@5 87.500 (87.960)	L 1.5342 (1.8432)
Test on T training set - [0][430/1731]	T 0.160 (0.229)	D 0.061 (0.128)	T@1 65.625 (48.463)	T@5 90.625 (88.131)	L 1.1670 (1.8275)
Test on T training set - [0][440/1731]	T 0.159 (0.228)	D 0.057 (0.126)	T@1 68.750 (48.902)	T@5 93.750 (88.322)	L 0.7942 (1.8098)
Test on T training set - [0][450/1731]	T 0.168 (0.226)	D 0.062 (0.125)	T@1 65.625 (49.314)	T@5 93.750 (88.505)	L 1.1274 (1.7925)
Test on T training set - [0][460/1731]	T 0.165 (0.225)	D 0.069 (0.124)	T@1 84.375 (49.797)	T@5 100.000 (88.713)	L 0.5685 (1.7740)
Test on T training set - [0][470/1731]	T 0.151 (0.224)	D 0.055 (0.122)	T@1 84.375 (50.199)	T@5 96.875 (88.880)	L 0.6412 (1.7580)
Test on T training set - [0][480/1731]	T 0.167 (0.223)	D 0.059 (0.121)	T@1 59.375 (50.526)	T@5 93.750 (89.046)	L 1.2680 (1.7437)
Test on T training set - [0][490/1731]	T 0.167 (0.222)	D 0.062 (0.120)	T@1 65.625 (50.872)	T@5 96.875 (89.212)	L 1.0080 (1.7292)
Test on T training set - [0][500/1731]	T 0.171 (0.221)	D 0.075 (0.119)	T@1 75.000 (51.191)	T@5 100.000 (89.365)	L 0.7605 (1.7160)
Test on T training set - [0][510/1731]	T 0.174 (0.225)	D 0.070 (0.123)	T@1 62.500 (51.388)	T@5 96.875 (89.481)	L 1.1135 (1.7082)
Test on T training set - [0][520/1731]	T 0.161 (0.223)	D 0.058 (0.122)	T@1 46.875 (51.392)	T@5 87.500 (89.575)	L 1.7470 (1.7041)
Test on T training set - [0][530/1731]	T 0.163 (0.222)	D 0.068 (0.121)	T@1 53.125 (51.448)	T@5 87.500 (89.648)	L 1.6690 (1.7006)
Test on T training set - [0][540/1731]	T 0.169 (0.221)	D 0.062 (0.119)	T@1 71.875 (51.473)	T@5 100.000 (89.764)	L 1.0019 (1.6958)
Test on T training set - [0][550/1731]	T 0.165 (0.220)	D 0.063 (0.118)	T@1 50.000 (51.554)	T@5 90.625 (89.837)	L 1.5385 (1.6917)
Test on T training set - [0][560/1731]	T 0.171 (0.219)	D 0.071 (0.118)	T@1 31.250 (51.387)	T@5 81.250 (89.817)	L 2.6206 (1.6954)
Test on T training set - [0][570/1731]	T 0.191 (0.219)	D 0.090 (0.117)	T@1 59.375 (51.505)	T@5 96.875 (89.903)	L 1.1183 (1.6898)
Test on T training set - [0][580/1731]	T 0.168 (0.218)	D 0.072 (0.116)	T@1 71.875 (51.732)	T@5 96.875 (89.990)	L 0.7631 (1.6807)
Test on T training set - [0][590/1731]	T 0.183 (0.217)	D 0.077 (0.115)	T@1 71.875 (52.046)	T@5 96.875 (90.128)	L 0.9351 (1.6689)
Test on T training set - [0][600/1731]	T 0.173 (0.217)	D 0.073 (0.115)	T@1 71.875 (52.319)	T@5 93.750 (90.209)	L 0.9817 (1.6594)
Test on T training set - [0][610/1731]	T 0.159 (0.216)	D 0.060 (0.114)	T@1 81.250 (52.649)	T@5 100.000 (90.308)	L 0.6590 (1.6474)
Test on T training set - [0][620/1731]	T 0.184 (0.220)	D 0.088 (0.118)	T@1 68.750 (52.904)	T@5 93.750 (90.368)	L 0.9463 (1.6372)
Test on T training set - [0][630/1731]	T 0.166 (0.219)	D 0.061 (0.117)	T@1 75.000 (53.130)	T@5 96.875 (90.437)	L 1.0326 (1.6284)
Test on T training set - [0][640/1731]	T 0.165 (0.219)	D 0.059 (0.117)	T@1 81.250 (53.349)	T@5 96.875 (90.503)	L 0.7522 (1.6207)
Test on T training set - [0][650/1731]	T 0.164 (0.218)	D 0.059 (0.116)	T@1 65.625 (53.605)	T@5 93.750 (90.596)	L 1.3273 (1.6100)
Test on T training set - [0][660/1731]	T 0.161 (0.217)	D 0.062 (0.115)	T@1 62.500 (53.867)	T@5 87.500 (90.668)	L 1.1566 (1.6008)
Test on T training set - [0][670/1731]	T 0.169 (0.216)	D 0.072 (0.114)	T@1 75.000 (54.052)	T@5 93.750 (90.751)	L 1.2557 (1.5934)
Test on T training set - [0][680/1731]	T 0.155 (0.215)	D 0.059 (0.114)	T@1 56.250 (54.190)	T@5 93.750 (90.827)	L 1.5374 (1.5869)
Test on T training set - [0][690/1731]	T 0.230 (0.215)	D 0.127 (0.113)	T@1 9.375 (54.079)	T@5 53.125 (90.711)	L 3.7980 (1.5921)
Test on T training set - [0][700/1731]	T 0.155 (0.214)	D 0.057 (0.113)	T@1 15.625 (53.473)	T@5 34.375 (90.032)	L 3.3153 (1.6210)
Test on T training set - [0][710/1731]	T 0.170 (0.214)	D 0.074 (0.112)	T@1 21.875 (53.151)	T@5 56.250 (89.605)	L 3.1185 (1.6370)
Test on T training set - [0][720/1731]	T 0.175 (0.213)	D 0.071 (0.112)	T@1 43.750 (52.913)	T@5 75.000 (89.325)	L 2.0517 (1.6486)
Test on T training set - [0][730/1731]	T 0.223 (0.217)	D 0.118 (0.115)	T@1 50.000 (52.693)	T@5 84.375 (89.052)	L 2.0011 (1.6586)
Test on T training set - [0][740/1731]	T 0.222 (0.217)	D 0.121 (0.115)	T@1 37.500 (52.606)	T@5 75.000 (88.925)	L 2.1966 (1.6616)
Test on T training set - [0][750/1731]	T 0.199 (0.217)	D 0.093 (0.115)	T@1 50.000 (52.484)	T@5 78.125 (88.802)	L 1.8118 (1.6661)
Test on T training set - [0][760/1731]	T 0.223 (0.217)	D 0.127 (0.115)	T@1 62.500 (52.394)	T@5 90.625 (88.699)	L 1.3623 (1.6698)
Test on T training set - [0][770/1731]	T 0.206 (0.217)	D 0.111 (0.115)	T@1 46.875 (52.327)	T@5 75.000 (88.574)	L 2.0557 (1.6740)
Test on T training set - [0][780/1731]	T 0.224 (0.217)	D 0.126 (0.115)	T@1 53.125 (52.185)	T@5 71.875 (88.372)	L 2.2487 (1.6826)
Test on T training set - [0][790/1731]	T 0.219 (0.217)	D 0.116 (0.115)	T@1 62.500 (52.074)	T@5 87.500 (88.262)	L 1.7536 (1.6892)
Test on T training set - [0][800/1731]	T 0.211 (0.217)	D 0.110 (0.115)	T@1 40.625 (51.970)	T@5 78.125 (88.194)	L 2.2584 (1.6934)
Test on T training set - [0][810/1731]	T 0.198 (0.217)	D 0.094 (0.115)	T@1 31.250 (51.823)	T@5 65.625 (88.001)	L 2.5364 (1.7009)
Test on T training set - [0][820/1731]	T 0.274 (0.221)	D 0.164 (0.119)	T@1 40.625 (51.736)	T@5 90.625 (87.903)	L 2.0737 (1.7054)
Test on T training set - [0][830/1731]	T 0.193 (0.221)	D 0.088 (0.119)	T@1 50.000 (51.655)	T@5 84.375 (87.752)	L 1.8527 (1.7097)
Test on T training set - [0][840/1731]	T 0.168 (0.220)	D 0.066 (0.119)	T@1 34.375 (51.486)	T@5 65.625 (87.604)	L 2.5354 (1.7172)
Test on T training set - [0][850/1731]	T 0.153 (0.220)	D 0.054 (0.118)	T@1 0.000 (50.911)	T@5 40.625 (87.195)	L 3.6834 (1.7400)
Test on T training set - [0][860/1731]	T 0.168 (0.219)	D 0.067 (0.117)	T@1 3.125 (50.356)	T@5 68.750 (86.814)	L 3.3824 (1.7628)
Test on T training set - [0][870/1731]	T 0.172 (0.218)	D 0.071 (0.117)	T@1 3.125 (49.839)	T@5 53.125 (86.406)	L 3.7416 (1.7837)
Test on T training set - [0][880/1731]	T 0.167 (0.218)	D 0.071 (0.116)	T@1 12.500 (49.347)	T@5 68.750 (86.063)	L 3.2369 (1.8042)
Test on T training set - [0][890/1731]	T 0.171 (0.217)	D 0.072 (0.116)	T@1 6.250 (48.867)	T@5 59.375 (85.729)	L 3.5886 (1.8244)
Test on T training set - [0][900/1731]	T 0.169 (0.217)	D 0.064 (0.115)	T@1 9.375 (48.387)	T@5 78.125 (85.391)	L 3.6350 (1.8447)
Test on T training set - [0][910/1731]	T 0.172 (0.216)	D 0.076 (0.115)	T@1 68.750 (48.336)	T@5 100.000 (85.291)	L 0.9458 (1.8467)
Test on T training set - [0][920/1731]	T 0.156 (0.219)	D 0.056 (0.117)	T@1 71.875 (48.619)	T@5 100.000 (85.440)	L 0.8916 (1.8354)
Test on T training set - [0][930/1731]	T 0.248 (0.219)	D 0.140 (0.117)	T@1 87.500 (48.943)	T@5 100.000 (85.597)	L 0.4713 (1.8232)
Test on T training set - [0][940/1731]	T 0.250 (0.219)	D 0.155 (0.118)	T@1 84.375 (49.249)	T@5 100.000 (85.737)	L 0.4720 (1.8115)
Test on T training set - [0][950/1731]	T 0.229 (0.219)	D 0.134 (0.118)	T@1 75.000 (49.553)	T@5 96.875 (85.883)	L 0.7665 (1.7999)
Test on T training set - [0][960/1731]	T 0.225 (0.219)	D 0.114 (0.118)	T@1 65.625 (49.873)	T@5 100.000 (86.027)	L 1.0438 (1.7880)
Test on T training set - [0][970/1731]	T 0.233 (0.219)	D 0.129 (0.118)	T@1 78.125 (50.183)	T@5 100.000 (86.164)	L 0.7085 (1.7754)
Test on T training set - [0][980/1731]	T 0.232 (0.220)	D 0.127 (0.118)	T@1 71.875 (50.487)	T@5 100.000 (86.302)	L 0.7299 (1.7633)
Test on T training set - [0][990/1731]	T 0.229 (0.219)	D 0.133 (0.118)	T@1 87.500 (50.798)	T@5 100.000 (86.440)	L 0.4425 (1.7516)
Test on T training set - [0][1000/1731]	T 0.218 (0.219)	D 0.112 (0.118)	T@1 68.750 (51.080)	T@5 96.875 (86.567)	L 0.9476 (1.7405)
Test on T training set - [0][1010/1731]	T 0.203 (0.222)	D 0.101 (0.120)	T@1 65.625 (51.351)	T@5 100.000 (86.696)	L 1.0787 (1.7303)
Test on T training set - [0][1020/1731]	T 0.203 (0.222)	D 0.107 (0.120)	T@1 81.250 (51.595)	T@5 96.875 (86.817)	L 0.5646 (1.7205)
Test on T training set - [0][1030/1731]	T 0.159 (0.221)	D 0.064 (0.120)	T@1 75.000 (51.828)	T@5 96.875 (86.936)	L 1.0344 (1.7112)
Test on T training set - [0][1040/1731]	T 0.172 (0.221)	D 0.077 (0.119)	T@1 53.125 (52.065)	T@5 100.000 (87.050)	L 1.3189 (1.7022)
Test on T training set - [0][1050/1731]	T 0.169 (0.221)	D 0.069 (0.119)	T@1 65.625 (52.203)	T@5 100.000 (87.155)	L 1.0063 (1.6963)
Test on T training set - [0][1060/1731]	T 0.160 (0.220)	D 0.053 (0.119)	T@1 65.625 (52.271)	T@5 96.875 (87.250)	L 1.0258 (1.6920)
Test on T training set - [0][1070/1731]	T 0.203 (0.220)	D 0.098 (0.118)	T@1 71.875 (52.387)	T@5 100.000 (87.354)	L 1.1103 (1.6868)
Test on T training set - [0][1080/1731]	T 0.166 (0.219)	D 0.063 (0.118)	T@1 56.250 (52.579)	T@5 96.875 (87.462)	L 1.4210 (1.6793)
Test on T training set - [0][1090/1731]	T 0.172 (0.219)	D 0.076 (0.118)	T@1 3.125 (52.463)	T@5 25.000 (87.262)	L 4.1698 (1.6860)
Test on T training set - [0][1100/1731]	T 0.200 (0.219)	D 0.098 (0.117)	T@1 9.375 (52.075)	T@5 40.625 (86.790)	L 4.2350 (1.7068)
Test on T training set - [0][1110/1731]	T 0.275 (0.222)	D 0.169 (0.120)	T@1 9.375 (51.648)	T@5 37.500 (86.291)	L 3.9223 (1.7294)
Test on T training set - [0][1120/1731]	T 0.190 (0.221)	D 0.094 (0.120)	T@1 9.375 (51.235)	T@5 40.625 (85.819)	L 4.2661 (1.7518)
Test on T training set - [0][1130/1731]	T 0.193 (0.221)	D 0.088 (0.120)	T@1 0.000 (50.829)	T@5 18.750 (85.375)	L 4.2561 (1.7728)
Test on T training set - [0][1140/1731]	T 0.190 (0.221)	D 0.090 (0.119)	T@1 15.625 (50.427)	T@5 34.375 (84.898)	L 4.0808 (1.7955)
Test on T training set - [0][1150/1731]	T 0.183 (0.221)	D 0.079 (0.119)	T@1 6.250 (50.038)	T@5 37.500 (84.435)	L 4.2138 (1.8168)
Test on T training set - [0][1160/1731]	T 0.174 (0.220)	D 0.072 (0.119)	T@1 3.125 (49.666)	T@5 31.250 (84.001)	L 4.2000 (1.8369)
Test on T training set - [0][1170/1731]	T 0.186 (0.220)	D 0.080 (0.118)	T@1 6.250 (49.279)	T@5 21.875 (83.569)	L 4.4700 (1.8575)
Test on T training set - [0][1180/1731]	T 0.188 (0.220)	D 0.085 (0.118)	T@1 0.000 (48.897)	T@5 25.000 (83.160)	L 4.5741 (1.8782)
Test on T training set - [0][1190/1731]	T 0.191 (0.219)	D 0.092 (0.118)	T@1 9.375 (48.546)	T@5 34.375 (82.732)	L 4.2342 (1.8977)
Test on T training set - [0][1200/1731]	T 0.215 (0.221)	D 0.115 (0.120)	T@1 6.250 (48.184)	T@5 25.000 (82.293)	L 4.1608 (1.9170)
Test on T training set - [0][1210/1731]	T 0.188 (0.221)	D 0.091 (0.120)	T@1 12.500 (47.843)	T@5 37.500 (81.869)	L 4.0152 (1.9353)
Test on T training set - [0][1220/1731]	T 0.165 (0.221)	D 0.070 (0.119)	T@1 53.125 (47.786)	T@5 81.250 (81.834)	L 1.6104 (1.9362)
Test on T training set - [0][1230/1731]	T 0.163 (0.220)	D 0.059 (0.119)	T@1 56.250 (47.766)	T@5 81.250 (81.869)	L 1.6543 (1.9353)
Test on T training set - [0][1240/1731]	T 0.177 (0.220)	D 0.074 (0.118)	T@1 59.375 (47.794)	T@5 96.875 (81.935)	L 1.3439 (1.9331)
Test on T training set - [0][1250/1731]	T 0.177 (0.220)	D 0.081 (0.118)	T@1 68.750 (47.889)	T@5 100.000 (82.019)	L 0.9511 (1.9284)
Test on T training set - [0][1260/1731]	T 0.192 (0.219)	D 0.090 (0.118)	T@1 59.375 (47.958)	T@5 84.375 (82.078)	L 1.4900 (1.9245)
Test on T training set - [0][1270/1731]	T 0.180 (0.219)	D 0.073 (0.118)	T@1 56.250 (48.033)	T@5 96.875 (82.145)	L 1.1585 (1.9208)
Test on T training set - [0][1280/1731]	T 0.190 (0.219)	D 0.088 (0.117)	T@1 65.625 (48.161)	T@5 90.625 (82.245)	L 1.2019 (1.9149)
Test on T training set - [0][1290/1731]	T 0.168 (0.218)	D 0.070 (0.117)	T@1 40.625 (48.243)	T@5 93.750 (82.315)	L 1.7571 (1.9107)
Test on T training set - [0][1300/1731]	T 0.176 (0.218)	D 0.074 (0.117)	T@1 65.625 (48.331)	T@5 81.250 (82.384)	L 1.4947 (1.9064)
Test on T training set - [0][1310/1731]	T 0.180 (0.218)	D 0.084 (0.116)	T@1 65.625 (48.432)	T@5 90.625 (82.473)	L 1.3010 (1.9011)
Test on T training set - [0][1320/1731]	T 0.192 (0.220)	D 0.095 (0.118)	T@1 59.375 (48.574)	T@5 100.000 (82.577)	L 1.1057 (1.8947)
Test on T training set - [0][1330/1731]	T 0.176 (0.219)	D 0.071 (0.118)	T@1 75.000 (48.676)	T@5 90.625 (82.638)	L 1.2478 (1.8906)
Test on T training set - [0][1340/1731]	T 0.162 (0.219)	D 0.058 (0.117)	T@1 78.125 (48.756)	T@5 93.750 (82.699)	L 0.7923 (1.8870)
Test on T training set - [0][1350/1731]	T 0.177 (0.219)	D 0.072 (0.117)	T@1 68.750 (48.850)	T@5 93.750 (82.765)	L 1.0764 (1.8825)
Test on T training set - [0][1360/1731]	T 0.167 (0.218)	D 0.063 (0.117)	T@1 9.375 (48.680)	T@5 56.250 (82.618)	L 3.6524 (1.8900)
Test on T training set - [0][1370/1731]	T 0.160 (0.218)	D 0.061 (0.116)	T@1 12.500 (48.441)	T@5 65.625 (82.472)	L 3.0153 (1.8985)
Test on T training set - [0][1380/1731]	T 0.165 (0.218)	D 0.067 (0.116)	T@1 21.875 (48.267)	T@5 65.625 (82.370)	L 3.1832 (1.9045)
Test on T training set - [0][1390/1731]	T 0.169 (0.217)	D 0.064 (0.116)	T@1 18.750 (48.052)	T@5 68.750 (82.234)	L 3.1835 (1.9126)
Test on T training set - [0][1400/1731]	T 0.185 (0.217)	D 0.077 (0.115)	T@1 25.000 (47.870)	T@5 81.250 (82.138)	L 2.9743 (1.9207)
Test on T training set - [0][1410/1731]	T 0.177 (0.219)	D 0.074 (0.117)	T@1 25.000 (47.666)	T@5 59.375 (82.001)	L 2.9173 (1.9289)
Test on T training set - [0][1420/1731]	T 0.168 (0.218)	D 0.064 (0.117)	T@1 31.250 (47.473)	T@5 71.875 (81.842)	L 2.6255 (1.9369)
Test on T training set - [0][1430/1731]	T 0.213 (0.218)	D 0.109 (0.116)	T@1 87.500 (47.462)	T@5 100.000 (81.824)	L 0.4160 (1.9374)
Test on T training set - [0][1440/1731]	T 0.244 (0.218)	D 0.147 (0.117)	T@1 81.250 (47.751)	T@5 100.000 (81.946)	L 0.4322 (1.9263)
Test on T training set - [0][1450/1731]	T 0.235 (0.218)	D 0.128 (0.117)	T@1 90.625 (48.021)	T@5 100.000 (82.066)	L 0.4247 (1.9160)
Test on T training set - [0][1460/1731]	T 0.237 (0.219)	D 0.131 (0.117)	T@1 93.750 (48.270)	T@5 100.000 (82.183)	L 0.3032 (1.9062)
Test on T training set - [0][1470/1731]	T 0.240 (0.219)	D 0.144 (0.117)	T@1 87.500 (48.517)	T@5 96.875 (82.289)	L 0.5706 (1.8966)
Test on T training set - [0][1480/1731]	T 0.247 (0.219)	D 0.146 (0.117)	T@1 96.875 (48.789)	T@5 100.000 (82.406)	L 0.1576 (1.8863)
Test on T training set - [0][1490/1731]	T 0.233 (0.221)	D 0.137 (0.120)	T@1 81.250 (49.048)	T@5 100.000 (82.522)	L 0.5037 (1.8763)
Test on T training set - [0][1500/1731]	T 0.259 (0.221)	D 0.155 (0.120)	T@1 87.500 (49.278)	T@5 100.000 (82.637)	L 0.2754 (1.8672)
Test on T training set - [0][1510/1731]	T 0.232 (0.221)	D 0.131 (0.120)	T@1 90.625 (49.516)	T@5 100.000 (82.749)	L 0.4249 (1.8584)
Test on T training set - [0][1520/1731]	T 0.231 (0.222)	D 0.135 (0.120)	T@1 78.125 (49.739)	T@5 96.875 (82.861)	L 0.7854 (1.8495)
Test on T training set - [0][1530/1731]	T 0.228 (0.222)	D 0.123 (0.120)	T@1 90.625 (49.963)	T@5 100.000 (82.971)	L 0.2631 (1.8407)
Test on T training set - [0][1540/1731]	T 0.211 (0.222)	D 0.101 (0.120)	T@1 71.875 (50.120)	T@5 96.875 (83.067)	L 1.1142 (1.8343)
Test on T training set - [0][1550/1731]	T 0.247 (0.222)	D 0.142 (0.120)	T@1 84.375 (50.250)	T@5 100.000 (83.156)	L 0.4879 (1.8286)
Test on T training set - [0][1560/1731]	T 0.208 (0.223)	D 0.112 (0.122)	T@1 9.375 (50.296)	T@5 59.375 (83.170)	L 3.9690 (1.8280)
Test on T training set - [0][1570/1731]	T 0.186 (0.223)	D 0.075 (0.121)	T@1 9.375 (50.042)	T@5 71.875 (83.072)	L 3.9546 (1.8400)
Test on T training set - [0][1580/1731]	T 0.160 (0.223)	D 0.063 (0.121)	T@1 18.750 (49.792)	T@5 75.000 (82.964)	L 3.0099 (1.8509)
Test on T training set - [0][1590/1731]	T 0.158 (0.222)	D 0.061 (0.121)	T@1 9.375 (49.554)	T@5 68.750 (82.867)	L 3.7026 (1.8621)
Test on T training set - [0][1600/1731]	T 0.194 (0.222)	D 0.093 (0.120)	T@1 3.125 (49.295)	T@5 62.500 (82.800)	L 3.8872 (1.8741)
Test on T training set - [0][1610/1731]	T 0.179 (0.222)	D 0.077 (0.120)	T@1 3.125 (49.030)	T@5 65.625 (82.697)	L 4.1611 (1.8866)
Test on T training set - [0][1620/1731]	T 0.183 (0.222)	D 0.088 (0.120)	T@1 15.625 (48.772)	T@5 68.750 (82.599)	L 3.3205 (1.8985)
Test on T training set - [0][1630/1731]	T 0.175 (0.221)	D 0.073 (0.120)	T@1 6.250 (48.523)	T@5 56.250 (82.455)	L 4.1752 (1.9107)
Test on T training set - [0][1640/1731]	T 0.222 (0.221)	D 0.117 (0.119)	T@1 12.500 (48.282)	T@5 59.375 (82.351)	L 3.7674 (1.9219)
Test on T training set - [0][1650/1731]	T 0.227 (0.223)	D 0.119 (0.121)	T@1 9.375 (48.079)	T@5 75.000 (82.323)	L 3.7687 (1.9310)
Test on T training set - [0][1660/1731]	T 0.215 (0.222)	D 0.111 (0.121)	T@1 21.875 (47.887)	T@5 81.250 (82.289)	L 3.0130 (1.9402)
Test on T training set - [0][1670/1731]	T 0.197 (0.222)	D 0.100 (0.121)	T@1 9.375 (47.703)	T@5 78.125 (82.241)	L 3.5981 (1.9491)
Test on T training set - [0][1680/1731]	T 0.200 (0.222)	D 0.095 (0.121)	T@1 12.500 (47.515)	T@5 75.000 (82.200)	L 3.2317 (1.9578)
Test on T training set - [0][1690/1731]	T 0.224 (0.222)	D 0.117 (0.121)	T@1 15.625 (47.339)	T@5 84.375 (82.194)	L 3.1881 (1.9664)
Test on T training set - [0][1700/1731]	T 0.213 (0.222)	D 0.117 (0.121)	T@1 21.875 (47.154)	T@5 84.375 (82.156)	L 3.2775 (1.9756)
Test on T training set - [0][1710/1731]	T 0.219 (0.222)	D 0.123 (0.121)	T@1 15.625 (46.986)	T@5 81.250 (82.125)	L 3.6312 (1.9838)
Test on T training set - [0][1720/1731]	T 0.203 (0.222)	D 0.095 (0.121)	T@1 12.500 (46.804)	T@5 75.000 (82.094)	L 3.6191 (1.9917)
Test on T training set - [0][1730/1731]	T 0.169 (0.222)	D 0.077 (0.121)	T@1 7.143 (46.636)	T@5 75.000 (82.050)	L 3.6974 (1.9990)
 * Test on T training set - Prec@1 46.636, Prec@5 82.050
Test on T test set - [0][0/1731]	Time 0.291 (0.291)	Loss 1.1550 (1.1550)	Prec@1 65.625 (65.625)	Prec@5 96.875 (96.875)
Test on T test set - [0][10/1731]	Time 0.209 (0.198)	Loss 0.9988 (0.9484)	Prec@1 68.750 (71.307)	Prec@5 96.875 (98.011)
Test on T test set - [0][20/1731]	Time 0.219 (0.209)	Loss 0.7669 (0.8581)	Prec@1 75.000 (72.619)	Prec@5 100.000 (98.958)
Test on T test set - [0][30/1731]	Time 0.199 (0.210)	Loss 0.6627 (0.7956)	Prec@1 78.125 (73.690)	Prec@5 96.875 (98.790)
Test on T test set - [0][40/1731]	Time 0.231 (0.211)	Loss 1.0461 (0.8189)	Prec@1 68.750 (73.247)	Prec@5 96.875 (98.857)
Test on T test set - [0][50/1731]	Time 0.223 (0.212)	Loss 0.5298 (0.8363)	Prec@1 90.625 (72.549)	Prec@5 100.000 (99.081)
Test on T test set - [0][60/1731]	Time 0.217 (0.213)	Loss 0.9612 (0.8199)	Prec@1 71.875 (73.053)	Prec@5 93.750 (99.078)
Test on T test set - [0][70/1731]	Time 0.252 (0.253)	Loss 0.7954 (0.8312)	Prec@1 78.125 (72.931)	Prec@5 100.000 (99.076)
Test on T test set - [0][80/1731]	Time 0.196 (0.247)	Loss 0.7009 (0.8295)	Prec@1 84.375 (73.187)	Prec@5 100.000 (98.997)
Test on T test set - [0][90/1731]	Time 0.178 (0.242)	Loss 1.0133 (0.8355)	Prec@1 65.625 (73.008)	Prec@5 100.000 (99.038)
Test on T test set - [0][100/1731]	Time 0.178 (0.237)	Loss 1.0285 (0.8358)	Prec@1 62.500 (73.051)	Prec@5 96.875 (98.979)
Test on T test set - [0][110/1731]	Time 0.224 (0.232)	Loss 1.4030 (0.8575)	Prec@1 56.250 (72.551)	Prec@5 100.000 (98.874)
Test on T test set - [0][120/1731]	Time 0.199 (0.228)	Loss 2.7989 (0.9953)	Prec@1 34.375 (69.267)	Prec@5 81.250 (97.753)
Test on T test set - [0][130/1731]	Time 0.194 (0.225)	Loss 3.1255 (1.1452)	Prec@1 25.000 (65.768)	Prec@5 71.875 (96.231)
Test on T test set - [0][140/1731]	Time 0.182 (0.223)	Loss 3.0906 (1.2830)	Prec@1 21.875 (62.478)	Prec@5 68.750 (94.747)
Test on T test set - [0][150/1731]	Time 0.201 (0.221)	Loss 3.0042 (1.4077)	Prec@1 25.000 (59.706)	Prec@5 71.875 (93.233)
Test on T test set - [0][160/1731]	Time 0.186 (0.218)	Loss 2.5368 (1.5061)	Prec@1 31.250 (57.395)	Prec@5 78.125 (92.061)
Test on T test set - [0][170/1731]	Time 0.167 (0.216)	Loss 3.7638 (1.6131)	Prec@1 3.125 (54.843)	Prec@5 59.375 (90.826)
Test on T test set - [0][180/1731]	Time 0.157 (0.233)	Loss 3.4927 (1.7219)	Prec@1 15.625 (52.469)	Prec@5 37.500 (88.933)
Test on T test set - [0][190/1731]	Time 0.183 (0.229)	Loss 3.2900 (1.8289)	Prec@1 6.250 (50.131)	Prec@5 62.500 (87.336)
Test on T test set - [0][200/1731]	Time 0.159 (0.226)	Loss 4.3103 (1.9218)	Prec@1 6.250 (48.181)	Prec@5 37.500 (85.463)
Test on T test set - [0][210/1731]	Time 0.178 (0.223)	Loss 3.2445 (2.0061)	Prec@1 12.500 (46.268)	Prec@5 65.625 (84.094)
Test on T test set - [0][220/1731]	Time 0.180 (0.221)	Loss 3.1398 (2.0706)	Prec@1 18.750 (44.825)	Prec@5 81.250 (83.131)
Test on T test set - [0][230/1731]	Time 0.174 (0.219)	Loss 3.0642 (2.1070)	Prec@1 15.625 (43.777)	Prec@5 90.625 (82.806)
Test on T test set - [0][240/1731]	Time 0.236 (0.220)	Loss 1.0799 (2.0872)	Prec@1 65.625 (43.970)	Prec@5 96.875 (83.364)
Test on T test set - [0][250/1731]	Time 0.212 (0.220)	Loss 1.5941 (2.0669)	Prec@1 53.125 (44.273)	Prec@5 96.875 (83.815)
Test on T test set - [0][260/1731]	Time 0.223 (0.221)	Loss 2.2619 (2.0494)	Prec@1 40.625 (44.624)	Prec@5 93.750 (84.255)
Test on T test set - [0][270/1731]	Time 0.238 (0.233)	Loss 1.5458 (2.0290)	Prec@1 56.250 (44.949)	Prec@5 90.625 (84.652)
Test on T test set - [0][280/1731]	Time 0.232 (0.233)	Loss 1.2625 (2.0075)	Prec@1 65.625 (45.296)	Prec@5 90.625 (85.031)
Test on T test set - [0][290/1731]	Time 0.227 (0.232)	Loss 1.0885 (1.9929)	Prec@1 56.250 (45.436)	Prec@5 96.875 (85.363)
Test on T test set - [0][300/1731]	Time 0.228 (0.232)	Loss 1.8744 (1.9767)	Prec@1 46.875 (45.816)	Prec@5 93.750 (85.642)
Test on T test set - [0][310/1731]	Time 0.226 (0.232)	Loss 1.9490 (1.9655)	Prec@1 43.750 (45.941)	Prec@5 93.750 (85.902)
Test on T test set - [0][320/1731]	Time 0.196 (0.231)	Loss 1.2164 (1.9524)	Prec@1 46.875 (46.125)	Prec@5 100.000 (86.195)
Test on T test set - [0][330/1731]	Time 0.192 (0.230)	Loss 1.3922 (1.9428)	Prec@1 59.375 (46.233)	Prec@5 96.875 (86.528)
Test on T test set - [0][340/1731]	Time 0.233 (0.236)	Loss 2.0206 (1.9576)	Prec@1 37.500 (45.858)	Prec@5 93.750 (86.437)
Test on T test set - [0][350/1731]	Time 0.195 (0.235)	Loss 2.3681 (1.9618)	Prec@1 34.375 (45.646)	Prec@5 93.750 (86.583)
Test on T test set - [0][360/1731]	Time 0.232 (0.234)	Loss 1.2515 (1.9454)	Prec@1 59.375 (46.035)	Prec@5 100.000 (86.859)
Test on T test set - [0][370/1731]	Time 0.170 (0.234)	Loss 1.5235 (1.9323)	Prec@1 56.250 (46.201)	Prec@5 96.875 (87.087)
Test on T test set - [0][380/1731]	Time 0.178 (0.232)	Loss 0.7323 (1.9163)	Prec@1 68.750 (46.498)	Prec@5 100.000 (87.279)
Test on T test set - [0][390/1731]	Time 0.164 (0.231)	Loss 1.2630 (1.8912)	Prec@1 59.375 (47.083)	Prec@5 93.750 (87.548)
Test on T test set - [0][400/1731]	Time 0.153 (0.229)	Loss 1.5574 (1.8723)	Prec@1 46.875 (47.475)	Prec@5 100.000 (87.804)
Test on T test set - [0][410/1731]	Time 0.162 (0.227)	Loss 1.2267 (1.8581)	Prec@1 59.375 (47.780)	Prec@5 96.875 (88.032)
Test on T test set - [0][420/1731]	Time 0.159 (0.226)	Loss 1.7810 (1.8452)	Prec@1 50.000 (48.011)	Prec@5 90.625 (88.175)
Test on T test set - [0][430/1731]	Time 0.159 (0.224)	Loss 1.3269 (1.8294)	Prec@1 62.500 (48.376)	Prec@5 90.625 (88.348)
Test on T test set - [0][440/1731]	Time 0.151 (0.223)	Loss 0.7442 (1.8111)	Prec@1 68.750 (48.767)	Prec@5 96.875 (88.549)
Test on T test set - [0][450/1731]	Time 0.198 (0.228)	Loss 1.2198 (1.7932)	Prec@1 59.375 (49.210)	Prec@5 96.875 (88.747)
Test on T test set - [0][460/1731]	Time 0.164 (0.227)	Loss 0.7379 (1.7745)	Prec@1 78.125 (49.756)	Prec@5 96.875 (88.971)
Test on T test set - [0][470/1731]	Time 0.154 (0.225)	Loss 0.6265 (1.7586)	Prec@1 81.250 (50.133)	Prec@5 96.875 (89.159)
Test on T test set - [0][480/1731]	Time 0.158 (0.224)	Loss 1.2429 (1.7433)	Prec@1 62.500 (50.494)	Prec@5 96.875 (89.352)
Test on T test set - [0][490/1731]	Time 0.166 (0.223)	Loss 1.0617 (1.7284)	Prec@1 68.750 (50.815)	Prec@5 96.875 (89.530)
Test on T test set - [0][500/1731]	Time 0.163 (0.222)	Loss 0.5852 (1.7138)	Prec@1 81.250 (51.223)	Prec@5 100.000 (89.689)
Test on T test set - [0][510/1731]	Time 0.159 (0.220)	Loss 1.0986 (1.7051)	Prec@1 78.125 (51.498)	Prec@5 93.750 (89.793)
Test on T test set - [0][520/1731]	Time 0.151 (0.219)	Loss 1.7007 (1.7011)	Prec@1 50.000 (51.542)	Prec@5 96.875 (89.893)
Test on T test set - [0][530/1731]	Time 0.164 (0.218)	Loss 1.5835 (1.6976)	Prec@1 50.000 (51.571)	Prec@5 90.625 (89.966)
Test on T test set - [0][540/1731]	Time 0.163 (0.217)	Loss 0.8404 (1.6924)	Prec@1 78.125 (51.664)	Prec@5 100.000 (90.053)
Test on T test set - [0][550/1731]	Time 0.148 (0.216)	Loss 1.5448 (1.6877)	Prec@1 59.375 (51.758)	Prec@5 90.625 (90.137)
Test on T test set - [0][560/1731]	Time 0.170 (0.215)	Loss 2.3289 (1.6916)	Prec@1 28.125 (51.554)	Prec@5 84.375 (90.090)
Test on T test set - [0][570/1731]	Time 0.195 (0.214)	Loss 1.2341 (1.6857)	Prec@1 65.625 (51.691)	Prec@5 96.875 (90.160)
Test on T test set - [0][580/1731]	Time 0.164 (0.218)	Loss 0.6398 (1.6767)	Prec@1 78.125 (51.883)	Prec@5 100.000 (90.270)
Test on T test set - [0][590/1731]	Time 0.180 (0.217)	Loss 0.9653 (1.6646)	Prec@1 75.000 (52.194)	Prec@5 96.875 (90.398)
Test on T test set - [0][600/1731]	Time 0.160 (0.217)	Loss 1.0720 (1.6544)	Prec@1 68.750 (52.480)	Prec@5 100.000 (90.479)
Test on T test set - [0][610/1731]	Time 0.166 (0.216)	Loss 0.7500 (1.6422)	Prec@1 78.125 (52.772)	Prec@5 96.875 (90.584)
Test on T test set - [0][620/1731]	Time 0.176 (0.215)	Loss 1.1687 (1.6316)	Prec@1 59.375 (53.014)	Prec@5 96.875 (90.675)
Test on T test set - [0][630/1731]	Time 0.159 (0.215)	Loss 0.7685 (1.6221)	Prec@1 84.375 (53.269)	Prec@5 93.750 (90.769)
Test on T test set - [0][640/1731]	Time 0.155 (0.214)	Loss 0.7385 (1.6137)	Prec@1 81.250 (53.496)	Prec@5 100.000 (90.844)
Test on T test set - [0][650/1731]	Time 0.156 (0.213)	Loss 1.2810 (1.6029)	Prec@1 56.250 (53.759)	Prec@5 93.750 (90.942)
Test on T test set - [0][660/1731]	Time 0.176 (0.212)	Loss 1.1876 (1.5937)	Prec@1 59.375 (53.976)	Prec@5 87.500 (91.036)
Test on T test set - [0][670/1731]	Time 0.167 (0.211)	Loss 1.1276 (1.5860)	Prec@1 71.875 (54.182)	Prec@5 96.875 (91.133)
Test on T test set - [0][680/1731]	Time 0.160 (0.211)	Loss 1.5007 (1.5788)	Prec@1 53.125 (54.341)	Prec@5 93.750 (91.217)
Test on T test set - [0][690/1731]	Time 0.262 (0.214)	Loss 3.8980 (1.5853)	Prec@1 3.125 (54.215)	Prec@5 50.000 (91.064)
Test on T test set - [0][700/1731]	Time 0.157 (0.213)	Loss 3.4508 (1.6152)	Prec@1 15.625 (53.620)	Prec@5 37.500 (90.384)
Test on T test set - [0][710/1731]	Time 0.167 (0.213)	Loss 3.0774 (1.6310)	Prec@1 28.125 (53.314)	Prec@5 56.250 (89.983)
Test on T test set - [0][720/1731]	Time 0.165 (0.212)	Loss 2.1291 (1.6429)	Prec@1 43.750 (53.073)	Prec@5 75.000 (89.732)
Test on T test set - [0][730/1731]	Time 0.214 (0.212)	Loss 1.6316 (1.6526)	Prec@1 56.250 (52.864)	Prec@5 96.875 (89.492)
Test on T test set - [0][740/1731]	Time 0.221 (0.212)	Loss 2.3387 (1.6560)	Prec@1 34.375 (52.783)	Prec@5 81.250 (89.415)
Test on T test set - [0][750/1731]	Time 0.189 (0.212)	Loss 1.7173 (1.6599)	Prec@1 56.250 (52.684)	Prec@5 81.250 (89.293)
Test on T test set - [0][760/1731]	Time 0.232 (0.212)	Loss 1.3352 (1.6642)	Prec@1 56.250 (52.575)	Prec@5 93.750 (89.184)
Test on T test set - [0][770/1731]	Time 0.201 (0.212)	Loss 2.0145 (1.6682)	Prec@1 40.625 (52.489)	Prec@5 75.000 (89.052)
Test on T test set - [0][780/1731]	Time 0.237 (0.216)	Loss 1.8688 (1.6762)	Prec@1 43.750 (52.329)	Prec@5 78.125 (88.852)
Test on T test set - [0][790/1731]	Time 0.221 (0.216)	Loss 1.8607 (1.6821)	Prec@1 56.250 (52.224)	Prec@5 87.500 (88.733)
Test on T test set - [0][800/1731]	Time 0.199 (0.216)	Loss 2.3959 (1.6861)	Prec@1 43.750 (52.138)	Prec@5 75.000 (88.643)
Test on T test set - [0][810/1731]	Time 0.205 (0.216)	Loss 2.5251 (1.6937)	Prec@1 37.500 (51.988)	Prec@5 59.375 (88.436)
Test on T test set - [0][820/1731]	Time 0.216 (0.216)	Loss 1.9732 (1.6981)	Prec@1 40.625 (51.884)	Prec@5 87.500 (88.326)
Test on T test set - [0][830/1731]	Time 0.196 (0.215)	Loss 1.8643 (1.7030)	Prec@1 53.125 (51.805)	Prec@5 81.250 (88.188)
Test on T test set - [0][840/1731]	Time 0.168 (0.215)	Loss 2.3673 (1.7093)	Prec@1 31.250 (51.635)	Prec@5 68.750 (88.046)
Test on T test set - [0][850/1731]	Time 0.150 (0.214)	Loss 3.5951 (1.7321)	Prec@1 0.000 (51.072)	Prec@5 50.000 (87.654)
Test on T test set - [0][860/1731]	Time 0.166 (0.214)	Loss 3.3547 (1.7547)	Prec@1 9.375 (50.512)	Prec@5 56.250 (87.242)
Test on T test set - [0][870/1731]	Time 0.165 (0.216)	Loss 3.6892 (1.7752)	Prec@1 3.125 (50.004)	Prec@5 50.000 (86.840)
Test on T test set - [0][880/1731]	Time 0.175 (0.216)	Loss 3.2513 (1.7952)	Prec@1 9.375 (49.503)	Prec@5 53.125 (86.475)
Test on T test set - [0][890/1731]	Time 0.162 (0.215)	Loss 3.5714 (1.8154)	Prec@1 9.375 (49.028)	Prec@5 50.000 (86.104)
Test on T test set - [0][900/1731]	Time 0.165 (0.215)	Loss 3.4581 (1.8364)	Prec@1 12.500 (48.550)	Prec@5 59.375 (85.738)
Test on T test set - [0][910/1731]	Time 0.171 (0.214)	Loss 1.0196 (1.8391)	Prec@1 75.000 (48.508)	Prec@5 96.875 (85.620)
Test on T test set - [0][920/1731]	Time 0.156 (0.214)	Loss 0.9080 (1.8282)	Prec@1 68.750 (48.762)	Prec@5 100.000 (85.770)
Test on T test set - [0][930/1731]	Time 0.226 (0.214)	Loss 0.5307 (1.8155)	Prec@1 84.375 (49.097)	Prec@5 100.000 (85.922)
Test on T test set - [0][940/1731]	Time 0.242 (0.214)	Loss 0.4541 (1.8039)	Prec@1 87.500 (49.416)	Prec@5 100.000 (86.059)
Test on T test set - [0][950/1731]	Time 0.229 (0.214)	Loss 0.6414 (1.7915)	Prec@1 78.125 (49.744)	Prec@5 96.875 (86.195)
Test on T test set - [0][960/1731]	Time 0.213 (0.219)	Loss 1.0188 (1.7794)	Prec@1 68.750 (50.072)	Prec@5 100.000 (86.339)
Test on T test set - [0][970/1731]	Time 0.231 (0.219)	Loss 0.6182 (1.7668)	Prec@1 84.375 (50.402)	Prec@5 100.000 (86.477)
Test on T test set - [0][980/1731]	Time 0.204 (0.219)	Loss 0.7739 (1.7549)	Prec@1 68.750 (50.717)	Prec@5 100.000 (86.608)
Test on T test set - [0][990/1731]	Time 0.222 (0.219)	Loss 0.5877 (1.7432)	Prec@1 81.250 (51.037)	Prec@5 100.000 (86.743)
Test on T test set - [0][1000/1731]	Time 0.209 (0.219)	Loss 0.8444 (1.7319)	Prec@1 75.000 (51.342)	Prec@5 96.875 (86.873)
Test on T test set - [0][1010/1731]	Time 0.188 (0.219)	Loss 1.0995 (1.7222)	Prec@1 65.625 (51.604)	Prec@5 96.875 (86.987)
Test on T test set - [0][1020/1731]	Time 0.197 (0.219)	Loss 0.4713 (1.7121)	Prec@1 84.375 (51.861)	Prec@5 100.000 (87.102)
Test on T test set - [0][1030/1731]	Time 0.178 (0.218)	Loss 1.0506 (1.7029)	Prec@1 71.875 (52.094)	Prec@5 96.875 (87.221)
Test on T test set - [0][1040/1731]	Time 0.170 (0.221)	Loss 1.3351 (1.6943)	Prec@1 62.500 (52.329)	Prec@5 96.875 (87.332)
Test on T test set - [0][1050/1731]	Time 0.187 (0.220)	Loss 1.0176 (1.6884)	Prec@1 62.500 (52.444)	Prec@5 100.000 (87.435)
Test on T test set - [0][1060/1731]	Time 0.161 (0.220)	Loss 1.1016 (1.6839)	Prec@1 59.375 (52.504)	Prec@5 100.000 (87.535)
Test on T test set - [0][1070/1731]	Time 0.209 (0.219)	Loss 1.0734 (1.6787)	Prec@1 62.500 (52.582)	Prec@5 100.000 (87.640)
Test on T test set - [0][1080/1731]	Time 0.152 (0.219)	Loss 1.4632 (1.6715)	Prec@1 59.375 (52.772)	Prec@5 96.875 (87.746)
Test on T test set - [0][1090/1731]	Time 0.178 (0.219)	Loss 4.5700 (1.6785)	Prec@1 3.125 (52.658)	Prec@5 28.125 (87.540)
Test on T test set - [0][1100/1731]	Time 0.192 (0.218)	Loss 4.3117 (1.7001)	Prec@1 6.250 (52.254)	Prec@5 40.625 (87.094)
Test on T test set - [0][1110/1731]	Time 0.208 (0.218)	Loss 4.1120 (1.7230)	Prec@1 9.375 (51.825)	Prec@5 31.250 (86.566)
Test on T test set - [0][1120/1731]	Time 0.193 (0.218)	Loss 4.2944 (1.7457)	Prec@1 6.250 (51.425)	Prec@5 43.750 (86.084)
Test on T test set - [0][1130/1731]	Time 0.174 (0.218)	Loss 4.5017 (1.7671)	Prec@1 0.000 (51.022)	Prec@5 15.625 (85.621)
Test on T test set - [0][1140/1731]	Time 0.184 (0.218)	Loss 3.8787 (1.7892)	Prec@1 18.750 (50.613)	Prec@5 37.500 (85.164)
Test on T test set - [0][1150/1731]	Time 0.173 (0.218)	Loss 4.2310 (1.8103)	Prec@1 6.250 (50.214)	Prec@5 31.250 (84.695)
Test on T test set - [0][1160/1731]	Time 0.175 (0.218)	Loss 4.2478 (1.8307)	Prec@1 6.250 (49.841)	Prec@5 28.125 (84.254)
Test on T test set - [0][1170/1731]	Time 0.182 (0.217)	Loss 4.1229 (1.8504)	Prec@1 6.250 (49.464)	Prec@5 34.375 (83.820)
Test on T test set - [0][1180/1731]	Time 0.184 (0.217)	Loss 4.4261 (1.8710)	Prec@1 0.000 (49.077)	Prec@5 25.000 (83.383)
Test on T test set - [0][1190/1731]	Time 0.186 (0.217)	Loss 4.2587 (1.8910)	Prec@1 6.250 (48.701)	Prec@5 34.375 (82.942)
Test on T test set - [0][1200/1731]	Time 0.188 (0.217)	Loss 4.2051 (1.9105)	Prec@1 3.125 (48.332)	Prec@5 31.250 (82.499)
Test on T test set - [0][1210/1731]	Time 0.192 (0.216)	Loss 4.0918 (1.9285)	Prec@1 12.500 (47.987)	Prec@5 37.500 (82.086)
Test on T test set - [0][1220/1731]	Time 0.168 (0.216)	Loss 1.6988 (1.9293)	Prec@1 50.000 (47.937)	Prec@5 81.250 (82.036)
Test on T test set - [0][1230/1731]	Time 0.156 (0.216)	Loss 1.8501 (1.9284)	Prec@1 43.750 (47.939)	Prec@5 90.625 (82.067)
Test on T test set - [0][1240/1731]	Time 0.168 (0.215)	Loss 1.4824 (1.9262)	Prec@1 53.125 (47.960)	Prec@5 90.625 (82.119)
Test on T test set - [0][1250/1731]	Time 0.174 (0.217)	Loss 0.9298 (1.9211)	Prec@1 68.750 (48.039)	Prec@5 93.750 (82.204)
Test on T test set - [0][1260/1731]	Time 0.196 (0.217)	Loss 1.4808 (1.9179)	Prec@1 56.250 (48.104)	Prec@5 87.500 (82.271)
Test on T test set - [0][1270/1731]	Time 0.169 (0.217)	Loss 0.9922 (1.9139)	Prec@1 65.625 (48.168)	Prec@5 100.000 (82.334)
Test on T test set - [0][1280/1731]	Time 0.185 (0.216)	Loss 1.0854 (1.9076)	Prec@1 65.625 (48.307)	Prec@5 93.750 (82.431)
Test on T test set - [0][1290/1731]	Time 0.165 (0.216)	Loss 1.7708 (1.9031)	Prec@1 46.875 (48.390)	Prec@5 84.375 (82.494)
Test on T test set - [0][1300/1731]	Time 0.166 (0.216)	Loss 1.3853 (1.8992)	Prec@1 62.500 (48.472)	Prec@5 81.250 (82.574)
Test on T test set - [0][1310/1731]	Time 0.184 (0.215)	Loss 1.3275 (1.8939)	Prec@1 62.500 (48.589)	Prec@5 87.500 (82.656)
Test on T test set - [0][1320/1731]	Time 0.193 (0.215)	Loss 1.1076 (1.8880)	Prec@1 59.375 (48.730)	Prec@5 100.000 (82.759)
Test on T test set - [0][1330/1731]	Time 0.167 (0.215)	Loss 1.3617 (1.8836)	Prec@1 62.500 (48.817)	Prec@5 87.500 (82.818)
Test on T test set - [0][1340/1731]	Time 0.160 (0.214)	Loss 0.7612 (1.8804)	Prec@1 84.375 (48.888)	Prec@5 96.875 (82.888)
Test on T test set - [0][1350/1731]	Time 0.175 (0.216)	Loss 0.9861 (1.8759)	Prec@1 75.000 (48.985)	Prec@5 93.750 (82.962)
Test on T test set - [0][1360/1731]	Time 0.160 (0.215)	Loss 3.7555 (1.8834)	Prec@1 6.250 (48.806)	Prec@5 53.125 (82.816)
Test on T test set - [0][1370/1731]	Time 0.153 (0.215)	Loss 3.0486 (1.8919)	Prec@1 15.625 (48.580)	Prec@5 62.500 (82.652)
Test on T test set - [0][1380/1731]	Time 0.161 (0.214)	Loss 3.0195 (1.8977)	Prec@1 21.875 (48.421)	Prec@5 71.875 (82.560)
Test on T test set - [0][1390/1731]	Time 0.163 (0.214)	Loss 3.3361 (1.9063)	Prec@1 18.750 (48.207)	Prec@5 62.500 (82.416)
Test on T test set - [0][1400/1731]	Time 0.175 (0.214)	Loss 2.8425 (1.9139)	Prec@1 18.750 (48.013)	Prec@5 75.000 (82.323)
Test on T test set - [0][1410/1731]	Time 0.172 (0.213)	Loss 3.0818 (1.9222)	Prec@1 21.875 (47.799)	Prec@5 56.250 (82.174)
Test on T test set - [0][1420/1731]	Time 0.160 (0.213)	Loss 2.6252 (1.9301)	Prec@1 31.250 (47.612)	Prec@5 65.625 (82.004)
Test on T test set - [0][1430/1731]	Time 0.208 (0.213)	Loss 0.4992 (1.9306)	Prec@1 81.250 (47.600)	Prec@5 100.000 (81.975)
Test on T test set - [0][1440/1731]	Time 0.239 (0.213)	Loss 0.2584 (1.9194)	Prec@1 90.625 (47.896)	Prec@5 100.000 (82.094)
Test on T test set - [0][1450/1731]	Time 0.228 (0.215)	Loss 0.3979 (1.9089)	Prec@1 93.750 (48.176)	Prec@5 100.000 (82.206)
Test on T test set - [0][1460/1731]	Time 0.243 (0.215)	Loss 0.2759 (1.8992)	Prec@1 90.625 (48.417)	Prec@5 100.000 (82.324)
Test on T test set - [0][1470/1731]	Time 0.235 (0.215)	Loss 0.6860 (1.8897)	Prec@1 81.250 (48.657)	Prec@5 96.875 (82.431)
Test on T test set - [0][1480/1731]	Time 0.246 (0.216)	Loss 0.2378 (1.8794)	Prec@1 90.625 (48.918)	Prec@5 96.875 (82.548)
Test on T test set - [0][1490/1731]	Time 0.225 (0.216)	Loss 0.5551 (1.8697)	Prec@1 75.000 (49.172)	Prec@5 100.000 (82.661)
Test on T test set - [0][1500/1731]	Time 0.240 (0.216)	Loss 0.4577 (1.8608)	Prec@1 81.250 (49.405)	Prec@5 100.000 (82.772)
Test on T test set - [0][1510/1731]	Time 0.223 (0.216)	Loss 0.4817 (1.8518)	Prec@1 75.000 (49.622)	Prec@5 100.000 (82.882)
Test on T test set - [0][1520/1731]	Time 0.235 (0.217)	Loss 0.6378 (1.8429)	Prec@1 81.250 (49.848)	Prec@5 100.000 (82.988)
Test on T test set - [0][1530/1731]	Time 0.222 (0.217)	Loss 0.3061 (1.8341)	Prec@1 90.625 (50.078)	Prec@5 100.000 (83.097)
Test on T test set - [0][1540/1731]	Time 0.187 (0.217)	Loss 0.9294 (1.8272)	Prec@1 68.750 (50.251)	Prec@5 96.875 (83.189)
Test on T test set - [0][1550/1731]	Time 0.247 (0.217)	Loss 0.5241 (1.8220)	Prec@1 81.250 (50.365)	Prec@5 96.875 (83.275)
Test on T test set - [0][1560/1731]	Time 0.189 (0.217)	Loss 3.9457 (1.8213)	Prec@1 0.000 (50.402)	Prec@5 62.500 (83.292)
Test on T test set - [0][1570/1731]	Time 0.196 (0.217)	Loss 3.8311 (1.8334)	Prec@1 9.375 (50.149)	Prec@5 71.875 (83.178)
Test on T test set - [0][1580/1731]	Time 0.160 (0.217)	Loss 2.9830 (1.8447)	Prec@1 25.000 (49.915)	Prec@5 78.125 (83.078)
Test on T test set - [0][1590/1731]	Time 0.160 (0.217)	Loss 3.6101 (1.8562)	Prec@1 15.625 (49.674)	Prec@5 68.750 (82.963)
Test on T test set - [0][1600/1731]	Time 0.182 (0.216)	Loss 3.8374 (1.8691)	Prec@1 15.625 (49.416)	Prec@5 75.000 (82.895)
Test on T test set - [0][1610/1731]	Time 0.173 (0.216)	Loss 4.1909 (1.8820)	Prec@1 9.375 (49.162)	Prec@5 59.375 (82.777)
Test on T test set - [0][1620/1731]	Time 0.184 (0.217)	Loss 3.3529 (1.8935)	Prec@1 9.375 (48.911)	Prec@5 68.750 (82.682)
Test on T test set - [0][1630/1731]	Time 0.172 (0.217)	Loss 4.2578 (1.9059)	Prec@1 9.375 (48.655)	Prec@5 62.500 (82.530)
Test on T test set - [0][1640/1731]	Time 0.213 (0.217)	Loss 4.0331 (1.9178)	Prec@1 6.250 (48.410)	Prec@5 65.625 (82.429)
Test on T test set - [0][1650/1731]	Time 0.218 (0.217)	Loss 3.4128 (1.9265)	Prec@1 6.250 (48.209)	Prec@5 81.250 (82.403)
Test on T test set - [0][1660/1731]	Time 0.211 (0.217)	Loss 2.9199 (1.9355)	Prec@1 18.750 (48.011)	Prec@5 75.000 (82.373)
Test on T test set - [0][1670/1731]	Time 0.210 (0.217)	Loss 3.5023 (1.9441)	Prec@1 15.625 (47.829)	Prec@5 78.125 (82.338)
Test on T test set - [0][1680/1731]	Time 0.192 (0.217)	Loss 3.2043 (1.9525)	Prec@1 21.875 (47.637)	Prec@5 87.500 (82.306)
Test on T test set - [0][1690/1731]	Time 0.214 (0.217)	Loss 3.1877 (1.9611)	Prec@1 18.750 (47.466)	Prec@5 78.125 (82.307)
Test on T test set - [0][1700/1731]	Time 0.216 (0.217)	Loss 3.1536 (1.9702)	Prec@1 21.875 (47.285)	Prec@5 87.500 (82.290)
Test on T test set - [0][1710/1731]	Time 0.225 (0.219)	Loss 3.7108 (1.9783)	Prec@1 9.375 (47.111)	Prec@5 78.125 (82.265)
Test on T test set - [0][1720/1731]	Time 0.196 (0.219)	Loss 3.5609 (1.9863)	Prec@1 12.500 (46.935)	Prec@5 65.625 (82.225)
Test on T test set - [0][1730/1731]	Time 0.165 (0.219)	Loss 3.8106 (1.9936)	Prec@1 3.571 (46.766)	Prec@5 75.000 (82.197)
 * Test on T test set - Prec@1 46.766, Prec@5 82.197
Epoch 0 - Kernel K-means clustering 0: Clustering time 42.481, Prec@1 50.125
Epoch 0 - Kernel K-means clustering 1: Clustering time 40.529, Prec@1 50.872
Epoch 0 - Kernel K-means clustering 2: Clustering time 40.337, Prec@1 51.118
Epoch 0 - Kernel K-means clustering 3: Clustering time 40.436, Prec@1 51.224
Epoch 0 - Kernel K-means clustering 4: Clustering time 40.184, Prec@1 51.320
Epoch 0 - Kernel K-means clustering 5: Clustering time 40.195, Prec@1 51.452
Epoch 0 - Kernel K-means clustering 6: Clustering time 40.302, Prec@1 51.504
Epoch 0 - Kernel K-means clustering 7: Clustering time 40.074, Prec@1 51.591
Epoch 0 - Kernel K-means clustering 8: Clustering time 40.409, Prec@1 51.672
Epoch 0 - Kernel K-means clustering 9: Clustering time 40.021, Prec@1 51.721
Epoch 0 - Kernel K-means clustering 10: Clustering time 40.637, Prec@1 51.708
Epoch 0 - Kernel K-means clustering 11: Clustering time 42.444, Prec@1 51.652
Epoch 0 - Kernel K-means clustering 12: Clustering time 40.440, Prec@1 51.551
Epoch 0 - Kernel K-means clustering 13: Clustering time 40.299, Prec@1 51.441
Epoch 0 - Kernel K-means clustering 14: Clustering time 40.797, Prec@1 51.314
Epoch 0 - Kernel K-means clustering 15: Clustering time 41.850, Prec@1 51.211
Epoch 0 - Kernel K-means clustering 16: Clustering time 41.384, Prec@1 51.109
Epoch 0 - Kernel K-means clustering 17: Clustering time 41.729, Prec@1 51.096
Epoch 0 - Kernel K-means clustering 18: Clustering time 39.865, Prec@1 51.065
Epoch 0 - Kernel K-means clustering 19: Clustering time 40.164, Prec@1 51.067
Epoch 0 - Kernel K-means clustering 20: Clustering time 39.874, Prec@1 51.058
Epoch 0 - Kernel K-means clustering 21: Clustering time 40.280, Prec@1 51.065
Epoch 0 - Kernel K-means clustering 22: Clustering time 40.049, Prec@1 51.058
Epoch 0 - Kernel K-means clustering 23: Clustering time 40.117, Prec@1 51.040
Epoch 0 - Kernel K-means clustering 24: Clustering time 40.044, Prec@1 51.058
Epoch 0 - Kernel K-means clustering 25: Clustering time 40.101, Prec@1 51.067
Epoch 0 - Kernel K-means clustering 26: Clustering time 40.131, Prec@1 51.072
Epoch 0 - Kernel K-means clustering 27: Clustering time 40.057, Prec@1 51.081
Epoch 0 - Kernel K-means clustering 28: Clustering time 40.136, Prec@1 51.089
Epoch 0 - Kernel K-means clustering 29: Clustering time 39.897, Prec@1 51.089
Epoch 0 - Kernel K-means clustering 30: Clustering time 40.236, Prec@1 51.092
Epoch 0 - Kernel K-means clustering 31: Clustering time 43.364, Prec@1 51.103
Epoch 0 - Kernel K-means clustering 32: Clustering time 40.142, Prec@1 51.109
Epoch 0 - Kernel K-means clustering 33: Clustering time 40.163, Prec@1 51.114
Epoch 0 - Kernel K-means clustering 34: Clustering time 42.986, Prec@1 51.123
Epoch 0 - Kernel K-means clustering 35: Clustering time 40.031, Prec@1 51.136
Epoch 0 - Kernel K-means clustering 36: Clustering time 40.167, Prec@1 51.143
Epoch 0 - Kernel K-means clustering 37: Clustering time 40.014, Prec@1 51.141
Epoch 0 - Kernel K-means clustering 38: Clustering time 40.049, Prec@1 51.145
Epoch 0 - Kernel K-means clustering 39: Clustering time 40.208, Prec@1 51.143
Epoch 0 - Kernel K-means clustering 40: Clustering time 40.191, Prec@1 51.145
Epoch 0 - Kernel K-means clustering 41: Clustering time 40.151, Prec@1 51.152
Epoch 0 - Kernel K-means clustering 42: Clustering time 41.598, Prec@1 51.154
Epoch 0 - Kernel K-means clustering 43: Clustering time 40.083, Prec@1 51.154
Epoch 0 - Kernel K-means clustering 44: Clustering time 39.879, Prec@1 51.155
Epoch 0 - Kernel K-means clustering 45: Clustering time 39.950, Prec@1 51.155
Converged at iteration 46
Epoch 0 - Kernel K-means clustering 0: Clustering time 42.335, Prec@1 48.476
Epoch 0 - Kernel K-means clustering 1: Clustering time 41.546, Prec@1 48.855
Epoch 0 - Kernel K-means clustering 2: Clustering time 40.892, Prec@1 48.361
Epoch 0 - Kernel K-means clustering 3: Clustering time 41.555, Prec@1 47.754
Epoch 0 - Kernel K-means clustering 4: Clustering time 41.024, Prec@1 47.413
Epoch 0 - Kernel K-means clustering 5: Clustering time 41.240, Prec@1 47.227
Epoch 0 - Kernel K-means clustering 6: Clustering time 41.139, Prec@1 47.153
Epoch 0 - Kernel K-means clustering 7: Clustering time 41.260, Prec@1 47.109
Epoch 0 - Kernel K-means clustering 8: Clustering time 41.104, Prec@1 47.064
Epoch 0 - Kernel K-means clustering 9: Clustering time 41.132, Prec@1 47.034
Epoch 0 - Kernel K-means clustering 10: Clustering time 41.255, Prec@1 47.025
Epoch 0 - Kernel K-means clustering 11: Clustering time 44.352, Prec@1 46.969
Epoch 0 - Kernel K-means clustering 12: Clustering time 43.135, Prec@1 46.931
Epoch 0 - Kernel K-means clustering 13: Clustering time 44.147, Prec@1 46.913
Epoch 0 - Kernel K-means clustering 14: Clustering time 41.161, Prec@1 46.896
Epoch 0 - Kernel K-means clustering 15: Clustering time 41.192, Prec@1 46.864
Epoch 0 - Kernel K-means clustering 16: Clustering time 41.459, Prec@1 46.844
Epoch 0 - Kernel K-means clustering 17: Clustering time 42.854, Prec@1 46.833
Epoch 0 - Kernel K-means clustering 18: Clustering time 41.160, Prec@1 46.821
Epoch 0 - Kernel K-means clustering 19: Clustering time 41.170, Prec@1 46.806
Epoch 0 - Kernel K-means clustering 20: Clustering time 41.139, Prec@1 46.788
Epoch 0 - Kernel K-means clustering 21: Clustering time 41.209, Prec@1 46.772
Epoch 0 - Kernel K-means clustering 22: Clustering time 41.374, Prec@1 46.745
Epoch 0 - Kernel K-means clustering 23: Clustering time 40.993, Prec@1 46.743
Epoch 0 - Kernel K-means clustering 24: Clustering time 41.254, Prec@1 46.725
Epoch 0 - Kernel K-means clustering 25: Clustering time 41.187, Prec@1 46.712
Epoch 0 - Kernel K-means clustering 26: Clustering time 41.172, Prec@1 46.703
Epoch 0 - Kernel K-means clustering 27: Clustering time 41.137, Prec@1 46.680
Epoch 0 - Kernel K-means clustering 28: Clustering time 41.159, Prec@1 46.667
Epoch 0 - Kernel K-means clustering 29: Clustering time 41.038, Prec@1 46.645
Epoch 0 - Kernel K-means clustering 30: Clustering time 41.306, Prec@1 46.629
Epoch 0 - Kernel K-means clustering 31: Clustering time 41.095, Prec@1 46.617
Epoch 0 - Kernel K-means clustering 32: Clustering time 42.951, Prec@1 46.602
Epoch 0 - Kernel K-means clustering 33: Clustering time 41.096, Prec@1 46.582
Epoch 0 - Kernel K-means clustering 34: Clustering time 41.218, Prec@1 46.570
Epoch 0 - Kernel K-means clustering 35: Clustering time 41.142, Prec@1 46.559
Epoch 0 - Kernel K-means clustering 36: Clustering time 42.020, Prec@1 46.543
Epoch 0 - Kernel K-means clustering 37: Clustering time 41.055, Prec@1 46.532
Epoch 0 - Kernel K-means clustering 38: Clustering time 41.356, Prec@1 46.525
Epoch 0 - Kernel K-means clustering 39: Clustering time 40.908, Prec@1 46.528
Epoch 0 - Kernel K-means clustering 40: Clustering time 41.126, Prec@1 46.528
Converged at iteration 41
Train - epoch [1/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8340 (0.8340)
Train - epoch [1/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7516 (0.7516)
Train - epoch [1/200]	BT 3.410 (3.410)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7570 (0.7570)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7314 (0.7314)
Train - epoch [1/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8014 (0.8014)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7248 (0.7248)
Train - epoch [1/200]	BT 1.308 (1.308)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7740 (0.7740)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7511 (0.7511)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7753 (0.7753)
Train - epoch [1/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7340 (0.7340)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7939 (0.7939)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7488 (0.7488)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7359 (0.7359)
Train - epoch [1/200]	BT 1.336 (1.336)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7504 (0.7504)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7294 (0.7294)
Train - epoch [1/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7230 (0.7230)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7501 (0.7501)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8379 (0.8379)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7885 (0.7885)
Train - epoch [1/200]	BT 4.232 (4.232)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7361 (0.7361)
Train - epoch [1/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7670 (0.7670)
Train - epoch [1/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7483 (0.7483)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7470 (0.7470)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7439 (0.7439)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7994 (0.7994)
Train - epoch [1/200]	BT 1.306 (1.306)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7272 (0.7272)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7865 (0.7865)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8423 (0.8423)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.8815 (0.8815)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.8559 (0.8559)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7640 (0.7640)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7213 (0.7213)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7145 (0.7145)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7297 (0.7297)
Train - epoch [1/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7230 (0.7230)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7429 (0.7429)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7706 (0.7706)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7498 (0.7498)
Train - epoch [1/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7232 (0.7232)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8056 (0.8056)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7449 (0.7449)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8198 (0.8198)
Train - epoch [1/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7113 (0.7113)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7097 (0.7097)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7489 (0.7489)
Train - epoch [1/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7451 (0.7451)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8021 (0.8021)
Train - epoch [1/200]	BT 4.089 (4.089)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7281 (0.7281)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7043 (0.7043)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7225 (0.7225)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7883 (0.7883)
Train - epoch [1/200]	BT 4.316 (4.316)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7123 (0.7123)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7139 (0.7139)
Train - epoch [1/200]	BT 1.237 (1.237)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7478 (0.7478)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7139 (0.7139)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7247 (0.7247)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7208 (0.7208)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7103 (0.7103)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7755 (0.7755)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7187 (0.7187)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7169 (0.7169)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7608 (0.7608)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8109 (0.8109)
Train - epoch [1/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7736 (0.7736)
Train - epoch [1/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7239 (0.7239)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7242 (0.7242)
Train - epoch [1/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7029 (0.7029)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7112 (0.7112)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7775 (0.7775)
Train - epoch [1/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7436 (0.7436)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6991 (0.6991)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6982 (0.6982)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6985 (0.6985)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7315 (0.7315)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7179 (0.7179)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7496 (0.7496)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7710 (0.7710)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7111 (0.7111)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7238 (0.7238)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7161 (0.7161)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7236 (0.7236)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7119 (0.7119)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7073 (0.7073)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7185 (0.7185)
Train - epoch [1/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7305 (0.7305)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6949 (0.6949)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7061 (0.7061)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.8673 (0.8673)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7226 (0.7226)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7141 (0.7141)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6927 (0.6927)
Train - epoch [1/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7159 (0.7159)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7024 (0.7024)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7058 (0.7058)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7011 (0.7011)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6895 (0.6895)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7748 (0.7748)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7239 (0.7239)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7501 (0.7501)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7511 (0.7511)
Train - epoch [1/200]	BT 3.849 (3.849)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7232 (0.7232)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7084 (0.7084)
Train - epoch [1/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7035 (0.7035)
Train - epoch [1/200]	BT 1.308 (1.308)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6883 (0.6883)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7018 (0.7018)
Train - epoch [1/200]	BT 1.297 (1.297)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7099 (0.7099)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7358 (0.7358)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7145 (0.7145)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7171 (0.7171)
Train - epoch [1/200]	BT 3.837 (3.837)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7046 (0.7046)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6846 (0.6846)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6997 (0.6997)
Train - epoch [1/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6935 (0.6935)
Train - epoch [1/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7794 (0.7794)
Train - epoch [1/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7105 (0.7105)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8043 (0.8043)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7686 (0.7686)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6942 (0.6942)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7951 (0.7951)
Train - epoch [1/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7067 (0.7067)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6952 (0.6952)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7086 (0.7086)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6934 (0.6934)
Train - epoch [1/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7209 (0.7209)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7016 (0.7016)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8090 (0.8090)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7917 (0.7917)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7566 (0.7566)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7948 (0.7948)
Train - epoch [1/200]	BT 4.463 (4.463)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7966 (0.7966)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8417 (0.8417)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7768 (0.7768)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6858 (0.6858)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7113 (0.7113)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7662 (0.7662)
Train - epoch [1/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8212 (0.8212)
Train - epoch [1/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6934 (0.6934)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7282 (0.7282)
Train - epoch [1/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7140 (0.7140)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7412 (0.7412)
Train - epoch [1/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6909 (0.6909)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8341 (0.8341)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7042 (0.7042)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6810 (0.6810)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7188 (0.7188)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7393 (0.7393)
Train - epoch [1/200]	BT 4.110 (4.110)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6948 (0.6948)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6942 (0.6942)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7046 (0.7046)
Train - epoch [1/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7110 (0.7110)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6895 (0.6895)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7021 (0.7021)
Train - epoch [1/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.8198 (0.8198)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6845 (0.6845)
Train - epoch [1/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6896 (0.6896)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6827 (0.6827)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7201 (0.7201)
Train - epoch [1/200]	BT 4.337 (4.337)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6985 (0.6985)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6994 (0.6994)
Train - epoch [1/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7622 (0.7622)
Train - epoch [1/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7022 (0.7022)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6848 (0.6848)
Train - epoch [1/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6982 (0.6982)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6809 (0.6809)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.8071 (0.8071)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7045 (0.7045)
Train - epoch [1/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7068 (0.7068)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6800 (0.6800)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6943 (0.6943)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6860 (0.6860)
Train - epoch [1/200]	BT 4.401 (4.401)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6890 (0.6890)
Train - epoch [1/200]	BT 1.371 (1.371)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7226 (0.7226)
Train - epoch [1/200]	BT 1.244 (1.244)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7269 (0.7269)
Train - epoch [1/200]	BT 4.141 (4.141)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7037 (0.7037)
Train - epoch [1/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6614 (0.6614)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6871 (0.6871)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6696 (0.6696)
Train - epoch [1/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7662 (0.7662)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6626 (0.6626)
Train - epoch [1/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7002 (0.7002)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7041 (0.7041)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6743 (0.6743)
Train - epoch [1/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6901 (0.6901)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7065 (0.7065)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6617 (0.6617)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6884 (0.6884)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6879 (0.6879)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7297 (0.7297)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6912 (0.6912)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7200 (0.7200)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7511 (0.7511)
Train - epoch [1/200]	BT 4.819 (4.819)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6821 (0.6821)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6796 (0.6796)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6877 (0.6877)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6670 (0.6670)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6887 (0.6887)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7092 (0.7092)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7319 (0.7319)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6833 (0.6833)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6922 (0.6922)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6737 (0.6737)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7811 (0.7811)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6824 (0.6824)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6814 (0.6814)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6675 (0.6675)
Train - epoch [1/200]	BT 3.489 (3.489)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7505 (0.7505)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6742 (0.6742)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7560 (0.7560)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6937 (0.6937)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6958 (0.6958)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6947 (0.6947)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6817 (0.6817)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6688 (0.6688)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6843 (0.6843)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7032 (0.7032)
Train - epoch [1/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7064 (0.7064)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6785 (0.6785)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6790 (0.6790)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6716 (0.6716)
Train - epoch [1/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7261 (0.7261)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6943 (0.6943)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6595 (0.6595)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7119 (0.7119)
Train - epoch [1/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6703 (0.6703)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7159 (0.7159)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6639 (0.6639)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7104 (0.7104)
Train - epoch [1/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6701 (0.6701)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6642 (0.6642)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6664 (0.6664)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6705 (0.6705)
Train - epoch [1/200]	BT 4.424 (4.424)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7413 (0.7413)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6910 (0.6910)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7956 (0.7956)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6788 (0.6788)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7064 (0.7064)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6677 (0.6677)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6583 (0.6583)
Train - epoch [1/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.8633 (0.8633)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6597 (0.6597)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7155 (0.7155)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6657 (0.6657)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6610 (0.6610)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6620 (0.6620)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6604 (0.6604)
Train - epoch [1/200]	BT 4.557 (4.557)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6811 (0.6811)
Train - epoch [1/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7018 (0.7018)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7265 (0.7265)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7820 (0.7820)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7499 (0.7499)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7385 (0.7385)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6997 (0.6997)
Train - epoch [1/200]	BT 4.152 (4.152)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7571 (0.7571)
Train - epoch [1/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7597 (0.7597)
Train - epoch [1/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6947 (0.6947)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7578 (0.7578)
Train - epoch [1/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6637 (0.6637)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6703 (0.6703)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6759 (0.6759)
Train - epoch [1/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6594 (0.6594)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6511 (0.6511)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6558 (0.6558)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6852 (0.6852)
Train - epoch [1/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6612 (0.6612)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6690 (0.6690)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7059 (0.7059)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6717 (0.6717)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6710 (0.6710)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6591 (0.6591)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6954 (0.6954)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6527 (0.6527)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6461 (0.6461)
Train - epoch [1/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6553 (0.6553)
Train - epoch [1/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6768 (0.6768)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6525 (0.6525)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6808 (0.6808)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6822 (0.6822)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6694 (0.6694)
Train - epoch [1/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7587 (0.7587)
Train - epoch [1/200]	BT 4.565 (4.565)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6588 (0.6588)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6727 (0.6727)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6614 (0.6614)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6437 (0.6437)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7165 (0.7165)
Train - epoch [1/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6612 (0.6612)
Train - epoch [1/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6773 (0.6773)
Train - epoch [1/200]	BT 4.018 (4.018)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6633 (0.6633)
Train - epoch [1/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6913 (0.6913)
Train - epoch [1/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6358 (0.6358)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6495 (0.6495)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7425 (0.7425)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6575 (0.6575)
Train - epoch [1/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6598 (0.6598)
Train - epoch [1/200]	BT 3.982 (3.982)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7601 (0.7601)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7544 (0.7544)
Train - epoch [1/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6566 (0.6566)
Train - epoch [1/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6498 (0.6498)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6430 (0.6430)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7199 (0.7199)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7098 (0.7098)
Train - epoch [1/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6877 (0.6877)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6995 (0.6995)
Train - epoch [1/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6681 (0.6681)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6830 (0.6830)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7085 (0.7085)
Train - epoch [1/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6740 (0.6740)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7235 (0.7235)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6938 (0.6938)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6875 (0.6875)
Train - epoch [1/200]	BT 4.093 (4.093)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6651 (0.6651)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6503 (0.6503)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6588 (0.6588)
Train - epoch [1/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6536 (0.6536)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7093 (0.7093)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6510 (0.6510)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6616 (0.6616)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.8776 (0.8776)
Train - epoch [1/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6637 (0.6637)
Train - epoch [1/200]	BT 4.658 (4.658)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7536 (0.7536)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6595 (0.6595)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6687 (0.6687)
Train - epoch [1/200]	BT 4.138 (4.138)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6402 (0.6402)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6939 (0.6939)
Train - epoch [1/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7227 (0.7227)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7972 (0.7972)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6954 (0.6954)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6467 (0.6467)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6525 (0.6525)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6491 (0.6491)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6870 (0.6870)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6607 (0.6607)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6681 (0.6681)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6721 (0.6721)
Train - epoch [1/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6612 (0.6612)
Train - epoch [1/200]	BT 4.330 (4.330)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6382 (0.6382)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6907 (0.6907)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7435 (0.7435)
Train - epoch [1/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6400 (0.6400)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6598 (0.6598)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6843 (0.6843)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6943 (0.6943)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6554 (0.6554)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6459 (0.6459)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6841 (0.6841)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7420 (0.7420)
Train - epoch [1/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7774 (0.7774)
Train - epoch [1/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6977 (0.6977)
Train - epoch [1/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6587 (0.6587)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6670 (0.6670)
Train - epoch [1/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6778 (0.6778)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7244 (0.7244)
Train - epoch [1/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6770 (0.6770)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6679 (0.6679)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6430 (0.6430)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7226 (0.7226)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6916 (0.6916)
Train - epoch [1/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6480 (0.6480)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6495 (0.6495)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.8324 (0.8324)
Train - epoch [1/200]	BT 4.608 (4.608)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7164 (0.7164)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6530 (0.6530)
Train - epoch [1/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7092 (0.7092)
Train - epoch [1/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6431 (0.6431)
Train - epoch [1/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6420 (0.6420)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6411 (0.6411)
Train - epoch [1/200]	BT 1.306 (1.306)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6610 (0.6610)
Train - epoch [1/200]	BT 4.310 (4.310)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6443 (0.6443)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6478 (0.6478)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6636 (0.6636)
Train - epoch [1/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6301 (0.6301)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6728 (0.6728)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.8069 (0.8069)
Train - epoch [1/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6627 (0.6627)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7925 (0.7925)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6478 (0.6478)
Train - epoch [1/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6805 (0.6805)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6430 (0.6430)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7133 (0.7133)
Train - epoch [1/200]	BT 1.297 (1.297)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6523 (0.6523)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6581 (0.6581)
Train - epoch [1/200]	BT 3.946 (3.946)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6573 (0.6573)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7084 (0.7084)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6571 (0.6571)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6366 (0.6366)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6599 (0.6599)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6690 (0.6690)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6302 (0.6302)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.8100 (0.8100)
Train - epoch [1/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6507 (0.6507)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6478 (0.6478)
Train - epoch [1/200]	BT 3.840 (3.840)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6472 (0.6472)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6425 (0.6425)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6555 (0.6555)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6445 (0.6445)
Train - epoch [1/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6819 (0.6819)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6292 (0.6292)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.7176 (0.7176)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6713 (0.6713)
Train - epoch [1/200]	BT 4.243 (4.243)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6533 (0.6533)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.7513 (0.7513)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6308 (0.6308)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6361 (0.6361)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6842 (0.6842)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6370 (0.6370)
Train - epoch [1/200]	BT 4.601 (4.601)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6777 (0.6777)
Train - epoch [1/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6996 (0.6996)
Train - epoch [1/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6364 (0.6364)
Train - epoch [1/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7061 (0.7061)
Train - epoch [1/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6595 (0.6595)
Train - epoch [1/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6253 (0.6253)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7121 (0.7121)
Train - epoch [1/200]	BT 1.301 (1.301)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.7295 (0.7295)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6357 (0.6357)
Train - epoch [1/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6891 (0.6891)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6412 (0.6412)
Train - epoch [1/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6494 (0.6494)
Train - epoch [1/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 0.7035 (0.7035)
Train - epoch [1/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7050 (0.7050)
Train - epoch [1/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6802 (0.6802)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6366 (0.6366)
Train - epoch [1/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.8273 (0.8273)
Train - epoch [1/200]	BT 4.322 (4.322)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6451 (0.6451)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6477 (0.6477)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6779 (0.6779)
Train - epoch [1/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6462 (0.6462)
Train - epoch [1/200]	BT 1.333 (1.333)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7811 (0.7811)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6383 (0.6383)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 0.7281 (0.7281)
Train - epoch [1/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6710 (0.6710)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7591 (0.7591)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6541 (0.6541)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6658 (0.6658)
Train - epoch [1/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.7488 (0.7488)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7211 (0.7211)
Train - epoch [1/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6553 (0.6553)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 0.8575 (0.8575)
Train - epoch [1/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.7943 (0.7943)
Train - epoch [1/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6887 (0.6887)
Train - epoch [1/200]	BT 3.999 (3.999)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 0.7946 (0.7946)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 0.6554 (0.6554)
Train - epoch [1/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6285 (0.6285)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7231 (0.7231)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 0.9433 (0.9433)
Train - epoch [1/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6783 (0.6783)
Train - epoch [1/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7190 (0.7190)
Train - epoch [1/200]	BT 1.307 (1.307)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6539 (0.6539)
Train - epoch [1/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 0.8754 (0.8754)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6489 (0.6489)
Train - epoch [1/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6339 (0.6339)
Train - epoch [1/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6216 (0.6216)
Train - epoch [1/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6348 (0.6348)
Train - epoch [1/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.8161 (0.8161)
Train - epoch [1/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6437 (0.6437)
Train - epoch [1/200]	BT 1.466 (1.466)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6385 (0.6385)
Train - epoch [1/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6516 (0.6516)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7084 (0.7084)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7138 (0.7138)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6220 (0.6220)
Train - epoch [1/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6308 (0.6308)
Train - epoch [1/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6216 (0.6216)
Train - epoch [1/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6366 (0.6366)
Train - epoch [1/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6340 (0.6340)
Train - epoch [1/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.6519 (0.6519)
Train - epoch [1/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6229 (0.6229)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6472 (0.6472)
Train - epoch [1/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6288 (0.6288)
Train - epoch [1/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.7445 (0.7445)
Train - epoch [1/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 0.7157 (0.7157)
Train - epoch [1/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 0.6452 (0.6452)
Train - epoch [1/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6267 (0.6267)
Train - epoch [1/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 0.8473 (0.8473)
Train - epoch [1/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 0.7540 (0.7540)
Train - epoch [1/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 0.6681 (0.6681)
Train - epoch [1/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6461 (0.6461)
Train - epoch [1/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 0.6876 (0.6876)
Train - epoch [1/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 0.8293 (0.8293)
Test on T training set - [1][0/1731]	T 0.304 (0.304)	D 0.194 (0.194)	T@1 37.500 (37.500)	T@5 78.125 (78.125)	L 2.2662 (2.2662)
Test on T training set - [1][10/1731]	T 0.210 (0.205)	D 0.114 (0.102)	T@1 59.375 (57.670)	T@5 93.750 (84.943)	L 1.4104 (1.5239)
Test on T training set - [1][20/1731]	T 0.225 (0.215)	D 0.119 (0.112)	T@1 75.000 (63.542)	T@5 96.875 (89.583)	L 1.0066 (1.3150)
Test on T training set - [1][30/1731]	T 0.207 (0.215)	D 0.106 (0.112)	T@1 84.375 (66.734)	T@5 100.000 (91.734)	L 0.4433 (1.2042)
Test on T training set - [1][40/1731]	T 0.239 (0.216)	D 0.131 (0.113)	T@1 65.625 (67.226)	T@5 90.625 (92.607)	L 1.1794 (1.1737)
Test on T training set - [1][50/1731]	T 0.221 (0.217)	D 0.121 (0.114)	T@1 93.750 (67.586)	T@5 100.000 (93.199)	L 0.4685 (1.1465)
Test on T training set - [1][60/1731]	T 0.234 (0.261)	D 0.128 (0.159)	T@1 62.500 (67.982)	T@5 96.875 (93.904)	L 1.1736 (1.1266)
Test on T training set - [1][70/1731]	T 0.203 (0.254)	D 0.100 (0.152)	T@1 75.000 (67.958)	T@5 93.750 (94.058)	L 0.9555 (1.1299)
Test on T training set - [1][80/1731]	T 0.203 (0.249)	D 0.101 (0.147)	T@1 71.875 (68.133)	T@5 93.750 (94.097)	L 1.2028 (1.1310)
Test on T training set - [1][90/1731]	T 0.187 (0.244)	D 0.091 (0.142)	T@1 68.750 (68.647)	T@5 93.750 (94.265)	L 1.2479 (1.1146)
Test on T training set - [1][100/1731]	T 0.187 (0.239)	D 0.087 (0.137)	T@1 56.250 (68.657)	T@5 90.625 (94.090)	L 1.3274 (1.1196)
Test on T training set - [1][110/1731]	T 0.199 (0.234)	D 0.101 (0.132)	T@1 46.875 (67.202)	T@5 84.375 (93.131)	L 1.7187 (1.1755)
Test on T training set - [1][120/1731]	T 0.199 (0.231)	D 0.096 (0.129)	T@1 59.375 (65.263)	T@5 84.375 (92.614)	L 1.7776 (1.2496)
Test on T training set - [1][130/1731]	T 0.200 (0.228)	D 0.092 (0.126)	T@1 53.125 (63.740)	T@5 87.500 (92.128)	L 1.9581 (1.3157)
Test on T training set - [1][140/1731]	T 0.186 (0.226)	D 0.082 (0.124)	T@1 40.625 (62.234)	T@5 81.250 (91.711)	L 2.3608 (1.3719)
Test on T training set - [1][150/1731]	T 0.205 (0.224)	D 0.095 (0.121)	T@1 46.875 (61.134)	T@5 84.375 (91.411)	L 2.1305 (1.4242)
Test on T training set - [1][160/1731]	T 0.178 (0.238)	D 0.083 (0.136)	T@1 56.250 (60.520)	T@5 96.875 (91.246)	L 1.4392 (1.4509)
Test on T training set - [1][170/1731]	T 0.175 (0.235)	D 0.072 (0.132)	T@1 25.000 (59.302)	T@5 75.000 (90.954)	L 2.4688 (1.4954)
Test on T training set - [1][180/1731]	T 0.166 (0.231)	D 0.060 (0.129)	T@1 34.375 (57.977)	T@5 53.125 (90.073)	L 2.6468 (1.5486)
Test on T training set - [1][190/1731]	T 0.186 (0.228)	D 0.084 (0.126)	T@1 21.875 (56.594)	T@5 68.750 (89.365)	L 2.8281 (1.6005)
Test on T training set - [1][200/1731]	T 0.163 (0.225)	D 0.067 (0.123)	T@1 31.250 (55.162)	T@5 71.875 (88.355)	L 2.5986 (1.6549)
Test on T training set - [1][210/1731]	T 0.181 (0.222)	D 0.073 (0.120)	T@1 31.250 (53.940)	T@5 81.250 (87.693)	L 2.4762 (1.7049)
Test on T training set - [1][220/1731]	T 0.175 (0.221)	D 0.079 (0.119)	T@1 43.750 (53.125)	T@5 96.875 (87.387)	L 1.9370 (1.7384)
Test on T training set - [1][230/1731]	T 0.185 (0.219)	D 0.078 (0.117)	T@1 53.125 (52.773)	T@5 96.875 (87.608)	L 1.4649 (1.7417)
Test on T training set - [1][240/1731]	T 0.228 (0.219)	D 0.132 (0.118)	T@1 84.375 (53.916)	T@5 100.000 (88.045)	L 0.4371 (1.6983)
Test on T training set - [1][250/1731]	T 0.216 (0.220)	D 0.107 (0.118)	T@1 84.375 (54.880)	T@5 100.000 (88.459)	L 0.6802 (1.6593)
Test on T training set - [1][260/1731]	T 0.234 (0.232)	D 0.138 (0.130)	T@1 87.500 (55.843)	T@5 96.875 (88.865)	L 0.5008 (1.6228)
Test on T training set - [1][270/1731]	T 0.243 (0.232)	D 0.139 (0.130)	T@1 75.000 (56.642)	T@5 100.000 (89.253)	L 0.6310 (1.5881)
Test on T training set - [1][280/1731]	T 0.237 (0.232)	D 0.131 (0.130)	T@1 68.750 (57.440)	T@5 96.875 (89.602)	L 0.9254 (1.5575)
Test on T training set - [1][290/1731]	T 0.232 (0.231)	D 0.136 (0.130)	T@1 84.375 (58.183)	T@5 100.000 (89.927)	L 0.4018 (1.5269)
Test on T training set - [1][300/1731]	T 0.223 (0.231)	D 0.117 (0.130)	T@1 78.125 (58.918)	T@5 100.000 (90.241)	L 0.8204 (1.5000)
Test on T training set - [1][310/1731]	T 0.238 (0.231)	D 0.129 (0.129)	T@1 78.125 (59.556)	T@5 100.000 (90.464)	L 0.7377 (1.4735)
Test on T training set - [1][320/1731]	T 0.198 (0.231)	D 0.097 (0.129)	T@1 96.875 (60.134)	T@5 100.000 (90.713)	L 0.3638 (1.4507)
Test on T training set - [1][330/1731]	T 0.197 (0.230)	D 0.100 (0.128)	T@1 78.125 (60.602)	T@5 100.000 (90.927)	L 0.7092 (1.4325)
Test on T training set - [1][340/1731]	T 0.200 (0.236)	D 0.094 (0.135)	T@1 59.375 (60.328)	T@5 93.750 (90.946)	L 1.4151 (1.4383)
Test on T training set - [1][350/1731]	T 0.199 (0.235)	D 0.104 (0.133)	T@1 71.875 (60.345)	T@5 96.875 (91.079)	L 0.9188 (1.4345)
Test on T training set - [1][360/1731]	T 0.240 (0.235)	D 0.141 (0.133)	T@1 87.500 (60.968)	T@5 100.000 (91.292)	L 0.4626 (1.4106)
Test on T training set - [1][370/1731]	T 0.176 (0.234)	D 0.075 (0.133)	T@1 37.500 (61.237)	T@5 59.375 (91.265)	L 2.3261 (1.3990)
Test on T training set - [1][380/1731]	T 0.198 (0.233)	D 0.092 (0.131)	T@1 68.750 (60.876)	T@5 90.625 (90.805)	L 1.0907 (1.4136)
Test on T training set - [1][390/1731]	T 0.177 (0.232)	D 0.072 (0.130)	T@1 59.375 (61.053)	T@5 78.125 (90.697)	L 1.6559 (1.4078)
Test on T training set - [1][400/1731]	T 0.170 (0.230)	D 0.062 (0.128)	T@1 46.875 (60.895)	T@5 68.750 (90.360)	L 1.7699 (1.4159)
Test on T training set - [1][410/1731]	T 0.169 (0.229)	D 0.064 (0.127)	T@1 53.125 (60.789)	T@5 78.125 (90.024)	L 1.6342 (1.4214)
Test on T training set - [1][420/1731]	T 0.173 (0.227)	D 0.068 (0.126)	T@1 37.500 (60.444)	T@5 56.250 (89.489)	L 2.4143 (1.4363)
Test on T training set - [1][430/1731]	T 0.168 (0.233)	D 0.066 (0.131)	T@1 46.875 (60.376)	T@5 78.125 (89.153)	L 1.8382 (1.4417)
Test on T training set - [1][440/1731]	T 0.155 (0.231)	D 0.058 (0.129)	T@1 71.875 (60.410)	T@5 81.250 (88.967)	L 1.2599 (1.4414)
Test on T training set - [1][450/1731]	T 0.168 (0.230)	D 0.066 (0.128)	T@1 75.000 (60.553)	T@5 93.750 (88.900)	L 1.1041 (1.4380)
Test on T training set - [1][460/1731]	T 0.176 (0.229)	D 0.071 (0.127)	T@1 75.000 (60.677)	T@5 93.750 (88.869)	L 0.9438 (1.4350)
Test on T training set - [1][470/1731]	T 0.157 (0.228)	D 0.055 (0.126)	T@1 78.125 (60.755)	T@5 87.500 (88.761)	L 0.9122 (1.4325)
Test on T training set - [1][480/1731]	T 0.161 (0.226)	D 0.056 (0.125)	T@1 65.625 (60.863)	T@5 93.750 (88.734)	L 1.4642 (1.4289)
Test on T training set - [1][490/1731]	T 0.162 (0.225)	D 0.058 (0.123)	T@1 50.000 (60.883)	T@5 78.125 (88.595)	L 1.9585 (1.4303)
Test on T training set - [1][500/1731]	T 0.171 (0.224)	D 0.070 (0.122)	T@1 65.625 (60.903)	T@5 90.625 (88.486)	L 1.1289 (1.4302)
Test on T training set - [1][510/1731]	T 0.173 (0.223)	D 0.066 (0.121)	T@1 43.750 (60.653)	T@5 68.750 (88.167)	L 2.0788 (1.4410)
Test on T training set - [1][520/1731]	T 0.164 (0.222)	D 0.059 (0.120)	T@1 37.500 (60.269)	T@5 50.000 (87.686)	L 2.4823 (1.4581)
Test on T training set - [1][530/1731]	T 0.176 (0.226)	D 0.069 (0.124)	T@1 43.750 (59.911)	T@5 65.625 (87.235)	L 2.4169 (1.4747)
Test on T training set - [1][540/1731]	T 0.157 (0.225)	D 0.061 (0.123)	T@1 68.750 (59.612)	T@5 81.250 (86.795)	L 1.2518 (1.4889)
Test on T training set - [1][550/1731]	T 0.162 (0.224)	D 0.055 (0.122)	T@1 43.750 (59.313)	T@5 71.875 (86.428)	L 2.1642 (1.5025)
Test on T training set - [1][560/1731]	T 0.237 (0.223)	D 0.126 (0.121)	T@1 18.750 (58.857)	T@5 50.000 (85.868)	L 3.1723 (1.5229)
Test on T training set - [1][570/1731]	T 0.188 (0.222)	D 0.091 (0.120)	T@1 46.875 (58.658)	T@5 81.250 (85.546)	L 1.7686 (1.5316)
Test on T training set - [1][580/1731]	T 0.169 (0.221)	D 0.070 (0.119)	T@1 56.250 (58.611)	T@5 84.375 (85.483)	L 1.5511 (1.5326)
Test on T training set - [1][590/1731]	T 0.179 (0.221)	D 0.083 (0.119)	T@1 65.625 (58.598)	T@5 96.875 (85.406)	L 1.0971 (1.5339)
Test on T training set - [1][600/1731]	T 0.166 (0.220)	D 0.066 (0.118)	T@1 50.000 (58.631)	T@5 78.125 (85.316)	L 1.8842 (1.5341)
Test on T training set - [1][610/1731]	T 0.164 (0.219)	D 0.064 (0.117)	T@1 59.375 (58.700)	T@5 75.000 (85.270)	L 1.6875 (1.5321)
Test on T training set - [1][620/1731]	T 0.184 (0.219)	D 0.088 (0.117)	T@1 65.625 (58.701)	T@5 84.375 (85.225)	L 1.2810 (1.5322)
Test on T training set - [1][630/1731]	T 0.165 (0.218)	D 0.066 (0.116)	T@1 53.125 (58.721)	T@5 78.125 (85.128)	L 1.8249 (1.5331)
Test on T training set - [1][640/1731]	T 0.171 (0.222)	D 0.063 (0.120)	T@1 59.375 (58.644)	T@5 78.125 (84.931)	L 1.4681 (1.5370)
Test on T training set - [1][650/1731]	T 0.162 (0.221)	D 0.059 (0.119)	T@1 34.375 (58.708)	T@5 59.375 (84.879)	L 2.6527 (1.5357)
Test on T training set - [1][660/1731]	T 0.164 (0.220)	D 0.068 (0.118)	T@1 53.125 (58.656)	T@5 75.000 (84.786)	L 1.6690 (1.5377)
Test on T training set - [1][670/1731]	T 0.173 (0.219)	D 0.074 (0.117)	T@1 59.375 (58.616)	T@5 71.875 (84.687)	L 1.7264 (1.5395)
Test on T training set - [1][680/1731]	T 0.167 (0.218)	D 0.061 (0.117)	T@1 46.875 (58.517)	T@5 78.125 (84.536)	L 1.7086 (1.5432)
Test on T training set - [1][690/1731]	T 0.223 (0.218)	D 0.118 (0.116)	T@1 0.000 (58.222)	T@5 25.000 (84.167)	L 3.9767 (1.5561)
Test on T training set - [1][700/1731]	T 0.157 (0.217)	D 0.053 (0.116)	T@1 18.750 (57.605)	T@5 46.875 (83.488)	L 2.9667 (1.5814)
Test on T training set - [1][710/1731]	T 0.191 (0.217)	D 0.082 (0.115)	T@1 40.625 (57.322)	T@5 56.250 (83.162)	L 2.2443 (1.5923)
Test on T training set - [1][720/1731]	T 0.173 (0.216)	D 0.071 (0.114)	T@1 50.000 (57.082)	T@5 81.250 (82.906)	L 1.7249 (1.6005)
Test on T training set - [1][730/1731]	T 0.224 (0.216)	D 0.119 (0.114)	T@1 56.250 (56.887)	T@5 68.750 (82.691)	L 1.7223 (1.6078)
Test on T training set - [1][740/1731]	T 0.223 (0.219)	D 0.120 (0.117)	T@1 43.750 (56.798)	T@5 56.250 (82.549)	L 2.2464 (1.6110)
Test on T training set - [1][750/1731]	T 0.202 (0.219)	D 0.095 (0.117)	T@1 56.250 (56.666)	T@5 78.125 (82.398)	L 1.6394 (1.6151)
Test on T training set - [1][760/1731]	T 0.226 (0.219)	D 0.130 (0.117)	T@1 71.875 (56.554)	T@5 81.250 (82.264)	L 1.2315 (1.6203)
Test on T training set - [1][770/1731]	T 0.203 (0.219)	D 0.103 (0.117)	T@1 46.875 (56.428)	T@5 68.750 (82.150)	L 1.9868 (1.6243)
Test on T training set - [1][780/1731]	T 0.226 (0.219)	D 0.127 (0.117)	T@1 37.500 (56.222)	T@5 71.875 (81.914)	L 1.9647 (1.6317)
Test on T training set - [1][790/1731]	T 0.222 (0.219)	D 0.118 (0.117)	T@1 56.250 (56.104)	T@5 71.875 (81.736)	L 1.5567 (1.6359)
Test on T training set - [1][800/1731]	T 0.199 (0.219)	D 0.102 (0.117)	T@1 37.500 (55.985)	T@5 65.625 (81.644)	L 2.3162 (1.6398)
Test on T training set - [1][810/1731]	T 0.204 (0.219)	D 0.096 (0.117)	T@1 40.625 (55.830)	T@5 56.250 (81.454)	L 2.2555 (1.6447)
Test on T training set - [1][820/1731]	T 0.209 (0.219)	D 0.112 (0.117)	T@1 46.875 (55.721)	T@5 68.750 (81.315)	L 1.7777 (1.6480)
Test on T training set - [1][830/1731]	T 0.190 (0.218)	D 0.094 (0.117)	T@1 50.000 (55.618)	T@5 75.000 (81.182)	L 1.8910 (1.6510)
Test on T training set - [1][840/1731]	T 0.174 (0.221)	D 0.071 (0.119)	T@1 43.750 (55.488)	T@5 81.250 (81.053)	L 1.9332 (1.6550)
Test on T training set - [1][850/1731]	T 0.160 (0.220)	D 0.054 (0.118)	T@1 31.250 (55.288)	T@5 81.250 (81.059)	L 2.1650 (1.6605)
Test on T training set - [1][860/1731]	T 0.165 (0.220)	D 0.066 (0.118)	T@1 28.125 (55.045)	T@5 81.250 (81.029)	L 2.6566 (1.6679)
Test on T training set - [1][870/1731]	T 0.168 (0.219)	D 0.067 (0.117)	T@1 28.125 (54.704)	T@5 84.375 (80.985)	L 2.4766 (1.6783)
Test on T training set - [1][880/1731]	T 0.163 (0.219)	D 0.067 (0.117)	T@1 28.125 (54.391)	T@5 78.125 (80.952)	L 2.5020 (1.6873)
Test on T training set - [1][890/1731]	T 0.166 (0.218)	D 0.070 (0.116)	T@1 15.625 (54.065)	T@5 68.750 (80.910)	L 2.9964 (1.6971)
Test on T training set - [1][900/1731]	T 0.167 (0.218)	D 0.066 (0.116)	T@1 28.125 (53.746)	T@5 84.375 (80.893)	L 2.4053 (1.7062)
Test on T training set - [1][910/1731]	T 0.173 (0.217)	D 0.075 (0.115)	T@1 78.125 (53.770)	T@5 96.875 (80.976)	L 0.7537 (1.7046)
Test on T training set - [1][920/1731]	T 0.163 (0.217)	D 0.064 (0.115)	T@1 81.250 (54.095)	T@5 96.875 (81.148)	L 0.6149 (1.6930)
Test on T training set - [1][930/1731]	T 0.244 (0.217)	D 0.135 (0.115)	T@1 87.500 (54.434)	T@5 96.875 (81.324)	L 0.4707 (1.6804)
Test on T training set - [1][940/1731]	T 0.253 (0.219)	D 0.157 (0.117)	T@1 93.750 (54.736)	T@5 100.000 (81.502)	L 0.2935 (1.6693)
Test on T training set - [1][950/1731]	T 0.241 (0.219)	D 0.132 (0.117)	T@1 81.250 (55.028)	T@5 96.875 (81.651)	L 0.7841 (1.6586)
Test on T training set - [1][960/1731]	T 0.216 (0.219)	D 0.116 (0.117)	T@1 84.375 (55.356)	T@5 90.625 (81.787)	L 0.7420 (1.6473)
Test on T training set - [1][970/1731]	T 0.231 (0.219)	D 0.126 (0.117)	T@1 90.625 (55.655)	T@5 96.875 (81.958)	L 0.4125 (1.6363)
Test on T training set - [1][980/1731]	T 0.211 (0.219)	D 0.110 (0.117)	T@1 81.250 (55.986)	T@5 96.875 (82.113)	L 0.6462 (1.6244)
Test on T training set - [1][990/1731]	T 0.232 (0.219)	D 0.127 (0.117)	T@1 90.625 (56.300)	T@5 93.750 (82.262)	L 0.4696 (1.6134)
Test on T training set - [1][1000/1731]	T 0.230 (0.219)	D 0.124 (0.117)	T@1 75.000 (56.593)	T@5 96.875 (82.411)	L 0.8309 (1.6025)
Test on T training set - [1][1010/1731]	T 0.199 (0.222)	D 0.103 (0.120)	T@1 84.375 (56.871)	T@5 90.625 (82.551)	L 0.6088 (1.5928)
Test on T training set - [1][1020/1731]	T 0.201 (0.221)	D 0.105 (0.120)	T@1 90.625 (57.147)	T@5 100.000 (82.698)	L 0.4217 (1.5837)
Test on T training set - [1][1030/1731]	T 0.175 (0.221)	D 0.074 (0.119)	T@1 87.500 (57.426)	T@5 93.750 (82.823)	L 0.6440 (1.5739)
Test on T training set - [1][1040/1731]	T 0.178 (0.221)	D 0.077 (0.119)	T@1 62.500 (57.649)	T@5 84.375 (82.922)	L 1.4009 (1.5664)
Test on T training set - [1][1050/1731]	T 0.174 (0.220)	D 0.071 (0.118)	T@1 84.375 (57.769)	T@5 96.875 (83.010)	L 0.7226 (1.5626)
Test on T training set - [1][1060/1731]	T 0.160 (0.220)	D 0.058 (0.118)	T@1 71.875 (57.917)	T@5 96.875 (83.114)	L 1.0198 (1.5573)
Test on T training set - [1][1070/1731]	T 0.208 (0.219)	D 0.102 (0.118)	T@1 71.875 (58.015)	T@5 90.625 (83.185)	L 1.1477 (1.5542)
Test on T training set - [1][1080/1731]	T 0.159 (0.219)	D 0.063 (0.117)	T@1 62.500 (58.219)	T@5 93.750 (83.300)	L 1.3854 (1.5469)
Test on T training set - [1][1090/1731]	T 0.419 (0.219)	D 0.316 (0.117)	T@1 21.875 (58.155)	T@5 43.750 (83.181)	L 3.1289 (1.5506)
Test on T training set - [1][1100/1731]	T 0.194 (0.219)	D 0.098 (0.117)	T@1 15.625 (57.837)	T@5 37.500 (82.814)	L 3.1909 (1.5644)
Test on T training set - [1][1110/1731]	T 0.210 (0.219)	D 0.113 (0.117)	T@1 18.750 (57.462)	T@5 31.250 (82.369)	L 3.2378 (1.5805)
Test on T training set - [1][1120/1731]	T 0.198 (0.221)	D 0.103 (0.119)	T@1 21.875 (57.170)	T@5 31.250 (82.005)	L 3.3601 (1.5941)
Test on T training set - [1][1130/1731]	T 0.183 (0.220)	D 0.079 (0.119)	T@1 21.875 (56.869)	T@5 40.625 (81.629)	L 3.1694 (1.6077)
Test on T training set - [1][1140/1731]	T 0.195 (0.220)	D 0.095 (0.118)	T@1 15.625 (56.570)	T@5 31.250 (81.280)	L 3.2977 (1.6213)
Test on T training set - [1][1150/1731]	T 0.190 (0.220)	D 0.085 (0.118)	T@1 21.875 (56.293)	T@5 43.750 (80.946)	L 2.9094 (1.6340)
Test on T training set - [1][1160/1731]	T 0.179 (0.220)	D 0.076 (0.118)	T@1 21.875 (55.997)	T@5 43.750 (80.615)	L 3.2283 (1.6470)
Test on T training set - [1][1170/1731]	T 0.180 (0.219)	D 0.079 (0.118)	T@1 15.625 (55.714)	T@5 40.625 (80.279)	L 3.1941 (1.6588)
Test on T training set - [1][1180/1731]	T 0.192 (0.219)	D 0.089 (0.117)	T@1 9.375 (55.432)	T@5 34.375 (79.961)	L 3.4331 (1.6704)
Test on T training set - [1][1190/1731]	T 0.192 (0.219)	D 0.092 (0.117)	T@1 34.375 (55.174)	T@5 37.500 (79.642)	L 2.9259 (1.6824)
Test on T training set - [1][1200/1731]	T 0.179 (0.219)	D 0.081 (0.117)	T@1 34.375 (54.923)	T@5 62.500 (79.356)	L 2.5181 (1.6934)
Test on T training set - [1][1210/1731]	T 0.196 (0.218)	D 0.095 (0.117)	T@1 25.000 (54.702)	T@5 31.250 (79.093)	L 2.9944 (1.7032)
Test on T training set - [1][1220/1731]	T 0.162 (0.218)	D 0.066 (0.116)	T@1 68.750 (54.832)	T@5 96.875 (79.202)	L 1.1348 (1.6983)
Test on T training set - [1][1230/1731]	T 0.162 (0.220)	D 0.059 (0.118)	T@1 65.625 (54.965)	T@5 90.625 (79.331)	L 1.1113 (1.6930)
Test on T training set - [1][1240/1731]	T 0.179 (0.219)	D 0.075 (0.117)	T@1 78.125 (55.137)	T@5 100.000 (79.487)	L 0.6703 (1.6868)
Test on T training set - [1][1250/1731]	T 0.175 (0.219)	D 0.079 (0.117)	T@1 84.375 (55.346)	T@5 100.000 (79.624)	L 0.5268 (1.6785)
Test on T training set - [1][1260/1731]	T 0.185 (0.219)	D 0.089 (0.117)	T@1 71.875 (55.511)	T@5 96.875 (79.768)	L 0.8526 (1.6717)
Test on T training set - [1][1270/1731]	T 0.186 (0.218)	D 0.080 (0.117)	T@1 93.750 (55.704)	T@5 100.000 (79.908)	L 0.2771 (1.6641)
Test on T training set - [1][1280/1731]	T 0.193 (0.218)	D 0.089 (0.116)	T@1 90.625 (55.935)	T@5 96.875 (80.052)	L 0.3472 (1.6552)
Test on T training set - [1][1290/1731]	T 0.164 (0.218)	D 0.067 (0.116)	T@1 75.000 (56.100)	T@5 100.000 (80.185)	L 1.1107 (1.6484)
Test on T training set - [1][1300/1731]	T 0.167 (0.218)	D 0.071 (0.116)	T@1 71.875 (56.276)	T@5 96.875 (80.330)	L 0.8277 (1.6409)
Test on T training set - [1][1310/1731]	T 0.184 (0.217)	D 0.082 (0.115)	T@1 78.125 (56.507)	T@5 100.000 (80.473)	L 0.6957 (1.6325)
Test on T training set - [1][1320/1731]	T 0.196 (0.217)	D 0.094 (0.115)	T@1 84.375 (56.718)	T@5 100.000 (80.611)	L 0.4724 (1.6246)
Test on T training set - [1][1330/1731]	T 0.167 (0.217)	D 0.067 (0.115)	T@1 81.250 (56.924)	T@5 96.875 (80.741)	L 0.7205 (1.6168)
Test on T training set - [1][1340/1731]	T 0.155 (0.218)	D 0.059 (0.116)	T@1 81.250 (57.096)	T@5 100.000 (80.868)	L 0.5872 (1.6103)
Test on T training set - [1][1350/1731]	T 0.169 (0.218)	D 0.073 (0.116)	T@1 87.500 (57.291)	T@5 100.000 (81.002)	L 0.4157 (1.6026)
Test on T training set - [1][1360/1731]	T 0.169 (0.217)	D 0.067 (0.116)	T@1 28.125 (57.164)	T@5 71.875 (80.956)	L 2.6104 (1.6074)
Test on T training set - [1][1370/1731]	T 0.159 (0.217)	D 0.063 (0.115)	T@1 50.000 (57.068)	T@5 87.500 (80.940)	L 1.7444 (1.6098)
Test on T training set - [1][1380/1731]	T 0.160 (0.217)	D 0.064 (0.115)	T@1 34.375 (56.990)	T@5 78.125 (80.926)	L 2.1994 (1.6119)
Test on T training set - [1][1390/1731]	T 0.176 (0.216)	D 0.070 (0.115)	T@1 40.625 (56.881)	T@5 71.875 (80.918)	L 2.3385 (1.6156)
Test on T training set - [1][1400/1731]	T 0.175 (0.216)	D 0.072 (0.114)	T@1 46.875 (56.776)	T@5 84.375 (80.900)	L 1.7986 (1.6195)
Test on T training set - [1][1410/1731]	T 0.181 (0.216)	D 0.079 (0.114)	T@1 46.875 (56.686)	T@5 71.875 (80.867)	L 1.8232 (1.6225)
Test on T training set - [1][1420/1731]	T 0.161 (0.215)	D 0.065 (0.114)	T@1 62.500 (56.593)	T@5 81.250 (80.843)	L 1.7431 (1.6258)
Test on T training set - [1][1430/1731]	T 0.230 (0.215)	D 0.127 (0.113)	T@1 75.000 (56.506)	T@5 100.000 (80.892)	L 0.8982 (1.6278)
Test on T training set - [1][1440/1731]	T 0.244 (0.215)	D 0.147 (0.114)	T@1 65.625 (56.621)	T@5 100.000 (81.022)	L 1.0738 (1.6226)
Test on T training set - [1][1450/1731]	T 0.230 (0.218)	D 0.127 (0.116)	T@1 56.250 (56.704)	T@5 100.000 (81.149)	L 1.2677 (1.6184)
Test on T training set - [1][1460/1731]	T 0.225 (0.218)	D 0.129 (0.116)	T@1 81.250 (56.778)	T@5 100.000 (81.269)	L 0.9450 (1.6151)
Test on T training set - [1][1470/1731]	T 0.255 (0.218)	D 0.147 (0.117)	T@1 62.500 (56.851)	T@5 100.000 (81.388)	L 1.5852 (1.6120)
Test on T training set - [1][1480/1731]	T 0.243 (0.219)	D 0.142 (0.117)	T@1 78.125 (56.921)	T@5 96.875 (81.512)	L 0.7370 (1.6082)
Test on T training set - [1][1490/1731]	T 0.240 (0.219)	D 0.133 (0.117)	T@1 62.500 (57.025)	T@5 100.000 (81.631)	L 1.3857 (1.6040)
Test on T training set - [1][1500/1731]	T 0.250 (0.219)	D 0.146 (0.117)	T@1 65.625 (57.058)	T@5 96.875 (81.748)	L 0.9437 (1.6013)
Test on T training set - [1][1510/1731]	T 0.235 (0.219)	D 0.130 (0.117)	T@1 59.375 (57.086)	T@5 96.875 (81.860)	L 1.5762 (1.5996)
Test on T training set - [1][1520/1731]	T 0.224 (0.219)	D 0.125 (0.117)	T@1 46.875 (57.129)	T@5 96.875 (81.975)	L 1.3726 (1.5965)
Test on T training set - [1][1530/1731]	T 0.232 (0.219)	D 0.126 (0.117)	T@1 68.750 (57.160)	T@5 96.875 (82.079)	L 1.0469 (1.5944)
Test on T training set - [1][1540/1731]	T 0.201 (0.221)	D 0.096 (0.119)	T@1 37.500 (57.144)	T@5 96.875 (82.189)	L 2.2817 (1.5946)
Test on T training set - [1][1550/1731]	T 0.246 (0.221)	D 0.144 (0.119)	T@1 59.375 (57.070)	T@5 100.000 (82.288)	L 1.4056 (1.5960)
Test on T training set - [1][1560/1731]	T 0.195 (0.221)	D 0.093 (0.119)	T@1 6.250 (56.989)	T@5 59.375 (82.283)	L 3.8014 (1.5993)
Test on T training set - [1][1570/1731]	T 0.185 (0.220)	D 0.074 (0.119)	T@1 6.250 (56.680)	T@5 46.875 (82.064)	L 4.4362 (1.6156)
Test on T training set - [1][1580/1731]	T 0.162 (0.220)	D 0.061 (0.118)	T@1 6.250 (56.380)	T@5 37.500 (81.863)	L 4.0259 (1.6311)
Test on T training set - [1][1590/1731]	T 0.165 (0.220)	D 0.062 (0.118)	T@1 3.125 (56.077)	T@5 50.000 (81.657)	L 4.1471 (1.6464)
Test on T training set - [1][1600/1731]	T 0.183 (0.219)	D 0.083 (0.118)	T@1 6.250 (55.778)	T@5 43.750 (81.445)	L 4.2680 (1.6618)
Test on T training set - [1][1610/1731]	T 0.173 (0.219)	D 0.073 (0.117)	T@1 9.375 (55.480)	T@5 40.625 (81.198)	L 4.2485 (1.6765)
Test on T training set - [1][1620/1731]	T 0.185 (0.219)	D 0.079 (0.117)	T@1 21.875 (55.205)	T@5 59.375 (81.003)	L 3.5794 (1.6897)
Test on T training set - [1][1630/1731]	T 0.175 (0.220)	D 0.074 (0.118)	T@1 6.250 (54.911)	T@5 43.750 (80.767)	L 4.2568 (1.7043)
Test on T training set - [1][1640/1731]	T 0.218 (0.220)	D 0.117 (0.118)	T@1 9.375 (54.633)	T@5 59.375 (80.570)	L 3.8805 (1.7188)
Test on T training set - [1][1650/1731]	T 0.218 (0.220)	D 0.122 (0.118)	T@1 18.750 (54.403)	T@5 68.750 (80.478)	L 3.7787 (1.7301)
Test on T training set - [1][1660/1731]	T 0.207 (0.220)	D 0.109 (0.118)	T@1 31.250 (54.194)	T@5 65.625 (80.400)	L 3.1176 (1.7406)
Test on T training set - [1][1670/1731]	T 0.201 (0.220)	D 0.104 (0.118)	T@1 18.750 (53.967)	T@5 65.625 (80.326)	L 3.2538 (1.7514)
Test on T training set - [1][1680/1731]	T 0.201 (0.220)	D 0.097 (0.118)	T@1 12.500 (53.733)	T@5 68.750 (80.257)	L 3.8416 (1.7619)
Test on T training set - [1][1690/1731]	T 0.226 (0.220)	D 0.118 (0.118)	T@1 15.625 (53.524)	T@5 65.625 (80.195)	L 3.5878 (1.7724)
Test on T training set - [1][1700/1731]	T 0.220 (0.220)	D 0.124 (0.118)	T@1 21.875 (53.309)	T@5 71.875 (80.124)	L 3.5840 (1.7833)
Test on T training set - [1][1710/1731]	T 0.220 (0.222)	D 0.114 (0.120)	T@1 9.375 (53.085)	T@5 65.625 (80.048)	L 3.5612 (1.7932)
Test on T training set - [1][1720/1731]	T 0.190 (0.222)	D 0.094 (0.120)	T@1 15.625 (52.887)	T@5 78.125 (79.984)	L 3.6724 (1.8030)
Test on T training set - [1][1730/1731]	T 0.169 (0.221)	D 0.077 (0.120)	T@1 28.571 (52.719)	T@5 57.143 (79.893)	L 3.1868 (1.8116)
 * Test on T training set - Prec@1 52.719, Prec@5 79.893
Test on T test set - [1][0/1731]	Time 0.298 (0.298)	Loss 2.2739 (2.2739)	Prec@1 34.375 (34.375)	Prec@5 81.250 (81.250)
Test on T test set - [1][10/1731]	Time 0.218 (0.201)	Loss 1.4174 (1.4774)	Prec@1 56.250 (58.523)	Prec@5 93.750 (86.932)
Test on T test set - [1][20/1731]	Time 0.228 (0.211)	Loss 1.0659 (1.2808)	Prec@1 68.750 (63.690)	Prec@5 93.750 (90.625)
Test on T test set - [1][30/1731]	Time 0.194 (0.305)	Loss 0.5091 (1.1668)	Prec@1 84.375 (67.137)	Prec@5 96.875 (92.339)
Test on T test set - [1][40/1731]	Time 0.225 (0.284)	Loss 1.1525 (1.1297)	Prec@1 68.750 (68.598)	Prec@5 90.625 (92.988)
Test on T test set - [1][50/1731]	Time 0.223 (0.271)	Loss 0.6180 (1.1151)	Prec@1 84.375 (68.627)	Prec@5 100.000 (93.505)
Test on T test set - [1][60/1731]	Time 0.224 (0.262)	Loss 1.1496 (1.0870)	Prec@1 65.625 (69.365)	Prec@5 96.875 (94.057)
Test on T test set - [1][70/1731]	Time 0.195 (0.254)	Loss 0.9764 (1.0916)	Prec@1 71.875 (69.322)	Prec@5 90.625 (94.058)
Test on T test set - [1][80/1731]	Time 0.193 (0.249)	Loss 1.0845 (1.0879)	Prec@1 68.750 (69.406)	Prec@5 90.625 (94.020)
Test on T test set - [1][90/1731]	Time 0.181 (0.244)	Loss 1.1428 (1.0764)	Prec@1 68.750 (69.643)	Prec@5 96.875 (94.196)
Test on T test set - [1][100/1731]	Time 0.191 (0.239)	Loss 1.2785 (1.0883)	Prec@1 65.625 (69.276)	Prec@5 90.625 (93.998)
Test on T test set - [1][110/1731]	Time 0.199 (0.234)	Loss 1.6738 (1.1481)	Prec@1 40.625 (67.624)	Prec@5 87.500 (93.018)
Test on T test set - [1][120/1731]	Time 0.202 (0.231)	Loss 1.9685 (1.2303)	Prec@1 50.000 (65.599)	Prec@5 84.375 (92.459)
Test on T test set - [1][130/1731]	Time 0.198 (0.240)	Loss 2.0543 (1.2905)	Prec@1 53.125 (64.313)	Prec@5 84.375 (92.009)
Test on T test set - [1][140/1731]	Time 0.172 (0.236)	Loss 2.2837 (1.3473)	Prec@1 43.750 (62.788)	Prec@5 78.125 (91.534)
Test on T test set - [1][150/1731]	Time 0.205 (0.232)	Loss 2.4108 (1.3984)	Prec@1 37.500 (61.569)	Prec@5 81.250 (91.080)
Test on T test set - [1][160/1731]	Time 0.195 (0.229)	Loss 1.5193 (1.4240)	Prec@1 59.375 (61.083)	Prec@5 90.625 (90.858)
Test on T test set - [1][170/1731]	Time 0.172 (0.226)	Loss 2.5243 (1.4688)	Prec@1 31.250 (59.868)	Prec@5 75.000 (90.552)
Test on T test set - [1][180/1731]	Time 0.159 (0.223)	Loss 2.9722 (1.5277)	Prec@1 31.250 (58.529)	Prec@5 56.250 (89.693)
Test on T test set - [1][190/1731]	Time 0.174 (0.220)	Loss 3.1003 (1.5853)	Prec@1 12.500 (57.215)	Prec@5 65.625 (88.891)
Test on T test set - [1][200/1731]	Time 0.169 (0.217)	Loss 2.7890 (1.6425)	Prec@1 28.125 (55.784)	Prec@5 75.000 (87.982)
Test on T test set - [1][210/1731]	Time 0.173 (0.214)	Loss 2.3764 (1.6971)	Prec@1 34.375 (54.458)	Prec@5 81.250 (87.352)
Test on T test set - [1][220/1731]	Time 0.223 (0.225)	Loss 1.8431 (1.7297)	Prec@1 46.875 (53.662)	Prec@5 90.625 (86.920)
Test on T test set - [1][230/1731]	Time 0.182 (0.223)	Loss 1.5068 (1.7307)	Prec@1 59.375 (53.436)	Prec@5 96.875 (87.135)
Test on T test set - [1][240/1731]	Time 0.232 (0.223)	Loss 0.3228 (1.6895)	Prec@1 90.625 (54.422)	Prec@5 100.000 (87.604)
Test on T test set - [1][250/1731]	Time 0.203 (0.223)	Loss 0.4948 (1.6497)	Prec@1 84.375 (55.416)	Prec@5 96.875 (88.048)
Test on T test set - [1][260/1731]	Time 0.236 (0.223)	Loss 0.3982 (1.6143)	Prec@1 90.625 (56.250)	Prec@5 100.000 (88.446)
Test on T test set - [1][270/1731]	Time 0.232 (0.224)	Loss 0.5682 (1.5782)	Prec@1 75.000 (57.126)	Prec@5 100.000 (88.815)
Test on T test set - [1][280/1731]	Time 0.229 (0.224)	Loss 0.6449 (1.5469)	Prec@1 81.250 (57.918)	Prec@5 100.000 (89.179)
Test on T test set - [1][290/1731]	Time 0.250 (0.224)	Loss 0.3937 (1.5164)	Prec@1 87.500 (58.720)	Prec@5 100.000 (89.519)
Test on T test set - [1][300/1731]	Time 0.213 (0.224)	Loss 0.8804 (1.4898)	Prec@1 71.875 (59.406)	Prec@5 100.000 (89.826)
Test on T test set - [1][310/1731]	Time 0.224 (0.223)	Loss 0.6535 (1.4639)	Prec@1 84.375 (60.038)	Prec@5 100.000 (90.082)
Test on T test set - [1][320/1731]	Time 0.189 (0.232)	Loss 0.3964 (1.4425)	Prec@1 87.500 (60.621)	Prec@5 100.000 (90.333)
Test on T test set - [1][330/1731]	Time 0.200 (0.231)	Loss 0.6049 (1.4243)	Prec@1 81.250 (61.103)	Prec@5 100.000 (90.568)
Test on T test set - [1][340/1731]	Time 0.187 (0.230)	Loss 1.4061 (1.4281)	Prec@1 56.250 (60.896)	Prec@5 93.750 (90.588)
Test on T test set - [1][350/1731]	Time 0.203 (0.229)	Loss 0.9787 (1.4236)	Prec@1 65.625 (60.942)	Prec@5 96.875 (90.750)
Test on T test set - [1][360/1731]	Time 0.228 (0.229)	Loss 0.4047 (1.3993)	Prec@1 90.625 (61.582)	Prec@5 100.000 (90.980)
Test on T test set - [1][370/1731]	Time 0.168 (0.228)	Loss 2.1363 (1.3894)	Prec@1 40.625 (61.792)	Prec@5 71.875 (91.012)
Test on T test set - [1][380/1731]	Time 0.189 (0.227)	Loss 1.1317 (1.4049)	Prec@1 68.750 (61.360)	Prec@5 93.750 (90.559)
Test on T test set - [1][390/1731]	Time 0.170 (0.226)	Loss 1.4830 (1.4004)	Prec@1 59.375 (61.517)	Prec@5 75.000 (90.401)
Test on T test set - [1][400/1731]	Time 0.171 (0.233)	Loss 2.2496 (1.4109)	Prec@1 40.625 (61.253)	Prec@5 59.375 (89.994)
Test on T test set - [1][410/1731]	Time 0.189 (0.231)	Loss 1.6608 (1.4196)	Prec@1 56.250 (61.078)	Prec@5 78.125 (89.644)
Test on T test set - [1][420/1731]	Time 0.164 (0.229)	Loss 2.3962 (1.4319)	Prec@1 37.500 (60.770)	Prec@5 62.500 (89.178)
Test on T test set - [1][430/1731]	Time 0.164 (0.228)	Loss 1.8686 (1.4372)	Prec@1 50.000 (60.702)	Prec@5 81.250 (88.892)
Test on T test set - [1][440/1731]	Time 0.156 (0.226)	Loss 1.1888 (1.4365)	Prec@1 65.625 (60.743)	Prec@5 87.500 (88.754)
Test on T test set - [1][450/1731]	Time 0.161 (0.225)	Loss 1.2292 (1.4346)	Prec@1 68.750 (60.830)	Prec@5 87.500 (88.685)
Test on T test set - [1][460/1731]	Time 0.163 (0.224)	Loss 0.9027 (1.4300)	Prec@1 78.125 (61.002)	Prec@5 96.875 (88.686)
Test on T test set - [1][470/1731]	Time 0.161 (0.223)	Loss 0.8108 (1.4285)	Prec@1 81.250 (61.080)	Prec@5 90.625 (88.562)
Test on T test set - [1][480/1731]	Time 0.156 (0.222)	Loss 1.3850 (1.4263)	Prec@1 65.625 (61.162)	Prec@5 96.875 (88.533)
Test on T test set - [1][490/1731]	Time 0.160 (0.220)	Loss 1.9207 (1.4272)	Prec@1 53.125 (61.119)	Prec@5 75.000 (88.372)
Test on T test set - [1][500/1731]	Time 0.163 (0.219)	Loss 0.9596 (1.4259)	Prec@1 75.000 (61.159)	Prec@5 93.750 (88.280)
Test on T test set - [1][510/1731]	Time 0.165 (0.223)	Loss 2.0525 (1.4349)	Prec@1 40.625 (60.916)	Prec@5 71.875 (88.014)
Test on T test set - [1][520/1731]	Time 0.156 (0.222)	Loss 2.6551 (1.4522)	Prec@1 37.500 (60.533)	Prec@5 43.750 (87.548)
Test on T test set - [1][530/1731]	Time 0.172 (0.221)	Loss 2.7024 (1.4690)	Prec@1 34.375 (60.181)	Prec@5 53.125 (87.082)
Test on T test set - [1][540/1731]	Time 0.163 (0.219)	Loss 1.2578 (1.4820)	Prec@1 68.750 (59.883)	Prec@5 75.000 (86.639)
Test on T test set - [1][550/1731]	Time 0.148 (0.218)	Loss 2.0651 (1.4963)	Prec@1 40.625 (59.539)	Prec@5 62.500 (86.213)
Test on T test set - [1][560/1731]	Time 0.167 (0.217)	Loss 3.3407 (1.5154)	Prec@1 21.875 (59.119)	Prec@5 43.750 (85.667)
Test on T test set - [1][570/1731]	Time 0.183 (0.217)	Loss 1.9138 (1.5251)	Prec@1 46.875 (58.899)	Prec@5 87.500 (85.398)
Test on T test set - [1][580/1731]	Time 0.169 (0.216)	Loss 1.2863 (1.5244)	Prec@1 62.500 (58.912)	Prec@5 84.375 (85.343)
Test on T test set - [1][590/1731]	Time 0.176 (0.215)	Loss 0.9828 (1.5253)	Prec@1 68.750 (58.915)	Prec@5 96.875 (85.247)
Test on T test set - [1][600/1731]	Time 0.164 (0.214)	Loss 1.8784 (1.5260)	Prec@1 46.875 (58.933)	Prec@5 81.250 (85.150)
Test on T test set - [1][610/1731]	Time 0.156 (0.214)	Loss 1.9265 (1.5245)	Prec@1 53.125 (58.971)	Prec@5 65.625 (85.122)
Test on T test set - [1][620/1731]	Time 0.175 (0.213)	Loss 1.0850 (1.5229)	Prec@1 71.875 (58.993)	Prec@5 84.375 (85.090)
Test on T test set - [1][630/1731]	Time 0.160 (0.216)	Loss 1.6164 (1.5231)	Prec@1 59.375 (59.004)	Prec@5 75.000 (84.984)
Test on T test set - [1][640/1731]	Time 0.155 (0.215)	Loss 1.4844 (1.5263)	Prec@1 56.250 (58.941)	Prec@5 81.250 (84.814)
Test on T test set - [1][650/1731]	Time 0.156 (0.215)	Loss 2.5172 (1.5252)	Prec@1 37.500 (58.953)	Prec@5 53.125 (84.749)
Test on T test set - [1][660/1731]	Time 0.162 (0.214)	Loss 1.7852 (1.5271)	Prec@1 46.875 (58.898)	Prec@5 78.125 (84.654)
Test on T test set - [1][670/1731]	Time 0.165 (0.213)	Loss 1.5780 (1.5280)	Prec@1 62.500 (58.872)	Prec@5 75.000 (84.571)
Test on T test set - [1][680/1731]	Time 0.161 (0.212)	Loss 1.6622 (1.5320)	Prec@1 59.375 (58.765)	Prec@5 78.125 (84.453)
Test on T test set - [1][690/1731]	Time 0.219 (0.212)	Loss 4.1439 (1.5441)	Prec@1 3.125 (58.480)	Prec@5 21.875 (84.108)
Test on T test set - [1][700/1731]	Time 0.153 (0.211)	Loss 2.7296 (1.5690)	Prec@1 25.000 (57.877)	Prec@5 50.000 (83.434)
Test on T test set - [1][710/1731]	Time 0.173 (0.211)	Loss 2.2599 (1.5802)	Prec@1 46.875 (57.608)	Prec@5 62.500 (83.096)
Test on T test set - [1][720/1731]	Time 3.207 (0.215)	Loss 1.8710 (1.5887)	Prec@1 46.875 (57.351)	Prec@5 84.375 (82.845)
Test on T test set - [1][730/1731]	Time 0.210 (0.214)	Loss 1.3948 (1.5962)	Prec@1 56.250 (57.161)	Prec@5 81.250 (82.644)
Test on T test set - [1][740/1731]	Time 0.217 (0.214)	Loss 2.3175 (1.6004)	Prec@1 37.500 (57.022)	Prec@5 62.500 (82.519)
Test on T test set - [1][750/1731]	Time 0.181 (0.214)	Loss 1.6272 (1.6055)	Prec@1 56.250 (56.882)	Prec@5 75.000 (82.332)
Test on T test set - [1][760/1731]	Time 0.238 (0.214)	Loss 1.1684 (1.6102)	Prec@1 71.875 (56.759)	Prec@5 78.125 (82.207)
Test on T test set - [1][770/1731]	Time 0.199 (0.214)	Loss 1.8935 (1.6137)	Prec@1 50.000 (56.651)	Prec@5 78.125 (82.093)
Test on T test set - [1][780/1731]	Time 0.223 (0.214)	Loss 1.9774 (1.6209)	Prec@1 37.500 (56.458)	Prec@5 75.000 (81.886)
Test on T test set - [1][790/1731]	Time 0.220 (0.214)	Loss 1.5581 (1.6253)	Prec@1 53.125 (56.337)	Prec@5 71.875 (81.720)
Test on T test set - [1][800/1731]	Time 0.241 (0.214)	Loss 2.3218 (1.6290)	Prec@1 37.500 (56.219)	Prec@5 75.000 (81.628)
Test on T test set - [1][810/1731]	Time 0.220 (0.214)	Loss 2.2595 (1.6351)	Prec@1 37.500 (56.023)	Prec@5 62.500 (81.408)
Test on T test set - [1][820/1731]	Time 0.210 (0.217)	Loss 1.8109 (1.6383)	Prec@1 46.875 (55.930)	Prec@5 75.000 (81.280)
Test on T test set - [1][830/1731]	Time 0.195 (0.217)	Loss 1.7911 (1.6411)	Prec@1 53.125 (55.836)	Prec@5 75.000 (81.171)
Test on T test set - [1][840/1731]	Time 0.169 (0.217)	Loss 1.8214 (1.6449)	Prec@1 46.875 (55.707)	Prec@5 78.125 (81.057)
Test on T test set - [1][850/1731]	Time 0.147 (0.216)	Loss 2.3264 (1.6510)	Prec@1 34.375 (55.516)	Prec@5 87.500 (81.070)
Test on T test set - [1][860/1731]	Time 0.156 (0.215)	Loss 2.5227 (1.6577)	Prec@1 31.250 (55.288)	Prec@5 71.875 (81.083)
Test on T test set - [1][870/1731]	Time 0.178 (0.215)	Loss 2.4967 (1.6685)	Prec@1 28.125 (54.930)	Prec@5 78.125 (80.992)
Test on T test set - [1][880/1731]	Time 0.170 (0.214)	Loss 2.3051 (1.6770)	Prec@1 28.125 (54.622)	Prec@5 78.125 (81.030)
Test on T test set - [1][890/1731]	Time 0.174 (0.214)	Loss 2.9519 (1.6864)	Prec@1 18.750 (54.310)	Prec@5 65.625 (80.990)
Test on T test set - [1][900/1731]	Time 0.165 (0.213)	Loss 2.4636 (1.6951)	Prec@1 28.125 (54.009)	Prec@5 87.500 (81.007)
Test on T test set - [1][910/1731]	Time 0.215 (0.216)	Loss 0.7860 (1.6931)	Prec@1 78.125 (54.048)	Prec@5 96.875 (81.089)
Test on T test set - [1][920/1731]	Time 0.161 (0.216)	Loss 0.5811 (1.6824)	Prec@1 87.500 (54.363)	Prec@5 96.875 (81.257)
Test on T test set - [1][930/1731]	Time 0.237 (0.216)	Loss 0.3650 (1.6695)	Prec@1 87.500 (54.713)	Prec@5 96.875 (81.428)
Test on T test set - [1][940/1731]	Time 0.246 (0.216)	Loss 0.3796 (1.6587)	Prec@1 93.750 (55.015)	Prec@5 96.875 (81.579)
Test on T test set - [1][950/1731]	Time 0.233 (0.216)	Loss 0.5690 (1.6475)	Prec@1 84.375 (55.327)	Prec@5 96.875 (81.733)
Test on T test set - [1][960/1731]	Time 0.231 (0.216)	Loss 0.7273 (1.6359)	Prec@1 84.375 (55.668)	Prec@5 96.875 (81.884)
Test on T test set - [1][970/1731]	Time 0.241 (0.216)	Loss 0.4028 (1.6256)	Prec@1 90.625 (55.954)	Prec@5 93.750 (82.051)
Test on T test set - [1][980/1731]	Time 0.200 (0.216)	Loss 0.6849 (1.6139)	Prec@1 78.125 (56.298)	Prec@5 93.750 (82.206)
Test on T test set - [1][990/1731]	Time 2.354 (0.218)	Loss 0.3763 (1.6025)	Prec@1 93.750 (56.609)	Prec@5 96.875 (82.357)
Test on T test set - [1][1000/1731]	Time 0.248 (0.218)	Loss 0.9258 (1.5917)	Prec@1 71.875 (56.915)	Prec@5 100.000 (82.514)
Test on T test set - [1][1010/1731]	Time 0.188 (0.218)	Loss 0.6138 (1.5822)	Prec@1 87.500 (57.205)	Prec@5 93.750 (82.659)
Test on T test set - [1][1020/1731]	Time 0.200 (0.218)	Loss 0.6217 (1.5729)	Prec@1 84.375 (57.468)	Prec@5 96.875 (82.808)
Test on T test set - [1][1030/1731]	Time 0.179 (0.218)	Loss 0.6273 (1.5633)	Prec@1 81.250 (57.741)	Prec@5 90.625 (82.926)
Test on T test set - [1][1040/1731]	Time 0.170 (0.217)	Loss 1.0489 (1.5549)	Prec@1 68.750 (57.988)	Prec@5 87.500 (83.030)
Test on T test set - [1][1050/1731]	Time 0.167 (0.217)	Loss 0.7576 (1.5523)	Prec@1 81.250 (58.067)	Prec@5 96.875 (83.105)
Test on T test set - [1][1060/1731]	Time 0.156 (0.216)	Loss 0.9310 (1.5466)	Prec@1 75.000 (58.217)	Prec@5 90.625 (83.209)
Test on T test set - [1][1070/1731]	Time 0.201 (0.216)	Loss 1.0427 (1.5429)	Prec@1 75.000 (58.342)	Prec@5 87.500 (83.281)
Test on T test set - [1][1080/1731]	Time 0.168 (0.216)	Loss 1.2786 (1.5361)	Prec@1 68.750 (58.545)	Prec@5 100.000 (83.398)
Test on T test set - [1][1090/1731]	Time 0.176 (0.218)	Loss 3.0641 (1.5398)	Prec@1 21.875 (58.476)	Prec@5 37.500 (83.238)
Test on T test set - [1][1100/1731]	Time 0.189 (0.218)	Loss 3.3093 (1.5530)	Prec@1 18.750 (58.166)	Prec@5 31.250 (82.874)
Test on T test set - [1][1110/1731]	Time 0.205 (0.218)	Loss 3.1210 (1.5684)	Prec@1 25.000 (57.811)	Prec@5 34.375 (82.454)
Test on T test set - [1][1120/1731]	Time 0.187 (0.217)	Loss 3.0243 (1.5826)	Prec@1 25.000 (57.493)	Prec@5 34.375 (82.067)
Test on T test set - [1][1130/1731]	Time 0.178 (0.217)	Loss 3.1500 (1.5964)	Prec@1 15.625 (57.178)	Prec@5 37.500 (81.689)
Test on T test set - [1][1140/1731]	Time 0.191 (0.217)	Loss 3.0993 (1.6095)	Prec@1 18.750 (56.888)	Prec@5 50.000 (81.373)
Test on T test set - [1][1150/1731]	Time 0.168 (0.217)	Loss 2.7132 (1.6223)	Prec@1 25.000 (56.600)	Prec@5 50.000 (81.030)
Test on T test set - [1][1160/1731]	Time 0.183 (0.216)	Loss 3.2634 (1.6353)	Prec@1 21.875 (56.293)	Prec@5 37.500 (80.701)
Test on T test set - [1][1170/1731]	Time 0.176 (0.216)	Loss 3.0173 (1.6477)	Prec@1 21.875 (56.004)	Prec@5 43.750 (80.353)
Test on T test set - [1][1180/1731]	Time 0.188 (0.218)	Loss 3.2319 (1.6592)	Prec@1 21.875 (55.737)	Prec@5 37.500 (80.046)
Test on T test set - [1][1190/1731]	Time 0.192 (0.218)	Loss 2.9327 (1.6716)	Prec@1 25.000 (55.458)	Prec@5 43.750 (79.712)
Test on T test set - [1][1200/1731]	Time 0.174 (0.218)	Loss 2.4069 (1.6829)	Prec@1 37.500 (55.204)	Prec@5 59.375 (79.413)
Test on T test set - [1][1210/1731]	Time 0.179 (0.218)	Loss 2.9752 (1.6932)	Prec@1 25.000 (54.962)	Prec@5 40.625 (79.152)
Test on T test set - [1][1220/1731]	Time 0.191 (0.217)	Loss 0.9608 (1.6885)	Prec@1 75.000 (55.091)	Prec@5 96.875 (79.261)
Test on T test set - [1][1230/1731]	Time 0.163 (0.217)	Loss 1.1715 (1.6833)	Prec@1 65.625 (55.222)	Prec@5 90.625 (79.392)
Test on T test set - [1][1240/1731]	Time 0.169 (0.216)	Loss 0.6259 (1.6767)	Prec@1 78.125 (55.389)	Prec@5 100.000 (79.545)
Test on T test set - [1][1250/1731]	Time 0.173 (0.216)	Loss 0.4583 (1.6684)	Prec@1 84.375 (55.598)	Prec@5 100.000 (79.681)
Test on T test set - [1][1260/1731]	Time 0.183 (0.216)	Loss 0.7368 (1.6620)	Prec@1 78.125 (55.749)	Prec@5 96.875 (79.830)
Test on T test set - [1][1270/1731]	Time 0.176 (0.218)	Loss 0.3669 (1.6543)	Prec@1 87.500 (55.957)	Prec@5 100.000 (79.976)
Test on T test set - [1][1280/1731]	Time 0.194 (0.218)	Loss 0.4771 (1.6454)	Prec@1 81.250 (56.189)	Prec@5 96.875 (80.118)
Test on T test set - [1][1290/1731]	Time 0.173 (0.218)	Loss 1.0396 (1.6381)	Prec@1 78.125 (56.378)	Prec@5 100.000 (80.260)
Test on T test set - [1][1300/1731]	Time 0.176 (0.217)	Loss 0.8772 (1.6303)	Prec@1 78.125 (56.584)	Prec@5 96.875 (80.404)
Test on T test set - [1][1310/1731]	Time 0.184 (0.217)	Loss 0.6623 (1.6219)	Prec@1 81.250 (56.817)	Prec@5 96.875 (80.542)
Test on T test set - [1][1320/1731]	Time 0.187 (0.217)	Loss 0.3666 (1.6134)	Prec@1 90.625 (57.052)	Prec@5 100.000 (80.682)
Test on T test set - [1][1330/1731]	Time 0.162 (0.217)	Loss 0.6292 (1.6057)	Prec@1 84.375 (57.250)	Prec@5 96.875 (80.811)
Test on T test set - [1][1340/1731]	Time 0.154 (0.216)	Loss 0.3990 (1.5990)	Prec@1 87.500 (57.441)	Prec@5 100.000 (80.935)
Test on T test set - [1][1350/1731]	Time 0.168 (0.216)	Loss 0.2894 (1.5909)	Prec@1 93.750 (57.654)	Prec@5 100.000 (81.067)
Test on T test set - [1][1360/1731]	Time 0.159 (0.216)	Loss 2.5496 (1.5957)	Prec@1 25.000 (57.511)	Prec@5 75.000 (81.007)
Test on T test set - [1][1370/1731]	Time 0.159 (0.217)	Loss 1.8440 (1.5986)	Prec@1 50.000 (57.399)	Prec@5 84.375 (80.986)
Test on T test set - [1][1380/1731]	Time 0.161 (0.217)	Loss 2.0411 (1.6005)	Prec@1 50.000 (57.338)	Prec@5 81.250 (80.997)
Test on T test set - [1][1390/1731]	Time 0.175 (0.217)	Loss 2.2276 (1.6040)	Prec@1 28.125 (57.230)	Prec@5 68.750 (80.983)
Test on T test set - [1][1400/1731]	Time 0.182 (0.216)	Loss 1.7637 (1.6083)	Prec@1 50.000 (57.113)	Prec@5 87.500 (80.949)
Test on T test set - [1][1410/1731]	Time 0.167 (0.216)	Loss 1.7157 (1.6115)	Prec@1 46.875 (57.003)	Prec@5 81.250 (80.927)
Test on T test set - [1][1420/1731]	Time 0.154 (0.216)	Loss 1.7847 (1.6144)	Prec@1 56.250 (56.912)	Prec@5 75.000 (80.889)
Test on T test set - [1][1430/1731]	Time 0.200 (0.215)	Loss 0.8495 (1.6167)	Prec@1 75.000 (56.829)	Prec@5 96.875 (80.916)
Test on T test set - [1][1440/1731]	Time 0.254 (0.215)	Loss 1.1655 (1.6112)	Prec@1 65.625 (56.948)	Prec@5 100.000 (81.044)
Test on T test set - [1][1450/1731]	Time 0.228 (0.216)	Loss 1.2494 (1.6077)	Prec@1 62.500 (57.032)	Prec@5 100.000 (81.166)
Test on T test set - [1][1460/1731]	Time 0.232 (0.217)	Loss 1.0307 (1.6043)	Prec@1 68.750 (57.127)	Prec@5 100.000 (81.291)
Test on T test set - [1][1470/1731]	Time 0.244 (0.217)	Loss 1.8293 (1.6016)	Prec@1 46.875 (57.178)	Prec@5 96.875 (81.403)
Test on T test set - [1][1480/1731]	Time 0.230 (0.217)	Loss 0.7788 (1.5982)	Prec@1 78.125 (57.246)	Prec@5 100.000 (81.526)
Test on T test set - [1][1490/1731]	Time 0.228 (0.218)	Loss 1.3670 (1.5939)	Prec@1 59.375 (57.344)	Prec@5 100.000 (81.646)
Test on T test set - [1][1500/1731]	Time 0.256 (0.218)	Loss 1.0255 (1.5912)	Prec@1 65.625 (57.399)	Prec@5 100.000 (81.762)
Test on T test set - [1][1510/1731]	Time 0.232 (0.218)	Loss 1.5858 (1.5897)	Prec@1 53.125 (57.412)	Prec@5 100.000 (81.875)
Test on T test set - [1][1520/1731]	Time 0.217 (0.218)	Loss 1.2625 (1.5871)	Prec@1 56.250 (57.460)	Prec@5 96.875 (81.986)
Test on T test set - [1][1530/1731]	Time 0.227 (0.220)	Loss 1.1915 (1.5850)	Prec@1 65.625 (57.491)	Prec@5 100.000 (82.097)
Test on T test set - [1][1540/1731]	Time 0.189 (0.220)	Loss 2.0912 (1.5851)	Prec@1 34.375 (57.457)	Prec@5 96.875 (82.197)
Test on T test set - [1][1550/1731]	Time 0.238 (0.220)	Loss 1.6010 (1.5870)	Prec@1 53.125 (57.382)	Prec@5 96.875 (82.284)
Test on T test set - [1][1560/1731]	Time 0.189 (0.220)	Loss 4.0545 (1.5906)	Prec@1 9.375 (57.297)	Prec@5 56.250 (82.281)
Test on T test set - [1][1570/1731]	Time 0.174 (0.220)	Loss 4.3789 (1.6067)	Prec@1 0.000 (56.976)	Prec@5 56.250 (82.044)
Test on T test set - [1][1580/1731]	Time 0.163 (0.219)	Loss 4.0813 (1.6227)	Prec@1 6.250 (56.669)	Prec@5 34.375 (81.819)
Test on T test set - [1][1590/1731]	Time 0.162 (0.219)	Loss 4.1651 (1.6379)	Prec@1 3.125 (56.362)	Prec@5 37.500 (81.582)
Test on T test set - [1][1600/1731]	Time 0.180 (0.219)	Loss 4.2517 (1.6536)	Prec@1 6.250 (56.063)	Prec@5 59.375 (81.385)
Test on T test set - [1][1610/1731]	Time 0.181 (0.219)	Loss 4.2854 (1.6686)	Prec@1 6.250 (55.765)	Prec@5 43.750 (81.186)
Test on T test set - [1][1620/1731]	Time 0.233 (0.220)	Loss 3.6315 (1.6823)	Prec@1 15.625 (55.479)	Prec@5 62.500 (80.978)
Test on T test set - [1][1630/1731]	Time 0.170 (0.220)	Loss 4.4515 (1.6969)	Prec@1 6.250 (55.196)	Prec@5 46.875 (80.761)
Test on T test set - [1][1640/1731]	Time 0.211 (0.219)	Loss 3.9673 (1.7116)	Prec@1 9.375 (54.909)	Prec@5 53.125 (80.559)
Test on T test set - [1][1650/1731]	Time 0.230 (0.219)	Loss 3.7780 (1.7235)	Prec@1 12.500 (54.668)	Prec@5 62.500 (80.457)
Test on T test set - [1][1660/1731]	Time 0.229 (0.219)	Loss 3.2468 (1.7339)	Prec@1 21.875 (54.455)	Prec@5 68.750 (80.401)
Test on T test set - [1][1670/1731]	Time 0.223 (0.219)	Loss 3.0586 (1.7446)	Prec@1 21.875 (54.236)	Prec@5 68.750 (80.292)
Test on T test set - [1][1680/1731]	Time 0.185 (0.219)	Loss 3.6042 (1.7552)	Prec@1 12.500 (53.997)	Prec@5 75.000 (80.233)
Test on T test set - [1][1690/1731]	Time 0.278 (0.219)	Loss 3.6587 (1.7660)	Prec@1 12.500 (53.783)	Prec@5 65.625 (80.171)
Test on T test set - [1][1700/1731]	Time 2.673 (0.221)	Loss 3.5428 (1.7771)	Prec@1 18.750 (53.562)	Prec@5 78.125 (80.104)
Test on T test set - [1][1710/1731]	Time 0.216 (0.221)	Loss 3.6576 (1.7868)	Prec@1 12.500 (53.361)	Prec@5 59.375 (80.032)
Test on T test set - [1][1720/1731]	Time 0.189 (0.221)	Loss 3.3277 (1.7967)	Prec@1 25.000 (53.149)	Prec@5 68.750 (79.946)
Test on T test set - [1][1730/1731]	Time 0.166 (0.221)	Loss 3.2034 (1.8056)	Prec@1 17.857 (52.963)	Prec@5 57.143 (79.866)
 * Test on T test set - Prec@1 52.963, Prec@5 79.866
Epoch 1 - Kernel K-means clustering 0: Clustering time 41.788, Prec@1 52.759
Epoch 1 - Kernel K-means clustering 1: Clustering time 41.885, Prec@1 52.472
Epoch 1 - Kernel K-means clustering 2: Clustering time 41.431, Prec@1 52.374
Epoch 1 - Kernel K-means clustering 3: Clustering time 41.225, Prec@1 52.235
Epoch 1 - Kernel K-means clustering 4: Clustering time 43.666, Prec@1 52.111
Epoch 1 - Kernel K-means clustering 5: Clustering time 42.155, Prec@1 52.053
Epoch 1 - Kernel K-means clustering 6: Clustering time 42.276, Prec@1 52.020
Epoch 1 - Kernel K-means clustering 7: Clustering time 42.824, Prec@1 52.008
Epoch 1 - Kernel K-means clustering 8: Clustering time 41.902, Prec@1 51.988
Epoch 1 - Kernel K-means clustering 9: Clustering time 41.252, Prec@1 51.982
Epoch 1 - Kernel K-means clustering 10: Clustering time 41.314, Prec@1 51.973
Epoch 1 - Kernel K-means clustering 11: Clustering time 41.307, Prec@1 51.966
Epoch 1 - Kernel K-means clustering 12: Clustering time 41.279, Prec@1 51.961
Converged at iteration 13
Epoch 1 - Kernel K-means clustering 0: Clustering time 41.225, Prec@1 53.017
Epoch 1 - Kernel K-means clustering 1: Clustering time 40.998, Prec@1 53.100
Epoch 1 - Kernel K-means clustering 2: Clustering time 41.108, Prec@1 53.156
Epoch 1 - Kernel K-means clustering 3: Clustering time 41.191, Prec@1 53.147
Epoch 1 - Kernel K-means clustering 4: Clustering time 41.221, Prec@1 53.160
Epoch 1 - Kernel K-means clustering 5: Clustering time 41.184, Prec@1 53.161
Epoch 1 - Kernel K-means clustering 6: Clustering time 41.169, Prec@1 53.167
Epoch 1 - Kernel K-means clustering 7: Clustering time 41.178, Prec@1 53.172
Epoch 1 - Kernel K-means clustering 8: Clustering time 41.293, Prec@1 53.169
Epoch 1 - Kernel K-means clustering 9: Clustering time 41.274, Prec@1 53.163
Epoch 1 - Kernel K-means clustering 10: Clustering time 42.932, Prec@1 53.161
Converged at iteration 11
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2217 (1.2217)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.2552 (1.2552)
Train - epoch [2/200]	BT 1.304 (1.304)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2438 (1.2438)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.3535 (1.3535)
Train - epoch [2/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2955 (1.2955)
Train - epoch [2/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2300 (1.2300)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.2216 (1.2216)
Train - epoch [2/200]	BT 1.304 (1.304)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.2437 (1.2437)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2587 (1.2587)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.2142 (1.2142)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2700 (1.2700)
Train - epoch [2/200]	BT 4.607 (4.607)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2688 (1.2688)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.2066 (1.2066)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.2146 (1.2146)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2470 (1.2470)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2340 (1.2340)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2442 (1.2442)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2744 (1.2744)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.3282 (1.3282)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2892 (1.2892)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2164 (1.2164)
Train - epoch [2/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3999 (1.3999)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2204 (1.2204)
Train - epoch [2/200]	BT 1.299 (1.299)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2713 (1.2713)
Train - epoch [2/200]	BT 4.177 (4.177)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.5141 (1.5141)
Train - epoch [2/200]	BT 1.305 (1.305)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3254 (1.3254)
Train - epoch [2/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.3219 (1.3219)
Train - epoch [2/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2825 (1.2825)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3464 (1.3464)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2544 (1.2544)
Train - epoch [2/200]	BT 4.241 (4.241)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.3071 (1.3071)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2853 (1.2853)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2550 (1.2550)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 100.000 (100.000)	Loss 1.2350 (1.2350)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.4272 (1.4272)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2513 (1.2513)
Train - epoch [2/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2955 (1.2955)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2478 (1.2478)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3560 (1.3560)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.3151 (1.3151)
Train - epoch [2/200]	BT 3.981 (3.981)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2966 (1.2966)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2861 (1.2861)
Train - epoch [2/200]	BT 1.241 (1.241)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2678 (1.2678)
Train - epoch [2/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.3689 (1.3689)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2192 (1.2192)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3030 (1.3030)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2727 (1.2727)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2214 (1.2214)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.4198 (1.4198)
Train - epoch [2/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2464 (1.2464)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2458 (1.2458)
Train - epoch [2/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2834 (1.2834)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2796 (1.2796)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2436 (1.2436)
Train - epoch [2/200]	BT 4.095 (4.095)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2346 (1.2346)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2818 (1.2818)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2443 (1.2443)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3076 (1.3076)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2406 (1.2406)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2723 (1.2723)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2376 (1.2376)
Train - epoch [2/200]	BT 4.312 (4.312)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2463 (1.2463)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2300 (1.2300)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2872 (1.2872)
Train - epoch [2/200]	BT 4.120 (4.120)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2852 (1.2852)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.4435 (1.4435)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2458 (1.2458)
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2302 (1.2302)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3300 (1.3300)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2471 (1.2471)
Train - epoch [2/200]	BT 4.297 (4.297)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2559 (1.2559)
Train - epoch [2/200]	BT 1.301 (1.301)	DT 0.000 (0.000)	S@1 96.875 (96.875)	Loss 1.2039 (1.2039)
Train - epoch [2/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2636 (1.2636)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2742 (1.2742)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.4629 (1.4629)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2333 (1.2333)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2918 (1.2918)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2532 (1.2532)
Train - epoch [2/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2219 (1.2219)
Train - epoch [2/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.4548 (1.4548)
Train - epoch [2/200]	BT 4.136 (4.136)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2231 (1.2231)
Train - epoch [2/200]	BT 1.297 (1.297)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2456 (1.2456)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2564 (1.2564)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2635 (1.2635)
Train - epoch [2/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2429 (1.2429)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3189 (1.3189)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2603 (1.2603)
Train - epoch [2/200]	BT 3.806 (3.806)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3410 (1.3410)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2274 (1.2274)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3271 (1.3271)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3002 (1.3002)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.3081 (1.3081)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2614 (1.2614)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.5257 (1.5257)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2342 (1.2342)
Train - epoch [2/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2667 (1.2667)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.3676 (1.3676)
Train - epoch [2/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2618 (1.2618)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2634 (1.2634)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3528 (1.3528)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2521 (1.2521)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 93.750 (93.750)	Loss 1.2399 (1.2399)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2928 (1.2928)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2873 (1.2873)
Train - epoch [2/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2421 (1.2421)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3377 (1.3377)
Train - epoch [2/200]	BT 4.303 (4.303)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3411 (1.3411)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2487 (1.2487)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2362 (1.2362)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2537 (1.2537)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2548 (1.2548)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2988 (1.2988)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2375 (1.2375)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2336 (1.2336)
Train - epoch [2/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.3594 (1.3594)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2554 (1.2554)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2654 (1.2654)
Train - epoch [2/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2960 (1.2960)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2456 (1.2456)
Train - epoch [2/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3557 (1.3557)
Train - epoch [2/200]	BT 3.633 (3.633)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3618 (1.3618)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2687 (1.2687)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2498 (1.2498)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2921 (1.2921)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3534 (1.3534)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.3330 (1.3330)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3473 (1.3473)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3050 (1.3050)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2553 (1.2553)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2657 (1.2657)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3471 (1.3471)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2386 (1.2386)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2935 (1.2935)
Train - epoch [2/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2686 (1.2686)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2526 (1.2526)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2226 (1.2226)
Train - epoch [2/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2395 (1.2395)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2492 (1.2492)
Train - epoch [2/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2206 (1.2206)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2785 (1.2785)
Train - epoch [2/200]	BT 4.191 (4.191)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2285 (1.2285)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.2831 (1.2831)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.4064 (1.4064)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2754 (1.2754)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3363 (1.3363)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2235 (1.2235)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2566 (1.2566)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3134 (1.3134)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2479 (1.2479)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3432 (1.3432)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 90.625 (90.625)	Loss 1.2294 (1.2294)
Train - epoch [2/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2943 (1.2943)
Train - epoch [2/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2508 (1.2508)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3521 (1.3521)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.4032 (1.4032)
Train - epoch [2/200]	BT 4.604 (4.604)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.4434 (1.4434)
Train - epoch [2/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3156 (1.3156)
Train - epoch [2/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2880 (1.2880)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3270 (1.3270)
Train - epoch [2/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3993 (1.3993)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2355 (1.2355)
Train - epoch [2/200]	BT 1.302 (1.302)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3522 (1.3522)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.4738 (1.4738)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.4196 (1.4196)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3787 (1.3787)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2282 (1.2282)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2304 (1.2304)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.3027 (1.3027)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3871 (1.3871)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.4963 (1.4963)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2319 (1.2319)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.4272 (1.4272)
Train - epoch [2/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.4040 (1.4040)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2569 (1.2569)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2139 (1.2139)
Train - epoch [2/200]	BT 4.358 (4.358)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.2460 (1.2460)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3603 (1.3603)
Train - epoch [2/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.4313 (1.4313)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.4795 (1.4795)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2371 (1.2371)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.5157 (1.5157)
Train - epoch [2/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.5153 (1.5153)
Train - epoch [2/200]	BT 3.924 (3.924)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3082 (1.3082)
Train - epoch [2/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.4471 (1.4471)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2256 (1.2256)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2658 (1.2658)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.4145 (1.4145)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2391 (1.2391)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3507 (1.3507)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2392 (1.2392)
Train - epoch [2/200]	BT 3.785 (3.785)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3597 (1.3597)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2935 (1.2935)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2457 (1.2457)
Train - epoch [2/200]	BT 4.873 (4.873)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2991 (1.2991)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2647 (1.2647)
Train - epoch [2/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2933 (1.2933)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2752 (1.2752)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.3391 (1.3391)
Train - epoch [2/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2702 (1.2702)
Train - epoch [2/200]	BT 1.302 (1.302)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2416 (1.2416)
Train - epoch [2/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2521 (1.2521)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2412 (1.2412)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3236 (1.3236)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3638 (1.3638)
Train - epoch [2/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3550 (1.3550)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3183 (1.3183)
Train - epoch [2/200]	BT 4.276 (4.276)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2196 (1.2196)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.2680 (1.2680)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.3494 (1.3494)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.4179 (1.4179)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.2636 (1.2636)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3140 (1.3140)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3150 (1.3150)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3999 (1.3999)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3043 (1.3043)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2537 (1.2537)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3398 (1.3398)
Train - epoch [2/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.2918 (1.2918)
Train - epoch [2/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2437 (1.2437)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2817 (1.2817)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2500 (1.2500)
Train - epoch [2/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2710 (1.2710)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3572 (1.3572)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3174 (1.3174)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.5201 (1.5201)
Train - epoch [2/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2174 (1.2174)
Train - epoch [2/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2504 (1.2504)
Train - epoch [2/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3333 (1.3333)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2572 (1.2572)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2864 (1.2864)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2403 (1.2403)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.4935 (1.4935)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2311 (1.2311)
Train - epoch [2/200]	BT 4.334 (4.334)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2731 (1.2731)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.3666 (1.3666)
Train - epoch [2/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.4302 (1.4302)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3156 (1.3156)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3460 (1.3460)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2738 (1.2738)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2284 (1.2284)
Train - epoch [2/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2416 (1.2416)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2755 (1.2755)
Train - epoch [2/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3174 (1.3174)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2477 (1.2477)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2999 (1.2999)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3953 (1.3953)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2361 (1.2361)
Train - epoch [2/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.4215 (1.4215)
Train - epoch [2/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.4468 (1.4468)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2513 (1.2513)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3028 (1.3028)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2622 (1.2622)
Train - epoch [2/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2412 (1.2412)
Train - epoch [2/200]	BT 4.085 (4.085)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3497 (1.3497)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3463 (1.3463)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2492 (1.2492)
Train - epoch [2/200]	BT 4.526 (4.526)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3773 (1.3773)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3364 (1.3364)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.3476 (1.3476)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.4393 (1.4393)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2657 (1.2657)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2738 (1.2738)
Train - epoch [2/200]	BT 1.307 (1.307)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2810 (1.2810)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.3478 (1.3478)
Train - epoch [2/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.3901 (1.3901)
Train - epoch [2/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.4329 (1.4329)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2619 (1.2619)
Train - epoch [2/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3305 (1.3305)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.3154 (1.3154)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2623 (1.2623)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2956 (1.2956)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2769 (1.2769)
Train - epoch [2/200]	BT 4.276 (4.276)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2370 (1.2370)
Train - epoch [2/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2362 (1.2362)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2574 (1.2574)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3548 (1.3548)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 1.7022 (1.7022)
Train - epoch [2/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2922 (1.2922)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2625 (1.2625)
Train - epoch [2/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2586 (1.2586)
Train - epoch [2/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2344 (1.2344)
Train - epoch [2/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2755 (1.2755)
Train - epoch [2/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2971 (1.2971)
Train - epoch [2/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2608 (1.2608)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3623 (1.3623)
Train - epoch [2/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3181 (1.3181)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2686 (1.2686)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2551 (1.2551)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2227 (1.2227)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2352 (1.2352)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2632 (1.2632)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3558 (1.3558)
Train - epoch [2/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.2787 (1.2787)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2322 (1.2322)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3687 (1.3687)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2600 (1.2600)
Train - epoch [2/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2666 (1.2666)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2241 (1.2241)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2550 (1.2550)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2515 (1.2515)
Train - epoch [2/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.2904 (1.2904)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2758 (1.2758)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.4380 (1.4380)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.3605 (1.3605)
Train - epoch [2/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3394 (1.3394)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2621 (1.2621)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2961 (1.2961)
Train - epoch [2/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2551 (1.2551)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2126 (1.2126)
Train - epoch [2/200]	BT 4.548 (4.548)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2269 (1.2269)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.4928 (1.4928)
Train - epoch [2/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.4472 (1.4472)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3609 (1.3609)
Train - epoch [2/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.3030 (1.3030)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2332 (1.2332)
Train - epoch [2/200]	BT 4.049 (4.049)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.2678 (1.2678)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2818 (1.2818)
Train - epoch [2/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2574 (1.2574)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3759 (1.3759)
Train - epoch [2/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.2799 (1.2799)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3289 (1.3289)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3174 (1.3174)
Train - epoch [2/200]	BT 4.149 (4.149)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2742 (1.2742)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3617 (1.3617)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2648 (1.2648)
Train - epoch [2/200]	BT 4.555 (4.555)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2834 (1.2834)
Train - epoch [2/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2838 (1.2838)
Train - epoch [2/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3182 (1.3182)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.3418 (1.3418)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2530 (1.2530)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2587 (1.2587)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2628 (1.2628)
Train - epoch [2/200]	BT 4.078 (4.078)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2459 (1.2459)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2906 (1.2906)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3740 (1.3740)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.3891 (1.3891)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3651 (1.3651)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.3989 (1.3989)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2515 (1.2515)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2582 (1.2582)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2826 (1.2826)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3743 (1.3743)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3098 (1.3098)
Train - epoch [2/200]	BT 3.928 (3.928)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 1.5644 (1.5644)
Train - epoch [2/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2557 (1.2557)
Train - epoch [2/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.3859 (1.3859)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2567 (1.2567)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2410 (1.2410)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2531 (1.2531)
Train - epoch [2/200]	BT 1.306 (1.306)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2732 (1.2732)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3269 (1.3269)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2937 (1.2937)
Train - epoch [2/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3479 (1.3479)
Train - epoch [2/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2484 (1.2484)
Train - epoch [2/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3425 (1.3425)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2970 (1.2970)
Train - epoch [2/200]	BT 1.299 (1.299)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.4479 (1.4479)
Train - epoch [2/200]	BT 4.061 (4.061)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.4248 (1.4248)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2667 (1.2667)
Train - epoch [2/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.2785 (1.2785)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3075 (1.3075)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3253 (1.3253)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3227 (1.3227)
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2431 (1.2431)
Train - epoch [2/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2977 (1.2977)
Train - epoch [2/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2475 (1.2475)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3101 (1.3101)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.4055 (1.4055)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3335 (1.3335)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2585 (1.2585)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3241 (1.3241)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2782 (1.2782)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.3173 (1.3173)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2119 (1.2119)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2682 (1.2682)
Train - epoch [2/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3095 (1.3095)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3492 (1.3492)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.2913 (1.2913)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2297 (1.2297)
Train - epoch [2/200]	BT 4.336 (4.336)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2988 (1.2988)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3085 (1.3085)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.4752 (1.4752)
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3110 (1.3110)
Train - epoch [2/200]	BT 1.825 (1.825)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3240 (1.3240)
Train - epoch [2/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2333 (1.2333)
Train - epoch [2/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2515 (1.2515)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.4183 (1.4183)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2870 (1.2870)
Train - epoch [2/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2381 (1.2381)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.3345 (1.3345)
Train - epoch [2/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2943 (1.2943)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2400 (1.2400)
Train - epoch [2/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2734 (1.2734)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2096 (1.2096)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2691 (1.2691)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.2503 (1.2503)
Train - epoch [2/200]	BT 1.299 (1.299)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2620 (1.2620)
Train - epoch [2/200]	BT 1.300 (1.300)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3903 (1.3903)
Train - epoch [2/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.3906 (1.3906)
Train - epoch [2/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2694 (1.2694)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2341 (1.2341)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.3248 (1.3248)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3970 (1.3970)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 87.500 (87.500)	Loss 1.2962 (1.2962)
Train - epoch [2/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.5327 (1.5327)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3269 (1.3269)
Train - epoch [2/200]	BT 1.299 (1.299)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.2514 (1.2514)
Train - epoch [2/200]	BT 1.237 (1.237)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2807 (1.2807)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3998 (1.3998)
Train - epoch [2/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2619 (1.2619)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.5033 (1.5033)
Train - epoch [2/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2763 (1.2763)
Train - epoch [2/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2707 (1.2707)
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2425 (1.2425)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.2906 (1.2906)
Train - epoch [2/200]	BT 4.129 (4.129)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2555 (1.2555)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.4902 (1.4902)
Train - epoch [2/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.2907 (1.2907)
Train - epoch [2/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.3051 (1.3051)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.3682 (1.3682)
Train - epoch [2/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3549 (1.3549)
Train - epoch [2/200]	BT 3.619 (3.619)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2424 (1.2424)
Train - epoch [2/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2394 (1.2394)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.4607 (1.4607)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.5117 (1.5117)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.3051 (1.3051)
Train - epoch [2/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3880 (1.3880)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 1.2157 (1.2157)
Train - epoch [2/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2298 (1.2298)
Train - epoch [2/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3745 (1.3745)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3029 (1.3029)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2795 (1.2795)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.4281 (1.4281)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.3490 (1.3490)
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.2484 (1.2484)
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2414 (1.2414)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2943 (1.2943)
Train - epoch [2/200]	BT 4.399 (4.399)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.5228 (1.5228)
Train - epoch [2/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3943 (1.3943)
Train - epoch [2/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3060 (1.3060)
Train - epoch [2/200]	BT 1.297 (1.297)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2807 (1.2807)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.3246 (1.3246)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3820 (1.3820)
Train - epoch [2/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.3175 (1.3175)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.2506 (1.2506)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3447 (1.3447)
Train - epoch [2/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.4141 (1.4141)
Train - epoch [2/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.3978 (1.3978)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2701 (1.2701)
Train - epoch [2/200]	BT 4.026 (4.026)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2584 (1.2584)
Train - epoch [2/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3755 (1.3755)
Train - epoch [2/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.2812 (1.2812)
Train - epoch [2/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2965 (1.2965)
Train - epoch [2/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.4813 (1.4813)
Train - epoch [2/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2696 (1.2696)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2976 (1.2976)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.3251 (1.3251)
Train - epoch [2/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2030 (1.2030)
Train - epoch [2/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3105 (1.3105)
Train - epoch [2/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.2186 (1.2186)
Train - epoch [2/200]	BT 4.201 (4.201)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.3044 (1.3044)
Train - epoch [2/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3468 (1.3468)
Train - epoch [2/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.3705 (1.3705)
Train - epoch [2/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2681 (1.2681)
Train - epoch [2/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2515 (1.2515)
Train - epoch [2/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2786 (1.2786)
Train - epoch [2/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.2752 (1.2752)
Train - epoch [2/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.2238 (1.2238)
Train - epoch [2/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.2388 (1.2388)
Train - epoch [2/200]	BT 4.048 (4.048)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.2603 (1.2603)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 1.2383 (1.2383)
Train - epoch [2/200]	BT 1.305 (1.305)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.2993 (1.2993)
Train - epoch [2/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.2562 (1.2562)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.3723 (1.3723)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.3913 (1.3913)
Train - epoch [2/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.2956 (1.2956)
Test on T training set - [2][0/1731]	T 0.318 (0.318)	D 0.206 (0.206)	T@1 12.500 (12.500)	T@5 21.875 (21.875)	L 4.0364 (4.0364)
Test on T training set - [2][10/1731]	T 0.217 (0.206)	D 0.114 (0.104)	T@1 12.500 (14.773)	T@5 34.375 (40.341)	L 3.8067 (3.5253)
Test on T training set - [2][20/1731]	T 0.229 (0.217)	D 0.122 (0.115)	T@1 15.625 (15.030)	T@5 46.875 (43.304)	L 3.2160 (3.5547)
Test on T training set - [2][30/1731]	T 0.197 (0.217)	D 0.101 (0.114)	T@1 31.250 (15.121)	T@5 59.375 (43.548)	L 2.7813 (3.5156)
Test on T training set - [2][40/1731]	T 0.241 (0.218)	D 0.136 (0.116)	T@1 0.000 (14.253)	T@5 37.500 (43.979)	L 4.0010 (3.5324)
Test on T training set - [2][50/1731]	T 0.214 (0.219)	D 0.113 (0.116)	T@1 9.375 (13.848)	T@5 43.750 (44.056)	L 4.0400 (3.5713)
Test on T training set - [2][60/1731]	T 0.224 (0.219)	D 0.128 (0.117)	T@1 6.250 (13.473)	T@5 40.625 (43.904)	L 4.1215 (3.5670)
Test on T training set - [2][70/1731]	T 0.194 (0.218)	D 0.098 (0.116)	T@1 9.375 (13.072)	T@5 56.250 (43.706)	L 3.8084 (3.5915)
Test on T training set - [2][80/1731]	T 0.214 (0.217)	D 0.107 (0.115)	T@1 15.625 (12.924)	T@5 40.625 (43.673)	L 3.4558 (3.5900)
Test on T training set - [2][90/1731]	T 0.187 (0.232)	D 0.091 (0.130)	T@1 18.750 (13.084)	T@5 56.250 (43.750)	L 3.1752 (3.5718)
Test on T training set - [2][100/1731]	T 0.188 (0.228)	D 0.088 (0.126)	T@1 9.375 (13.243)	T@5 28.125 (43.719)	L 3.8126 (3.5769)
Test on T training set - [2][110/1731]	T 0.202 (0.224)	D 0.102 (0.122)	T@1 15.625 (13.851)	T@5 34.375 (43.609)	L 3.6801 (3.5560)
Test on T training set - [2][120/1731]	T 0.209 (0.221)	D 0.107 (0.119)	T@1 18.750 (13.843)	T@5 34.375 (42.820)	L 4.4567 (3.6193)
Test on T training set - [2][130/1731]	T 0.201 (0.219)	D 0.093 (0.118)	T@1 12.500 (13.955)	T@5 28.125 (41.746)	L 4.6422 (3.6984)
Test on T training set - [2][140/1731]	T 0.184 (0.217)	D 0.086 (0.116)	T@1 9.375 (14.384)	T@5 9.375 (41.157)	L 5.0959 (3.7476)
Test on T training set - [2][150/1731]	T 0.194 (0.216)	D 0.098 (0.114)	T@1 21.875 (14.652)	T@5 34.375 (40.459)	L 4.1314 (3.8092)
Test on T training set - [2][160/1731]	T 0.180 (0.214)	D 0.085 (0.112)	T@1 28.125 (15.159)	T@5 40.625 (40.373)	L 4.4708 (3.8458)
Test on T training set - [2][170/1731]	T 0.182 (0.212)	D 0.079 (0.110)	T@1 9.375 (15.278)	T@5 18.750 (39.766)	L 5.6713 (3.8950)
Test on T training set - [2][180/1731]	T 0.157 (0.210)	D 0.058 (0.108)	T@1 9.375 (15.297)	T@5 12.500 (39.002)	L 5.0142 (3.9374)
Test on T training set - [2][190/1731]	T 0.182 (0.208)	D 0.082 (0.106)	T@1 15.625 (15.151)	T@5 21.875 (38.056)	L 4.5021 (4.0060)
Test on T training set - [2][200/1731]	T 0.166 (0.216)	D 0.066 (0.114)	T@1 9.375 (14.941)	T@5 34.375 (37.251)	L 4.7061 (4.0473)
Test on T training set - [2][210/1731]	T 0.173 (0.214)	D 0.073 (0.112)	T@1 21.875 (14.944)	T@5 28.125 (36.685)	L 4.2642 (4.0729)
Test on T training set - [2][220/1731]	T 0.182 (0.212)	D 0.079 (0.110)	T@1 21.875 (15.031)	T@5 40.625 (36.213)	L 4.2680 (4.1004)
Test on T training set - [2][230/1731]	T 0.177 (0.211)	D 0.070 (0.109)	T@1 34.375 (15.571)	T@5 96.875 (38.231)	L 2.2806 (4.0526)
Test on T training set - [2][240/1731]	T 0.235 (0.212)	D 0.130 (0.110)	T@1 18.750 (15.949)	T@5 90.625 (40.508)	L 3.9775 (4.0191)
Test on T training set - [2][250/1731]	T 0.208 (0.213)	D 0.100 (0.111)	T@1 31.250 (16.322)	T@5 93.750 (42.605)	L 2.9955 (3.9805)
Test on T training set - [2][260/1731]	T 0.239 (0.213)	D 0.136 (0.112)	T@1 37.500 (16.798)	T@5 93.750 (44.588)	L 2.7242 (3.9463)
Test on T training set - [2][270/1731]	T 0.238 (0.214)	D 0.133 (0.112)	T@1 15.625 (17.113)	T@5 87.500 (46.402)	L 3.1748 (3.9160)
Test on T training set - [2][280/1731]	T 0.236 (0.223)	D 0.130 (0.121)	T@1 34.375 (17.538)	T@5 93.750 (48.109)	L 2.8989 (3.8831)
Test on T training set - [2][290/1731]	T 0.228 (0.223)	D 0.132 (0.121)	T@1 28.125 (17.902)	T@5 96.875 (49.774)	L 3.5551 (3.8584)
Test on T training set - [2][300/1731]	T 0.209 (0.223)	D 0.113 (0.121)	T@1 34.375 (18.210)	T@5 90.625 (51.204)	L 3.2759 (3.8378)
Test on T training set - [2][310/1731]	T 0.246 (0.223)	D 0.133 (0.121)	T@1 28.125 (18.660)	T@5 100.000 (52.613)	L 2.7420 (3.8074)
Test on T training set - [2][320/1731]	T 0.209 (0.223)	D 0.102 (0.121)	T@1 40.625 (19.013)	T@5 100.000 (53.933)	L 2.9041 (3.7805)
Test on T training set - [2][330/1731]	T 0.198 (0.222)	D 0.096 (0.120)	T@1 34.375 (19.354)	T@5 93.750 (55.145)	L 2.9383 (3.7536)
Test on T training set - [2][340/1731]	T 0.195 (0.221)	D 0.091 (0.119)	T@1 37.500 (19.804)	T@5 90.625 (56.250)	L 2.8422 (3.7221)
Test on T training set - [2][350/1731]	T 0.207 (0.220)	D 0.109 (0.118)	T@1 28.125 (20.085)	T@5 90.625 (57.247)	L 2.4033 (3.6969)
Test on T training set - [2][360/1731]	T 0.234 (0.221)	D 0.138 (0.119)	T@1 21.875 (20.412)	T@5 96.875 (58.354)	L 3.4805 (3.6759)
Test on T training set - [2][370/1731]	T 0.171 (0.223)	D 0.075 (0.122)	T@1 21.875 (20.670)	T@5 84.375 (59.316)	L 3.0713 (3.6537)
Test on T training set - [2][380/1731]	T 0.196 (0.222)	D 0.090 (0.120)	T@1 50.000 (20.817)	T@5 96.875 (60.146)	L 1.6162 (3.6259)
Test on T training set - [2][390/1731]	T 0.178 (0.221)	D 0.072 (0.119)	T@1 34.375 (21.164)	T@5 93.750 (61.069)	L 2.5397 (3.5933)
Test on T training set - [2][400/1731]	T 0.174 (0.220)	D 0.068 (0.118)	T@1 25.000 (21.353)	T@5 96.875 (61.845)	L 2.7575 (3.5676)
Test on T training set - [2][410/1731]	T 0.163 (0.219)	D 0.061 (0.117)	T@1 9.375 (21.411)	T@5 90.625 (62.584)	L 3.1255 (3.5467)
Test on T training set - [2][420/1731]	T 0.172 (0.218)	D 0.068 (0.116)	T@1 12.500 (21.474)	T@5 93.750 (63.294)	L 3.1819 (3.5281)
Test on T training set - [2][430/1731]	T 0.166 (0.216)	D 0.064 (0.114)	T@1 12.500 (21.527)	T@5 81.250 (63.936)	L 3.2468 (3.5094)
Test on T training set - [2][440/1731]	T 0.164 (0.215)	D 0.061 (0.113)	T@1 12.500 (21.606)	T@5 93.750 (64.647)	L 3.3457 (3.4898)
Test on T training set - [2][450/1731]	T 0.169 (0.214)	D 0.066 (0.112)	T@1 31.250 (21.792)	T@5 93.750 (65.341)	L 2.6757 (3.4672)
Test on T training set - [2][460/1731]	T 0.165 (0.213)	D 0.070 (0.111)	T@1 31.250 (22.024)	T@5 96.875 (66.039)	L 2.2316 (3.4433)
Test on T training set - [2][470/1731]	T 0.152 (0.212)	D 0.056 (0.110)	T@1 28.125 (22.207)	T@5 90.625 (66.633)	L 2.3825 (3.4231)
Test on T training set - [2][480/1731]	T 0.162 (0.211)	D 0.057 (0.110)	T@1 37.500 (22.453)	T@5 96.875 (67.230)	L 2.1883 (3.4007)
Test on T training set - [2][490/1731]	T 0.166 (0.214)	D 0.060 (0.112)	T@1 18.750 (22.543)	T@5 87.500 (67.732)	L 2.7305 (3.3844)
Test on T training set - [2][500/1731]	T 0.170 (0.213)	D 0.068 (0.111)	T@1 37.500 (22.705)	T@5 93.750 (68.257)	L 2.1527 (3.3686)
Test on T training set - [2][510/1731]	T 0.170 (0.212)	D 0.072 (0.110)	T@1 18.750 (22.707)	T@5 87.500 (68.719)	L 2.7967 (3.3570)
Test on T training set - [2][520/1731]	T 0.164 (0.212)	D 0.059 (0.110)	T@1 12.500 (22.697)	T@5 87.500 (69.164)	L 3.2068 (3.3457)
Test on T training set - [2][530/1731]	T 0.174 (0.211)	D 0.070 (0.109)	T@1 18.750 (22.669)	T@5 78.125 (69.550)	L 3.0512 (3.3359)
Test on T training set - [2][540/1731]	T 0.157 (0.210)	D 0.061 (0.108)	T@1 21.875 (22.603)	T@5 84.375 (69.917)	L 2.7619 (3.3292)
Test on T training set - [2][550/1731]	T 0.156 (0.209)	D 0.053 (0.107)	T@1 15.625 (22.544)	T@5 81.250 (70.259)	L 2.8020 (3.3186)
Test on T training set - [2][560/1731]	T 0.175 (0.208)	D 0.076 (0.106)	T@1 9.375 (22.504)	T@5 75.000 (70.549)	L 3.4670 (3.3105)
Test on T training set - [2][570/1731]	T 0.197 (0.208)	D 0.091 (0.106)	T@1 34.375 (22.526)	T@5 90.625 (70.939)	L 2.2125 (3.2997)
Test on T training set - [2][580/1731]	T 0.172 (0.207)	D 0.071 (0.105)	T@1 34.375 (22.574)	T@5 87.500 (71.316)	L 2.5062 (3.2899)
Test on T training set - [2][590/1731]	T 0.179 (0.207)	D 0.083 (0.105)	T@1 37.500 (22.615)	T@5 96.875 (71.685)	L 2.3637 (3.2788)
Test on T training set - [2][600/1731]	T 0.170 (0.208)	D 0.071 (0.106)	T@1 25.000 (22.697)	T@5 93.750 (72.026)	L 3.0120 (3.2670)
Test on T training set - [2][610/1731]	T 0.170 (0.208)	D 0.063 (0.106)	T@1 15.625 (22.775)	T@5 93.750 (72.371)	L 2.8547 (3.2548)
Test on T training set - [2][620/1731]	T 0.184 (0.207)	D 0.088 (0.105)	T@1 21.875 (22.876)	T@5 93.750 (72.730)	L 2.5813 (3.2433)
Test on T training set - [2][630/1731]	T 0.160 (0.207)	D 0.056 (0.105)	T@1 21.875 (22.969)	T@5 96.875 (73.093)	L 2.8400 (3.2329)
Test on T training set - [2][640/1731]	T 0.169 (0.206)	D 0.062 (0.104)	T@1 28.125 (23.026)	T@5 96.875 (73.416)	L 2.3235 (3.2223)
Test on T training set - [2][650/1731]	T 0.156 (0.206)	D 0.059 (0.104)	T@1 21.875 (23.133)	T@5 84.375 (73.709)	L 3.1790 (3.2109)
Test on T training set - [2][660/1731]	T 0.166 (0.205)	D 0.070 (0.103)	T@1 31.250 (23.208)	T@5 87.500 (74.026)	L 2.7670 (3.2035)
Test on T training set - [2][670/1731]	T 0.177 (0.204)	D 0.072 (0.102)	T@1 28.125 (23.235)	T@5 87.500 (74.297)	L 2.5993 (3.1960)
Test on T training set - [2][680/1731]	T 0.166 (0.204)	D 0.070 (0.102)	T@1 28.125 (23.183)	T@5 90.625 (74.518)	L 2.5619 (3.1915)
Test on T training set - [2][690/1731]	T 0.222 (0.203)	D 0.117 (0.101)	T@1 46.875 (23.291)	T@5 90.625 (74.724)	L 1.7811 (3.1821)
Test on T training set - [2][700/1731]	T 0.160 (0.203)	D 0.057 (0.101)	T@1 0.000 (23.186)	T@5 3.125 (74.028)	L 4.8421 (3.1909)
Test on T training set - [2][710/1731]	T 0.184 (0.203)	D 0.074 (0.101)	T@1 0.000 (22.868)	T@5 3.125 (73.070)	L 4.8381 (3.2121)
Test on T training set - [2][720/1731]	T 0.174 (0.205)	D 0.067 (0.103)	T@1 0.000 (22.551)	T@5 9.375 (72.148)	L 4.6839 (3.2340)
Test on T training set - [2][730/1731]	T 0.216 (0.205)	D 0.111 (0.102)	T@1 0.000 (22.243)	T@5 9.375 (71.306)	L 4.6861 (3.2536)
Test on T training set - [2][740/1731]	T 0.221 (0.205)	D 0.119 (0.103)	T@1 0.000 (21.955)	T@5 3.125 (70.475)	L 4.2650 (3.2708)
Test on T training set - [2][750/1731]	T 0.202 (0.205)	D 0.095 (0.103)	T@1 0.000 (21.667)	T@5 15.625 (69.678)	L 4.7307 (3.2890)
Test on T training set - [2][760/1731]	T 0.240 (0.205)	D 0.134 (0.103)	T@1 3.125 (21.395)	T@5 15.625 (68.918)	L 4.6437 (3.3084)
Test on T training set - [2][770/1731]	T 0.202 (0.205)	D 0.106 (0.103)	T@1 0.000 (21.125)	T@5 15.625 (68.158)	L 4.4275 (3.3257)
Test on T training set - [2][780/1731]	T 0.223 (0.205)	D 0.125 (0.103)	T@1 3.125 (20.863)	T@5 12.500 (67.426)	L 4.5014 (3.3443)
Test on T training set - [2][790/1731]	T 0.216 (0.205)	D 0.120 (0.103)	T@1 0.000 (20.599)	T@5 9.375 (66.660)	L 4.6799 (3.3626)
Test on T training set - [2][800/1731]	T 0.205 (0.205)	D 0.100 (0.104)	T@1 0.000 (20.350)	T@5 9.375 (65.988)	L 4.6582 (3.3782)
Test on T training set - [2][810/1731]	T 0.201 (0.205)	D 0.097 (0.104)	T@1 0.000 (20.106)	T@5 9.375 (65.278)	L 4.7952 (3.3946)
Test on T training set - [2][820/1731]	T 0.210 (0.208)	D 0.102 (0.106)	T@1 0.000 (19.861)	T@5 9.375 (64.582)	L 4.6847 (3.4106)
Test on T training set - [2][830/1731]	T 0.196 (0.208)	D 0.090 (0.106)	T@1 0.000 (19.626)	T@5 12.500 (63.921)	L 4.6254 (3.4272)
Test on T training set - [2][840/1731]	T 0.185 (0.207)	D 0.080 (0.105)	T@1 9.375 (19.419)	T@5 40.625 (63.329)	L 3.5822 (3.4418)
Test on T training set - [2][850/1731]	T 0.154 (0.207)	D 0.052 (0.105)	T@1 18.750 (19.334)	T@5 93.750 (63.682)	L 2.3256 (3.4331)
Test on T training set - [2][860/1731]	T 0.170 (0.206)	D 0.065 (0.104)	T@1 21.875 (19.265)	T@5 90.625 (64.028)	L 2.3806 (3.4240)
Test on T training set - [2][870/1731]	T 0.174 (0.206)	D 0.071 (0.104)	T@1 12.500 (19.213)	T@5 90.625 (64.351)	L 2.7218 (3.4142)
Test on T training set - [2][880/1731]	T 0.174 (0.205)	D 0.072 (0.103)	T@1 15.625 (19.140)	T@5 96.875 (64.692)	L 2.7594 (3.4061)
Test on T training set - [2][890/1731]	T 0.169 (0.205)	D 0.067 (0.103)	T@1 6.250 (19.069)	T@5 87.500 (64.990)	L 2.7028 (3.3977)
Test on T training set - [2][900/1731]	T 0.174 (0.205)	D 0.069 (0.103)	T@1 18.750 (19.038)	T@5 90.625 (65.299)	L 2.7749 (3.3881)
Test on T training set - [2][910/1731]	T 0.183 (0.204)	D 0.079 (0.102)	T@1 3.125 (18.898)	T@5 59.375 (65.436)	L 5.0965 (3.3936)
Test on T training set - [2][920/1731]	T 0.187 (0.204)	D 0.079 (0.102)	T@1 0.000 (18.730)	T@5 68.750 (65.442)	L 5.5750 (3.4144)
Test on T training set - [2][930/1731]	T 0.235 (0.207)	D 0.132 (0.106)	T@1 6.250 (18.542)	T@5 65.625 (65.497)	L 5.2136 (3.4350)
Test on T training set - [2][940/1731]	T 0.251 (0.208)	D 0.155 (0.106)	T@1 3.125 (18.378)	T@5 78.125 (65.565)	L 5.1586 (3.4521)
Test on T training set - [2][950/1731]	T 0.238 (0.208)	D 0.132 (0.106)	T@1 0.000 (18.201)	T@5 71.875 (65.609)	L 5.4707 (3.4709)
Test on T training set - [2][960/1731]	T 0.229 (0.208)	D 0.119 (0.106)	T@1 6.250 (18.048)	T@5 62.500 (65.632)	L 4.8137 (3.4879)
Test on T training set - [2][970/1731]	T 0.226 (0.208)	D 0.122 (0.106)	T@1 3.125 (17.904)	T@5 75.000 (65.693)	L 5.4331 (3.5049)
Test on T training set - [2][980/1731]	T 0.198 (0.208)	D 0.102 (0.107)	T@1 0.000 (17.734)	T@5 56.250 (65.730)	L 5.2932 (3.5245)
Test on T training set - [2][990/1731]	T 0.222 (0.208)	D 0.126 (0.107)	T@1 0.000 (17.593)	T@5 71.875 (65.745)	L 5.5060 (3.5426)
Test on T training set - [2][1000/1731]	T 0.228 (0.209)	D 0.122 (0.107)	T@1 6.250 (17.451)	T@5 78.125 (65.875)	L 5.1686 (3.5602)
Test on T training set - [2][1010/1731]	T 0.199 (0.211)	D 0.096 (0.109)	T@1 3.125 (17.310)	T@5 71.875 (65.882)	L 5.2399 (3.5752)
Test on T training set - [2][1020/1731]	T 0.204 (0.211)	D 0.108 (0.109)	T@1 6.250 (17.158)	T@5 75.000 (65.900)	L 4.8916 (3.5913)
Test on T training set - [2][1030/1731]	T 0.170 (0.211)	D 0.074 (0.109)	T@1 0.000 (17.037)	T@5 65.625 (65.913)	L 5.3860 (3.6071)
Test on T training set - [2][1040/1731]	T 0.176 (0.210)	D 0.071 (0.109)	T@1 0.000 (16.916)	T@5 43.750 (65.901)	L 5.4577 (3.6225)
Test on T training set - [2][1050/1731]	T 0.171 (0.210)	D 0.075 (0.108)	T@1 6.250 (16.817)	T@5 62.500 (65.753)	L 5.1641 (3.6346)
Test on T training set - [2][1060/1731]	T 0.165 (0.210)	D 0.058 (0.108)	T@1 0.000 (16.679)	T@5 50.000 (65.596)	L 5.1110 (3.6474)
Test on T training set - [2][1070/1731]	T 0.209 (0.209)	D 0.103 (0.108)	T@1 6.250 (16.567)	T@5 53.125 (65.432)	L 5.4151 (3.6589)
Test on T training set - [2][1080/1731]	T 0.164 (0.209)	D 0.066 (0.107)	T@1 0.000 (16.434)	T@5 46.875 (65.411)	L 5.2107 (3.6723)
Test on T training set - [2][1090/1731]	T 0.180 (0.209)	D 0.083 (0.107)	T@1 0.000 (16.298)	T@5 6.250 (65.198)	L 4.6857 (3.6830)
Test on T training set - [2][1100/1731]	T 0.205 (0.209)	D 0.099 (0.107)	T@1 0.000 (16.153)	T@5 3.125 (64.688)	L 4.5958 (3.6911)
Test on T training set - [2][1110/1731]	T 0.214 (0.209)	D 0.112 (0.107)	T@1 0.000 (16.008)	T@5 6.250 (64.185)	L 4.7031 (3.6998)
Test on T training set - [2][1120/1731]	T 0.185 (0.210)	D 0.089 (0.108)	T@1 0.000 (15.865)	T@5 15.625 (63.685)	L 4.3514 (3.7083)
Test on T training set - [2][1130/1731]	T 0.192 (0.210)	D 0.088 (0.108)	T@1 0.000 (15.724)	T@5 3.125 (63.194)	L 4.9578 (3.7159)
Test on T training set - [2][1140/1731]	T 0.194 (0.210)	D 0.095 (0.108)	T@1 0.000 (15.587)	T@5 15.625 (62.719)	L 4.4042 (3.7237)
Test on T training set - [2][1150/1731]	T 0.189 (0.210)	D 0.084 (0.108)	T@1 0.000 (15.451)	T@5 9.375 (62.248)	L 4.9217 (3.7322)
Test on T training set - [2][1160/1731]	T 0.176 (0.209)	D 0.073 (0.108)	T@1 0.000 (15.318)	T@5 6.250 (61.800)	L 4.5771 (3.7392)
Test on T training set - [2][1170/1731]	T 0.179 (0.209)	D 0.080 (0.107)	T@1 0.000 (15.187)	T@5 3.125 (61.336)	L 4.4985 (3.7462)
Test on T training set - [2][1180/1731]	T 0.182 (0.209)	D 0.083 (0.107)	T@1 0.000 (15.059)	T@5 15.625 (60.883)	L 4.9631 (3.7535)
Test on T training set - [2][1190/1731]	T 0.198 (0.209)	D 0.095 (0.107)	T@1 0.000 (14.932)	T@5 6.250 (60.448)	L 4.0723 (3.7600)
Test on T training set - [2][1200/1731]	T 0.172 (0.209)	D 0.076 (0.107)	T@1 0.000 (14.808)	T@5 6.250 (60.049)	L 4.2622 (3.7669)
Test on T training set - [2][1210/1731]	T 0.202 (0.209)	D 0.096 (0.107)	T@1 0.000 (14.686)	T@5 9.375 (59.630)	L 4.8156 (3.7737)
Test on T training set - [2][1220/1731]	T 0.165 (0.208)	D 0.069 (0.106)	T@1 6.250 (14.583)	T@5 31.250 (59.334)	L 4.1444 (3.7805)
Test on T training set - [2][1230/1731]	T 0.157 (0.209)	D 0.057 (0.107)	T@1 6.250 (14.483)	T@5 28.125 (59.027)	L 4.2778 (3.7871)
Test on T training set - [2][1240/1731]	T 0.170 (0.209)	D 0.075 (0.107)	T@1 0.000 (14.376)	T@5 34.375 (58.740)	L 4.9214 (3.7944)
Test on T training set - [2][1250/1731]	T 0.177 (0.209)	D 0.081 (0.107)	T@1 0.000 (14.286)	T@5 28.125 (58.496)	L 5.0616 (3.8009)
Test on T training set - [2][1260/1731]	T 0.192 (0.208)	D 0.092 (0.107)	T@1 0.000 (14.190)	T@5 25.000 (58.260)	L 5.1268 (3.8085)
Test on T training set - [2][1270/1731]	T 0.184 (0.208)	D 0.083 (0.106)	T@1 0.000 (14.093)	T@5 31.250 (58.025)	L 5.1497 (3.8158)
Test on T training set - [2][1280/1731]	T 0.197 (0.208)	D 0.094 (0.106)	T@1 9.375 (14.000)	T@5 25.000 (57.784)	L 4.6384 (3.8229)
Test on T training set - [2][1290/1731]	T 0.176 (0.208)	D 0.071 (0.106)	T@1 0.000 (13.906)	T@5 21.875 (57.543)	L 4.8570 (3.8295)
Test on T training set - [2][1300/1731]	T 0.174 (0.208)	D 0.078 (0.106)	T@1 3.125 (13.814)	T@5 28.125 (57.321)	L 4.5603 (3.8368)
Test on T training set - [2][1310/1731]	T 0.181 (0.207)	D 0.085 (0.106)	T@1 9.375 (13.735)	T@5 21.875 (57.144)	L 4.7063 (3.8434)
Test on T training set - [2][1320/1731]	T 0.200 (0.207)	D 0.097 (0.105)	T@1 0.000 (13.645)	T@5 37.500 (56.929)	L 4.9631 (3.8509)
Test on T training set - [2][1330/1731]	T 0.170 (0.208)	D 0.068 (0.106)	T@1 3.125 (13.552)	T@5 31.250 (56.713)	L 4.8306 (3.8585)
Test on T training set - [2][1340/1731]	T 0.172 (0.208)	D 0.065 (0.106)	T@1 0.000 (13.462)	T@5 28.125 (56.485)	L 5.1449 (3.8669)
Test on T training set - [2][1350/1731]	T 0.166 (0.208)	D 0.070 (0.106)	T@1 3.125 (13.372)	T@5 25.000 (56.264)	L 5.0581 (3.8754)
Test on T training set - [2][1360/1731]	T 0.173 (0.207)	D 0.064 (0.106)	T@1 15.625 (13.320)	T@5 68.750 (56.232)	L 3.2373 (3.8749)
Test on T training set - [2][1370/1731]	T 0.161 (0.207)	D 0.060 (0.105)	T@1 9.375 (13.311)	T@5 53.125 (56.314)	L 3.1987 (3.8708)
Test on T training set - [2][1380/1731]	T 0.176 (0.207)	D 0.069 (0.105)	T@1 25.000 (13.326)	T@5 62.500 (56.372)	L 2.5340 (3.8663)
Test on T training set - [2][1390/1731]	T 0.176 (0.207)	D 0.071 (0.105)	T@1 3.125 (13.304)	T@5 50.000 (56.398)	L 3.7979 (3.8634)
Test on T training set - [2][1400/1731]	T 0.175 (0.206)	D 0.072 (0.104)	T@1 3.125 (13.270)	T@5 40.625 (56.460)	L 3.5884 (3.8605)
Test on T training set - [2][1410/1731]	T 0.176 (0.206)	D 0.073 (0.104)	T@1 0.000 (13.249)	T@5 59.375 (56.529)	L 3.6430 (3.8570)
Test on T training set - [2][1420/1731]	T 0.171 (0.206)	D 0.066 (0.104)	T@1 21.875 (13.250)	T@5 59.375 (56.593)	L 2.8121 (3.8530)
Test on T training set - [2][1430/1731]	T 0.213 (0.208)	D 0.109 (0.106)	T@1 12.500 (13.258)	T@5 96.875 (56.750)	L 3.5809 (3.8498)
Test on T training set - [2][1440/1731]	T 0.244 (0.208)	D 0.147 (0.106)	T@1 21.875 (13.294)	T@5 87.500 (56.976)	L 3.4004 (3.8462)
Test on T training set - [2][1450/1731]	T 0.236 (0.208)	D 0.133 (0.106)	T@1 9.375 (13.295)	T@5 87.500 (57.202)	L 3.6006 (3.8433)
Test on T training set - [2][1460/1731]	T 0.225 (0.209)	D 0.129 (0.107)	T@1 15.625 (13.345)	T@5 93.750 (57.444)	L 3.1092 (3.8376)
Test on T training set - [2][1470/1731]	T 0.243 (0.209)	D 0.134 (0.107)	T@1 12.500 (13.354)	T@5 87.500 (57.637)	L 3.4798 (3.8347)
Test on T training set - [2][1480/1731]	T 0.247 (0.209)	D 0.148 (0.107)	T@1 9.375 (13.393)	T@5 96.875 (57.847)	L 3.6443 (3.8295)
Test on T training set - [2][1490/1731]	T 0.226 (0.209)	D 0.129 (0.107)	T@1 25.000 (13.418)	T@5 93.750 (58.080)	L 2.9139 (3.8248)
Test on T training set - [2][1500/1731]	T 0.252 (0.209)	D 0.147 (0.107)	T@1 18.750 (13.441)	T@5 93.750 (58.284)	L 3.2940 (3.8209)
Test on T training set - [2][1510/1731]	T 0.243 (0.210)	D 0.138 (0.108)	T@1 25.000 (13.464)	T@5 84.375 (58.498)	L 3.1608 (3.8176)
Test on T training set - [2][1520/1731]	T 0.225 (0.210)	D 0.127 (0.108)	T@1 21.875 (13.494)	T@5 90.625 (58.705)	L 3.2518 (3.8139)
Test on T training set - [2][1530/1731]	T 0.227 (0.210)	D 0.122 (0.108)	T@1 15.625 (13.504)	T@5 93.750 (58.924)	L 3.3220 (3.8109)
Test on T training set - [2][1540/1731]	T 0.192 (0.210)	D 0.096 (0.108)	T@1 18.750 (13.502)	T@5 75.000 (59.097)	L 3.7791 (3.8093)
Test on T training set - [2][1550/1731]	T 0.237 (0.210)	D 0.141 (0.108)	T@1 9.375 (13.501)	T@5 84.375 (59.252)	L 3.5190 (3.8081)
Test on T training set - [2][1560/1731]	T 0.192 (0.210)	D 0.096 (0.108)	T@1 3.125 (13.509)	T@5 50.000 (59.349)	L 4.4187 (3.8070)
Test on T training set - [2][1570/1731]	T 0.192 (0.210)	D 0.080 (0.108)	T@1 0.000 (13.441)	T@5 28.125 (59.198)	L 4.5767 (3.8120)
Test on T training set - [2][1580/1731]	T 0.164 (0.210)	D 0.062 (0.108)	T@1 9.375 (13.380)	T@5 53.125 (59.071)	L 3.6162 (3.8165)
Test on T training set - [2][1590/1731]	T 0.163 (0.210)	D 0.064 (0.108)	T@1 6.250 (13.307)	T@5 18.750 (58.915)	L 4.3836 (3.8206)
Test on T training set - [2][1600/1731]	T 0.182 (0.210)	D 0.086 (0.108)	T@1 6.250 (13.236)	T@5 34.375 (58.784)	L 4.2481 (3.8248)
Test on T training set - [2][1610/1731]	T 0.176 (0.211)	D 0.074 (0.109)	T@1 0.000 (13.171)	T@5 34.375 (58.634)	L 4.6998 (3.8287)
Test on T training set - [2][1620/1731]	T 0.177 (0.210)	D 0.081 (0.109)	T@1 3.125 (13.115)	T@5 50.000 (58.492)	L 4.8789 (3.8327)
Test on T training set - [2][1630/1731]	T 0.171 (0.210)	D 0.075 (0.108)	T@1 9.375 (13.065)	T@5 34.375 (58.375)	L 4.2383 (3.8357)
Test on T training set - [2][1640/1731]	T 0.221 (0.210)	D 0.121 (0.108)	T@1 0.000 (13.005)	T@5 43.750 (58.267)	L 4.8995 (3.8403)
Test on T training set - [2][1650/1731]	T 0.224 (0.210)	D 0.128 (0.108)	T@1 3.125 (12.939)	T@5 37.500 (58.188)	L 4.8961 (3.8458)
Test on T training set - [2][1660/1731]	T 0.209 (0.210)	D 0.109 (0.108)	T@1 3.125 (12.882)	T@5 46.875 (58.137)	L 4.8000 (3.8510)
Test on T training set - [2][1670/1731]	T 0.211 (0.210)	D 0.101 (0.108)	T@1 0.000 (12.814)	T@5 53.125 (58.086)	L 4.7790 (3.8570)
Test on T training set - [2][1680/1731]	T 0.202 (0.210)	D 0.097 (0.108)	T@1 3.125 (12.760)	T@5 40.625 (58.040)	L 4.3003 (3.8624)
Test on T training set - [2][1690/1731]	T 0.229 (0.210)	D 0.121 (0.109)	T@1 3.125 (12.705)	T@5 59.375 (58.009)	L 5.0310 (3.8684)
Test on T training set - [2][1700/1731]	T 0.216 (0.210)	D 0.120 (0.109)	T@1 9.375 (12.649)	T@5 59.375 (57.973)	L 4.6826 (3.8736)
Test on T training set - [2][1710/1731]	T 0.223 (0.212)	D 0.127 (0.110)	T@1 0.000 (12.589)	T@5 43.750 (57.903)	L 4.7077 (3.8788)
Test on T training set - [2][1720/1731]	T 0.196 (0.212)	D 0.100 (0.110)	T@1 0.000 (12.531)	T@5 34.375 (57.844)	L 5.0700 (3.8845)
Test on T training set - [2][1730/1731]	T 0.171 (0.212)	D 0.079 (0.110)	T@1 0.000 (12.476)	T@5 57.143 (57.803)	L 4.8125 (3.8899)
 * Test on T training set - Prec@1 12.476, Prec@5 57.803
Test on T test set - [2][0/1731]	Time 0.297 (0.297)	Loss 3.6316 (3.6316)	Prec@1 15.625 (15.625)	Prec@5 28.125 (28.125)
Test on T test set - [2][10/1731]	Time 0.205 (0.200)	Loss 3.9700 (3.4800)	Prec@1 12.500 (14.489)	Prec@5 34.375 (38.352)
Test on T test set - [2][20/1731]	Time 0.222 (0.211)	Loss 3.5209 (3.5200)	Prec@1 12.500 (14.137)	Prec@5 37.500 (40.625)
Test on T test set - [2][30/1731]	Time 0.210 (0.212)	Loss 2.5314 (3.4776)	Prec@1 34.375 (14.819)	Prec@5 53.125 (42.036)
Test on T test set - [2][40/1731]	Time 0.231 (0.213)	Loss 3.7803 (3.4853)	Prec@1 9.375 (14.482)	Prec@5 40.625 (42.530)
Test on T test set - [2][50/1731]	Time 0.222 (0.214)	Loss 3.6799 (3.5225)	Prec@1 15.625 (13.971)	Prec@5 40.625 (42.157)
Test on T test set - [2][60/1731]	Time 0.218 (0.214)	Loss 3.7768 (3.5455)	Prec@1 15.625 (13.627)	Prec@5 31.250 (41.906)
Test on T test set - [2][70/1731]	Time 0.197 (0.213)	Loss 3.6586 (3.5756)	Prec@1 12.500 (13.028)	Prec@5 59.375 (41.813)
Test on T test set - [2][80/1731]	Time 0.195 (0.238)	Loss 4.0882 (3.5829)	Prec@1 6.250 (13.079)	Prec@5 37.500 (42.207)
Test on T test set - [2][90/1731]	Time 0.194 (0.234)	Loss 3.3304 (3.5778)	Prec@1 15.625 (12.981)	Prec@5 34.375 (41.999)
Test on T test set - [2][100/1731]	Time 0.186 (0.230)	Loss 3.8649 (3.5784)	Prec@1 9.375 (13.119)	Prec@5 34.375 (42.110)
Test on T test set - [2][110/1731]	Time 0.207 (0.225)	Loss 3.4752 (3.5607)	Prec@1 15.625 (13.570)	Prec@5 40.625 (42.286)
Test on T test set - [2][120/1731]	Time 0.199 (0.222)	Loss 4.3261 (3.6171)	Prec@1 15.625 (13.765)	Prec@5 37.500 (41.348)
Test on T test set - [2][130/1731]	Time 0.196 (0.220)	Loss 4.9136 (3.7005)	Prec@1 15.625 (13.860)	Prec@5 18.750 (40.434)
Test on T test set - [2][140/1731]	Time 0.176 (0.217)	Loss 4.9715 (3.7412)	Prec@1 6.250 (14.317)	Prec@5 15.625 (40.226)
Test on T test set - [2][150/1731]	Time 0.202 (0.215)	Loss 3.3975 (3.7901)	Prec@1 34.375 (14.756)	Prec@5 43.750 (39.839)
Test on T test set - [2][160/1731]	Time 0.187 (0.213)	Loss 4.6441 (3.8292)	Prec@1 15.625 (15.334)	Prec@5 37.500 (39.752)
Test on T test set - [2][170/1731]	Time 0.174 (0.227)	Loss 5.5922 (3.8813)	Prec@1 6.250 (15.461)	Prec@5 21.875 (39.236)
Test on T test set - [2][180/1731]	Time 0.157 (0.224)	Loss 4.7125 (3.9246)	Prec@1 12.500 (15.625)	Prec@5 18.750 (38.450)
Test on T test set - [2][190/1731]	Time 0.179 (0.220)	Loss 4.5536 (3.9896)	Prec@1 15.625 (15.445)	Prec@5 28.125 (37.484)
Test on T test set - [2][200/1731]	Time 0.165 (0.218)	Loss 4.9164 (4.0362)	Prec@1 15.625 (15.221)	Prec@5 25.000 (36.614)
Test on T test set - [2][210/1731]	Time 0.176 (0.215)	Loss 3.4476 (4.0594)	Prec@1 31.250 (15.373)	Prec@5 40.625 (36.167)
Test on T test set - [2][220/1731]	Time 0.183 (0.214)	Loss 4.1915 (4.0788)	Prec@1 28.125 (15.554)	Prec@5 40.625 (35.874)
Test on T test set - [2][230/1731]	Time 0.165 (0.212)	Loss 2.6843 (4.0283)	Prec@1 31.250 (16.315)	Prec@5 100.000 (37.865)
Test on T test set - [2][240/1731]	Time 0.221 (0.213)	Loss 3.2549 (3.9954)	Prec@1 25.000 (16.662)	Prec@5 96.875 (40.210)
Test on T test set - [2][250/1731]	Time 0.210 (0.214)	Loss 2.9050 (3.9597)	Prec@1 21.875 (17.107)	Prec@5 93.750 (42.331)
Test on T test set - [2][260/1731]	Time 0.235 (0.214)	Loss 3.0018 (3.9311)	Prec@1 31.250 (17.421)	Prec@5 96.875 (44.361)
Test on T test set - [2][270/1731]	Time 0.233 (0.215)	Loss 3.4822 (3.9001)	Prec@1 21.875 (17.862)	Prec@5 96.875 (46.275)
Test on T test set - [2][280/1731]	Time 0.237 (0.219)	Loss 3.1802 (3.8707)	Prec@1 31.250 (18.250)	Prec@5 90.625 (47.965)
Test on T test set - [2][290/1731]	Time 0.226 (0.219)	Loss 3.2055 (3.8471)	Prec@1 28.125 (18.546)	Prec@5 96.875 (49.613)
Test on T test set - [2][300/1731]	Time 0.207 (0.219)	Loss 2.7652 (3.8275)	Prec@1 40.625 (18.802)	Prec@5 84.375 (51.100)
Test on T test set - [2][310/1731]	Time 0.210 (0.219)	Loss 2.6718 (3.7969)	Prec@1 34.375 (19.273)	Prec@5 100.000 (52.512)
Test on T test set - [2][320/1731]	Time 0.196 (0.219)	Loss 2.9569 (3.7679)	Prec@1 25.000 (19.694)	Prec@5 96.875 (53.777)
Test on T test set - [2][330/1731]	Time 0.199 (0.218)	Loss 2.8723 (3.7389)	Prec@1 31.250 (19.987)	Prec@5 90.625 (55.013)
Test on T test set - [2][340/1731]	Time 0.183 (0.217)	Loss 3.2406 (3.7151)	Prec@1 21.875 (20.216)	Prec@5 84.375 (56.122)
Test on T test set - [2][350/1731]	Time 0.201 (0.216)	Loss 2.5266 (3.6904)	Prec@1 37.500 (20.522)	Prec@5 96.875 (57.140)
Test on T test set - [2][360/1731]	Time 0.232 (0.216)	Loss 3.3965 (3.6673)	Prec@1 25.000 (20.880)	Prec@5 96.875 (58.241)
Test on T test set - [2][370/1731]	Time 0.170 (0.218)	Loss 2.7045 (3.6513)	Prec@1 25.000 (21.092)	Prec@5 84.375 (59.215)
Test on T test set - [2][380/1731]	Time 0.178 (0.217)	Loss 1.8499 (3.6240)	Prec@1 53.125 (21.276)	Prec@5 93.750 (59.998)
Test on T test set - [2][390/1731]	Time 0.172 (0.216)	Loss 2.6012 (3.5909)	Prec@1 31.250 (21.579)	Prec@5 93.750 (60.941)
Test on T test set - [2][400/1731]	Time 0.151 (0.215)	Loss 2.4501 (3.5662)	Prec@1 31.250 (21.735)	Prec@5 90.625 (61.666)
Test on T test set - [2][410/1731]	Time 0.161 (0.214)	Loss 3.0692 (3.5456)	Prec@1 15.625 (21.799)	Prec@5 81.250 (62.386)
Test on T test set - [2][420/1731]	Time 0.156 (0.212)	Loss 3.1474 (3.5281)	Prec@1 15.625 (21.816)	Prec@5 90.625 (63.064)
Test on T test set - [2][430/1731]	Time 0.167 (0.211)	Loss 3.0254 (3.5077)	Prec@1 18.750 (21.897)	Prec@5 81.250 (63.682)
Test on T test set - [2][440/1731]	Time 0.158 (0.210)	Loss 3.2521 (3.4874)	Prec@1 18.750 (21.981)	Prec@5 100.000 (64.392)
Test on T test set - [2][450/1731]	Time 0.160 (0.209)	Loss 2.5145 (3.4644)	Prec@1 34.375 (22.201)	Prec@5 96.875 (65.112)
Test on T test set - [2][460/1731]	Time 0.165 (0.208)	Loss 2.1889 (3.4390)	Prec@1 34.375 (22.465)	Prec@5 96.875 (65.794)
Test on T test set - [2][470/1731]	Time 0.161 (0.207)	Loss 2.4983 (3.4184)	Prec@1 31.250 (22.698)	Prec@5 93.750 (66.381)
Test on T test set - [2][480/1731]	Time 0.164 (0.206)	Loss 2.2612 (3.3966)	Prec@1 34.375 (22.889)	Prec@5 100.000 (67.009)
Test on T test set - [2][490/1731]	Time 0.160 (0.212)	Loss 2.5609 (3.3784)	Prec@1 28.125 (23.059)	Prec@5 90.625 (67.490)
Test on T test set - [2][500/1731]	Time 0.171 (0.211)	Loss 2.2626 (3.3608)	Prec@1 40.625 (23.210)	Prec@5 96.875 (68.033)
Test on T test set - [2][510/1731]	Time 0.158 (0.210)	Loss 2.6404 (3.3489)	Prec@1 28.125 (23.196)	Prec@5 84.375 (68.493)
Test on T test set - [2][520/1731]	Time 0.149 (0.209)	Loss 3.2273 (3.3377)	Prec@1 18.750 (23.177)	Prec@5 78.125 (68.882)
Test on T test set - [2][530/1731]	Time 0.166 (0.208)	Loss 3.0773 (3.3264)	Prec@1 18.750 (23.152)	Prec@5 87.500 (69.274)
Test on T test set - [2][540/1731]	Time 0.161 (0.207)	Loss 2.6201 (3.3201)	Prec@1 18.750 (23.076)	Prec@5 93.750 (69.680)
Test on T test set - [2][550/1731]	Time 0.149 (0.206)	Loss 2.6848 (3.3100)	Prec@1 21.875 (23.055)	Prec@5 81.250 (70.088)
Test on T test set - [2][560/1731]	Time 0.170 (0.205)	Loss 3.2684 (3.3023)	Prec@1 9.375 (22.961)	Prec@5 81.250 (70.354)
Test on T test set - [2][570/1731]	Time 0.197 (0.205)	Loss 2.2360 (3.2907)	Prec@1 40.625 (23.041)	Prec@5 93.750 (70.742)
Test on T test set - [2][580/1731]	Time 0.163 (0.204)	Loss 2.6266 (3.2808)	Prec@1 28.125 (23.080)	Prec@5 96.875 (71.111)
Test on T test set - [2][590/1731]	Time 0.182 (0.204)	Loss 2.0091 (3.2685)	Prec@1 43.750 (23.155)	Prec@5 100.000 (71.489)
Test on T test set - [2][600/1731]	Time 0.160 (0.203)	Loss 3.2137 (3.2575)	Prec@1 15.625 (23.191)	Prec@5 90.625 (71.813)
Test on T test set - [2][610/1731]	Time 0.159 (0.207)	Loss 2.8497 (3.2449)	Prec@1 18.750 (23.266)	Prec@5 90.625 (72.187)
Test on T test set - [2][620/1731]	Time 0.173 (0.206)	Loss 2.5065 (3.2339)	Prec@1 31.250 (23.349)	Prec@5 93.750 (72.539)
Test on T test set - [2][630/1731]	Time 0.160 (0.206)	Loss 2.9181 (3.2226)	Prec@1 15.625 (23.435)	Prec@5 93.750 (72.900)
Test on T test set - [2][640/1731]	Time 0.164 (0.205)	Loss 2.1374 (3.2140)	Prec@1 34.375 (23.464)	Prec@5 93.750 (73.191)
Test on T test set - [2][650/1731]	Time 0.158 (0.205)	Loss 3.1414 (3.2021)	Prec@1 21.875 (23.584)	Prec@5 87.500 (73.469)
Test on T test set - [2][660/1731]	Time 0.163 (0.204)	Loss 2.6289 (3.1939)	Prec@1 34.375 (23.634)	Prec@5 96.875 (73.804)
Test on T test set - [2][670/1731]	Time 0.168 (0.203)	Loss 2.5361 (3.1859)	Prec@1 25.000 (23.635)	Prec@5 93.750 (74.078)
Test on T test set - [2][680/1731]	Time 0.153 (0.203)	Loss 2.6747 (3.1816)	Prec@1 21.875 (23.573)	Prec@5 90.625 (74.307)
Test on T test set - [2][690/1731]	Time 0.214 (0.202)	Loss 1.5535 (3.1724)	Prec@1 56.250 (23.693)	Prec@5 93.750 (74.516)
Test on T test set - [2][700/1731]	Time 0.155 (0.202)	Loss 4.5139 (3.1808)	Prec@1 0.000 (23.587)	Prec@5 3.125 (73.819)
Test on T test set - [2][710/1731]	Time 0.181 (0.201)	Loss 4.6510 (3.2024)	Prec@1 0.000 (23.259)	Prec@5 0.000 (72.868)
Test on T test set - [2][720/1731]	Time 0.177 (0.201)	Loss 4.7333 (3.2241)	Prec@1 0.000 (22.937)	Prec@5 6.250 (71.966)
Test on T test set - [2][730/1731]	Time 0.211 (0.204)	Loss 4.7394 (3.2432)	Prec@1 0.000 (22.632)	Prec@5 6.250 (71.140)
Test on T test set - [2][740/1731]	Time 0.212 (0.204)	Loss 4.2861 (3.2614)	Prec@1 3.125 (22.343)	Prec@5 6.250 (70.331)
Test on T test set - [2][750/1731]	Time 0.189 (0.204)	Loss 4.4995 (3.2807)	Prec@1 0.000 (22.054)	Prec@5 18.750 (69.545)
Test on T test set - [2][760/1731]	Time 0.236 (0.205)	Loss 4.6502 (3.3005)	Prec@1 0.000 (21.776)	Prec@5 21.875 (68.812)
Test on T test set - [2][770/1731]	Time 0.198 (0.205)	Loss 4.7708 (3.3174)	Prec@1 0.000 (21.502)	Prec@5 9.375 (68.057)
Test on T test set - [2][780/1731]	Time 0.223 (0.205)	Loss 4.4805 (3.3359)	Prec@1 3.125 (21.235)	Prec@5 15.625 (67.298)
Test on T test set - [2][790/1731]	Time 0.216 (0.205)	Loss 4.6922 (3.3537)	Prec@1 0.000 (20.970)	Prec@5 6.250 (66.546)
Test on T test set - [2][800/1731]	Time 0.209 (0.205)	Loss 4.4403 (3.3698)	Prec@1 0.000 (20.716)	Prec@5 12.500 (65.855)
Test on T test set - [2][810/1731]	Time 0.199 (0.205)	Loss 4.6971 (3.3872)	Prec@1 3.125 (20.472)	Prec@5 9.375 (65.128)
Test on T test set - [2][820/1731]	Time 0.212 (0.205)	Loss 5.0412 (3.4041)	Prec@1 0.000 (20.231)	Prec@5 12.500 (64.441)
Test on T test set - [2][830/1731]	Time 0.192 (0.207)	Loss 4.4317 (3.4214)	Prec@1 0.000 (19.991)	Prec@5 15.625 (63.771)
Test on T test set - [2][840/1731]	Time 0.168 (0.206)	Loss 3.8141 (3.4361)	Prec@1 6.250 (19.764)	Prec@5 43.750 (63.202)
Test on T test set - [2][850/1731]	Time 0.155 (0.206)	Loss 2.5194 (3.4270)	Prec@1 18.750 (19.690)	Prec@5 96.875 (63.554)
Test on T test set - [2][860/1731]	Time 0.166 (0.205)	Loss 2.4229 (3.4172)	Prec@1 15.625 (19.614)	Prec@5 93.750 (63.926)
Test on T test set - [2][870/1731]	Time 0.163 (0.205)	Loss 2.8569 (3.4078)	Prec@1 15.625 (19.557)	Prec@5 87.500 (64.247)
Test on T test set - [2][880/1731]	Time 0.160 (0.204)	Loss 2.8500 (3.3983)	Prec@1 3.125 (19.498)	Prec@5 96.875 (64.593)
Test on T test set - [2][890/1731]	Time 0.167 (0.204)	Loss 2.8649 (3.3905)	Prec@1 12.500 (19.430)	Prec@5 96.875 (64.902)
Test on T test set - [2][900/1731]	Time 0.168 (0.204)	Loss 2.2796 (3.3808)	Prec@1 21.875 (19.378)	Prec@5 93.750 (65.226)
Test on T test set - [2][910/1731]	Time 0.162 (0.203)	Loss 5.3846 (3.3878)	Prec@1 0.000 (19.237)	Prec@5 62.500 (65.364)
Test on T test set - [2][920/1731]	Time 0.154 (0.203)	Loss 5.6390 (3.4085)	Prec@1 0.000 (19.062)	Prec@5 59.375 (65.347)
Test on T test set - [2][930/1731]	Time 0.239 (0.203)	Loss 5.4277 (3.4291)	Prec@1 6.250 (18.881)	Prec@5 71.875 (65.424)
Test on T test set - [2][940/1731]	Time 0.246 (0.205)	Loss 5.3385 (3.4462)	Prec@1 0.000 (18.720)	Prec@5 81.250 (65.499)
Test on T test set - [2][950/1731]	Time 0.225 (0.205)	Loss 5.0498 (3.4651)	Prec@1 0.000 (18.533)	Prec@5 81.250 (65.530)
Test on T test set - [2][960/1731]	Time 0.226 (0.205)	Loss 4.6907 (3.4818)	Prec@1 0.000 (18.383)	Prec@5 56.250 (65.586)
Test on T test set - [2][970/1731]	Time 0.231 (0.205)	Loss 5.7592 (3.5004)	Prec@1 3.125 (18.222)	Prec@5 75.000 (65.667)
Test on T test set - [2][980/1731]	Time 0.202 (0.205)	Loss 4.9788 (3.5194)	Prec@1 6.250 (18.049)	Prec@5 59.375 (65.714)
Test on T test set - [2][990/1731]	Time 0.214 (0.206)	Loss 5.5789 (3.5379)	Prec@1 0.000 (17.892)	Prec@5 78.125 (65.732)
Test on T test set - [2][1000/1731]	Time 0.220 (0.206)	Loss 5.1457 (3.5556)	Prec@1 9.375 (17.751)	Prec@5 78.125 (65.862)
Test on T test set - [2][1010/1731]	Time 0.200 (0.206)	Loss 4.8579 (3.5716)	Prec@1 6.250 (17.600)	Prec@5 75.000 (65.925)
Test on T test set - [2][1020/1731]	Time 0.210 (0.205)	Loss 5.4996 (3.5884)	Prec@1 3.125 (17.452)	Prec@5 71.875 (65.943)
Test on T test set - [2][1030/1731]	Time 0.167 (0.205)	Loss 5.0495 (3.6045)	Prec@1 3.125 (17.331)	Prec@5 62.500 (65.964)
Test on T test set - [2][1040/1731]	Time 0.168 (0.207)	Loss 5.0190 (3.6194)	Prec@1 3.125 (17.201)	Prec@5 43.750 (65.973)
Test on T test set - [2][1050/1731]	Time 0.171 (0.207)	Loss 4.7291 (3.6303)	Prec@1 6.250 (17.094)	Prec@5 71.875 (65.836)
Test on T test set - [2][1060/1731]	Time 0.161 (0.206)	Loss 5.1147 (3.6429)	Prec@1 3.125 (16.965)	Prec@5 46.875 (65.687)
Test on T test set - [2][1070/1731]	Time 0.202 (0.206)	Loss 5.1128 (3.6527)	Prec@1 6.250 (16.856)	Prec@5 59.375 (65.575)
Test on T test set - [2][1080/1731]	Time 0.162 (0.206)	Loss 4.9498 (3.6658)	Prec@1 0.000 (16.718)	Prec@5 46.875 (65.544)
Test on T test set - [2][1090/1731]	Time 0.182 (0.206)	Loss 4.6523 (3.6762)	Prec@1 0.000 (16.585)	Prec@5 15.625 (65.319)
Test on T test set - [2][1100/1731]	Time 0.203 (0.206)	Loss 4.3893 (3.6840)	Prec@1 0.000 (16.434)	Prec@5 6.250 (64.813)
Test on T test set - [2][1110/1731]	Time 0.220 (0.206)	Loss 4.7610 (3.6925)	Prec@1 0.000 (16.286)	Prec@5 6.250 (64.303)
Test on T test set - [2][1120/1731]	Time 0.197 (0.205)	Loss 4.6344 (3.7011)	Prec@1 0.000 (16.141)	Prec@5 9.375 (63.824)
Test on T test set - [2][1130/1731]	Time 0.176 (0.205)	Loss 4.8445 (3.7091)	Prec@1 0.000 (15.998)	Prec@5 12.500 (63.345)
Test on T test set - [2][1140/1731]	Time 0.199 (0.206)	Loss 4.4500 (3.7166)	Prec@1 0.000 (15.858)	Prec@5 12.500 (62.848)
Test on T test set - [2][1150/1731]	Time 0.174 (0.206)	Loss 4.7631 (3.7255)	Prec@1 0.000 (15.720)	Prec@5 15.625 (62.413)
Test on T test set - [2][1160/1731]	Time 0.177 (0.206)	Loss 4.6505 (3.7327)	Prec@1 0.000 (15.585)	Prec@5 0.000 (61.967)
Test on T test set - [2][1170/1731]	Time 0.180 (0.206)	Loss 4.6220 (3.7395)	Prec@1 0.000 (15.452)	Prec@5 0.000 (61.499)
Test on T test set - [2][1180/1731]	Time 0.191 (0.206)	Loss 4.9211 (3.7478)	Prec@1 0.000 (15.321)	Prec@5 6.250 (61.068)
Test on T test set - [2][1190/1731]	Time 0.190 (0.206)	Loss 4.1732 (3.7545)	Prec@1 0.000 (15.192)	Prec@5 9.375 (60.632)
Test on T test set - [2][1200/1731]	Time 0.176 (0.205)	Loss 4.2632 (3.7612)	Prec@1 0.000 (15.066)	Prec@5 18.750 (60.205)
Test on T test set - [2][1210/1731]	Time 0.188 (0.205)	Loss 5.0251 (3.7679)	Prec@1 0.000 (14.941)	Prec@5 6.250 (59.788)
Test on T test set - [2][1220/1731]	Time 0.161 (0.205)	Loss 4.4185 (3.7761)	Prec@1 6.250 (14.834)	Prec@5 25.000 (59.498)
Test on T test set - [2][1230/1731]	Time 0.162 (0.205)	Loss 4.1592 (3.7828)	Prec@1 6.250 (14.729)	Prec@5 21.875 (59.197)
Test on T test set - [2][1240/1731]	Time 0.175 (0.206)	Loss 4.8271 (3.7907)	Prec@1 0.000 (14.620)	Prec@5 37.500 (58.909)
Test on T test set - [2][1250/1731]	Time 0.175 (0.205)	Loss 4.9541 (3.7981)	Prec@1 0.000 (14.528)	Prec@5 37.500 (58.636)
Test on T test set - [2][1260/1731]	Time 0.201 (0.205)	Loss 5.4828 (3.8058)	Prec@1 0.000 (14.426)	Prec@5 31.250 (58.404)
Test on T test set - [2][1270/1731]	Time 0.176 (0.205)	Loss 5.0113 (3.8136)	Prec@1 0.000 (14.327)	Prec@5 21.875 (58.163)
Test on T test set - [2][1280/1731]	Time 0.186 (0.205)	Loss 5.0754 (3.8214)	Prec@1 3.125 (14.234)	Prec@5 25.000 (57.916)
Test on T test set - [2][1290/1731]	Time 0.168 (0.205)	Loss 4.6329 (3.8281)	Prec@1 0.000 (14.144)	Prec@5 25.000 (57.671)
Test on T test set - [2][1300/1731]	Time 0.182 (0.204)	Loss 4.7374 (3.8355)	Prec@1 6.250 (14.054)	Prec@5 21.875 (57.427)
Test on T test set - [2][1310/1731]	Time 0.180 (0.204)	Loss 4.7395 (3.8424)	Prec@1 9.375 (13.966)	Prec@5 34.375 (57.261)
Test on T test set - [2][1320/1731]	Time 0.191 (0.204)	Loss 4.8929 (3.8496)	Prec@1 0.000 (13.879)	Prec@5 40.625 (57.061)
Test on T test set - [2][1330/1731]	Time 0.175 (0.204)	Loss 4.8125 (3.8573)	Prec@1 3.125 (13.782)	Prec@5 43.750 (56.799)
Test on T test set - [2][1340/1731]	Time 0.160 (0.204)	Loss 4.9345 (3.8648)	Prec@1 0.000 (13.691)	Prec@5 28.125 (56.553)
Test on T test set - [2][1350/1731]	Time 0.169 (0.205)	Loss 5.1266 (3.8731)	Prec@1 3.125 (13.603)	Prec@5 28.125 (56.338)
Test on T test set - [2][1360/1731]	Time 0.158 (0.205)	Loss 2.9397 (3.8727)	Prec@1 18.750 (13.552)	Prec@5 68.750 (56.321)
Test on T test set - [2][1370/1731]	Time 0.151 (0.205)	Loss 3.2766 (3.8688)	Prec@1 6.250 (13.537)	Prec@5 71.875 (56.394)
Test on T test set - [2][1380/1731]	Time 0.170 (0.205)	Loss 2.9453 (3.8644)	Prec@1 21.875 (13.557)	Prec@5 81.250 (56.501)
Test on T test set - [2][1390/1731]	Time 0.179 (0.204)	Loss 3.5276 (3.8612)	Prec@1 6.250 (13.533)	Prec@5 59.375 (56.542)
Test on T test set - [2][1400/1731]	Time 0.169 (0.204)	Loss 3.5119 (3.8586)	Prec@1 0.000 (13.490)	Prec@5 53.125 (56.611)
Test on T test set - [2][1410/1731]	Time 0.179 (0.204)	Loss 3.5475 (3.8556)	Prec@1 3.125 (13.466)	Prec@5 56.250 (56.646)
Test on T test set - [2][1420/1731]	Time 0.151 (0.204)	Loss 3.3104 (3.8524)	Prec@1 9.375 (13.441)	Prec@5 62.500 (56.694)
Test on T test set - [2][1430/1731]	Time 0.211 (0.203)	Loss 3.5523 (3.8490)	Prec@1 9.375 (13.448)	Prec@5 96.875 (56.870)
Test on T test set - [2][1440/1731]	Time 0.236 (0.204)	Loss 3.1672 (3.8449)	Prec@1 15.625 (13.489)	Prec@5 90.625 (57.111)
Test on T test set - [2][1450/1731]	Time 0.249 (0.204)	Loss 3.8979 (3.8422)	Prec@1 9.375 (13.491)	Prec@5 87.500 (57.346)
Test on T test set - [2][1460/1731]	Time 0.243 (0.206)	Loss 2.7804 (3.8370)	Prec@1 25.000 (13.535)	Prec@5 90.625 (57.583)
Test on T test set - [2][1470/1731]	Time 0.232 (0.206)	Loss 3.4967 (3.8337)	Prec@1 18.750 (13.537)	Prec@5 90.625 (57.788)
Test on T test set - [2][1480/1731]	Time 0.240 (0.206)	Loss 3.7063 (3.8291)	Prec@1 9.375 (13.591)	Prec@5 96.875 (58.003)
Test on T test set - [2][1490/1731]	Time 0.228 (0.206)	Loss 3.0494 (3.8250)	Prec@1 25.000 (13.609)	Prec@5 100.000 (58.231)
Test on T test set - [2][1500/1731]	Time 0.244 (0.207)	Loss 3.4226 (3.8210)	Prec@1 12.500 (13.626)	Prec@5 93.750 (58.449)
Test on T test set - [2][1510/1731]	Time 0.229 (0.207)	Loss 2.7257 (3.8176)	Prec@1 21.875 (13.652)	Prec@5 87.500 (58.666)
Test on T test set - [2][1520/1731]	Time 0.230 (0.207)	Loss 3.4360 (3.8139)	Prec@1 15.625 (13.673)	Prec@5 93.750 (58.876)
Test on T test set - [2][1530/1731]	Time 0.217 (0.207)	Loss 3.5166 (3.8105)	Prec@1 9.375 (13.682)	Prec@5 93.750 (59.085)
Test on T test set - [2][1540/1731]	Time 0.189 (0.208)	Loss 4.1825 (3.8079)	Prec@1 9.375 (13.701)	Prec@5 78.125 (59.259)
Test on T test set - [2][1550/1731]	Time 0.234 (0.208)	Loss 3.4508 (3.8057)	Prec@1 18.750 (13.711)	Prec@5 84.375 (59.411)
Test on T test set - [2][1560/1731]	Time 0.189 (0.208)	Loss 4.6367 (3.8042)	Prec@1 0.000 (13.717)	Prec@5 50.000 (59.499)
Test on T test set - [2][1570/1731]	Time 0.185 (0.208)	Loss 4.6443 (3.8096)	Prec@1 0.000 (13.640)	Prec@5 46.875 (59.387)
Test on T test set - [2][1580/1731]	Time 0.163 (0.207)	Loss 3.9429 (3.8143)	Prec@1 3.125 (13.567)	Prec@5 50.000 (59.282)
Test on T test set - [2][1590/1731]	Time 0.163 (0.207)	Loss 4.4544 (3.8183)	Prec@1 6.250 (13.502)	Prec@5 37.500 (59.145)
Test on T test set - [2][1600/1731]	Time 0.178 (0.207)	Loss 4.4434 (3.8223)	Prec@1 3.125 (13.435)	Prec@5 31.250 (59.016)
Test on T test set - [2][1610/1731]	Time 0.172 (0.207)	Loss 4.5454 (3.8266)	Prec@1 3.125 (13.375)	Prec@5 28.125 (58.880)
Test on T test set - [2][1620/1731]	Time 0.175 (0.207)	Loss 4.6809 (3.8306)	Prec@1 3.125 (13.308)	Prec@5 50.000 (58.752)
Test on T test set - [2][1630/1731]	Time 0.167 (0.206)	Loss 4.3929 (3.8342)	Prec@1 6.250 (13.243)	Prec@5 37.500 (58.609)
Test on T test set - [2][1640/1731]	Time 0.216 (0.206)	Loss 5.1450 (3.8391)	Prec@1 0.000 (13.180)	Prec@5 50.000 (58.499)
Test on T test set - [2][1650/1731]	Time 0.227 (0.208)	Loss 4.9843 (3.8452)	Prec@1 0.000 (13.106)	Prec@5 43.750 (58.432)
Test on T test set - [2][1660/1731]	Time 0.214 (0.208)	Loss 4.9904 (3.8505)	Prec@1 0.000 (13.049)	Prec@5 40.625 (58.370)
Test on T test set - [2][1670/1731]	Time 0.196 (0.208)	Loss 4.7853 (3.8567)	Prec@1 3.125 (12.981)	Prec@5 56.250 (58.313)
Test on T test set - [2][1680/1731]	Time 0.196 (0.208)	Loss 4.2282 (3.8625)	Prec@1 3.125 (12.918)	Prec@5 46.875 (58.265)
Test on T test set - [2][1690/1731]	Time 0.210 (0.208)	Loss 5.1104 (3.8679)	Prec@1 3.125 (12.862)	Prec@5 59.375 (58.264)
Test on T test set - [2][1700/1731]	Time 0.208 (0.208)	Loss 4.9138 (3.8732)	Prec@1 3.125 (12.799)	Prec@5 56.250 (58.234)
Test on T test set - [2][1710/1731]	Time 0.218 (0.208)	Loss 4.9635 (3.8789)	Prec@1 0.000 (12.745)	Prec@5 37.500 (58.166)
Test on T test set - [2][1720/1731]	Time 0.188 (0.208)	Loss 4.7534 (3.8840)	Prec@1 3.125 (12.689)	Prec@5 28.125 (58.093)
Test on T test set - [2][1730/1731]	Time 0.166 (0.209)	Loss 4.6922 (3.8884)	Prec@1 0.000 (12.636)	Prec@5 39.286 (58.027)
 * Test on T test set - Prec@1 12.636, Prec@5 58.027
Epoch 2 - Kernel K-means clustering 0: Clustering time 47.183, Prec@1 11.611
Epoch 2 - Kernel K-means clustering 1: Clustering time 46.436, Prec@1 11.344
Epoch 2 - Kernel K-means clustering 2: Clustering time 48.238, Prec@1 11.085
Epoch 2 - Kernel K-means clustering 3: Clustering time 46.241, Prec@1 10.975
Epoch 2 - Kernel K-means clustering 4: Clustering time 46.167, Prec@1 10.934
Epoch 2 - Kernel K-means clustering 5: Clustering time 46.254, Prec@1 10.952
Epoch 2 - Kernel K-means clustering 6: Clustering time 48.424, Prec@1 10.946
Epoch 2 - Kernel K-means clustering 7: Clustering time 46.186, Prec@1 10.964
Epoch 2 - Kernel K-means clustering 8: Clustering time 46.131, Prec@1 10.997
Epoch 2 - Kernel K-means clustering 9: Clustering time 46.065, Prec@1 11.002
Epoch 2 - Kernel K-means clustering 10: Clustering time 46.256, Prec@1 11.002
Epoch 2 - Kernel K-means clustering 11: Clustering time 48.168, Prec@1 11.001
Epoch 2 - Kernel K-means clustering 12: Clustering time 46.605, Prec@1 11.008
Epoch 2 - Kernel K-means clustering 13: Clustering time 46.508, Prec@1 11.006
Epoch 2 - Kernel K-means clustering 14: Clustering time 46.451, Prec@1 11.002
Epoch 2 - Kernel K-means clustering 15: Clustering time 46.541, Prec@1 10.999
Epoch 2 - Kernel K-means clustering 16: Clustering time 46.622, Prec@1 11.004
Epoch 2 - Kernel K-means clustering 17: Clustering time 46.525, Prec@1 11.002
Epoch 2 - Kernel K-means clustering 18: Clustering time 46.022, Prec@1 11.006
Epoch 2 - Kernel K-means clustering 19: Clustering time 45.764, Prec@1 11.008
Epoch 2 - Kernel K-means clustering 20: Clustering time 46.022, Prec@1 11.010
Epoch 2 - Kernel K-means clustering 21: Clustering time 45.985, Prec@1 11.010
Epoch 2 - Kernel K-means clustering 22: Clustering time 46.194, Prec@1 11.010
Epoch 2 - Kernel K-means clustering 23: Clustering time 49.393, Prec@1 11.013
Converged at iteration 24
Epoch 2 - Kernel K-means clustering 0: Clustering time 47.748, Prec@1 11.977
Epoch 2 - Kernel K-means clustering 1: Clustering time 47.107, Prec@1 11.642
Epoch 2 - Kernel K-means clustering 2: Clustering time 47.616, Prec@1 11.277
Epoch 2 - Kernel K-means clustering 3: Clustering time 46.865, Prec@1 11.082
Epoch 2 - Kernel K-means clustering 4: Clustering time 46.306, Prec@1 11.010
Epoch 2 - Kernel K-means clustering 5: Clustering time 46.340, Prec@1 10.995
Epoch 2 - Kernel K-means clustering 6: Clustering time 48.800, Prec@1 11.006
Epoch 2 - Kernel K-means clustering 7: Clustering time 46.553, Prec@1 11.015
Epoch 2 - Kernel K-means clustering 8: Clustering time 46.629, Prec@1 10.999
Epoch 2 - Kernel K-means clustering 9: Clustering time 46.508, Prec@1 10.979
Epoch 2 - Kernel K-means clustering 10: Clustering time 49.292, Prec@1 10.983
Epoch 2 - Kernel K-means clustering 11: Clustering time 46.695, Prec@1 10.995
Epoch 2 - Kernel K-means clustering 12: Clustering time 46.685, Prec@1 10.999
Epoch 2 - Kernel K-means clustering 13: Clustering time 46.655, Prec@1 10.997
Epoch 2 - Kernel K-means clustering 14: Clustering time 46.797, Prec@1 10.988
Epoch 2 - Kernel K-means clustering 15: Clustering time 46.280, Prec@1 10.977
Epoch 2 - Kernel K-means clustering 16: Clustering time 45.685, Prec@1 10.988
Epoch 2 - Kernel K-means clustering 17: Clustering time 45.779, Prec@1 10.992
Epoch 2 - Kernel K-means clustering 18: Clustering time 45.873, Prec@1 11.008
Epoch 2 - Kernel K-means clustering 19: Clustering time 49.173, Prec@1 11.008
Epoch 2 - Kernel K-means clustering 20: Clustering time 46.447, Prec@1 11.019
Epoch 2 - Kernel K-means clustering 21: Clustering time 46.746, Prec@1 11.028
Epoch 2 - Kernel K-means clustering 22: Clustering time 46.610, Prec@1 11.035
Epoch 2 - Kernel K-means clustering 23: Clustering time 46.578, Prec@1 11.033
Epoch 2 - Kernel K-means clustering 24: Clustering time 47.378, Prec@1 11.035
Epoch 2 - Kernel K-means clustering 25: Clustering time 47.256, Prec@1 11.038
Epoch 2 - Kernel K-means clustering 26: Clustering time 47.138, Prec@1 11.044
Epoch 2 - Kernel K-means clustering 27: Clustering time 48.146, Prec@1 11.042
Epoch 2 - Kernel K-means clustering 28: Clustering time 47.718, Prec@1 11.044
Epoch 2 - Kernel K-means clustering 29: Clustering time 49.934, Prec@1 11.042
Epoch 2 - Kernel K-means clustering 30: Clustering time 47.340, Prec@1 11.049
Epoch 2 - Kernel K-means clustering 31: Clustering time 46.817, Prec@1 11.057
Epoch 2 - Kernel K-means clustering 32: Clustering time 47.863, Prec@1 11.053
Epoch 2 - Kernel K-means clustering 33: Clustering time 46.379, Prec@1 11.053
Epoch 2 - Kernel K-means clustering 34: Clustering time 46.307, Prec@1 11.051
Epoch 2 - Kernel K-means clustering 35: Clustering time 46.216, Prec@1 11.053
Epoch 2 - Kernel K-means clustering 36: Clustering time 46.370, Prec@1 11.051
Converged at iteration 37
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.7782 (1.7782)
Train - epoch [3/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8635 (1.8635)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8041 (1.8041)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.7423 (1.7423)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.7798 (1.7798)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.7347 (1.7347)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8065 (1.8065)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7778 (1.7778)
Train - epoch [3/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.7446 (1.7446)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.8895 (1.8895)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8811 (1.8811)
Train - epoch [3/200]	BT 1.588 (1.588)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7787 (1.7787)
Train - epoch [3/200]	BT 4.156 (4.156)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7982 (1.7982)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8437 (1.8437)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8138 (1.8138)
Train - epoch [3/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.9119 (1.9119)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.8739 (1.8739)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.9637 (1.9637)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9979 (1.9979)
Train - epoch [3/200]	BT 4.633 (4.633)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8002 (1.8002)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9197 (1.9197)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.7924 (1.7924)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8378 (1.8378)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.9635 (1.9635)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8384 (1.8384)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9003 (1.9003)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8219 (1.8219)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8164 (1.8164)
Train - epoch [3/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8924 (1.8924)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8923 (1.8923)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.7640 (1.7640)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.9094 (1.9094)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9117 (1.9117)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.0785 (2.0785)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.9594 (1.9594)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8082 (1.8082)
Train - epoch [3/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8876 (1.8876)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7591 (1.7591)
Train - epoch [3/200]	BT 4.588 (4.588)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8002 (1.8002)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9704 (1.9704)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.9478 (1.9478)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.9568 (1.9568)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8612 (1.8612)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8522 (1.8522)
Train - epoch [3/200]	BT 4.339 (4.339)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.8393 (1.8393)
Train - epoch [3/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7893 (1.7893)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.9472 (1.9472)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.7970 (1.7970)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8309 (1.8309)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8752 (1.8752)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.7562 (1.7562)
Train - epoch [3/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7964 (1.7964)
Train - epoch [3/200]	BT 1.301 (1.301)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7997 (1.7997)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8661 (1.8661)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.9858 (1.9858)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8401 (1.8401)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9767 (1.9767)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8628 (1.8628)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8207 (1.8207)
Train - epoch [3/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9069 (1.9069)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.8299 (1.8299)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7868 (1.7868)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8083 (1.8083)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.8256 (1.8256)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8615 (1.8615)
Train - epoch [3/200]	BT 4.104 (4.104)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7644 (1.7644)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.7946 (1.7946)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9224 (1.9224)
Train - epoch [3/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.7620 (1.7620)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.9643 (1.9643)
Train - epoch [3/200]	BT 1.299 (1.299)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.7665 (1.7665)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8493 (1.8493)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.7757 (1.7757)
Train - epoch [3/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.9145 (1.9145)
Train - epoch [3/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8708 (1.8708)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9926 (1.9926)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.8005 (1.8005)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8580 (1.8580)
Train - epoch [3/200]	BT 4.395 (4.395)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8446 (1.8446)
Train - epoch [3/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8107 (1.8107)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9109 (1.9109)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8413 (1.8413)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8614 (1.8614)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8550 (1.8550)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8980 (1.8980)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8052 (1.8052)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8267 (1.8267)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9046 (1.9046)
Train - epoch [3/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8980 (1.8980)
Train - epoch [3/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9365 (1.9365)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7927 (1.7927)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8482 (1.8482)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8241 (1.8241)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7845 (1.7845)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8320 (1.8320)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9252 (1.9252)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 1.8904 (1.8904)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8670 (1.8670)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8076 (1.8076)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7871 (1.7871)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7785 (1.7785)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.8496 (1.8496)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8451 (1.8451)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.7687 (1.7687)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7856 (1.7856)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7897 (1.7897)
Train - epoch [3/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8556 (1.8556)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8063 (1.8063)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8139 (1.8139)
Train - epoch [3/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 1.9667 (1.9667)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8901 (1.8901)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8063 (1.8063)
Train - epoch [3/200]	BT 3.773 (3.773)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8493 (1.8493)
Train - epoch [3/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8561 (1.8561)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8465 (1.8465)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8248 (1.8248)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7902 (1.7902)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8073 (1.8073)
Train - epoch [3/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8495 (1.8495)
Train - epoch [3/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8558 (1.8558)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8127 (1.8127)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.0015 (2.0015)
Train - epoch [3/200]	BT 4.637 (4.637)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7965 (1.7965)
Train - epoch [3/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9375 (1.9375)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8658 (1.8658)
Train - epoch [3/200]	BT 1.304 (1.304)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7842 (1.7842)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8217 (1.8217)
Train - epoch [3/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7909 (1.7909)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8633 (1.8633)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7778 (1.7778)
Train - epoch [3/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8653 (1.8653)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.7909 (1.7909)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9220 (1.9220)
Train - epoch [3/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8120 (1.8120)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.7800 (1.7800)
Train - epoch [3/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8141 (1.8141)
Train - epoch [3/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8394 (1.8394)
Train - epoch [3/200]	BT 4.457 (4.457)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.9017 (1.9017)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8641 (1.8641)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8081 (1.8081)
Train - epoch [3/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.7803 (1.7803)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.7813 (1.7813)
Train - epoch [3/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8343 (1.8343)
Train - epoch [3/200]	BT 3.519 (3.519)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8882 (1.8882)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7543 (1.7543)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7613 (1.7613)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9454 (1.9454)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9025 (1.9025)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9082 (1.9082)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8773 (1.8773)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9318 (1.9318)
Train - epoch [3/200]	BT 4.578 (4.578)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8769 (1.8769)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.9523 (1.9523)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8036 (1.8036)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.9723 (1.9723)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.8577 (1.8577)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.8458 (1.8458)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.9626 (1.9626)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8955 (1.8955)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8077 (1.8077)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7834 (1.7834)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8727 (1.8727)
Train - epoch [3/200]	BT 4.471 (4.471)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 1.9534 (1.9534)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7582 (1.7582)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8374 (1.8374)
Train - epoch [3/200]	BT 4.111 (4.111)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8829 (1.8829)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.9727 (1.9727)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8662 (1.8662)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7839 (1.7839)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8450 (1.8450)
Train - epoch [3/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.7855 (1.7855)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8683 (1.8683)
Train - epoch [3/200]	BT 1.306 (1.306)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.7697 (1.7697)
Train - epoch [3/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.7831 (1.7831)
Train - epoch [3/200]	BT 1.731 (1.731)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8924 (1.8924)
Train - epoch [3/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7497 (1.7497)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8657 (1.8657)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8521 (1.8521)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.7960 (1.7960)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8361 (1.8361)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.7699 (1.7699)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.8158 (1.8158)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8689 (1.8689)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.0401 (2.0401)
Train - epoch [3/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9125 (1.9125)
Train - epoch [3/200]	BT 4.400 (4.400)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7954 (1.7954)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8277 (1.8277)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7902 (1.7902)
Train - epoch [3/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8883 (1.8883)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 1.7964 (1.7964)
Train - epoch [3/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8281 (1.8281)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8416 (1.8416)
Train - epoch [3/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8490 (1.8490)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7892 (1.7892)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8782 (1.8782)
Train - epoch [3/200]	BT 4.244 (4.244)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8897 (1.8897)
Train - epoch [3/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7752 (1.7752)
Train - epoch [3/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8371 (1.8371)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8427 (1.8427)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8857 (1.8857)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8979 (1.8979)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8168 (1.8168)
Train - epoch [3/200]	BT 3.970 (3.970)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8167 (1.8167)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8881 (1.8881)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9463 (1.9463)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8214 (1.8214)
Train - epoch [3/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.0174 (2.0174)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8919 (1.8919)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9054 (1.9054)
Train - epoch [3/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8161 (1.8161)
Train - epoch [3/200]	BT 1.304 (1.304)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7916 (1.7916)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8791 (1.8791)
Train - epoch [3/200]	BT 1.306 (1.306)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9302 (1.9302)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8456 (1.8456)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8134 (1.8134)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8951 (1.8951)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8037 (1.8037)
Train - epoch [3/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.7860 (1.7860)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.9064 (1.9064)
Train - epoch [3/200]	BT 4.319 (4.319)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9764 (1.9764)
Train - epoch [3/200]	BT 1.302 (1.302)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.7785 (1.7785)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8265 (1.8265)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8634 (1.8634)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8289 (1.8289)
Train - epoch [3/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9459 (1.9459)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8494 (1.8494)
Train - epoch [3/200]	BT 3.748 (3.748)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8456 (1.8456)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8805 (1.8805)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.0110 (2.0110)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.0324 (2.0324)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.9475 (1.9475)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.9056 (1.9056)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8987 (1.8987)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8379 (1.8379)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.7984 (1.7984)
Train - epoch [3/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.0213 (2.0213)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8255 (1.8255)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7923 (1.7923)
Train - epoch [3/200]	BT 1.300 (1.300)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8156 (1.8156)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.9158 (1.9158)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8486 (1.8486)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.8258 (1.8258)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8557 (1.8557)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.7953 (1.7953)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.1202 (2.1202)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.7881 (1.7881)
Train - epoch [3/200]	BT 4.208 (4.208)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7881 (1.7881)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9584 (1.9584)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8001 (1.8001)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9548 (1.9548)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9518 (1.9518)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.9106 (1.9106)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9056 (1.9056)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8645 (1.8645)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.9160 (1.9160)
Train - epoch [3/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8301 (1.8301)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8778 (1.8778)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9160 (1.9160)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8305 (1.8305)
Train - epoch [3/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8148 (1.8148)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.0744 (2.0744)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9576 (1.9576)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8472 (1.8472)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8034 (1.8034)
Train - epoch [3/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8996 (1.8996)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.9109 (1.9109)
Train - epoch [3/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.9176 (1.9176)
Train - epoch [3/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8856 (1.8856)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8808 (1.8808)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.7658 (1.7658)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8722 (1.8722)
Train - epoch [3/200]	BT 1.300 (1.300)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8915 (1.8915)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8994 (1.8994)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8401 (1.8401)
Train - epoch [3/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.7761 (1.7761)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8203 (1.8203)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8020 (1.8020)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8155 (1.8155)
Train - epoch [3/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8367 (1.8367)
Train - epoch [3/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8596 (1.8596)
Train - epoch [3/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.7952 (1.7952)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.0996 (2.0996)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9558 (1.9558)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8733 (1.8733)
Train - epoch [3/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 1.8919 (1.8919)
Train - epoch [3/200]	BT 4.083 (4.083)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8556 (1.8556)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8044 (1.8044)
Train - epoch [3/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7329 (1.7329)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.7616 (1.7616)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.7748 (1.7748)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.7697 (1.7697)
Train - epoch [3/200]	BT 3.712 (3.712)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8022 (1.8022)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7868 (1.7868)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9098 (1.9098)
Train - epoch [3/200]	BT 1.444 (1.444)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9670 (1.9670)
Train - epoch [3/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.9096 (1.9096)
Train - epoch [3/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7845 (1.7845)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8762 (1.8762)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.9404 (1.9404)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8094 (1.8094)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8156 (1.8156)
Train - epoch [3/200]	BT 1.243 (1.243)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8178 (1.8178)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.0327 (2.0327)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9314 (1.9314)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8238 (1.8238)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8231 (1.8231)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9153 (1.9153)
Train - epoch [3/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.9272 (1.9272)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8658 (1.8658)
Train - epoch [3/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8709 (1.8709)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8903 (1.8903)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9141 (1.9141)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.0242 (2.0242)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.9090 (1.9090)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8644 (1.8644)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.8563 (1.8563)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.1537 (2.1537)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.7633 (1.7633)
Train - epoch [3/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8286 (1.8286)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.8444 (1.8444)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8081 (1.8081)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9337 (1.9337)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.7775 (1.7775)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9227 (1.9227)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9140 (1.9140)
Train - epoch [3/200]	BT 4.412 (4.412)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.8726 (1.8726)
Train - epoch [3/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8420 (1.8420)
Train - epoch [3/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8656 (1.8656)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9081 (1.9081)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 1.8926 (1.8926)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.0013 (2.0013)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9041 (1.9041)
Train - epoch [3/200]	BT 1.350 (1.350)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.7903 (1.7903)
Train - epoch [3/200]	BT 1.245 (1.245)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9252 (1.9252)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.9902 (1.9902)
Train - epoch [3/200]	BT 3.665 (3.665)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8637 (1.8637)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8495 (1.8495)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8110 (1.8110)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8960 (1.8960)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.8640 (1.8640)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8271 (1.8271)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8096 (1.8096)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8374 (1.8374)
Train - epoch [3/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8082 (1.8082)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8120 (1.8120)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.7836 (1.7836)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8115 (1.8115)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.0063 (2.0063)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8687 (1.8687)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 1.7879 (1.7879)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.7957 (1.7957)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8273 (1.8273)
Train - epoch [3/200]	BT 1.301 (1.301)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8967 (1.8967)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8843 (1.8843)
Train - epoch [3/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8221 (1.8221)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8469 (1.8469)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.0649 (2.0649)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8614 (1.8614)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.0460 (2.0460)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8957 (1.8957)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8050 (1.8050)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8233 (1.8233)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8340 (1.8340)
Train - epoch [3/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7664 (1.7664)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.9577 (1.9577)
Train - epoch [3/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8860 (1.8860)
Train - epoch [3/200]	BT 3.960 (3.960)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.7928 (1.7928)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9088 (1.9088)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9496 (1.9496)
Train - epoch [3/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.8547 (1.8547)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 1.8191 (1.8191)
Train - epoch [3/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8191 (1.8191)
Train - epoch [3/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7760 (1.7760)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 1.7952 (1.7952)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8950 (1.8950)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8216 (1.8216)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8530 (1.8530)
Train - epoch [3/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8429 (1.8429)
Train - epoch [3/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8323 (1.8323)
Train - epoch [3/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8102 (1.8102)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8767 (1.8767)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 1.7770 (1.7770)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8839 (1.8839)
Train - epoch [3/200]	BT 3.988 (3.988)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8416 (1.8416)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8858 (1.8858)
Train - epoch [3/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8571 (1.8571)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8173 (1.8173)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9606 (1.9606)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.1321 (2.1321)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8794 (1.8794)
Train - epoch [3/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8065 (1.8065)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 1.7920 (1.7920)
Train - epoch [3/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.7882 (1.7882)
Train - epoch [3/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.7851 (1.7851)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 1.7695 (1.7695)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8821 (1.8821)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.9894 (1.9894)
Train - epoch [3/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8105 (1.8105)
Train - epoch [3/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9054 (1.9054)
Train - epoch [3/200]	BT 4.629 (4.629)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8104 (1.8104)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.9397 (1.9397)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8064 (1.8064)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8023 (1.8023)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8008 (1.8008)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8127 (1.8127)
Train - epoch [3/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.7890 (1.7890)
Train - epoch [3/200]	BT 4.348 (4.348)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8875 (1.8875)
Train - epoch [3/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9805 (1.9805)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8891 (1.8891)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.9456 (1.9456)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8733 (1.8733)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8667 (1.8667)
Train - epoch [3/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8291 (1.8291)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8358 (1.8358)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.0454 (2.0454)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8201 (1.8201)
Train - epoch [3/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9767 (1.9767)
Train - epoch [3/200]	BT 4.698 (4.698)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8456 (1.8456)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.8774 (1.8774)
Train - epoch [3/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8614 (1.8614)
Train - epoch [3/200]	BT 1.306 (1.306)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7775 (1.7775)
Train - epoch [3/200]	BT 1.302 (1.302)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9563 (1.9563)
Train - epoch [3/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8834 (1.8834)
Train - epoch [3/200]	BT 3.914 (3.914)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.9078 (1.9078)
Train - epoch [3/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.0401 (2.0401)
Train - epoch [3/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.8998 (1.8998)
Train - epoch [3/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9611 (1.9611)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.9265 (1.9265)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.0642 (2.0642)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.9136 (1.9136)
Train - epoch [3/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.9424 (1.9424)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8848 (1.8848)
Train - epoch [3/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.7755 (1.7755)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8043 (1.8043)
Train - epoch [3/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8068 (1.8068)
Train - epoch [3/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.7960 (1.7960)
Train - epoch [3/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8428 (1.8428)
Train - epoch [3/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.0633 (2.0633)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8701 (1.8701)
Train - epoch [3/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.9636 (1.9636)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9752 (1.9752)
Train - epoch [3/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.9209 (1.9209)
Train - epoch [3/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.1369 (2.1369)
Train - epoch [3/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8876 (1.8876)
Train - epoch [3/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8732 (1.8732)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8485 (1.8485)
Train - epoch [3/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.8923 (1.8923)
Train - epoch [3/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8059 (1.8059)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.1564 (2.1564)
Train - epoch [3/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.8492 (1.8492)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.9028 (1.9028)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8582 (1.8582)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 1.8442 (1.8442)
Train - epoch [3/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.9013 (1.9013)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 1.8410 (1.8410)
Train - epoch [3/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8311 (1.8311)
Train - epoch [3/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.9650 (1.9650)
Train - epoch [3/200]	BT 4.617 (4.617)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8157 (1.8157)
Train - epoch [3/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.1056 (2.1056)
Train - epoch [3/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8749 (1.8749)
Train - epoch [3/200]	BT 4.338 (4.338)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9573 (1.9573)
Train - epoch [3/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.9270 (1.9270)
Train - epoch [3/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8920 (1.8920)
Train - epoch [3/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8848 (1.8848)
Train - epoch [3/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 1.8166 (1.8166)
Train - epoch [3/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.8201 (1.8201)
Train - epoch [3/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 1.7817 (1.7817)
Train - epoch [3/200]	BT 3.723 (3.723)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 1.8620 (1.8620)
Train - epoch [3/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 1.8647 (1.8647)
Train - epoch [3/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 1.8209 (1.8209)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 1.8791 (1.8791)
Train - epoch [3/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 1.7978 (1.7978)
Train - epoch [3/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 1.8247 (1.8247)
Train - epoch [3/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 1.9835 (1.9835)
Train - epoch [3/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 1.8606 (1.8606)
Train - epoch [3/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 1.9295 (1.9295)
Test on T training set - [3][0/1731]	T 0.307 (0.307)	D 0.198 (0.198)	T@1 0.000 (0.000)	T@5 9.375 (9.375)	L 4.4290 (4.4290)
Test on T training set - [3][10/1731]	T 0.215 (0.208)	D 0.119 (0.106)	T@1 0.000 (2.273)	T@5 21.875 (25.000)	L 4.2161 (4.2520)
Test on T training set - [3][20/1731]	T 0.229 (0.219)	D 0.133 (0.117)	T@1 6.250 (1.637)	T@5 31.250 (28.125)	L 3.9784 (4.2115)
Test on T training set - [3][30/1731]	T 0.221 (0.220)	D 0.114 (0.117)	T@1 0.000 (1.613)	T@5 34.375 (29.738)	L 4.1304 (4.1856)
Test on T training set - [3][40/1731]	T 0.237 (0.295)	D 0.135 (0.193)	T@1 3.125 (1.524)	T@5 25.000 (29.192)	L 4.4022 (4.1877)
Test on T training set - [3][50/1731]	T 0.227 (0.281)	D 0.122 (0.179)	T@1 0.000 (1.348)	T@5 25.000 (29.228)	L 4.3629 (4.1856)
Test on T training set - [3][60/1731]	T 0.231 (0.272)	D 0.125 (0.169)	T@1 0.000 (1.332)	T@5 21.875 (29.611)	L 4.2491 (4.1932)
Test on T training set - [3][70/1731]	T 0.210 (0.264)	D 0.110 (0.161)	T@1 0.000 (1.276)	T@5 43.750 (29.798)	L 4.1445 (4.1921)
Test on T training set - [3][80/1731]	T 0.204 (0.258)	D 0.099 (0.156)	T@1 0.000 (1.466)	T@5 28.125 (29.321)	L 4.3933 (4.1879)
Test on T training set - [3][90/1731]	T 0.185 (0.252)	D 0.089 (0.150)	T@1 3.125 (1.442)	T@5 28.125 (28.949)	L 4.3809 (4.1928)
Test on T training set - [3][100/1731]	T 0.196 (0.247)	D 0.090 (0.145)	T@1 0.000 (1.454)	T@5 34.375 (28.991)	L 4.3375 (4.1952)
Test on T training set - [3][110/1731]	T 0.206 (0.242)	D 0.104 (0.139)	T@1 0.000 (1.492)	T@5 21.875 (28.716)	L 4.4809 (4.2044)
Test on T training set - [3][120/1731]	T 0.202 (0.238)	D 0.106 (0.136)	T@1 0.000 (1.369)	T@5 3.125 (27.118)	L 4.5534 (4.2250)
Test on T training set - [3][130/1731]	T 0.189 (0.235)	D 0.093 (0.133)	T@1 0.000 (1.264)	T@5 9.375 (25.596)	L 4.3656 (4.2410)
Test on T training set - [3][140/1731]	T 0.179 (0.245)	D 0.082 (0.143)	T@1 0.000 (1.175)	T@5 6.250 (24.202)	L 4.7205 (4.2529)
Test on T training set - [3][150/1731]	T 0.204 (0.241)	D 0.094 (0.139)	T@1 0.000 (1.097)	T@5 9.375 (23.220)	L 4.4215 (4.2627)
Test on T training set - [3][160/1731]	T 0.188 (0.238)	D 0.086 (0.136)	T@1 0.000 (1.029)	T@5 6.250 (22.341)	L 4.3918 (4.2719)
Test on T training set - [3][170/1731]	T 0.172 (0.235)	D 0.071 (0.133)	T@1 0.000 (0.969)	T@5 3.125 (21.327)	L 4.5234 (4.2807)
Test on T training set - [3][180/1731]	T 0.163 (0.231)	D 0.057 (0.129)	T@1 0.000 (0.915)	T@5 3.125 (20.287)	L 4.5252 (4.2931)
Test on T training set - [3][190/1731]	T 0.178 (0.227)	D 0.082 (0.125)	T@1 0.000 (0.867)	T@5 0.000 (19.437)	L 4.4707 (4.3065)
Test on T training set - [3][200/1731]	T 0.164 (0.225)	D 0.065 (0.123)	T@1 0.000 (0.824)	T@5 0.000 (18.595)	L 4.5104 (4.3187)
Test on T training set - [3][210/1731]	T 0.172 (0.222)	D 0.071 (0.120)	T@1 0.000 (0.785)	T@5 3.125 (17.891)	L 4.3163 (4.3277)
Test on T training set - [3][220/1731]	T 0.173 (0.220)	D 0.077 (0.118)	T@1 0.000 (0.749)	T@5 12.500 (17.279)	L 4.2862 (4.3334)
Test on T training set - [3][230/1731]	T 0.176 (0.218)	D 0.069 (0.116)	T@1 9.375 (0.988)	T@5 93.750 (20.049)	L 2.4950 (4.2877)
Test on T training set - [3][240/1731]	T 0.230 (0.225)	D 0.128 (0.123)	T@1 3.125 (1.219)	T@5 93.750 (23.081)	L 3.0718 (4.2373)
Test on T training set - [3][250/1731]	T 0.214 (0.226)	D 0.105 (0.124)	T@1 9.375 (1.506)	T@5 90.625 (25.859)	L 3.0272 (4.1901)
Test on T training set - [3][260/1731]	T 0.235 (0.226)	D 0.137 (0.124)	T@1 3.125 (1.748)	T@5 90.625 (28.472)	L 2.9989 (4.1481)
Test on T training set - [3][270/1731]	T 0.246 (0.226)	D 0.140 (0.124)	T@1 9.375 (1.995)	T@5 100.000 (30.985)	L 3.0610 (4.1074)
Test on T training set - [3][280/1731]	T 0.237 (0.226)	D 0.138 (0.124)	T@1 9.375 (2.169)	T@5 96.875 (33.174)	L 3.0871 (4.0700)
Test on T training set - [3][290/1731]	T 0.232 (0.227)	D 0.134 (0.125)	T@1 9.375 (2.438)	T@5 100.000 (35.320)	L 3.1919 (4.0300)
Test on T training set - [3][300/1731]	T 0.212 (0.227)	D 0.114 (0.124)	T@1 6.250 (2.647)	T@5 87.500 (37.251)	L 3.2687 (4.0024)
Test on T training set - [3][310/1731]	T 0.235 (0.226)	D 0.127 (0.124)	T@1 15.625 (2.904)	T@5 96.875 (39.148)	L 2.7426 (3.9677)
Test on T training set - [3][320/1731]	T 0.206 (0.226)	D 0.098 (0.124)	T@1 6.250 (3.086)	T@5 96.875 (40.937)	L 2.9552 (3.9372)
Test on T training set - [3][330/1731]	T 0.204 (0.233)	D 0.096 (0.131)	T@1 12.500 (3.342)	T@5 96.875 (42.617)	L 2.7607 (3.9053)
Test on T training set - [3][340/1731]	T 0.189 (0.232)	D 0.085 (0.130)	T@1 3.125 (3.492)	T@5 96.875 (44.190)	L 3.0333 (3.8780)
Test on T training set - [3][350/1731]	T 0.206 (0.231)	D 0.110 (0.129)	T@1 9.375 (3.659)	T@5 96.875 (45.637)	L 3.2585 (3.8561)
Test on T training set - [3][360/1731]	T 0.236 (0.231)	D 0.140 (0.129)	T@1 15.625 (3.904)	T@5 96.875 (47.057)	L 2.5694 (3.8274)
Test on T training set - [3][370/1731]	T 0.172 (0.230)	D 0.077 (0.128)	T@1 3.125 (4.026)	T@5 65.625 (48.181)	L 4.2664 (3.8101)
Test on T training set - [3][380/1731]	T 0.182 (0.229)	D 0.086 (0.127)	T@1 3.125 (3.962)	T@5 62.500 (48.401)	L 4.1662 (3.8179)
Test on T training set - [3][390/1731]	T 0.175 (0.228)	D 0.078 (0.126)	T@1 6.250 (3.932)	T@5 53.125 (48.769)	L 3.9103 (3.8226)
Test on T training set - [3][400/1731]	T 0.162 (0.226)	D 0.059 (0.124)	T@1 6.250 (3.881)	T@5 59.375 (49.041)	L 3.8979 (3.8265)
Test on T training set - [3][410/1731]	T 0.157 (0.225)	D 0.061 (0.123)	T@1 9.375 (3.855)	T@5 43.750 (49.171)	L 3.5891 (3.8306)
Test on T training set - [3][420/1731]	T 0.162 (0.228)	D 0.060 (0.126)	T@1 0.000 (3.815)	T@5 59.375 (49.480)	L 4.1092 (3.8344)
Test on T training set - [3][430/1731]	T 0.171 (0.227)	D 0.067 (0.125)	T@1 3.125 (3.799)	T@5 53.125 (49.688)	L 4.0899 (3.8388)
Test on T training set - [3][440/1731]	T 0.163 (0.226)	D 0.061 (0.123)	T@1 0.000 (3.763)	T@5 68.750 (49.894)	L 4.4947 (3.8462)
Test on T training set - [3][450/1731]	T 0.166 (0.224)	D 0.066 (0.122)	T@1 3.125 (3.762)	T@5 59.375 (50.166)	L 4.1106 (3.8494)
Test on T training set - [3][460/1731]	T 0.169 (0.223)	D 0.072 (0.121)	T@1 3.125 (3.769)	T@5 56.250 (50.488)	L 3.9879 (3.8523)
Test on T training set - [3][470/1731]	T 0.158 (0.222)	D 0.056 (0.120)	T@1 0.000 (3.722)	T@5 59.375 (50.677)	L 4.1193 (3.8560)
Test on T training set - [3][480/1731]	T 0.162 (0.221)	D 0.056 (0.119)	T@1 3.125 (3.697)	T@5 81.250 (50.877)	L 3.9524 (3.8600)
Test on T training set - [3][490/1731]	T 0.164 (0.220)	D 0.066 (0.118)	T@1 0.000 (3.653)	T@5 50.000 (51.063)	L 4.2294 (3.8656)
Test on T training set - [3][500/1731]	T 0.185 (0.219)	D 0.078 (0.117)	T@1 0.000 (3.630)	T@5 56.250 (51.191)	L 4.0317 (3.8693)
Test on T training set - [3][510/1731]	T 0.173 (0.218)	D 0.066 (0.116)	T@1 3.125 (3.602)	T@5 56.250 (51.370)	L 4.0745 (3.8728)
Test on T training set - [3][520/1731]	T 0.165 (0.217)	D 0.059 (0.115)	T@1 9.375 (3.635)	T@5 50.000 (51.476)	L 3.8637 (3.8741)
Test on T training set - [3][530/1731]	T 0.174 (0.216)	D 0.071 (0.114)	T@1 0.000 (3.619)	T@5 50.000 (51.601)	L 4.3146 (3.8787)
Test on T training set - [3][540/1731]	T 0.164 (0.219)	D 0.062 (0.117)	T@1 3.125 (3.593)	T@5 59.375 (51.762)	L 3.9965 (3.8836)
Test on T training set - [3][550/1731]	T 0.163 (0.218)	D 0.056 (0.116)	T@1 0.000 (3.556)	T@5 59.375 (51.889)	L 4.2169 (3.8889)
Test on T training set - [3][560/1731]	T 0.179 (0.217)	D 0.076 (0.115)	T@1 0.000 (3.532)	T@5 50.000 (51.972)	L 4.3546 (3.8921)
Test on T training set - [3][570/1731]	T 0.198 (0.217)	D 0.092 (0.114)	T@1 6.250 (3.546)	T@5 65.625 (52.074)	L 4.0338 (3.8943)
Test on T training set - [3][580/1731]	T 0.180 (0.216)	D 0.074 (0.114)	T@1 0.000 (3.507)	T@5 65.625 (52.189)	L 4.0350 (3.8963)
Test on T training set - [3][590/1731]	T 0.191 (0.215)	D 0.083 (0.113)	T@1 6.250 (3.511)	T@5 71.875 (52.332)	L 3.6110 (3.8968)
Test on T training set - [3][600/1731]	T 0.168 (0.215)	D 0.067 (0.112)	T@1 0.000 (3.505)	T@5 68.750 (52.449)	L 4.0353 (3.8982)
Test on T training set - [3][610/1731]	T 0.162 (0.214)	D 0.061 (0.112)	T@1 3.125 (3.493)	T@5 56.250 (52.552)	L 4.0100 (3.9011)
Test on T training set - [3][620/1731]	T 0.182 (0.213)	D 0.084 (0.111)	T@1 0.000 (3.457)	T@5 56.250 (52.687)	L 4.0500 (3.9035)
Test on T training set - [3][630/1731]	T 0.158 (0.213)	D 0.055 (0.111)	T@1 3.125 (3.452)	T@5 56.250 (52.813)	L 3.9125 (3.9049)
Test on T training set - [3][640/1731]	T 0.171 (0.212)	D 0.064 (0.110)	T@1 3.125 (3.447)	T@5 71.875 (52.930)	L 3.8084 (3.9075)
Test on T training set - [3][650/1731]	T 0.165 (0.212)	D 0.060 (0.109)	T@1 0.000 (3.427)	T@5 43.750 (53.053)	L 3.9645 (3.9086)
Test on T training set - [3][660/1731]	T 0.167 (0.214)	D 0.071 (0.111)	T@1 3.125 (3.413)	T@5 62.500 (53.125)	L 3.9196 (3.9115)
Test on T training set - [3][670/1731]	T 0.170 (0.213)	D 0.072 (0.111)	T@1 3.125 (3.390)	T@5 53.125 (53.297)	L 4.0659 (3.9135)
Test on T training set - [3][680/1731]	T 0.164 (0.212)	D 0.060 (0.110)	T@1 0.000 (3.377)	T@5 56.250 (53.405)	L 3.9661 (3.9153)
Test on T training set - [3][690/1731]	T 0.227 (0.212)	D 0.126 (0.109)	T@1 0.000 (3.351)	T@5 43.750 (53.414)	L 4.2411 (3.9182)
Test on T training set - [3][700/1731]	T 0.161 (0.211)	D 0.056 (0.109)	T@1 0.000 (3.317)	T@5 21.875 (53.027)	L 4.1966 (3.9248)
Test on T training set - [3][710/1731]	T 0.175 (0.211)	D 0.071 (0.108)	T@1 0.000 (3.270)	T@5 25.000 (52.496)	L 4.2004 (3.9319)
Test on T training set - [3][720/1731]	T 0.173 (0.210)	D 0.068 (0.108)	T@1 0.000 (3.246)	T@5 28.125 (52.063)	L 4.2494 (3.9372)
Test on T training set - [3][730/1731]	T 0.215 (0.210)	D 0.111 (0.108)	T@1 0.000 (3.210)	T@5 18.750 (51.586)	L 4.3548 (3.9439)
Test on T training set - [3][740/1731]	T 0.220 (0.210)	D 0.115 (0.108)	T@1 0.000 (3.176)	T@5 15.625 (51.156)	L 4.3666 (3.9490)
Test on T training set - [3][750/1731]	T 0.190 (0.210)	D 0.094 (0.108)	T@1 0.000 (3.150)	T@5 12.500 (50.770)	L 4.5996 (3.9551)
Test on T training set - [3][760/1731]	T 0.243 (0.212)	D 0.135 (0.110)	T@1 0.000 (3.113)	T@5 21.875 (50.345)	L 4.2511 (3.9604)
Test on T training set - [3][770/1731]	T 0.209 (0.212)	D 0.107 (0.110)	T@1 3.125 (3.093)	T@5 18.750 (49.919)	L 4.3826 (3.9654)
Test on T training set - [3][780/1731]	T 0.228 (0.212)	D 0.127 (0.110)	T@1 0.000 (3.065)	T@5 18.750 (49.600)	L 4.2598 (3.9692)
Test on T training set - [3][790/1731]	T 0.215 (0.212)	D 0.112 (0.110)	T@1 0.000 (3.038)	T@5 15.625 (49.174)	L 4.4861 (3.9752)
Test on T training set - [3][800/1731]	T 0.203 (0.212)	D 0.105 (0.110)	T@1 3.125 (3.012)	T@5 31.250 (48.876)	L 3.9829 (3.9786)
Test on T training set - [3][810/1731]	T 0.194 (0.212)	D 0.098 (0.110)	T@1 0.000 (2.982)	T@5 15.625 (48.482)	L 4.5815 (3.9838)
Test on T training set - [3][820/1731]	T 0.221 (0.212)	D 0.113 (0.110)	T@1 3.125 (2.954)	T@5 28.125 (48.200)	L 4.0583 (3.9880)
Test on T training set - [3][830/1731]	T 0.191 (0.212)	D 0.095 (0.110)	T@1 3.125 (2.929)	T@5 25.000 (47.860)	L 4.2550 (3.9925)
Test on T training set - [3][840/1731]	T 0.181 (0.211)	D 0.077 (0.109)	T@1 9.375 (2.909)	T@5 43.750 (47.525)	L 3.6445 (3.9974)
Test on T training set - [3][850/1731]	T 0.166 (0.211)	D 0.062 (0.109)	T@1 28.125 (3.129)	T@5 100.000 (48.142)	L 1.8619 (3.9729)
Test on T training set - [3][860/1731]	T 0.169 (0.213)	D 0.070 (0.111)	T@1 31.250 (3.361)	T@5 100.000 (48.744)	L 1.7775 (3.9481)
Test on T training set - [3][870/1731]	T 0.162 (0.213)	D 0.066 (0.111)	T@1 18.750 (3.566)	T@5 100.000 (49.333)	L 1.9654 (3.9249)
Test on T training set - [3][880/1731]	T 0.173 (0.212)	D 0.076 (0.110)	T@1 15.625 (3.742)	T@5 100.000 (49.908)	L 1.9638 (3.9014)
Test on T training set - [3][890/1731]	T 0.171 (0.212)	D 0.067 (0.110)	T@1 28.125 (3.900)	T@5 100.000 (50.470)	L 2.0268 (3.8796)
Test on T training set - [3][900/1731]	T 0.172 (0.211)	D 0.066 (0.109)	T@1 25.000 (4.065)	T@5 100.000 (51.016)	L 1.7879 (3.8590)
Test on T training set - [3][910/1731]	T 0.184 (0.211)	D 0.080 (0.109)	T@1 0.000 (4.127)	T@5 3.125 (50.971)	L 4.6092 (3.8541)
Test on T training set - [3][920/1731]	T 0.174 (0.210)	D 0.066 (0.108)	T@1 0.000 (4.082)	T@5 0.000 (50.424)	L 4.6768 (3.8624)
Test on T training set - [3][930/1731]	T 0.244 (0.210)	D 0.142 (0.108)	T@1 0.000 (4.038)	T@5 9.375 (49.930)	L 4.4813 (3.8696)
Test on T training set - [3][940/1731]	T 0.254 (0.211)	D 0.158 (0.109)	T@1 0.000 (3.995)	T@5 3.125 (49.435)	L 4.5280 (3.8762)
Test on T training set - [3][950/1731]	T 0.235 (0.211)	D 0.134 (0.109)	T@1 0.000 (3.953)	T@5 3.125 (48.968)	L 4.4747 (3.8828)
Test on T training set - [3][960/1731]	T 0.211 (0.211)	D 0.115 (0.109)	T@1 0.000 (3.915)	T@5 9.375 (48.514)	L 4.4881 (3.8895)
Test on T training set - [3][970/1731]	T 0.237 (0.213)	D 0.132 (0.111)	T@1 0.000 (3.878)	T@5 3.125 (48.069)	L 4.6421 (3.8963)
Test on T training set - [3][980/1731]	T 0.203 (0.213)	D 0.105 (0.111)	T@1 0.000 (3.839)	T@5 6.250 (47.620)	L 4.4864 (3.9030)
Test on T training set - [3][990/1731]	T 0.221 (0.213)	D 0.126 (0.111)	T@1 0.000 (3.800)	T@5 3.125 (47.149)	L 4.6704 (3.9099)
Test on T training set - [3][1000/1731]	T 0.231 (0.213)	D 0.124 (0.111)	T@1 0.000 (3.765)	T@5 0.000 (46.703)	L 4.6364 (3.9164)
Test on T training set - [3][1010/1731]	T 0.203 (0.213)	D 0.102 (0.111)	T@1 0.000 (3.728)	T@5 9.375 (46.285)	L 4.7092 (3.9232)
Test on T training set - [3][1020/1731]	T 0.202 (0.213)	D 0.106 (0.111)	T@1 0.000 (3.691)	T@5 3.125 (45.868)	L 4.4029 (3.9299)
Test on T training set - [3][1030/1731]	T 0.168 (0.212)	D 0.071 (0.110)	T@1 0.000 (3.658)	T@5 6.250 (45.444)	L 4.4522 (3.9364)
Test on T training set - [3][1040/1731]	T 0.177 (0.212)	D 0.073 (0.110)	T@1 0.000 (3.623)	T@5 0.000 (45.020)	L 4.6418 (3.9428)
Test on T training set - [3][1050/1731]	T 0.179 (0.212)	D 0.077 (0.110)	T@1 3.125 (3.595)	T@5 3.125 (44.603)	L 4.3806 (3.9491)
Test on T training set - [3][1060/1731]	T 0.165 (0.212)	D 0.059 (0.110)	T@1 0.000 (3.561)	T@5 0.000 (44.192)	L 4.8116 (3.9558)
Test on T training set - [3][1070/1731]	T 0.218 (0.212)	D 0.111 (0.110)	T@1 0.000 (3.528)	T@5 3.125 (43.791)	L 4.5328 (3.9623)
Test on T training set - [3][1080/1731]	T 0.162 (0.212)	D 0.066 (0.110)	T@1 0.000 (3.495)	T@5 3.125 (43.412)	L 4.6432 (3.9688)
Test on T training set - [3][1090/1731]	T 0.178 (0.212)	D 0.075 (0.110)	T@1 9.375 (3.526)	T@5 18.750 (43.120)	L 3.9583 (3.9710)
Test on T training set - [3][1100/1731]	T 0.207 (0.212)	D 0.101 (0.110)	T@1 15.625 (3.602)	T@5 25.000 (42.918)	L 3.7258 (3.9711)
Test on T training set - [3][1110/1731]	T 0.207 (0.211)	D 0.111 (0.109)	T@1 12.500 (3.713)	T@5 18.750 (42.735)	L 4.1197 (3.9697)
Test on T training set - [3][1120/1731]	T 0.192 (0.211)	D 0.088 (0.109)	T@1 18.750 (3.839)	T@5 21.875 (42.582)	L 3.8882 (3.9676)
Test on T training set - [3][1130/1731]	T 0.182 (0.211)	D 0.081 (0.109)	T@1 12.500 (3.946)	T@5 28.125 (42.424)	L 3.7369 (3.9663)
Test on T training set - [3][1140/1731]	T 0.192 (0.211)	D 0.094 (0.109)	T@1 15.625 (4.029)	T@5 21.875 (42.238)	L 4.0417 (3.9659)
Test on T training set - [3][1150/1731]	T 0.190 (0.213)	D 0.086 (0.111)	T@1 25.000 (4.140)	T@5 34.375 (42.105)	L 3.5646 (3.9633)
Test on T training set - [3][1160/1731]	T 0.176 (0.212)	D 0.074 (0.110)	T@1 25.000 (4.250)	T@5 28.125 (41.949)	L 3.3828 (3.9616)
Test on T training set - [3][1170/1731]	T 0.180 (0.212)	D 0.082 (0.110)	T@1 21.875 (4.350)	T@5 21.875 (41.823)	L 3.6417 (3.9600)
Test on T training set - [3][1180/1731]	T 0.198 (0.212)	D 0.092 (0.110)	T@1 9.375 (4.459)	T@5 21.875 (41.697)	L 4.1982 (3.9582)
Test on T training set - [3][1190/1731]	T 0.191 (0.212)	D 0.094 (0.110)	T@1 18.750 (4.545)	T@5 28.125 (41.535)	L 3.6636 (3.9574)
Test on T training set - [3][1200/1731]	T 0.187 (0.212)	D 0.081 (0.110)	T@1 12.500 (4.621)	T@5 21.875 (41.367)	L 3.8140 (3.9567)
Test on T training set - [3][1210/1731]	T 0.199 (0.211)	D 0.100 (0.109)	T@1 12.500 (4.709)	T@5 25.000 (41.224)	L 3.8650 (3.9554)
Test on T training set - [3][1220/1731]	T 0.176 (0.211)	D 0.072 (0.109)	T@1 0.000 (4.684)	T@5 12.500 (40.994)	L 4.6212 (3.9591)
Test on T training set - [3][1230/1731]	T 0.159 (0.211)	D 0.063 (0.109)	T@1 0.000 (4.648)	T@5 0.000 (40.727)	L 4.5517 (3.9634)
Test on T training set - [3][1240/1731]	T 0.172 (0.210)	D 0.076 (0.109)	T@1 0.000 (4.616)	T@5 12.500 (40.489)	L 4.5249 (3.9671)
Test on T training set - [3][1250/1731]	T 0.177 (0.210)	D 0.081 (0.108)	T@1 0.000 (4.584)	T@5 9.375 (40.225)	L 4.6306 (3.9708)
Test on T training set - [3][1260/1731]	T 0.188 (0.212)	D 0.092 (0.110)	T@1 0.000 (4.550)	T@5 15.625 (40.010)	L 4.3992 (3.9745)
Test on T training set - [3][1270/1731]	T 0.180 (0.212)	D 0.075 (0.110)	T@1 0.000 (4.514)	T@5 9.375 (39.760)	L 4.4088 (3.9780)
Test on T training set - [3][1280/1731]	T 0.196 (0.212)	D 0.092 (0.110)	T@1 0.000 (4.481)	T@5 6.250 (39.517)	L 4.4064 (3.9821)
Test on T training set - [3][1290/1731]	T 0.168 (0.211)	D 0.070 (0.109)	T@1 0.000 (4.451)	T@5 9.375 (39.289)	L 4.2918 (3.9854)
Test on T training set - [3][1300/1731]	T 0.174 (0.211)	D 0.075 (0.109)	T@1 0.000 (4.422)	T@5 9.375 (39.064)	L 4.4423 (3.9888)
Test on T training set - [3][1310/1731]	T 0.180 (0.211)	D 0.083 (0.109)	T@1 0.000 (4.391)	T@5 18.750 (38.837)	L 4.4818 (3.9924)
Test on T training set - [3][1320/1731]	T 0.194 (0.211)	D 0.098 (0.109)	T@1 0.000 (4.362)	T@5 0.000 (38.619)	L 4.4057 (3.9957)
Test on T training set - [3][1330/1731]	T 0.175 (0.210)	D 0.075 (0.108)	T@1 3.125 (4.332)	T@5 9.375 (38.366)	L 4.4135 (3.9992)
Test on T training set - [3][1340/1731]	T 0.157 (0.210)	D 0.059 (0.108)	T@1 0.000 (4.299)	T@5 6.250 (38.164)	L 4.4187 (4.0028)
Test on T training set - [3][1350/1731]	T 0.181 (0.210)	D 0.075 (0.108)	T@1 3.125 (4.275)	T@5 12.500 (37.944)	L 4.2677 (4.0061)
Test on T training set - [3][1360/1731]	T 0.171 (0.211)	D 0.068 (0.109)	T@1 28.125 (4.324)	T@5 87.500 (38.148)	L 2.7998 (4.0025)
Test on T training set - [3][1370/1731]	T 0.164 (0.210)	D 0.061 (0.108)	T@1 9.375 (4.417)	T@5 84.375 (38.480)	L 3.3344 (3.9964)
Test on T training set - [3][1380/1731]	T 0.170 (0.210)	D 0.064 (0.108)	T@1 21.875 (4.523)	T@5 87.500 (38.819)	L 2.9925 (3.9890)
Test on T training set - [3][1390/1731]	T 0.176 (0.210)	D 0.068 (0.108)	T@1 12.500 (4.617)	T@5 84.375 (39.156)	L 3.1441 (3.9826)
Test on T training set - [3][1400/1731]	T 0.181 (0.209)	D 0.076 (0.107)	T@1 34.375 (4.731)	T@5 84.375 (39.499)	L 2.7312 (3.9757)
Test on T training set - [3][1410/1731]	T 0.173 (0.209)	D 0.072 (0.107)	T@1 18.750 (4.821)	T@5 87.500 (39.848)	L 3.3269 (3.9693)
Test on T training set - [3][1420/1731]	T 0.158 (0.209)	D 0.062 (0.107)	T@1 15.625 (4.893)	T@5 78.125 (40.181)	L 3.1666 (3.9635)
Test on T training set - [3][1430/1731]	T 0.213 (0.209)	D 0.110 (0.107)	T@1 37.500 (5.040)	T@5 100.000 (40.562)	L 1.5808 (3.9511)
Test on T training set - [3][1440/1731]	T 0.245 (0.209)	D 0.148 (0.107)	T@1 65.625 (5.385)	T@5 100.000 (40.974)	L 1.1023 (3.9325)
Test on T training set - [3][1450/1731]	T 0.244 (0.209)	D 0.138 (0.107)	T@1 37.500 (5.673)	T@5 100.000 (41.381)	L 1.1932 (3.9150)
Test on T training set - [3][1460/1731]	T 0.225 (0.210)	D 0.129 (0.108)	T@1 56.250 (5.944)	T@5 100.000 (41.782)	L 1.1040 (3.8976)
Test on T training set - [3][1470/1731]	T 0.242 (0.210)	D 0.135 (0.108)	T@1 59.375 (6.235)	T@5 100.000 (42.178)	L 0.9751 (3.8809)
Test on T training set - [3][1480/1731]	T 0.242 (0.210)	D 0.142 (0.108)	T@1 46.875 (6.501)	T@5 100.000 (42.568)	L 1.6021 (3.8643)
Test on T training set - [3][1490/1731]	T 0.230 (0.211)	D 0.134 (0.109)	T@1 56.250 (6.745)	T@5 100.000 (42.954)	L 1.2908 (3.8482)
Test on T training set - [3][1500/1731]	T 0.252 (0.211)	D 0.156 (0.109)	T@1 40.625 (6.995)	T@5 100.000 (43.334)	L 1.4469 (3.8318)
Test on T training set - [3][1510/1731]	T 0.246 (0.211)	D 0.141 (0.109)	T@1 34.375 (7.239)	T@5 100.000 (43.709)	L 1.4352 (3.8159)
Test on T training set - [3][1520/1731]	T 0.222 (0.211)	D 0.126 (0.109)	T@1 46.875 (7.559)	T@5 100.000 (44.079)	L 1.4155 (3.7990)
Test on T training set - [3][1530/1731]	T 0.237 (0.211)	D 0.131 (0.109)	T@1 56.250 (7.830)	T@5 100.000 (44.444)	L 1.1272 (3.7831)
Test on T training set - [3][1540/1731]	T 0.192 (0.213)	D 0.096 (0.111)	T@1 21.875 (8.059)	T@5 100.000 (44.805)	L 1.8015 (3.7681)
Test on T training set - [3][1550/1731]	T 0.247 (0.213)	D 0.143 (0.111)	T@1 53.125 (8.311)	T@5 100.000 (45.160)	L 1.1039 (3.7524)
Test on T training set - [3][1560/1731]	T 0.193 (0.213)	D 0.097 (0.111)	T@1 0.000 (8.458)	T@5 6.250 (45.322)	L 4.6466 (3.7443)
Test on T training set - [3][1570/1731]	T 0.195 (0.213)	D 0.082 (0.111)	T@1 0.000 (8.404)	T@5 6.250 (45.099)	L 4.3782 (3.7497)
Test on T training set - [3][1580/1731]	T 0.167 (0.213)	D 0.063 (0.111)	T@1 0.000 (8.351)	T@5 21.875 (44.889)	L 4.5434 (3.7546)
Test on T training set - [3][1590/1731]	T 0.172 (0.213)	D 0.066 (0.111)	T@1 0.000 (8.299)	T@5 12.500 (44.685)	L 4.6440 (3.7597)
Test on T training set - [3][1600/1731]	T 0.184 (0.212)	D 0.088 (0.110)	T@1 0.000 (8.247)	T@5 12.500 (44.464)	L 4.4218 (3.7647)
Test on T training set - [3][1610/1731]	T 0.177 (0.212)	D 0.076 (0.110)	T@1 0.000 (8.196)	T@5 9.375 (44.260)	L 4.6118 (3.7699)
Test on T training set - [3][1620/1731]	T 0.181 (0.212)	D 0.083 (0.110)	T@1 0.000 (8.145)	T@5 0.000 (44.066)	L 4.5117 (3.7750)
Test on T training set - [3][1630/1731]	T 0.178 (0.212)	D 0.076 (0.110)	T@1 0.000 (8.095)	T@5 15.625 (43.880)	L 4.5497 (3.7800)
Test on T training set - [3][1640/1731]	T 0.216 (0.213)	D 0.120 (0.111)	T@1 0.000 (8.046)	T@5 9.375 (43.674)	L 4.4260 (3.7846)
Test on T training set - [3][1650/1731]	T 0.225 (0.213)	D 0.129 (0.111)	T@1 0.000 (7.997)	T@5 15.625 (43.512)	L 4.5707 (3.7894)
Test on T training set - [3][1660/1731]	T 0.219 (0.213)	D 0.114 (0.111)	T@1 0.000 (7.949)	T@5 25.000 (43.364)	L 4.5912 (3.7941)
Test on T training set - [3][1670/1731]	T 0.213 (0.213)	D 0.109 (0.111)	T@1 0.000 (7.901)	T@5 15.625 (43.185)	L 4.4404 (3.7986)
Test on T training set - [3][1680/1731]	T 0.206 (0.213)	D 0.100 (0.111)	T@1 0.000 (7.854)	T@5 12.500 (43.005)	L 4.5183 (3.8030)
Test on T training set - [3][1690/1731]	T 0.226 (0.213)	D 0.129 (0.111)	T@1 0.000 (7.808)	T@5 15.625 (42.830)	L 4.8052 (3.8078)
Test on T training set - [3][1700/1731]	T 0.229 (0.213)	D 0.120 (0.111)	T@1 0.000 (7.762)	T@5 15.625 (42.650)	L 4.5028 (3.8122)
Test on T training set - [3][1710/1731]	T 0.229 (0.213)	D 0.128 (0.111)	T@1 0.000 (7.718)	T@5 6.250 (42.493)	L 4.8115 (3.8160)
Test on T training set - [3][1720/1731]	T 0.204 (0.215)	D 0.095 (0.113)	T@1 0.000 (7.674)	T@5 15.625 (42.332)	L 4.4878 (3.8205)
Test on T training set - [3][1730/1731]	T 0.170 (0.215)	D 0.078 (0.113)	T@1 0.000 (7.630)	T@5 21.429 (42.166)	L 4.6443 (3.8250)
 * Test on T training set - Prec@1 7.630, Prec@5 42.166
Test on T test set - [3][0/1731]	Time 0.299 (0.299)	Loss 4.3280 (4.3280)	Prec@1 3.125 (3.125)	Prec@5 21.875 (21.875)
Test on T test set - [3][10/1731]	Time 0.213 (0.200)	Loss 4.0519 (4.1220)	Prec@1 6.250 (4.261)	Prec@5 31.250 (28.409)
Test on T test set - [3][20/1731]	Time 0.213 (0.211)	Loss 4.2819 (4.1559)	Prec@1 3.125 (2.976)	Prec@5 31.250 (28.423)
Test on T test set - [3][30/1731]	Time 0.203 (0.211)	Loss 3.8510 (4.1439)	Prec@1 6.250 (2.823)	Prec@5 34.375 (30.343)
Test on T test set - [3][40/1731]	Time 0.228 (0.213)	Loss 4.4098 (4.1580)	Prec@1 0.000 (2.210)	Prec@5 12.500 (29.878)
Test on T test set - [3][50/1731]	Time 0.219 (0.214)	Loss 4.5114 (4.1653)	Prec@1 0.000 (2.206)	Prec@5 21.875 (29.657)
Test on T test set - [3][60/1731]	Time 0.228 (0.215)	Loss 4.1108 (4.1667)	Prec@1 0.000 (1.947)	Prec@5 28.125 (29.867)
Test on T test set - [3][70/1731]	Time 0.201 (0.214)	Loss 4.1173 (4.1651)	Prec@1 3.125 (1.937)	Prec@5 28.125 (29.665)
Test on T test set - [3][80/1731]	Time 0.208 (0.230)	Loss 4.2242 (4.1622)	Prec@1 0.000 (1.852)	Prec@5 31.250 (29.591)
Test on T test set - [3][90/1731]	Time 0.188 (0.228)	Loss 4.1055 (4.1642)	Prec@1 3.125 (1.717)	Prec@5 34.375 (29.258)
Test on T test set - [3][100/1731]	Time 0.182 (0.224)	Loss 4.0977 (4.1646)	Prec@1 3.125 (1.671)	Prec@5 31.250 (29.425)
Test on T test set - [3][110/1731]	Time 0.198 (0.221)	Loss 4.3563 (4.1743)	Prec@1 0.000 (1.689)	Prec@5 25.000 (29.476)
Test on T test set - [3][120/1731]	Time 0.202 (0.219)	Loss 4.4371 (4.1925)	Prec@1 0.000 (1.575)	Prec@5 3.125 (27.815)
Test on T test set - [3][130/1731]	Time 0.185 (0.217)	Loss 4.4338 (4.2076)	Prec@1 0.000 (1.455)	Prec@5 6.250 (26.407)
Test on T test set - [3][140/1731]	Time 0.177 (0.215)	Loss 4.5225 (4.2220)	Prec@1 0.000 (1.352)	Prec@5 6.250 (25.044)
Test on T test set - [3][150/1731]	Time 0.200 (0.213)	Loss 4.4421 (4.2350)	Prec@1 0.000 (1.262)	Prec@5 12.500 (23.841)
Test on T test set - [3][160/1731]	Time 0.180 (0.212)	Loss 4.4871 (4.2435)	Prec@1 0.000 (1.184)	Prec@5 6.250 (22.826)
Test on T test set - [3][170/1731]	Time 0.180 (0.220)	Loss 4.7672 (4.2557)	Prec@1 0.000 (1.115)	Prec@5 3.125 (21.784)
Test on T test set - [3][180/1731]	Time 0.164 (0.217)	Loss 4.6260 (4.2707)	Prec@1 0.000 (1.053)	Prec@5 3.125 (20.770)
Test on T test set - [3][190/1731]	Time 0.180 (0.214)	Loss 4.6322 (4.2835)	Prec@1 0.000 (0.998)	Prec@5 0.000 (19.846)
Test on T test set - [3][200/1731]	Time 0.165 (0.212)	Loss 4.5401 (4.2935)	Prec@1 0.000 (0.948)	Prec@5 0.000 (18.983)
Test on T test set - [3][210/1731]	Time 0.171 (0.210)	Loss 4.6004 (4.3047)	Prec@1 0.000 (0.903)	Prec@5 6.250 (18.276)
Test on T test set - [3][220/1731]	Time 0.182 (0.209)	Loss 4.3489 (4.3131)	Prec@1 0.000 (0.863)	Prec@5 3.125 (17.704)
Test on T test set - [3][230/1731]	Time 0.166 (0.207)	Loss 3.3046 (4.2737)	Prec@1 3.125 (1.109)	Prec@5 100.000 (20.468)
Test on T test set - [3][240/1731]	Time 0.235 (0.209)	Loss 3.3285 (4.2239)	Prec@1 6.250 (1.465)	Prec@5 93.750 (23.509)
Test on T test set - [3][250/1731]	Time 0.217 (0.210)	Loss 3.1973 (4.1785)	Prec@1 3.125 (1.805)	Prec@5 96.875 (26.357)
Test on T test set - [3][260/1731]	Time 0.228 (0.210)	Loss 2.9697 (4.1370)	Prec@1 9.375 (2.035)	Prec@5 93.750 (28.999)
Test on T test set - [3][270/1731]	Time 0.243 (0.211)	Loss 2.7413 (4.0937)	Prec@1 9.375 (2.341)	Prec@5 96.875 (31.400)
Test on T test set - [3][280/1731]	Time 0.226 (0.214)	Loss 3.0906 (4.0547)	Prec@1 9.375 (2.547)	Prec@5 93.750 (33.641)
Test on T test set - [3][290/1731]	Time 0.239 (0.214)	Loss 3.3647 (4.0216)	Prec@1 0.000 (2.738)	Prec@5 96.875 (35.771)
Test on T test set - [3][300/1731]	Time 0.213 (0.215)	Loss 3.4664 (3.9905)	Prec@1 6.250 (2.917)	Prec@5 90.625 (37.708)
Test on T test set - [3][310/1731]	Time 0.240 (0.215)	Loss 2.8344 (3.9597)	Prec@1 15.625 (3.236)	Prec@5 100.000 (39.459)
Test on T test set - [3][320/1731]	Time 0.203 (0.215)	Loss 3.3783 (3.9358)	Prec@1 3.125 (3.368)	Prec@5 93.750 (41.219)
Test on T test set - [3][330/1731]	Time 0.193 (0.215)	Loss 2.8370 (3.9055)	Prec@1 18.750 (3.606)	Prec@5 93.750 (42.863)
Test on T test set - [3][340/1731]	Time 0.190 (0.214)	Loss 2.7551 (3.8781)	Prec@1 6.250 (3.730)	Prec@5 93.750 (44.410)
Test on T test set - [3][350/1731]	Time 0.224 (0.213)	Loss 3.2298 (3.8512)	Prec@1 9.375 (4.006)	Prec@5 96.875 (45.878)
Test on T test set - [3][360/1731]	Time 0.239 (0.214)	Loss 2.8581 (3.8268)	Prec@1 15.625 (4.233)	Prec@5 100.000 (47.282)
Test on T test set - [3][370/1731]	Time 0.175 (0.214)	Loss 4.2150 (3.8072)	Prec@1 3.125 (4.363)	Prec@5 56.250 (48.332)
Test on T test set - [3][380/1731]	Time 0.181 (0.217)	Loss 4.2576 (3.8144)	Prec@1 3.125 (4.323)	Prec@5 65.625 (48.499)
Test on T test set - [3][390/1731]	Time 0.171 (0.216)	Loss 4.1916 (3.8203)	Prec@1 3.125 (4.244)	Prec@5 40.625 (48.801)
Test on T test set - [3][400/1731]	Time 0.171 (0.215)	Loss 4.0834 (3.8254)	Prec@1 0.000 (4.224)	Prec@5 53.125 (49.034)
Test on T test set - [3][410/1731]	Time 0.177 (0.214)	Loss 4.1177 (3.8299)	Prec@1 6.250 (4.174)	Prec@5 56.250 (49.262)
Test on T test set - [3][420/1731]	Time 0.161 (0.213)	Loss 3.8059 (3.8331)	Prec@1 9.375 (4.149)	Prec@5 59.375 (49.518)
Test on T test set - [3][430/1731]	Time 0.159 (0.212)	Loss 4.2466 (3.8353)	Prec@1 0.000 (4.147)	Prec@5 62.500 (49.811)
Test on T test set - [3][440/1731]	Time 0.167 (0.210)	Loss 4.2074 (3.8411)	Prec@1 0.000 (4.082)	Prec@5 62.500 (50.099)
Test on T test set - [3][450/1731]	Time 0.168 (0.210)	Loss 4.0620 (3.8428)	Prec@1 3.125 (4.060)	Prec@5 46.875 (50.305)
Test on T test set - [3][460/1731]	Time 0.163 (0.209)	Loss 3.9634 (3.8462)	Prec@1 3.125 (4.027)	Prec@5 56.250 (50.603)
Test on T test set - [3][470/1731]	Time 0.149 (0.208)	Loss 3.9942 (3.8507)	Prec@1 0.000 (3.968)	Prec@5 65.625 (50.876)
Test on T test set - [3][480/1731]	Time 0.155 (0.213)	Loss 3.9772 (3.8539)	Prec@1 0.000 (3.931)	Prec@5 68.750 (51.098)
Test on T test set - [3][490/1731]	Time 0.161 (0.212)	Loss 4.1256 (3.8583)	Prec@1 3.125 (3.895)	Prec@5 65.625 (51.267)
Test on T test set - [3][500/1731]	Time 0.164 (0.211)	Loss 4.3466 (3.8637)	Prec@1 0.000 (3.842)	Prec@5 56.250 (51.441)
Test on T test set - [3][510/1731]	Time 0.173 (0.210)	Loss 4.0177 (3.8669)	Prec@1 3.125 (3.816)	Prec@5 46.875 (51.559)
Test on T test set - [3][520/1731]	Time 0.159 (0.209)	Loss 3.7800 (3.8692)	Prec@1 9.375 (3.809)	Prec@5 62.500 (51.745)
Test on T test set - [3][530/1731]	Time 0.172 (0.208)	Loss 4.1457 (3.8726)	Prec@1 3.125 (3.802)	Prec@5 56.250 (51.848)
Test on T test set - [3][540/1731]	Time 0.157 (0.207)	Loss 3.9350 (3.8765)	Prec@1 3.125 (3.795)	Prec@5 65.625 (51.895)
Test on T test set - [3][550/1731]	Time 0.153 (0.207)	Loss 4.2617 (3.8817)	Prec@1 0.000 (3.749)	Prec@5 56.250 (51.940)
Test on T test set - [3][560/1731]	Time 0.170 (0.206)	Loss 4.2539 (3.8854)	Prec@1 0.000 (3.727)	Prec@5 37.500 (52.072)
Test on T test set - [3][570/1731]	Time 0.187 (0.205)	Loss 4.1849 (3.8899)	Prec@1 3.125 (3.705)	Prec@5 50.000 (52.145)
Test on T test set - [3][580/1731]	Time 0.165 (0.205)	Loss 3.8652 (3.8921)	Prec@1 6.250 (3.684)	Prec@5 62.500 (52.281)
Test on T test set - [3][590/1731]	Time 0.190 (0.206)	Loss 4.1839 (3.8943)	Prec@1 3.125 (3.675)	Prec@5 59.375 (52.395)
Test on T test set - [3][600/1731]	Time 0.169 (0.206)	Loss 3.9832 (3.8959)	Prec@1 0.000 (3.676)	Prec@5 59.375 (52.522)
Test on T test set - [3][610/1731]	Time 0.176 (0.205)	Loss 3.9835 (3.8976)	Prec@1 3.125 (3.647)	Prec@5 65.625 (52.675)
Test on T test set - [3][620/1731]	Time 0.181 (0.205)	Loss 4.0131 (3.8999)	Prec@1 3.125 (3.608)	Prec@5 59.375 (52.823)
Test on T test set - [3][630/1731]	Time 0.165 (0.204)	Loss 4.3748 (3.9018)	Prec@1 0.000 (3.615)	Prec@5 50.000 (52.967)
Test on T test set - [3][640/1731]	Time 0.165 (0.204)	Loss 4.0635 (3.9043)	Prec@1 3.125 (3.613)	Prec@5 53.125 (53.008)
Test on T test set - [3][650/1731]	Time 0.152 (0.203)	Loss 4.2359 (3.9051)	Prec@1 0.000 (3.610)	Prec@5 53.125 (53.135)
Test on T test set - [3][660/1731]	Time 0.170 (0.203)	Loss 4.2609 (3.9085)	Prec@1 3.125 (3.593)	Prec@5 50.000 (53.182)
Test on T test set - [3][670/1731]	Time 0.171 (0.202)	Loss 3.8230 (3.9106)	Prec@1 3.125 (3.567)	Prec@5 59.375 (53.255)
Test on T test set - [3][680/1731]	Time 0.156 (0.201)	Loss 3.9328 (3.9127)	Prec@1 0.000 (3.566)	Prec@5 62.500 (53.313)
Test on T test set - [3][690/1731]	Time 0.216 (0.201)	Loss 4.1720 (3.9149)	Prec@1 3.125 (3.550)	Prec@5 53.125 (53.365)
Test on T test set - [3][700/1731]	Time 0.163 (0.201)	Loss 4.5972 (3.9212)	Prec@1 0.000 (3.513)	Prec@5 12.500 (52.978)
Test on T test set - [3][710/1731]	Time 0.191 (0.203)	Loss 4.4593 (3.9283)	Prec@1 0.000 (3.468)	Prec@5 12.500 (52.461)
Test on T test set - [3][720/1731]	Time 0.167 (0.202)	Loss 4.2690 (3.9347)	Prec@1 0.000 (3.433)	Prec@5 25.000 (51.963)
Test on T test set - [3][730/1731]	Time 0.225 (0.202)	Loss 4.4306 (3.9412)	Prec@1 0.000 (3.399)	Prec@5 21.875 (51.513)
Test on T test set - [3][740/1731]	Time 0.223 (0.202)	Loss 4.4087 (3.9480)	Prec@1 0.000 (3.361)	Prec@5 15.625 (51.033)
Test on T test set - [3][750/1731]	Time 0.191 (0.203)	Loss 4.5472 (3.9547)	Prec@1 3.125 (3.329)	Prec@5 25.000 (50.578)
Test on T test set - [3][760/1731]	Time 0.233 (0.203)	Loss 4.4007 (3.9614)	Prec@1 0.000 (3.293)	Prec@5 18.750 (50.107)
Test on T test set - [3][770/1731]	Time 0.205 (0.203)	Loss 4.2375 (3.9655)	Prec@1 0.000 (3.259)	Prec@5 21.875 (49.749)
Test on T test set - [3][780/1731]	Time 0.229 (0.203)	Loss 4.3144 (3.9705)	Prec@1 3.125 (3.225)	Prec@5 15.625 (49.340)
Test on T test set - [3][790/1731]	Time 0.219 (0.203)	Loss 4.1668 (3.9759)	Prec@1 0.000 (3.192)	Prec@5 21.875 (48.977)
Test on T test set - [3][800/1731]	Time 0.205 (0.205)	Loss 4.1528 (3.9813)	Prec@1 3.125 (3.164)	Prec@5 21.875 (48.607)
Test on T test set - [3][810/1731]	Time 0.193 (0.205)	Loss 4.4120 (3.9871)	Prec@1 3.125 (3.140)	Prec@5 15.625 (48.185)
Test on T test set - [3][820/1731]	Time 0.224 (0.205)	Loss 4.5709 (3.9925)	Prec@1 0.000 (3.102)	Prec@5 9.375 (47.804)
Test on T test set - [3][830/1731]	Time 0.198 (0.205)	Loss 4.1769 (3.9973)	Prec@1 0.000 (3.069)	Prec@5 31.250 (47.458)
Test on T test set - [3][840/1731]	Time 0.184 (0.205)	Loss 3.5511 (4.0011)	Prec@1 12.500 (3.054)	Prec@5 40.625 (47.124)
Test on T test set - [3][850/1731]	Time 0.156 (0.204)	Loss 2.0331 (3.9763)	Prec@1 25.000 (3.283)	Prec@5 100.000 (47.745)
Test on T test set - [3][860/1731]	Time 0.171 (0.204)	Loss 1.9235 (3.9515)	Prec@1 15.625 (3.532)	Prec@5 100.000 (48.352)
Test on T test set - [3][870/1731]	Time 0.162 (0.203)	Loss 1.9378 (3.9286)	Prec@1 18.750 (3.717)	Prec@5 100.000 (48.945)
Test on T test set - [3][880/1731]	Time 0.162 (0.203)	Loss 1.8739 (3.9054)	Prec@1 18.750 (3.941)	Prec@5 100.000 (49.525)
Test on T test set - [3][890/1731]	Time 0.165 (0.203)	Loss 1.7364 (3.8828)	Prec@1 28.125 (4.114)	Prec@5 100.000 (50.088)
Test on T test set - [3][900/1731]	Time 0.168 (0.202)	Loss 2.1874 (3.8630)	Prec@1 12.500 (4.228)	Prec@5 100.000 (50.642)
Test on T test set - [3][910/1731]	Time 0.166 (0.204)	Loss 4.5764 (3.8578)	Prec@1 0.000 (4.278)	Prec@5 6.250 (50.600)
Test on T test set - [3][920/1731]	Time 0.161 (0.204)	Loss 4.7369 (3.8667)	Prec@1 0.000 (4.231)	Prec@5 0.000 (50.051)
Test on T test set - [3][930/1731]	Time 0.247 (0.204)	Loss 4.5583 (3.8737)	Prec@1 0.000 (4.189)	Prec@5 6.250 (49.564)
Test on T test set - [3][940/1731]	Time 0.254 (0.204)	Loss 4.5588 (3.8803)	Prec@1 0.000 (4.145)	Prec@5 3.125 (49.087)
Test on T test set - [3][950/1731]	Time 0.241 (0.204)	Loss 4.4335 (3.8869)	Prec@1 0.000 (4.101)	Prec@5 6.250 (48.630)
Test on T test set - [3][960/1731]	Time 0.221 (0.205)	Loss 4.5278 (3.8936)	Prec@1 0.000 (4.062)	Prec@5 12.500 (48.176)
Test on T test set - [3][970/1731]	Time 0.232 (0.205)	Loss 4.6122 (3.9002)	Prec@1 0.000 (4.020)	Prec@5 3.125 (47.728)
Test on T test set - [3][980/1731]	Time 0.207 (0.205)	Loss 4.3801 (3.9062)	Prec@1 0.000 (3.979)	Prec@5 3.125 (47.276)
Test on T test set - [3][990/1731]	Time 0.218 (0.207)	Loss 4.6704 (3.9131)	Prec@1 0.000 (3.939)	Prec@5 0.000 (46.809)
Test on T test set - [3][1000/1731]	Time 0.227 (0.207)	Loss 4.4924 (3.9195)	Prec@1 0.000 (3.902)	Prec@5 0.000 (46.375)
Test on T test set - [3][1010/1731]	Time 0.197 (0.207)	Loss 4.5789 (3.9256)	Prec@1 0.000 (3.867)	Prec@5 3.125 (45.948)
Test on T test set - [3][1020/1731]	Time 0.211 (0.207)	Loss 4.5406 (3.9321)	Prec@1 0.000 (3.829)	Prec@5 6.250 (45.547)
Test on T test set - [3][1030/1731]	Time 0.172 (0.207)	Loss 4.5332 (3.9386)	Prec@1 0.000 (3.795)	Prec@5 3.125 (45.132)
Test on T test set - [3][1040/1731]	Time 0.168 (0.207)	Loss 4.8160 (3.9453)	Prec@1 0.000 (3.761)	Prec@5 0.000 (44.723)
Test on T test set - [3][1050/1731]	Time 0.166 (0.207)	Loss 4.4785 (3.9516)	Prec@1 0.000 (3.732)	Prec@5 3.125 (44.309)
Test on T test set - [3][1060/1731]	Time 0.165 (0.206)	Loss 4.6619 (3.9584)	Prec@1 0.000 (3.696)	Prec@5 3.125 (43.897)
Test on T test set - [3][1070/1731]	Time 0.202 (0.206)	Loss 4.6494 (3.9649)	Prec@1 0.000 (3.662)	Prec@5 0.000 (43.496)
Test on T test set - [3][1080/1731]	Time 0.161 (0.206)	Loss 4.6390 (3.9708)	Prec@1 0.000 (3.631)	Prec@5 0.000 (43.108)
Test on T test set - [3][1090/1731]	Time 0.183 (0.206)	Loss 3.5319 (3.9738)	Prec@1 18.750 (3.643)	Prec@5 31.250 (42.831)
Test on T test set - [3][1100/1731]	Time 0.200 (0.207)	Loss 3.8689 (3.9729)	Prec@1 15.625 (3.747)	Prec@5 28.125 (42.649)
Test on T test set - [3][1110/1731]	Time 0.205 (0.207)	Loss 3.4539 (3.9712)	Prec@1 21.875 (3.854)	Prec@5 28.125 (42.484)
Test on T test set - [3][1120/1731]	Time 0.189 (0.207)	Loss 3.3241 (3.9706)	Prec@1 25.000 (3.922)	Prec@5 37.500 (42.303)
Test on T test set - [3][1130/1731]	Time 0.183 (0.206)	Loss 3.6156 (3.9699)	Prec@1 21.875 (3.995)	Prec@5 31.250 (42.139)
Test on T test set - [3][1140/1731]	Time 0.194 (0.206)	Loss 3.6207 (3.9685)	Prec@1 15.625 (4.086)	Prec@5 34.375 (41.992)
Test on T test set - [3][1150/1731]	Time 0.174 (0.206)	Loss 3.9567 (3.9664)	Prec@1 9.375 (4.200)	Prec@5 21.875 (41.860)
Test on T test set - [3][1160/1731]	Time 0.177 (0.206)	Loss 3.9312 (3.9652)	Prec@1 12.500 (4.285)	Prec@5 21.875 (41.688)
Test on T test set - [3][1170/1731]	Time 0.178 (0.206)	Loss 3.7284 (3.9630)	Prec@1 18.750 (4.401)	Prec@5 21.875 (41.556)
Test on T test set - [3][1180/1731]	Time 0.184 (0.206)	Loss 3.7597 (3.9619)	Prec@1 18.750 (4.477)	Prec@5 25.000 (41.400)
Test on T test set - [3][1190/1731]	Time 0.186 (0.205)	Loss 3.5434 (3.9603)	Prec@1 18.750 (4.565)	Prec@5 40.625 (41.286)
Test on T test set - [3][1200/1731]	Time 3.107 (0.208)	Loss 3.8673 (3.9588)	Prec@1 12.500 (4.658)	Prec@5 25.000 (41.148)
Test on T test set - [3][1210/1731]	Time 0.190 (0.208)	Loss 3.7248 (3.9563)	Prec@1 12.500 (4.766)	Prec@5 28.125 (41.035)
Test on T test set - [3][1220/1731]	Time 0.167 (0.207)	Loss 4.4672 (3.9596)	Prec@1 0.000 (4.748)	Prec@5 12.500 (40.789)
Test on T test set - [3][1230/1731]	Time 0.162 (0.207)	Loss 4.3990 (3.9638)	Prec@1 0.000 (4.712)	Prec@5 9.375 (40.521)
Test on T test set - [3][1240/1731]	Time 0.180 (0.207)	Loss 4.4174 (3.9679)	Prec@1 0.000 (4.676)	Prec@5 21.875 (40.283)
Test on T test set - [3][1250/1731]	Time 0.173 (0.206)	Loss 4.6118 (3.9715)	Prec@1 0.000 (4.646)	Prec@5 15.625 (40.043)
Test on T test set - [3][1260/1731]	Time 0.195 (0.206)	Loss 4.3084 (3.9754)	Prec@1 3.125 (4.614)	Prec@5 6.250 (39.815)
Test on T test set - [3][1270/1731]	Time 0.180 (0.206)	Loss 4.5184 (3.9786)	Prec@1 0.000 (4.588)	Prec@5 0.000 (39.573)
Test on T test set - [3][1280/1731]	Time 0.193 (0.206)	Loss 4.6430 (3.9823)	Prec@1 0.000 (4.559)	Prec@5 6.250 (39.310)
Test on T test set - [3][1290/1731]	Time 0.165 (0.206)	Loss 4.4206 (3.9858)	Prec@1 0.000 (4.529)	Prec@5 21.875 (39.090)
Test on T test set - [3][1300/1731]	Time 0.175 (0.205)	Loss 4.5331 (3.9889)	Prec@1 0.000 (4.497)	Prec@5 21.875 (38.884)
Test on T test set - [3][1310/1731]	Time 0.190 (0.206)	Loss 4.4509 (3.9921)	Prec@1 0.000 (4.467)	Prec@5 3.125 (38.654)
Test on T test set - [3][1320/1731]	Time 0.190 (0.206)	Loss 4.4774 (3.9956)	Prec@1 0.000 (4.436)	Prec@5 3.125 (38.437)
Test on T test set - [3][1330/1731]	Time 0.162 (0.206)	Loss 4.5123 (3.9990)	Prec@1 0.000 (4.405)	Prec@5 18.750 (38.216)
Test on T test set - [3][1340/1731]	Time 0.152 (0.206)	Loss 4.5242 (4.0023)	Prec@1 0.000 (4.376)	Prec@5 9.375 (38.008)
Test on T test set - [3][1350/1731]	Time 0.178 (0.205)	Loss 4.3848 (4.0051)	Prec@1 0.000 (4.346)	Prec@5 9.375 (37.810)
Test on T test set - [3][1360/1731]	Time 0.159 (0.205)	Loss 3.0463 (4.0015)	Prec@1 21.875 (4.413)	Prec@5 84.375 (38.012)
Test on T test set - [3][1370/1731]	Time 0.152 (0.205)	Loss 2.7588 (3.9935)	Prec@1 25.000 (4.550)	Prec@5 87.500 (38.375)
Test on T test set - [3][1380/1731]	Time 0.168 (0.205)	Loss 2.6493 (3.9854)	Prec@1 18.750 (4.659)	Prec@5 93.750 (38.740)
Test on T test set - [3][1390/1731]	Time 0.160 (0.204)	Loss 3.0367 (3.9792)	Prec@1 18.750 (4.745)	Prec@5 84.375 (39.095)
Test on T test set - [3][1400/1731]	Time 0.167 (0.204)	Loss 2.7448 (3.9725)	Prec@1 28.125 (4.843)	Prec@5 96.875 (39.434)
Test on T test set - [3][1410/1731]	Time 0.166 (0.204)	Loss 3.2750 (3.9659)	Prec@1 9.375 (4.928)	Prec@5 84.375 (39.788)
Test on T test set - [3][1420/1731]	Time 0.174 (0.203)	Loss 3.2675 (3.9592)	Prec@1 18.750 (5.021)	Prec@5 84.375 (40.132)
Test on T test set - [3][1430/1731]	Time 0.202 (0.205)	Loss 1.6157 (3.9463)	Prec@1 43.750 (5.211)	Prec@5 100.000 (40.503)
Test on T test set - [3][1440/1731]	Time 0.248 (0.205)	Loss 1.1125 (3.9284)	Prec@1 56.250 (5.524)	Prec@5 100.000 (40.916)
Test on T test set - [3][1450/1731]	Time 0.230 (0.205)	Loss 1.3232 (3.9107)	Prec@1 50.000 (5.800)	Prec@5 100.000 (41.323)
Test on T test set - [3][1460/1731]	Time 0.227 (0.206)	Loss 1.1357 (3.8937)	Prec@1 59.375 (6.077)	Prec@5 100.000 (41.724)
Test on T test set - [3][1470/1731]	Time 0.246 (0.206)	Loss 1.3920 (3.8771)	Prec@1 53.125 (6.320)	Prec@5 100.000 (42.121)
Test on T test set - [3][1480/1731]	Time 0.242 (0.206)	Loss 1.5505 (3.8605)	Prec@1 37.500 (6.573)	Prec@5 100.000 (42.511)
Test on T test set - [3][1490/1731]	Time 0.236 (0.206)	Loss 1.2412 (3.8436)	Prec@1 50.000 (6.833)	Prec@5 100.000 (42.897)
Test on T test set - [3][1500/1731]	Time 0.244 (0.206)	Loss 1.0322 (3.8269)	Prec@1 59.375 (7.124)	Prec@5 100.000 (43.277)
Test on T test set - [3][1510/1731]	Time 0.225 (0.207)	Loss 1.4560 (3.8103)	Prec@1 43.750 (7.421)	Prec@5 100.000 (43.653)
Test on T test set - [3][1520/1731]	Time 0.229 (0.207)	Loss 1.2813 (3.7941)	Prec@1 46.875 (7.688)	Prec@5 100.000 (44.023)
Test on T test set - [3][1530/1731]	Time 0.217 (0.208)	Loss 1.3229 (3.7780)	Prec@1 59.375 (7.967)	Prec@5 100.000 (44.389)
Test on T test set - [3][1540/1731]	Time 0.189 (0.208)	Loss 1.3727 (3.7628)	Prec@1 50.000 (8.201)	Prec@5 100.000 (44.750)
Test on T test set - [3][1550/1731]	Time 0.244 (0.208)	Loss 1.3665 (3.7477)	Prec@1 53.125 (8.442)	Prec@5 100.000 (45.106)
Test on T test set - [3][1560/1731]	Time 0.191 (0.208)	Loss 4.7214 (3.7400)	Prec@1 0.000 (8.578)	Prec@5 9.375 (45.253)
Test on T test set - [3][1570/1731]	Time 0.188 (0.208)	Loss 4.4658 (3.7458)	Prec@1 0.000 (8.524)	Prec@5 12.500 (45.043)
Test on T test set - [3][1580/1731]	Time 0.162 (0.207)	Loss 4.6408 (3.7507)	Prec@1 0.000 (8.470)	Prec@5 12.500 (44.839)
Test on T test set - [3][1590/1731]	Time 0.163 (0.207)	Loss 4.7281 (3.7561)	Prec@1 0.000 (8.416)	Prec@5 12.500 (44.616)
Test on T test set - [3][1600/1731]	Time 0.180 (0.207)	Loss 4.5221 (3.7615)	Prec@1 0.000 (8.364)	Prec@5 9.375 (44.410)
Test on T test set - [3][1610/1731]	Time 0.172 (0.208)	Loss 4.5043 (3.7664)	Prec@1 0.000 (8.312)	Prec@5 15.625 (44.192)
Test on T test set - [3][1620/1731]	Time 0.191 (0.208)	Loss 4.6711 (3.7715)	Prec@1 0.000 (8.261)	Prec@5 15.625 (43.976)
Test on T test set - [3][1630/1731]	Time 0.175 (0.208)	Loss 4.5061 (3.7762)	Prec@1 0.000 (8.210)	Prec@5 6.250 (43.773)
Test on T test set - [3][1640/1731]	Time 0.216 (0.208)	Loss 4.6200 (3.7811)	Prec@1 0.000 (8.160)	Prec@5 6.250 (43.575)
Test on T test set - [3][1650/1731]	Time 0.223 (0.208)	Loss 4.6163 (3.7860)	Prec@1 0.000 (8.111)	Prec@5 6.250 (43.390)
Test on T test set - [3][1660/1731]	Time 0.215 (0.208)	Loss 4.5684 (3.7907)	Prec@1 0.000 (8.062)	Prec@5 9.375 (43.219)
Test on T test set - [3][1670/1731]	Time 0.216 (0.208)	Loss 4.7738 (3.7958)	Prec@1 0.000 (8.014)	Prec@5 12.500 (43.039)
Test on T test set - [3][1680/1731]	Time 0.200 (0.208)	Loss 4.6565 (3.8004)	Prec@1 0.000 (7.966)	Prec@5 21.875 (42.861)
Test on T test set - [3][1690/1731]	Time 0.226 (0.208)	Loss 4.5919 (3.8051)	Prec@1 0.000 (7.919)	Prec@5 6.250 (42.684)
Test on T test set - [3][1700/1731]	Time 0.210 (0.208)	Loss 4.4151 (3.8094)	Prec@1 0.000 (7.872)	Prec@5 9.375 (42.506)
Test on T test set - [3][1710/1731]	Time 0.230 (0.209)	Loss 4.5889 (3.8138)	Prec@1 0.000 (7.828)	Prec@5 15.625 (42.324)
Test on T test set - [3][1720/1731]	Time 0.189 (0.209)	Loss 4.5968 (3.8185)	Prec@1 0.000 (7.783)	Prec@5 6.250 (42.156)
Test on T test set - [3][1730/1731]	Time 0.167 (0.209)	Loss 4.5509 (3.8228)	Prec@1 0.000 (7.738)	Prec@5 7.143 (41.996)
 * Test on T test set - Prec@1 7.738, Prec@5 41.996
Epoch 3 - Kernel K-means clustering 0: Clustering time 46.734, Prec@1 6.805
Epoch 3 - Kernel K-means clustering 1: Clustering time 45.446, Prec@1 6.944
Epoch 3 - Kernel K-means clustering 2: Clustering time 45.979, Prec@1 7.155
Epoch 3 - Kernel K-means clustering 3: Clustering time 46.378, Prec@1 7.352
Epoch 3 - Kernel K-means clustering 4: Clustering time 46.361, Prec@1 7.440
Epoch 3 - Kernel K-means clustering 5: Clustering time 46.851, Prec@1 7.540
Epoch 3 - Kernel K-means clustering 6: Clustering time 46.824, Prec@1 7.716
Epoch 3 - Kernel K-means clustering 7: Clustering time 46.964, Prec@1 7.825
Epoch 3 - Kernel K-means clustering 8: Clustering time 47.091, Prec@1 7.899
Epoch 3 - Kernel K-means clustering 9: Clustering time 47.835, Prec@1 7.917
Epoch 3 - Kernel K-means clustering 10: Clustering time 46.665, Prec@1 7.939
Epoch 3 - Kernel K-means clustering 11: Clustering time 46.771, Prec@1 7.958
Epoch 3 - Kernel K-means clustering 12: Clustering time 46.728, Prec@1 7.976
Epoch 3 - Kernel K-means clustering 13: Clustering time 47.124, Prec@1 7.984
Epoch 3 - Kernel K-means clustering 14: Clustering time 46.938, Prec@1 8.018
Epoch 3 - Kernel K-means clustering 15: Clustering time 46.863, Prec@1 8.016
Epoch 3 - Kernel K-means clustering 16: Clustering time 46.908, Prec@1 8.027
Epoch 3 - Kernel K-means clustering 17: Clustering time 46.597, Prec@1 8.025
Epoch 3 - Kernel K-means clustering 18: Clustering time 45.955, Prec@1 8.029
Epoch 3 - Kernel K-means clustering 19: Clustering time 46.106, Prec@1 8.022
Epoch 3 - Kernel K-means clustering 20: Clustering time 46.057, Prec@1 8.031
Epoch 3 - Kernel K-means clustering 21: Clustering time 46.422, Prec@1 8.034
Epoch 3 - Kernel K-means clustering 22: Clustering time 46.839, Prec@1 8.025
Epoch 3 - Kernel K-means clustering 23: Clustering time 46.548, Prec@1 8.029
Epoch 3 - Kernel K-means clustering 24: Clustering time 46.495, Prec@1 8.025
Epoch 3 - Kernel K-means clustering 25: Clustering time 46.310, Prec@1 8.022
Epoch 3 - Kernel K-means clustering 26: Clustering time 46.711, Prec@1 8.014
Epoch 3 - Kernel K-means clustering 27: Clustering time 46.359, Prec@1 8.018
Epoch 3 - Kernel K-means clustering 28: Clustering time 46.423, Prec@1 8.013
Epoch 3 - Kernel K-means clustering 29: Clustering time 46.282, Prec@1 8.011
Epoch 3 - Kernel K-means clustering 30: Clustering time 46.612, Prec@1 8.005
Epoch 3 - Kernel K-means clustering 31: Clustering time 46.476, Prec@1 8.002
Epoch 3 - Kernel K-means clustering 32: Clustering time 46.021, Prec@1 8.002
Epoch 3 - Kernel K-means clustering 33: Clustering time 46.479, Prec@1 8.004
Epoch 3 - Kernel K-means clustering 34: Clustering time 46.931, Prec@1 8.005
Epoch 3 - Kernel K-means clustering 35: Clustering time 46.285, Prec@1 8.005
Epoch 3 - Kernel K-means clustering 36: Clustering time 46.352, Prec@1 8.005
Epoch 3 - Kernel K-means clustering 37: Clustering time 46.445, Prec@1 8.013
Epoch 3 - Kernel K-means clustering 38: Clustering time 46.606, Prec@1 8.009
Epoch 3 - Kernel K-means clustering 39: Clustering time 46.828, Prec@1 8.011
Epoch 3 - Kernel K-means clustering 40: Clustering time 47.170, Prec@1 8.009
Epoch 3 - Kernel K-means clustering 41: Clustering time 46.957, Prec@1 8.009
Converged at iteration 42
Epoch 3 - Kernel K-means clustering 0: Clustering time 47.477, Prec@1 6.974
Epoch 3 - Kernel K-means clustering 1: Clustering time 46.468, Prec@1 7.056
Epoch 3 - Kernel K-means clustering 2: Clustering time 46.685, Prec@1 7.184
Epoch 3 - Kernel K-means clustering 3: Clustering time 46.692, Prec@1 7.303
Epoch 3 - Kernel K-means clustering 4: Clustering time 46.775, Prec@1 7.588
Epoch 3 - Kernel K-means clustering 5: Clustering time 46.475, Prec@1 7.778
Epoch 3 - Kernel K-means clustering 6: Clustering time 45.928, Prec@1 7.872
Epoch 3 - Kernel K-means clustering 7: Clustering time 45.956, Prec@1 7.881
Epoch 3 - Kernel K-means clustering 8: Clustering time 46.320, Prec@1 7.884
Epoch 3 - Kernel K-means clustering 9: Clustering time 46.679, Prec@1 7.901
Epoch 3 - Kernel K-means clustering 10: Clustering time 46.732, Prec@1 7.899
Epoch 3 - Kernel K-means clustering 11: Clustering time 47.105, Prec@1 7.893
Epoch 3 - Kernel K-means clustering 12: Clustering time 47.467, Prec@1 7.895
Epoch 3 - Kernel K-means clustering 13: Clustering time 47.895, Prec@1 7.897
Epoch 3 - Kernel K-means clustering 14: Clustering time 47.374, Prec@1 7.895
Epoch 3 - Kernel K-means clustering 15: Clustering time 48.499, Prec@1 7.893
Epoch 3 - Kernel K-means clustering 16: Clustering time 47.028, Prec@1 7.892
Epoch 3 - Kernel K-means clustering 17: Clustering time 46.911, Prec@1 7.892
Epoch 3 - Kernel K-means clustering 18: Clustering time 50.108, Prec@1 7.893
Epoch 3 - Kernel K-means clustering 19: Clustering time 46.968, Prec@1 7.893
Converged at iteration 20
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5566 (2.5566)
Train - epoch [4/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5292 (2.5292)
Train - epoch [4/200]	BT 1.294 (1.294)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.6309 (2.6309)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 2.7125 (2.7125)
Train - epoch [4/200]	BT 4.278 (4.278)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4308 (2.4308)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5344 (2.5344)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5704 (2.5704)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.5241 (2.5241)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.5225 (2.5225)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5278 (2.5278)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4937 (2.4937)
Train - epoch [4/200]	BT 3.808 (3.808)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4295 (2.4295)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4044 (2.4044)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4974 (2.4974)
Train - epoch [4/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3650 (2.3650)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4723 (2.4723)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4943 (2.4943)
Train - epoch [4/200]	BT 4.145 (4.145)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4521 (2.4521)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4757 (2.4757)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4342 (2.4342)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4870 (2.4870)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.7358 (2.7358)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.6133 (2.6133)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3821 (2.3821)
Train - epoch [4/200]	BT 4.159 (4.159)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4477 (2.4477)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5388 (2.5388)
Train - epoch [4/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4090 (2.4090)
Train - epoch [4/200]	BT 1.301 (1.301)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5208 (2.5208)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.5299 (2.5299)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5712 (2.5712)
Train - epoch [4/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3775 (2.3775)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4503 (2.4503)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5973 (2.5973)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3812 (2.3812)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4143 (2.4143)
Train - epoch [4/200]	BT 4.065 (4.065)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.5896 (2.5896)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.4014 (2.4014)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3961 (2.3961)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3816 (2.3816)
Train - epoch [4/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4193 (2.4193)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4276 (2.4276)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4874 (2.4874)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4662 (2.4662)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3683 (2.3683)
Train - epoch [4/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4703 (2.4703)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.6227 (2.6227)
Train - epoch [4/200]	BT 4.592 (4.592)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5347 (2.5347)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4480 (2.4480)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5599 (2.5599)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5299 (2.5299)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4141 (2.4141)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.6080 (2.6080)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.4681 (2.4681)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5382 (2.5382)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4278 (2.4278)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.5039 (2.5039)
Train - epoch [4/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.7105 (2.7105)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4221 (2.4221)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.3783 (2.3783)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4013 (2.4013)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4338 (2.4338)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9408 (2.9408)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.5810 (2.5810)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4712 (2.4712)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5171 (2.5171)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4957 (2.4957)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5502 (2.5502)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4960 (2.4960)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.6108 (2.6108)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4444 (2.4444)
Train - epoch [4/200]	BT 4.160 (4.160)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4362 (2.4362)
Train - epoch [4/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3600 (2.3600)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4869 (2.4869)
Train - epoch [4/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3824 (2.3824)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3562 (2.3562)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3517 (2.3517)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.5190 (2.5190)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4495 (2.4495)
Train - epoch [4/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5835 (2.5835)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3524 (2.3524)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.3904 (2.3904)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4621 (2.4621)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5322 (2.5322)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3987 (2.3987)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4743 (2.4743)
Train - epoch [4/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3443 (2.3443)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3903 (2.3903)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4963 (2.4963)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.5444 (2.5444)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4075 (2.4075)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.6202 (2.6202)
Train - epoch [4/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4807 (2.4807)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3686 (2.3686)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 2.5615 (2.5615)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4923 (2.4923)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5629 (2.5629)
Train - epoch [4/200]	BT 4.048 (4.048)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5798 (2.5798)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.3800 (2.3800)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4488 (2.4488)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4373 (2.4373)
Train - epoch [4/200]	BT 4.188 (4.188)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5478 (2.5478)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4353 (2.4353)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4927 (2.4927)
Train - epoch [4/200]	BT 1.302 (1.302)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5190 (2.5190)
Train - epoch [4/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4350 (2.4350)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4349 (2.4349)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3872 (2.3872)
Train - epoch [4/200]	BT 1.312 (1.312)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4496 (2.4496)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4161 (2.4161)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4071 (2.4071)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4468 (2.4468)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4744 (2.4744)
Train - epoch [4/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3866 (2.3866)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5963 (2.5963)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5246 (2.5246)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4313 (2.4313)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3906 (2.3906)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4909 (2.4909)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4839 (2.4839)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4178 (2.4178)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.6443 (2.6443)
Train - epoch [4/200]	BT 4.556 (4.556)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4020 (2.4020)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.4594 (2.4594)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5779 (2.5779)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.5102 (2.5102)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4390 (2.4390)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4789 (2.4789)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.4825 (2.4825)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.6512 (2.6512)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.5715 (2.5715)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3908 (2.3908)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4940 (2.4940)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4627 (2.4627)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.6184 (2.6184)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4646 (2.4646)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5624 (2.5624)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.3951 (2.3951)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4483 (2.4483)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4939 (2.4939)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.3589 (2.3589)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4814 (2.4814)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4376 (2.4376)
Train - epoch [4/200]	BT 4.570 (4.570)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3841 (2.3841)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4326 (2.4326)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5484 (2.5484)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4753 (2.4753)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5175 (2.5175)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4507 (2.4507)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4516 (2.4516)
Train - epoch [4/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.5793 (2.5793)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.8262 (2.8262)
Train - epoch [4/200]	BT 4.649 (4.649)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4728 (2.4728)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5220 (2.5220)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.5644 (2.5644)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.4157 (2.4157)
Train - epoch [4/200]	BT 4.397 (4.397)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.6531 (2.6531)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5518 (2.5518)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.6143 (2.6143)
Train - epoch [4/200]	BT 1.297 (1.297)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.5127 (2.5127)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3867 (2.3867)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3802 (2.3802)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.6199 (2.6199)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4362 (2.4362)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4782 (2.4782)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.3922 (2.3922)
Train - epoch [4/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4793 (2.4793)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.3938 (2.3938)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3725 (2.3725)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4840 (2.4840)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4265 (2.4265)
Train - epoch [4/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.6214 (2.6214)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.6068 (2.6068)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4084 (2.4084)
Train - epoch [4/200]	BT 4.542 (4.542)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5615 (2.5615)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.6572 (2.6572)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4710 (2.4710)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.5032 (2.5032)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4539 (2.4539)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3907 (2.3907)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4768 (2.4768)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4418 (2.4418)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5942 (2.5942)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5164 (2.5164)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3807 (2.3807)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5157 (2.5157)
Train - epoch [4/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5014 (2.5014)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4597 (2.4597)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3847 (2.3847)
Train - epoch [4/200]	BT 4.539 (4.539)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4596 (2.4596)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4610 (2.4610)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4660 (2.4660)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4521 (2.4521)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5877 (2.5877)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.6074 (2.6074)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.4635 (2.4635)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4278 (2.4278)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3828 (2.3828)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.4013 (2.4013)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.4863 (2.4863)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.4970 (2.4970)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4079 (2.4079)
Train - epoch [4/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.4789 (2.4789)
Train - epoch [4/200]	BT 4.175 (4.175)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.5321 (2.5321)
Train - epoch [4/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.5283 (2.5283)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3785 (2.3785)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3736 (2.3736)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4186 (2.4186)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4349 (2.4349)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4435 (2.4435)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.3770 (2.3770)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4080 (2.4080)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3867 (2.3867)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4005 (2.4005)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4378 (2.4378)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3791 (2.3791)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.5665 (2.5665)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4548 (2.4548)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4074 (2.4074)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4052 (2.4052)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4339 (2.4339)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3506 (2.3506)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3469 (2.3469)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4890 (2.4890)
Train - epoch [4/200]	BT 4.122 (4.122)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.6873 (2.6873)
Train - epoch [4/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5425 (2.5425)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3691 (2.3691)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4380 (2.4380)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4287 (2.4287)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5180 (2.5180)
Train - epoch [4/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3945 (2.3945)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4649 (2.4649)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.3511 (2.3511)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 2.4940 (2.4940)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4218 (2.4218)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4924 (2.4924)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.3438 (2.3438)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4300 (2.4300)
Train - epoch [4/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.5521 (2.5521)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3745 (2.3745)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.6512 (2.6512)
Train - epoch [4/200]	BT 4.022 (4.022)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.5140 (2.5140)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4642 (2.4642)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4092 (2.4092)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4075 (2.4075)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3844 (2.3844)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.5661 (2.5661)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3657 (2.3657)
Train - epoch [4/200]	BT 4.000 (4.000)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.3943 (2.3943)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4103 (2.4103)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4737 (2.4737)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.3704 (2.3704)
Train - epoch [4/200]	BT 5.089 (5.089)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5144 (2.5144)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 2.3857 (2.3857)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4324 (2.4324)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3886 (2.3886)
Train - epoch [4/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4302 (2.4302)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4646 (2.4646)
Train - epoch [4/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4037 (2.4037)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.5213 (2.5213)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.4594 (2.4594)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4636 (2.4636)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.6176 (2.6176)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4157 (2.4157)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.5357 (2.5357)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4074 (2.4074)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4188 (2.4188)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4348 (2.4348)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5141 (2.5141)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3534 (2.3534)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4268 (2.4268)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4927 (2.4927)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3997 (2.3997)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.6163 (2.6163)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4103 (2.4103)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3529 (2.3529)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4734 (2.4734)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4854 (2.4854)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5312 (2.5312)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5467 (2.5467)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4375 (2.4375)
Train - epoch [4/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.4447 (2.4447)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.5471 (2.5471)
Train - epoch [4/200]	BT 4.049 (4.049)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4207 (2.4207)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4416 (2.4416)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.5979 (2.5979)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4691 (2.4691)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3932 (2.3932)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 2.5363 (2.5363)
Train - epoch [4/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3539 (2.3539)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.4595 (2.4595)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4027 (2.4027)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.5079 (2.5079)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3542 (2.3542)
Train - epoch [4/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3468 (2.3468)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4293 (2.4293)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4407 (2.4407)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5775 (2.5775)
Train - epoch [4/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3534 (2.3534)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4782 (2.4782)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3932 (2.3932)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 2.3318 (2.3318)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.3739 (2.3739)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4502 (2.4502)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3681 (2.3681)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4412 (2.4412)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4263 (2.4263)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4406 (2.4406)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4882 (2.4882)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4016 (2.4016)
Train - epoch [4/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4394 (2.4394)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3828 (2.3828)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3684 (2.3684)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3734 (2.3734)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3850 (2.3850)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3700 (2.3700)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4075 (2.4075)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4792 (2.4792)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4428 (2.4428)
Train - epoch [4/200]	BT 4.213 (4.213)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3515 (2.3515)
Train - epoch [4/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4758 (2.4758)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.4570 (2.4570)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.3690 (2.3690)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.5795 (2.5795)
Train - epoch [4/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3760 (2.3760)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4185 (2.4185)
Train - epoch [4/200]	BT 4.119 (4.119)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4685 (2.4685)
Train - epoch [4/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4336 (2.4336)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4163 (2.4163)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4363 (2.4363)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4329 (2.4329)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.3928 (2.3928)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4177 (2.4177)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4169 (2.4169)
Train - epoch [4/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5208 (2.5208)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4211 (2.4211)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5585 (2.5585)
Train - epoch [4/200]	BT 4.215 (4.215)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.4485 (2.4485)
Train - epoch [4/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4197 (2.4197)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3814 (2.3814)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3491 (2.3491)
Train - epoch [4/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4069 (2.4069)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4518 (2.4518)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4279 (2.4279)
Train - epoch [4/200]	BT 3.636 (3.636)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 2.4104 (2.4104)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3794 (2.3794)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3593 (2.3593)
Train - epoch [4/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4556 (2.4556)
Train - epoch [4/200]	BT 1.295 (1.295)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.3928 (2.3928)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.3877 (2.3877)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3463 (2.3463)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 2.3609 (2.3609)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3837 (2.3837)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5040 (2.5040)
Train - epoch [4/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3803 (2.3803)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3720 (2.3720)
Train - epoch [4/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.4930 (2.4930)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3960 (2.3960)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4044 (2.4044)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4097 (2.4097)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5026 (2.5026)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.5190 (2.5190)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3792 (2.3792)
Train - epoch [4/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4052 (2.4052)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4819 (2.4819)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5142 (2.5142)
Train - epoch [4/200]	BT 1.304 (1.304)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.5002 (2.5002)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3575 (2.3575)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.6382 (2.6382)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4377 (2.4377)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3264 (2.3264)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4888 (2.4888)
Train - epoch [4/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.3576 (2.3576)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.3721 (2.3721)
Train - epoch [4/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4606 (2.4606)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 2.3688 (2.3688)
Train - epoch [4/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4685 (2.4685)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4699 (2.4699)
Train - epoch [4/200]	BT 3.860 (3.860)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3689 (2.3689)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4641 (2.4641)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.5031 (2.5031)
Train - epoch [4/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.6072 (2.6072)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4391 (2.4391)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.5018 (2.5018)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4645 (2.4645)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4156 (2.4156)
Train - epoch [4/200]	BT 1.291 (1.291)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4229 (2.4229)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3947 (2.3947)
Train - epoch [4/200]	BT 3.776 (3.776)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5244 (2.5244)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.4429 (2.4429)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3461 (2.3461)
Train - epoch [4/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3868 (2.3868)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4116 (2.4116)
Train - epoch [4/200]	BT 1.490 (1.490)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.5584 (2.5584)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3790 (2.3790)
Train - epoch [4/200]	BT 4.134 (4.134)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.5196 (2.5196)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.7511 (2.7511)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 2.4238 (2.4238)
Train - epoch [4/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5351 (2.5351)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3690 (2.3690)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4503 (2.4503)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.6903 (2.6903)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3562 (2.3562)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.4795 (2.4795)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5266 (2.5266)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4119 (2.4119)
Train - epoch [4/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.3895 (2.3895)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4120 (2.4120)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5525 (2.5525)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.4285 (2.4285)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.5529 (2.5529)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4216 (2.4216)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4092 (2.4092)
Train - epoch [4/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.3622 (2.3622)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4438 (2.4438)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 2.3493 (2.3493)
Train - epoch [4/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.7017 (2.7017)
Train - epoch [4/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4457 (2.4457)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4786 (2.4786)
Train - epoch [4/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4095 (2.4095)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3503 (2.3503)
Train - epoch [4/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4130 (2.4130)
Train - epoch [4/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.3554 (2.3554)
Train - epoch [4/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.3773 (2.3773)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3220 (2.3220)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.3638 (2.3638)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4540 (2.4540)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3511 (2.3511)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3839 (2.3839)
Train - epoch [4/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4856 (2.4856)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4063 (2.4063)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.3588 (2.3588)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4838 (2.4838)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4351 (2.4351)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.5082 (2.5082)
Train - epoch [4/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3465 (2.3465)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4061 (2.4061)
Train - epoch [4/200]	BT 1.285 (1.285)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4135 (2.4135)
Train - epoch [4/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4714 (2.4714)
Train - epoch [4/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.3613 (2.3613)
Train - epoch [4/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3486 (2.3486)
Train - epoch [4/200]	BT 1.289 (1.289)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4603 (2.4603)
Train - epoch [4/200]	BT 3.990 (3.990)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.3812 (2.3812)
Train - epoch [4/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4328 (2.4328)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4527 (2.4527)
Train - epoch [4/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.3815 (2.3815)
Train - epoch [4/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.6054 (2.6054)
Train - epoch [4/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.4478 (2.4478)
Train - epoch [4/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 2.3328 (2.3328)
Train - epoch [4/200]	BT 4.002 (4.002)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.4295 (2.4295)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.5615 (2.5615)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.4234 (2.4234)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.4118 (2.4118)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4029 (2.4029)
Train - epoch [4/200]	BT 1.292 (1.292)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 2.3328 (2.3328)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.4059 (2.4059)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.5014 (2.5014)
Train - epoch [4/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4608 (2.4608)
Train - epoch [4/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.4622 (2.4622)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.4545 (2.4545)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4953 (2.4953)
Train - epoch [4/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4048 (2.4048)
Train - epoch [4/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3491 (2.3491)
Train - epoch [4/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3419 (2.3419)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3392 (2.3392)
Train - epoch [4/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.3642 (2.3642)
Train - epoch [4/200]	BT 3.668 (3.668)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.5007 (2.5007)
Train - epoch [4/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.3192 (2.3192)
Train - epoch [4/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.3956 (2.3956)
Train - epoch [4/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4842 (2.4842)
Train - epoch [4/200]	BT 1.310 (1.310)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.4459 (2.4459)
Train - epoch [4/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.4094 (2.4094)
Train - epoch [4/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.3890 (2.3890)
Train - epoch [4/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.4584 (2.4584)
Train - epoch [4/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.3384 (2.3384)
Train - epoch [4/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.5360 (2.5360)
Train - epoch [4/200]	BT 1.298 (1.298)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.4998 (2.4998)
Test on T training set - [4][0/1731]	T 0.306 (0.306)	D 0.195 (0.195)	T@1 6.250 (6.250)	T@5 68.750 (68.750)	L 6.6908 (6.6908)
Test on T training set - [4][10/1731]	T 0.217 (0.206)	D 0.121 (0.105)	T@1 3.125 (2.557)	T@5 56.250 (51.420)	L 6.5554 (6.4177)
Test on T training set - [4][20/1731]	T 0.217 (0.350)	D 0.121 (0.247)	T@1 3.125 (2.679)	T@5 40.625 (52.530)	L 5.5139 (6.2225)
Test on T training set - [4][30/1731]	T 0.215 (0.307)	D 0.110 (0.205)	T@1 9.375 (3.125)	T@5 50.000 (52.520)	L 5.6610 (6.0333)
Test on T training set - [4][40/1731]	T 0.236 (0.286)	D 0.130 (0.184)	T@1 3.125 (3.049)	T@5 53.125 (52.439)	L 6.1474 (6.0533)
Test on T training set - [4][50/1731]	T 0.221 (0.273)	D 0.115 (0.171)	T@1 9.375 (3.248)	T@5 62.500 (52.819)	L 5.5916 (6.0264)
Test on T training set - [4][60/1731]	T 0.238 (0.265)	D 0.132 (0.163)	T@1 0.000 (3.176)	T@5 59.375 (52.254)	L 6.6582 (6.0283)
Test on T training set - [4][70/1731]	T 0.198 (0.257)	D 0.102 (0.155)	T@1 0.000 (3.081)	T@5 31.250 (52.245)	L 5.9062 (6.0385)
Test on T training set - [4][80/1731]	T 0.198 (0.252)	D 0.093 (0.150)	T@1 3.125 (3.164)	T@5 46.875 (52.006)	L 6.0687 (6.0298)
Test on T training set - [4][90/1731]	T 0.184 (0.247)	D 0.088 (0.145)	T@1 3.125 (3.194)	T@5 34.375 (51.717)	L 5.9522 (6.0249)
Test on T training set - [4][100/1731]	T 0.194 (0.259)	D 0.090 (0.157)	T@1 0.000 (3.125)	T@5 53.125 (51.640)	L 6.6140 (6.0418)
Test on T training set - [4][110/1731]	T 0.203 (0.253)	D 0.102 (0.151)	T@1 0.000 (3.125)	T@5 50.000 (51.830)	L 6.9210 (6.0746)
Test on T training set - [4][120/1731]	T 0.204 (0.248)	D 0.100 (0.146)	T@1 3.125 (3.022)	T@5 93.750 (54.416)	L 7.2560 (6.1482)
Test on T training set - [4][130/1731]	T 0.200 (0.244)	D 0.092 (0.142)	T@1 0.000 (3.006)	T@5 90.625 (57.323)	L 7.2739 (6.2083)
Test on T training set - [4][140/1731]	T 0.193 (0.241)	D 0.086 (0.138)	T@1 3.125 (3.081)	T@5 93.750 (59.796)	L 7.0929 (6.2664)
Test on T training set - [4][150/1731]	T 0.206 (0.237)	D 0.095 (0.135)	T@1 3.125 (3.270)	T@5 100.000 (61.962)	L 6.9914 (6.2975)
Test on T training set - [4][160/1731]	T 0.180 (0.234)	D 0.084 (0.132)	T@1 3.125 (3.261)	T@5 93.750 (63.820)	L 6.6723 (6.3366)
Test on T training set - [4][170/1731]	T 0.174 (0.231)	D 0.078 (0.129)	T@1 0.000 (3.363)	T@5 93.750 (65.625)	L 6.9887 (6.3720)
Test on T training set - [4][180/1731]	T 0.168 (0.228)	D 0.062 (0.126)	T@1 3.125 (3.349)	T@5 90.625 (67.231)	L 7.3273 (6.4116)
Test on T training set - [4][190/1731]	T 0.191 (0.225)	D 0.086 (0.123)	T@1 3.125 (3.272)	T@5 87.500 (68.668)	L 7.3800 (6.4490)
Test on T training set - [4][200/1731]	T 0.175 (0.222)	D 0.072 (0.120)	T@1 6.250 (3.265)	T@5 96.875 (69.947)	L 6.8997 (6.4813)
Test on T training set - [4][210/1731]	T 0.182 (0.233)	D 0.074 (0.131)	T@1 0.000 (3.303)	T@5 84.375 (71.046)	L 7.3960 (6.5077)
Test on T training set - [4][220/1731]	T 0.175 (0.231)	D 0.079 (0.128)	T@1 3.125 (3.394)	T@5 87.500 (71.974)	L 6.5683 (6.5250)
Test on T training set - [4][230/1731]	T 0.177 (0.229)	D 0.071 (0.126)	T@1 0.000 (3.301)	T@5 9.375 (69.697)	L 9.1243 (6.6273)
Test on T training set - [4][240/1731]	T 0.238 (0.229)	D 0.136 (0.127)	T@1 0.000 (3.164)	T@5 9.375 (67.012)	L 8.9450 (6.7408)
Test on T training set - [4][250/1731]	T 0.215 (0.229)	D 0.106 (0.127)	T@1 0.000 (3.038)	T@5 6.250 (64.430)	L 8.7762 (6.8490)
Test on T training set - [4][260/1731]	T 0.232 (0.229)	D 0.136 (0.127)	T@1 0.000 (2.921)	T@5 15.625 (62.069)	L 8.6544 (6.9540)
Test on T training set - [4][270/1731]	T 0.245 (0.229)	D 0.139 (0.127)	T@1 0.000 (2.825)	T@5 3.125 (59.929)	L 9.2974 (7.0479)
Test on T training set - [4][280/1731]	T 0.227 (0.230)	D 0.131 (0.127)	T@1 0.000 (2.725)	T@5 0.000 (57.896)	L 9.6847 (7.1422)
Test on T training set - [4][290/1731]	T 0.233 (0.241)	D 0.137 (0.139)	T@1 0.000 (2.631)	T@5 6.250 (55.971)	L 9.9287 (7.2302)
Test on T training set - [4][300/1731]	T 0.213 (0.241)	D 0.117 (0.138)	T@1 0.000 (2.544)	T@5 3.125 (54.163)	L 9.2411 (7.3115)
Test on T training set - [4][310/1731]	T 0.240 (0.240)	D 0.130 (0.138)	T@1 0.000 (2.462)	T@5 0.000 (52.522)	L 10.1717 (7.3873)
Test on T training set - [4][320/1731]	T 0.202 (0.240)	D 0.098 (0.137)	T@1 0.000 (2.385)	T@5 0.000 (50.954)	L 10.3781 (7.4606)
Test on T training set - [4][330/1731]	T 0.200 (0.239)	D 0.104 (0.136)	T@1 0.000 (2.313)	T@5 0.000 (49.547)	L 9.7359 (7.5236)
Test on T training set - [4][340/1731]	T 0.191 (0.237)	D 0.086 (0.135)	T@1 0.000 (2.245)	T@5 3.125 (48.213)	L 9.9964 (7.5870)
Test on T training set - [4][350/1731]	T 0.208 (0.236)	D 0.112 (0.134)	T@1 0.000 (2.181)	T@5 3.125 (46.964)	L 9.9747 (7.6432)
Test on T training set - [4][360/1731]	T 0.228 (0.236)	D 0.132 (0.134)	T@1 0.000 (2.121)	T@5 3.125 (45.741)	L 9.8878 (7.6963)
Test on T training set - [4][370/1731]	T 0.174 (0.241)	D 0.078 (0.139)	T@1 0.000 (2.064)	T@5 0.000 (44.567)	L 8.8496 (7.7462)
Test on T training set - [4][380/1731]	T 0.191 (0.239)	D 0.085 (0.137)	T@1 3.125 (2.018)	T@5 6.250 (43.504)	L 7.3170 (7.7558)
Test on T training set - [4][390/1731]	T 0.179 (0.238)	D 0.076 (0.135)	T@1 3.125 (1.998)	T@5 3.125 (42.519)	L 8.0191 (7.7640)
Test on T training set - [4][400/1731]	T 0.172 (0.236)	D 0.066 (0.134)	T@1 0.000 (1.964)	T@5 3.125 (41.607)	L 8.5467 (7.7723)
Test on T training set - [4][410/1731]	T 0.165 (0.234)	D 0.062 (0.132)	T@1 0.000 (1.946)	T@5 0.000 (40.731)	L 7.5296 (7.7793)
Test on T training set - [4][420/1731]	T 0.163 (0.233)	D 0.061 (0.131)	T@1 0.000 (1.930)	T@5 0.000 (39.846)	L 8.2083 (7.7897)
Test on T training set - [4][430/1731]	T 0.170 (0.231)	D 0.065 (0.129)	T@1 3.125 (1.892)	T@5 9.375 (39.023)	L 7.7399 (7.7902)
Test on T training set - [4][440/1731]	T 0.156 (0.230)	D 0.060 (0.128)	T@1 0.000 (1.871)	T@5 3.125 (38.251)	L 8.8042 (7.7966)
Test on T training set - [4][450/1731]	T 0.167 (0.229)	D 0.066 (0.126)	T@1 0.000 (1.850)	T@5 0.000 (37.493)	L 7.7027 (7.7995)
Test on T training set - [4][460/1731]	T 0.170 (0.227)	D 0.073 (0.125)	T@1 3.125 (1.830)	T@5 3.125 (36.781)	L 8.2922 (7.8070)
Test on T training set - [4][470/1731]	T 0.157 (0.226)	D 0.055 (0.124)	T@1 0.000 (1.805)	T@5 0.000 (36.093)	L 8.0402 (7.8098)
Test on T training set - [4][480/1731]	T 0.162 (0.225)	D 0.057 (0.123)	T@1 0.000 (1.767)	T@5 3.125 (35.453)	L 7.7685 (7.8139)
Test on T training set - [4][490/1731]	T 0.167 (0.227)	D 0.061 (0.125)	T@1 3.125 (1.744)	T@5 6.250 (34.833)	L 7.9084 (7.8161)
Test on T training set - [4][500/1731]	T 0.173 (0.226)	D 0.068 (0.124)	T@1 0.000 (1.709)	T@5 6.250 (34.219)	L 8.3621 (7.8158)
Test on T training set - [4][510/1731]	T 0.165 (0.225)	D 0.066 (0.123)	T@1 0.000 (1.688)	T@5 6.250 (33.629)	L 8.7660 (7.8269)
Test on T training set - [4][520/1731]	T 0.155 (0.224)	D 0.059 (0.122)	T@1 0.000 (1.661)	T@5 3.125 (33.067)	L 8.0565 (7.8338)
Test on T training set - [4][530/1731]	T 0.167 (0.223)	D 0.071 (0.121)	T@1 0.000 (1.642)	T@5 3.125 (32.527)	L 8.4926 (7.8385)
Test on T training set - [4][540/1731]	T 0.157 (0.222)	D 0.061 (0.120)	T@1 3.125 (1.635)	T@5 3.125 (32.018)	L 8.5961 (7.8461)
Test on T training set - [4][550/1731]	T 0.157 (0.221)	D 0.061 (0.119)	T@1 0.000 (1.611)	T@5 0.000 (31.488)	L 9.5489 (7.8596)
Test on T training set - [4][560/1731]	T 0.178 (0.220)	D 0.075 (0.118)	T@1 0.000 (1.593)	T@5 3.125 (30.971)	L 8.8492 (7.8737)
Test on T training set - [4][570/1731]	T 0.204 (0.219)	D 0.099 (0.117)	T@1 0.000 (1.582)	T@5 9.375 (30.517)	L 7.9812 (7.8786)
Test on T training set - [4][580/1731]	T 0.177 (0.218)	D 0.072 (0.116)	T@1 0.000 (1.560)	T@5 3.125 (30.072)	L 8.6637 (7.8848)
Test on T training set - [4][590/1731]	T 0.191 (0.218)	D 0.084 (0.115)	T@1 0.000 (1.560)	T@5 6.250 (29.669)	L 7.7165 (7.8877)
Test on T training set - [4][600/1731]	T 0.169 (0.219)	D 0.067 (0.117)	T@1 0.000 (1.544)	T@5 3.125 (29.233)	L 7.8489 (7.8907)
Test on T training set - [4][610/1731]	T 0.172 (0.219)	D 0.065 (0.116)	T@1 0.000 (1.545)	T@5 6.250 (28.821)	L 8.5617 (7.8980)
Test on T training set - [4][620/1731]	T 0.190 (0.218)	D 0.084 (0.116)	T@1 3.125 (1.535)	T@5 9.375 (28.417)	L 8.0510 (7.9061)
Test on T training set - [4][630/1731]	T 0.167 (0.217)	D 0.062 (0.115)	T@1 3.125 (1.535)	T@5 9.375 (28.046)	L 8.0723 (7.9056)
Test on T training set - [4][640/1731]	T 0.165 (0.217)	D 0.058 (0.114)	T@1 0.000 (1.521)	T@5 9.375 (27.672)	L 7.8512 (7.9114)
Test on T training set - [4][650/1731]	T 0.165 (0.216)	D 0.060 (0.114)	T@1 0.000 (1.507)	T@5 6.250 (27.299)	L 7.2544 (7.9173)
Test on T training set - [4][660/1731]	T 0.177 (0.215)	D 0.070 (0.113)	T@1 0.000 (1.484)	T@5 3.125 (26.934)	L 8.5450 (7.9245)
Test on T training set - [4][670/1731]	T 0.170 (0.214)	D 0.074 (0.112)	T@1 0.000 (1.467)	T@5 0.000 (26.607)	L 8.7039 (7.9294)
Test on T training set - [4][680/1731]	T 0.165 (0.214)	D 0.061 (0.111)	T@1 0.000 (1.455)	T@5 0.000 (26.239)	L 8.3107 (7.9367)
Test on T training set - [4][690/1731]	T 0.240 (0.213)	D 0.129 (0.111)	T@1 0.000 (1.443)	T@5 0.000 (25.936)	L 8.5200 (7.9406)
Test on T training set - [4][700/1731]	T 0.164 (0.216)	D 0.058 (0.114)	T@1 0.000 (1.422)	T@5 3.125 (25.602)	L 9.0902 (7.9556)
Test on T training set - [4][710/1731]	T 0.185 (0.215)	D 0.079 (0.113)	T@1 0.000 (1.406)	T@5 0.000 (25.308)	L 9.5347 (7.9726)
Test on T training set - [4][720/1731]	T 0.167 (0.215)	D 0.067 (0.113)	T@1 0.000 (1.387)	T@5 3.125 (24.983)	L 9.4261 (7.9897)
Test on T training set - [4][730/1731]	T 0.210 (0.215)	D 0.112 (0.112)	T@1 0.000 (1.368)	T@5 3.125 (24.709)	L 9.0316 (8.0058)
Test on T training set - [4][740/1731]	T 0.223 (0.215)	D 0.120 (0.112)	T@1 0.000 (1.350)	T@5 3.125 (24.426)	L 9.1742 (8.0199)
Test on T training set - [4][750/1731]	T 0.198 (0.215)	D 0.089 (0.113)	T@1 0.000 (1.332)	T@5 6.250 (24.147)	L 9.1246 (8.0330)
Test on T training set - [4][760/1731]	T 0.234 (0.215)	D 0.138 (0.113)	T@1 0.000 (1.314)	T@5 9.375 (23.891)	L 8.7907 (8.0455)
Test on T training set - [4][770/1731]	T 0.204 (0.215)	D 0.108 (0.113)	T@1 0.000 (1.297)	T@5 6.250 (23.662)	L 9.6071 (8.0591)
Test on T training set - [4][780/1731]	T 0.236 (0.215)	D 0.129 (0.113)	T@1 0.000 (1.280)	T@5 6.250 (23.423)	L 8.6098 (8.0704)
Test on T training set - [4][790/1731]	T 0.226 (0.216)	D 0.118 (0.114)	T@1 0.000 (1.264)	T@5 3.125 (23.198)	L 9.1636 (8.0808)
Test on T training set - [4][800/1731]	T 0.202 (0.216)	D 0.104 (0.114)	T@1 0.000 (1.248)	T@5 12.500 (22.963)	L 8.9136 (8.0920)
Test on T training set - [4][810/1731]	T 0.193 (0.216)	D 0.097 (0.114)	T@1 0.000 (1.233)	T@5 6.250 (22.750)	L 8.8571 (8.1028)
Test on T training set - [4][820/1731]	T 0.223 (0.216)	D 0.116 (0.114)	T@1 0.000 (1.222)	T@5 6.250 (22.533)	L 8.9675 (8.1134)
Test on T training set - [4][830/1731]	T 0.193 (0.216)	D 0.088 (0.113)	T@1 0.000 (1.207)	T@5 6.250 (22.319)	L 9.1552 (8.1261)
Test on T training set - [4][840/1731]	T 0.177 (0.215)	D 0.072 (0.113)	T@1 0.000 (1.193)	T@5 25.000 (22.120)	L 9.2124 (8.1365)
Test on T training set - [4][850/1731]	T 0.147 (0.215)	D 0.052 (0.112)	T@1 0.000 (1.212)	T@5 96.875 (22.977)	L 7.5643 (8.1303)
Test on T training set - [4][860/1731]	T 0.171 (0.214)	D 0.072 (0.112)	T@1 9.375 (1.252)	T@5 93.750 (23.828)	L 7.0951 (8.1226)
Test on T training set - [4][870/1731]	T 0.169 (0.214)	D 0.064 (0.111)	T@1 9.375 (1.295)	T@5 100.000 (24.641)	L 7.5603 (8.1123)
Test on T training set - [4][880/1731]	T 0.167 (0.213)	D 0.072 (0.111)	T@1 0.000 (1.323)	T@5 87.500 (25.436)	L 8.1442 (8.1052)
Test on T training set - [4][890/1731]	T 0.173 (0.213)	D 0.067 (0.110)	T@1 0.000 (1.340)	T@5 96.875 (26.221)	L 7.7377 (8.1013)
Test on T training set - [4][900/1731]	T 0.173 (0.214)	D 0.067 (0.112)	T@1 6.250 (1.373)	T@5 93.750 (26.987)	L 7.6444 (8.0945)
Test on T training set - [4][910/1731]	T 0.166 (0.214)	D 0.068 (0.111)	T@1 96.875 (1.921)	T@5 96.875 (27.720)	L 0.1650 (8.0476)
Test on T training set - [4][920/1731]	T 0.164 (0.213)	D 0.059 (0.111)	T@1 84.375 (2.928)	T@5 93.750 (28.491)	L 0.7861 (7.9633)
Test on T training set - [4][930/1731]	T 0.249 (0.213)	D 0.139 (0.111)	T@1 90.625 (3.867)	T@5 100.000 (29.226)	L 0.4092 (7.8824)
Test on T training set - [4][940/1731]	T 0.251 (0.213)	D 0.155 (0.111)	T@1 90.625 (4.779)	T@5 90.625 (29.925)	L 0.5644 (7.8032)
Test on T training set - [4][950/1731]	T 0.240 (0.214)	D 0.132 (0.111)	T@1 93.750 (5.701)	T@5 100.000 (30.645)	L 0.0868 (7.7244)
Test on T training set - [4][960/1731]	T 0.207 (0.214)	D 0.112 (0.112)	T@1 93.750 (6.591)	T@5 96.875 (31.318)	L 0.2408 (7.6488)
Test on T training set - [4][970/1731]	T 0.236 (0.214)	D 0.130 (0.112)	T@1 93.750 (7.434)	T@5 96.875 (31.987)	L 0.2815 (7.5752)
Test on T training set - [4][980/1731]	T 0.201 (0.214)	D 0.105 (0.112)	T@1 84.375 (8.279)	T@5 100.000 (32.652)	L 0.3961 (7.5024)
Test on T training set - [4][990/1731]	T 0.231 (0.215)	D 0.135 (0.113)	T@1 93.750 (9.123)	T@5 96.875 (33.309)	L 0.5076 (7.4306)
Test on T training set - [4][1000/1731]	T 0.241 (0.215)	D 0.132 (0.113)	T@1 90.625 (9.974)	T@5 100.000 (33.960)	L 0.3853 (7.3590)
Test on T training set - [4][1010/1731]	T 0.198 (0.215)	D 0.098 (0.113)	T@1 87.500 (10.757)	T@5 96.875 (34.564)	L 0.5970 (7.2908)
Test on T training set - [4][1020/1731]	T 0.203 (0.215)	D 0.107 (0.113)	T@1 87.500 (11.533)	T@5 100.000 (35.177)	L 0.5146 (7.2233)
Test on T training set - [4][1030/1731]	T 0.177 (0.215)	D 0.071 (0.113)	T@1 90.625 (12.306)	T@5 90.625 (35.751)	L 0.5790 (7.1578)
Test on T training set - [4][1040/1731]	T 0.168 (0.215)	D 0.070 (0.112)	T@1 93.750 (13.049)	T@5 93.750 (36.326)	L 0.3518 (7.0937)
Test on T training set - [4][1050/1731]	T 0.170 (0.214)	D 0.068 (0.112)	T@1 93.750 (13.802)	T@5 96.875 (36.887)	L 0.4704 (7.0297)
Test on T training set - [4][1060/1731]	T 0.160 (0.214)	D 0.055 (0.112)	T@1 90.625 (14.553)	T@5 96.875 (37.459)	L 0.4116 (6.9661)
Test on T training set - [4][1070/1731]	T 0.203 (0.213)	D 0.096 (0.111)	T@1 87.500 (15.260)	T@5 93.750 (37.993)	L 0.6984 (6.9065)
Test on T training set - [4][1080/1731]	T 0.159 (0.215)	D 0.064 (0.113)	T@1 90.625 (15.972)	T@5 93.750 (38.520)	L 0.5641 (6.8467)
Test on T training set - [4][1090/1731]	T 0.175 (0.215)	D 0.072 (0.113)	T@1 0.000 (16.298)	T@5 46.875 (38.872)	L 8.3201 (6.8176)
Test on T training set - [4][1100/1731]	T 0.197 (0.215)	D 0.097 (0.113)	T@1 0.000 (16.156)	T@5 59.375 (38.982)	L 8.3238 (6.8294)
Test on T training set - [4][1110/1731]	T 0.208 (0.215)	D 0.105 (0.112)	T@1 0.000 (16.016)	T@5 46.875 (39.055)	L 7.5971 (6.8384)
Test on T training set - [4][1120/1731]	T 0.190 (0.214)	D 0.092 (0.112)	T@1 0.000 (15.876)	T@5 56.250 (39.128)	L 8.0707 (6.8483)
Test on T training set - [4][1130/1731]	T 0.181 (0.214)	D 0.085 (0.112)	T@1 0.000 (15.747)	T@5 56.250 (39.246)	L 8.1282 (6.8584)
Test on T training set - [4][1140/1731]	T 0.187 (0.214)	D 0.088 (0.112)	T@1 0.000 (15.614)	T@5 46.875 (39.351)	L 8.0988 (6.8681)
Test on T training set - [4][1150/1731]	T 0.182 (0.214)	D 0.077 (0.112)	T@1 0.000 (15.484)	T@5 50.000 (39.425)	L 8.0531 (6.8770)
Test on T training set - [4][1160/1731]	T 0.174 (0.213)	D 0.071 (0.111)	T@1 0.000 (15.350)	T@5 50.000 (39.538)	L 8.5057 (6.8878)
Test on T training set - [4][1170/1731]	T 0.183 (0.213)	D 0.077 (0.111)	T@1 0.000 (15.225)	T@5 59.375 (39.664)	L 8.1811 (6.8983)
Test on T training set - [4][1180/1731]	T 0.192 (0.213)	D 0.087 (0.111)	T@1 0.000 (15.106)	T@5 59.375 (39.760)	L 8.0722 (6.9069)
Test on T training set - [4][1190/1731]	T 0.195 (0.214)	D 0.092 (0.112)	T@1 3.125 (14.987)	T@5 50.000 (39.827)	L 7.4516 (6.9162)
Test on T training set - [4][1200/1731]	T 0.179 (0.214)	D 0.074 (0.112)	T@1 6.250 (14.876)	T@5 43.750 (39.920)	L 7.0086 (6.9243)
Test on T training set - [4][1210/1731]	T 0.201 (0.214)	D 0.093 (0.112)	T@1 0.000 (14.763)	T@5 43.750 (40.029)	L 7.5349 (6.9338)
Test on T training set - [4][1220/1731]	T 0.174 (0.214)	D 0.068 (0.112)	T@1 0.000 (14.650)	T@5 0.000 (39.739)	L 9.1636 (6.9502)
Test on T training set - [4][1230/1731]	T 0.166 (0.213)	D 0.061 (0.111)	T@1 0.000 (14.536)	T@5 0.000 (39.432)	L 9.3800 (6.9662)
Test on T training set - [4][1240/1731]	T 0.179 (0.213)	D 0.075 (0.111)	T@1 0.000 (14.429)	T@5 0.000 (39.124)	L 8.5314 (6.9827)
Test on T training set - [4][1250/1731]	T 0.182 (0.213)	D 0.085 (0.111)	T@1 3.125 (14.321)	T@5 3.125 (38.824)	L 8.3112 (6.9964)
Test on T training set - [4][1260/1731]	T 0.191 (0.212)	D 0.090 (0.110)	T@1 0.000 (14.215)	T@5 0.000 (38.528)	L 8.6923 (7.0111)
Test on T training set - [4][1270/1731]	T 0.186 (0.212)	D 0.081 (0.110)	T@1 0.000 (14.106)	T@5 0.000 (38.233)	L 9.0820 (7.0261)
Test on T training set - [4][1280/1731]	T 0.196 (0.212)	D 0.089 (0.110)	T@1 0.000 (14.003)	T@5 6.250 (37.949)	L 8.6149 (7.0409)
Test on T training set - [4][1290/1731]	T 0.175 (0.212)	D 0.072 (0.110)	T@1 3.125 (13.897)	T@5 6.250 (37.662)	L 8.3647 (7.0552)
Test on T training set - [4][1300/1731]	T 0.176 (0.213)	D 0.074 (0.111)	T@1 0.000 (13.792)	T@5 0.000 (37.377)	L 8.7674 (7.0679)
Test on T training set - [4][1310/1731]	T 0.177 (0.213)	D 0.081 (0.111)	T@1 0.000 (13.689)	T@5 0.000 (37.104)	L 8.5594 (7.0804)
Test on T training set - [4][1320/1731]	T 0.193 (0.213)	D 0.095 (0.111)	T@1 0.000 (13.586)	T@5 0.000 (36.833)	L 8.5826 (7.0926)
Test on T training set - [4][1330/1731]	T 0.173 (0.213)	D 0.073 (0.110)	T@1 0.000 (13.484)	T@5 0.000 (36.559)	L 8.9342 (7.1065)
Test on T training set - [4][1340/1731]	T 0.161 (0.212)	D 0.055 (0.110)	T@1 0.000 (13.383)	T@5 0.000 (36.288)	L 9.1819 (7.1204)
Test on T training set - [4][1350/1731]	T 0.178 (0.212)	D 0.074 (0.110)	T@1 3.125 (13.286)	T@5 3.125 (36.027)	L 8.5764 (7.1340)
Test on T training set - [4][1360/1731]	T 0.161 (0.212)	D 0.063 (0.110)	T@1 0.000 (13.191)	T@5 9.375 (35.803)	L 8.4589 (7.1461)
Test on T training set - [4][1370/1731]	T 0.160 (0.211)	D 0.060 (0.109)	T@1 0.000 (13.095)	T@5 3.125 (35.592)	L 8.5756 (7.1556)
Test on T training set - [4][1380/1731]	T 0.160 (0.211)	D 0.062 (0.109)	T@1 0.000 (13.009)	T@5 0.000 (35.396)	L 8.7115 (7.1636)
Test on T training set - [4][1390/1731]	T 0.168 (0.211)	D 0.072 (0.109)	T@1 0.000 (12.920)	T@5 12.500 (35.206)	L 8.2905 (7.1711)
Test on T training set - [4][1400/1731]	T 0.171 (0.210)	D 0.071 (0.108)	T@1 0.000 (12.832)	T@5 9.375 (35.020)	L 8.2003 (7.1798)
Test on T training set - [4][1410/1731]	T 0.179 (0.210)	D 0.077 (0.108)	T@1 0.000 (12.744)	T@5 12.500 (34.831)	L 7.5303 (7.1859)
Test on T training set - [4][1420/1731]	T 0.165 (0.211)	D 0.063 (0.109)	T@1 0.000 (12.658)	T@5 12.500 (34.650)	L 8.3692 (7.1934)
Test on T training set - [4][1430/1731]	T 0.209 (0.211)	D 0.107 (0.109)	T@1 0.000 (12.581)	T@5 9.375 (34.506)	L 9.0670 (7.2019)
Test on T training set - [4][1440/1731]	T 0.249 (0.211)	D 0.144 (0.109)	T@1 0.000 (12.496)	T@5 12.500 (34.351)	L 8.9198 (7.2144)
Test on T training set - [4][1450/1731]	T 0.234 (0.211)	D 0.131 (0.109)	T@1 0.000 (12.412)	T@5 18.750 (34.203)	L 8.5391 (7.2257)
Test on T training set - [4][1460/1731]	T 0.222 (0.211)	D 0.127 (0.109)	T@1 3.125 (12.331)	T@5 25.000 (34.069)	L 8.3059 (7.2368)
Test on T training set - [4][1470/1731]	T 0.233 (0.211)	D 0.126 (0.109)	T@1 0.000 (12.247)	T@5 18.750 (33.925)	L 8.4650 (7.2483)
Test on T training set - [4][1480/1731]	T 0.228 (0.212)	D 0.130 (0.110)	T@1 0.000 (12.169)	T@5 15.625 (33.784)	L 9.0426 (7.2589)
Test on T training set - [4][1490/1731]	T 0.224 (0.212)	D 0.128 (0.110)	T@1 0.000 (12.087)	T@5 15.625 (33.644)	L 9.0668 (7.2694)
Test on T training set - [4][1500/1731]	T 0.245 (0.212)	D 0.141 (0.110)	T@1 0.000 (12.009)	T@5 12.500 (33.486)	L 9.3386 (7.2815)
Test on T training set - [4][1510/1731]	T 0.233 (0.213)	D 0.137 (0.111)	T@1 0.000 (11.929)	T@5 18.750 (33.337)	L 8.7140 (7.2937)
Test on T training set - [4][1520/1731]	T 0.222 (0.214)	D 0.124 (0.111)	T@1 0.000 (11.855)	T@5 15.625 (33.204)	L 8.7942 (7.3049)
Test on T training set - [4][1530/1731]	T 0.229 (0.214)	D 0.124 (0.112)	T@1 0.000 (11.777)	T@5 6.250 (33.050)	L 9.2775 (7.3162)
Test on T training set - [4][1540/1731]	T 0.202 (0.214)	D 0.095 (0.112)	T@1 0.000 (11.703)	T@5 9.375 (32.919)	L 9.3853 (7.3262)
Test on T training set - [4][1550/1731]	T 0.245 (0.214)	D 0.139 (0.112)	T@1 3.125 (11.632)	T@5 3.125 (32.807)	L 9.2607 (7.3350)
Test on T training set - [4][1560/1731]	T 0.193 (0.214)	D 0.097 (0.112)	T@1 0.000 (11.557)	T@5 50.000 (32.795)	L 7.9240 (7.3417)
Test on T training set - [4][1570/1731]	T 0.186 (0.214)	D 0.086 (0.112)	T@1 0.000 (11.484)	T@5 75.000 (33.022)	L 7.2318 (7.3440)
Test on T training set - [4][1580/1731]	T 0.167 (0.213)	D 0.061 (0.111)	T@1 0.000 (11.413)	T@5 71.875 (33.284)	L 7.6130 (7.3448)
Test on T training set - [4][1590/1731]	T 0.168 (0.215)	D 0.063 (0.113)	T@1 0.000 (11.341)	T@5 68.750 (33.515)	L 7.3069 (7.3459)
Test on T training set - [4][1600/1731]	T 0.186 (0.214)	D 0.085 (0.112)	T@1 0.000 (11.270)	T@5 65.625 (33.743)	L 7.8268 (7.3473)
Test on T training set - [4][1610/1731]	T 0.182 (0.214)	D 0.072 (0.112)	T@1 0.000 (11.200)	T@5 71.875 (33.970)	L 7.4266 (7.3486)
Test on T training set - [4][1620/1731]	T 0.185 (0.214)	D 0.079 (0.112)	T@1 0.000 (11.135)	T@5 68.750 (34.176)	L 8.1796 (7.3490)
Test on T training set - [4][1630/1731]	T 0.173 (0.214)	D 0.071 (0.112)	T@1 0.000 (11.067)	T@5 84.375 (34.396)	L 6.8145 (7.3489)
Test on T training set - [4][1640/1731]	T 0.213 (0.213)	D 0.112 (0.111)	T@1 0.000 (10.999)	T@5 53.125 (34.609)	L 7.3929 (7.3491)
Test on T training set - [4][1650/1731]	T 0.221 (0.213)	D 0.121 (0.111)	T@1 0.000 (10.933)	T@5 75.000 (34.827)	L 7.0618 (7.3495)
Test on T training set - [4][1660/1731]	T 0.211 (0.213)	D 0.108 (0.111)	T@1 0.000 (10.867)	T@5 87.500 (35.058)	L 7.8260 (7.3519)
Test on T training set - [4][1670/1731]	T 0.205 (0.213)	D 0.096 (0.111)	T@1 0.000 (10.804)	T@5 62.500 (35.278)	L 7.7797 (7.3532)
Test on T training set - [4][1680/1731]	T 0.193 (0.213)	D 0.090 (0.111)	T@1 0.000 (10.740)	T@5 59.375 (35.494)	L 7.3982 (7.3545)
Test on T training set - [4][1690/1731]	T 0.209 (0.213)	D 0.110 (0.111)	T@1 0.000 (10.676)	T@5 87.500 (35.720)	L 7.5990 (7.3566)
Test on T training set - [4][1700/1731]	T 0.210 (0.214)	D 0.114 (0.112)	T@1 3.125 (10.617)	T@5 78.125 (35.905)	L 7.7307 (7.3588)
Test on T training set - [4][1710/1731]	T 0.218 (0.214)	D 0.121 (0.112)	T@1 0.000 (10.555)	T@5 71.875 (36.123)	L 8.3114 (7.3623)
Test on T training set - [4][1720/1731]	T 0.197 (0.214)	D 0.089 (0.112)	T@1 0.000 (10.494)	T@5 78.125 (36.338)	L 7.9464 (7.3639)
Test on T training set - [4][1730/1731]	T 0.165 (0.214)	D 0.074 (0.112)	T@1 0.000 (10.434)	T@5 75.000 (36.531)	L 7.8301 (7.3674)
 * Test on T training set - Prec@1 10.434, Prec@5 36.531
Test on T test set - [4][0/1731]	Time 0.296 (0.296)	Loss 7.0010 (7.0010)	Prec@1 0.000 (0.000)	Prec@5 50.000 (50.000)
Test on T test set - [4][10/1731]	Time 0.207 (0.196)	Loss 6.5725 (6.3577)	Prec@1 3.125 (2.557)	Prec@5 56.250 (48.864)
Test on T test set - [4][20/1731]	Time 0.220 (0.209)	Loss 5.5274 (6.1806)	Prec@1 3.125 (2.976)	Prec@5 40.625 (51.786)
Test on T test set - [4][30/1731]	Time 0.201 (0.287)	Loss 5.6170 (6.0262)	Prec@1 3.125 (3.226)	Prec@5 62.500 (52.923)
Test on T test set - [4][40/1731]	Time 0.225 (0.269)	Loss 6.0036 (6.0412)	Prec@1 0.000 (3.049)	Prec@5 50.000 (52.973)
Test on T test set - [4][50/1731]	Time 0.203 (0.258)	Loss 5.2825 (6.0185)	Prec@1 6.250 (3.064)	Prec@5 59.375 (53.064)
Test on T test set - [4][60/1731]	Time 0.219 (0.250)	Loss 6.0524 (6.0112)	Prec@1 6.250 (3.176)	Prec@5 46.875 (52.664)
Test on T test set - [4][70/1731]	Time 0.203 (0.244)	Loss 5.8092 (6.0235)	Prec@1 3.125 (3.257)	Prec@5 56.250 (52.509)
Test on T test set - [4][80/1731]	Time 0.198 (0.240)	Loss 6.0118 (6.0246)	Prec@1 3.125 (3.356)	Prec@5 56.250 (52.855)
Test on T test set - [4][90/1731]	Time 0.179 (0.236)	Loss 6.4624 (6.0314)	Prec@1 0.000 (3.262)	Prec@5 53.125 (53.056)
Test on T test set - [4][100/1731]	Time 0.189 (0.231)	Loss 6.2530 (6.0524)	Prec@1 6.250 (3.125)	Prec@5 46.875 (52.939)
Test on T test set - [4][110/1731]	Time 0.209 (0.227)	Loss 6.6119 (6.0817)	Prec@1 0.000 (3.012)	Prec@5 43.750 (52.787)
Test on T test set - [4][120/1731]	Time 0.196 (0.224)	Loss 7.4917 (6.1647)	Prec@1 0.000 (2.918)	Prec@5 96.875 (55.449)
Test on T test set - [4][130/1731]	Time 0.196 (0.237)	Loss 6.7737 (6.2168)	Prec@1 6.250 (3.053)	Prec@5 100.000 (58.182)
Test on T test set - [4][140/1731]	Time 0.169 (0.233)	Loss 6.8547 (6.2602)	Prec@1 6.250 (3.191)	Prec@5 93.750 (60.705)
Test on T test set - [4][150/1731]	Time 0.210 (0.230)	Loss 6.9840 (6.2984)	Prec@1 6.250 (3.332)	Prec@5 96.875 (62.728)
Test on T test set - [4][160/1731]	Time 0.190 (0.228)	Loss 6.5428 (6.3302)	Prec@1 0.000 (3.280)	Prec@5 100.000 (64.596)
Test on T test set - [4][170/1731]	Time 0.169 (0.225)	Loss 7.0962 (6.3732)	Prec@1 0.000 (3.289)	Prec@5 100.000 (66.265)
Test on T test set - [4][180/1731]	Time 0.155 (0.222)	Loss 7.2966 (6.4080)	Prec@1 3.125 (3.367)	Prec@5 90.625 (67.835)
Test on T test set - [4][190/1731]	Time 0.181 (0.218)	Loss 7.0485 (6.4472)	Prec@1 0.000 (3.338)	Prec@5 96.875 (69.290)
Test on T test set - [4][200/1731]	Time 0.164 (0.216)	Loss 6.9058 (6.4849)	Prec@1 6.250 (3.327)	Prec@5 96.875 (70.600)
Test on T test set - [4][210/1731]	Time 0.177 (0.213)	Loss 7.3452 (6.5141)	Prec@1 3.125 (3.362)	Prec@5 87.500 (71.712)
Test on T test set - [4][220/1731]	Time 0.176 (0.212)	Loss 6.8729 (6.5359)	Prec@1 6.250 (3.365)	Prec@5 84.375 (72.653)
Test on T test set - [4][230/1731]	Time 0.170 (0.219)	Loss 8.8457 (6.6405)	Prec@1 0.000 (3.247)	Prec@5 6.250 (70.346)
Test on T test set - [4][240/1731]	Time 0.225 (0.219)	Loss 8.9764 (6.7523)	Prec@1 0.000 (3.125)	Prec@5 6.250 (67.557)
Test on T test set - [4][250/1731]	Time 0.202 (0.219)	Loss 9.1077 (6.8620)	Prec@1 0.000 (3.000)	Prec@5 9.375 (64.953)
Test on T test set - [4][260/1731]	Time 0.229 (0.220)	Loss 8.6871 (6.9652)	Prec@1 3.125 (2.898)	Prec@5 3.125 (62.512)
Test on T test set - [4][270/1731]	Time 0.223 (0.220)	Loss 9.7805 (7.0608)	Prec@1 0.000 (2.791)	Prec@5 0.000 (60.286)
Test on T test set - [4][280/1731]	Time 0.228 (0.220)	Loss 10.0375 (7.1517)	Prec@1 0.000 (2.702)	Prec@5 6.250 (58.241)
Test on T test set - [4][290/1731]	Time 0.229 (0.220)	Loss 9.8423 (7.2397)	Prec@1 3.125 (2.620)	Prec@5 3.125 (56.314)
Test on T test set - [4][300/1731]	Time 0.215 (0.220)	Loss 9.3850 (7.3130)	Prec@1 0.000 (2.533)	Prec@5 6.250 (54.568)
Test on T test set - [4][310/1731]	Time 0.211 (0.228)	Loss 10.1173 (7.3854)	Prec@1 0.000 (2.452)	Prec@5 6.250 (52.884)
Test on T test set - [4][320/1731]	Time 0.200 (0.228)	Loss 10.3422 (7.4592)	Prec@1 0.000 (2.375)	Prec@5 0.000 (51.295)
Test on T test set - [4][330/1731]	Time 0.203 (0.227)	Loss 9.1858 (7.5222)	Prec@1 0.000 (2.304)	Prec@5 0.000 (49.830)
Test on T test set - [4][340/1731]	Time 0.184 (0.226)	Loss 10.1881 (7.5837)	Prec@1 0.000 (2.236)	Prec@5 3.125 (48.488)
Test on T test set - [4][350/1731]	Time 0.195 (0.225)	Loss 9.7819 (7.6422)	Prec@1 0.000 (2.172)	Prec@5 0.000 (47.231)
Test on T test set - [4][360/1731]	Time 0.233 (0.225)	Loss 10.1019 (7.7026)	Prec@1 0.000 (2.112)	Prec@5 0.000 (46.009)
Test on T test set - [4][370/1731]	Time 0.165 (0.224)	Loss 8.8592 (7.7502)	Prec@1 0.000 (2.055)	Prec@5 3.125 (44.803)
Test on T test set - [4][380/1731]	Time 0.188 (0.223)	Loss 7.6450 (7.7573)	Prec@1 0.000 (2.010)	Prec@5 3.125 (43.725)
Test on T test set - [4][390/1731]	Time 0.172 (0.221)	Loss 7.7065 (7.7632)	Prec@1 6.250 (1.990)	Prec@5 9.375 (42.719)
Test on T test set - [4][400/1731]	Time 0.168 (0.226)	Loss 8.4754 (7.7708)	Prec@1 0.000 (1.948)	Prec@5 3.125 (41.747)
Test on T test set - [4][410/1731]	Time 0.161 (0.224)	Loss 7.8804 (7.7771)	Prec@1 0.000 (1.908)	Prec@5 3.125 (40.830)
Test on T test set - [4][420/1731]	Time 0.163 (0.222)	Loss 7.9409 (7.7863)	Prec@1 3.125 (1.893)	Prec@5 3.125 (39.964)
Test on T test set - [4][430/1731]	Time 0.166 (0.221)	Loss 7.6700 (7.7841)	Prec@1 0.000 (1.856)	Prec@5 3.125 (39.197)
Test on T test set - [4][440/1731]	Time 0.155 (0.220)	Loss 8.6968 (7.7932)	Prec@1 0.000 (1.814)	Prec@5 6.250 (38.372)
Test on T test set - [4][450/1731]	Time 0.155 (0.218)	Loss 7.5754 (7.7967)	Prec@1 3.125 (1.795)	Prec@5 6.250 (37.632)
Test on T test set - [4][460/1731]	Time 0.173 (0.217)	Loss 7.8634 (7.8022)	Prec@1 9.375 (1.796)	Prec@5 12.500 (36.910)
Test on T test set - [4][470/1731]	Time 0.159 (0.216)	Loss 7.9274 (7.8051)	Prec@1 0.000 (1.771)	Prec@5 3.125 (36.259)
Test on T test set - [4][480/1731]	Time 0.157 (0.215)	Loss 7.7780 (7.8071)	Prec@1 0.000 (1.735)	Prec@5 3.125 (35.603)
Test on T test set - [4][490/1731]	Time 0.163 (0.214)	Loss 7.7217 (7.8083)	Prec@1 3.125 (1.712)	Prec@5 3.125 (34.948)
Test on T test set - [4][500/1731]	Time 0.161 (0.213)	Loss 8.3408 (7.8046)	Prec@1 0.000 (1.684)	Prec@5 0.000 (34.313)
Test on T test set - [4][510/1731]	Time 0.171 (0.216)	Loss 8.8103 (7.8153)	Prec@1 0.000 (1.663)	Prec@5 6.250 (33.745)
Test on T test set - [4][520/1731]	Time 0.158 (0.215)	Loss 7.5589 (7.8207)	Prec@1 6.250 (1.643)	Prec@5 12.500 (33.181)
Test on T test set - [4][530/1731]	Time 0.162 (0.214)	Loss 8.3233 (7.8248)	Prec@1 0.000 (1.636)	Prec@5 6.250 (32.662)
Test on T test set - [4][540/1731]	Time 0.161 (0.213)	Loss 8.4103 (7.8322)	Prec@1 0.000 (1.612)	Prec@5 3.125 (32.163)
Test on T test set - [4][550/1731]	Time 0.156 (0.212)	Loss 9.3859 (7.8461)	Prec@1 0.000 (1.599)	Prec@5 3.125 (31.653)
Test on T test set - [4][560/1731]	Time 0.165 (0.211)	Loss 9.1429 (7.8573)	Prec@1 0.000 (1.571)	Prec@5 0.000 (31.155)
Test on T test set - [4][570/1731]	Time 0.195 (0.210)	Loss 7.6408 (7.8625)	Prec@1 0.000 (1.554)	Prec@5 6.250 (30.697)
Test on T test set - [4][580/1731]	Time 0.162 (0.210)	Loss 8.2591 (7.8683)	Prec@1 0.000 (1.538)	Prec@5 3.125 (30.266)
Test on T test set - [4][590/1731]	Time 0.175 (0.209)	Loss 7.5423 (7.8700)	Prec@1 0.000 (1.544)	Prec@5 6.250 (29.859)
Test on T test set - [4][600/1731]	Time 0.159 (0.208)	Loss 7.4634 (7.8720)	Prec@1 3.125 (1.524)	Prec@5 15.625 (29.425)
Test on T test set - [4][610/1731]	Time 0.155 (0.208)	Loss 8.4183 (7.8777)	Prec@1 0.000 (1.504)	Prec@5 6.250 (29.046)
Test on T test set - [4][620/1731]	Time 0.186 (0.209)	Loss 7.9496 (7.8833)	Prec@1 3.125 (1.485)	Prec@5 3.125 (28.608)
Test on T test set - [4][630/1731]	Time 0.157 (0.209)	Loss 8.6395 (7.8842)	Prec@1 0.000 (1.481)	Prec@5 0.000 (28.209)
Test on T test set - [4][640/1731]	Time 0.158 (0.208)	Loss 7.6373 (7.8884)	Prec@1 0.000 (1.467)	Prec@5 6.250 (27.847)
Test on T test set - [4][650/1731]	Time 0.155 (0.207)	Loss 7.7229 (7.8934)	Prec@1 0.000 (1.450)	Prec@5 9.375 (27.496)
Test on T test set - [4][660/1731]	Time 0.159 (0.207)	Loss 8.4998 (7.8991)	Prec@1 0.000 (1.447)	Prec@5 6.250 (27.151)
Test on T test set - [4][670/1731]	Time 0.172 (0.206)	Loss 8.6040 (7.9046)	Prec@1 0.000 (1.430)	Prec@5 3.125 (26.774)
Test on T test set - [4][680/1731]	Time 0.157 (0.205)	Loss 8.1546 (7.9110)	Prec@1 3.125 (1.423)	Prec@5 3.125 (26.432)
Test on T test set - [4][690/1731]	Time 0.215 (0.205)	Loss 8.6314 (7.9158)	Prec@1 0.000 (1.411)	Prec@5 0.000 (26.094)
Test on T test set - [4][700/1731]	Time 0.153 (0.204)	Loss 9.2461 (7.9303)	Prec@1 0.000 (1.391)	Prec@5 6.250 (25.780)
Test on T test set - [4][710/1731]	Time 0.172 (0.204)	Loss 9.2401 (7.9475)	Prec@1 0.000 (1.371)	Prec@5 3.125 (25.501)
Test on T test set - [4][720/1731]	Time 0.167 (0.208)	Loss 9.4666 (7.9641)	Prec@1 0.000 (1.352)	Prec@5 3.125 (25.199)
Test on T test set - [4][730/1731]	Time 0.214 (0.208)	Loss 9.3994 (7.9831)	Prec@1 0.000 (1.334)	Prec@5 3.125 (24.893)
Test on T test set - [4][740/1731]	Time 0.221 (0.208)	Loss 9.5226 (7.9967)	Prec@1 0.000 (1.320)	Prec@5 0.000 (24.620)
Test on T test set - [4][750/1731]	Time 0.195 (0.208)	Loss 8.6873 (8.0096)	Prec@1 0.000 (1.302)	Prec@5 9.375 (24.363)
Test on T test set - [4][760/1731]	Time 0.229 (0.208)	Loss 9.1104 (8.0223)	Prec@1 0.000 (1.285)	Prec@5 6.250 (24.109)
Test on T test set - [4][770/1731]	Time 0.198 (0.208)	Loss 9.5336 (8.0360)	Prec@1 0.000 (1.269)	Prec@5 3.125 (23.869)
Test on T test set - [4][780/1731]	Time 0.224 (0.208)	Loss 8.5429 (8.0484)	Prec@1 0.000 (1.252)	Prec@5 6.250 (23.612)
Test on T test set - [4][790/1731]	Time 0.214 (0.208)	Loss 9.1016 (8.0595)	Prec@1 0.000 (1.237)	Prec@5 0.000 (23.376)
Test on T test set - [4][800/1731]	Time 0.202 (0.208)	Loss 8.8849 (8.0712)	Prec@1 0.000 (1.221)	Prec@5 6.250 (23.151)
Test on T test set - [4][810/1731]	Time 0.198 (0.208)	Loss 9.1884 (8.0832)	Prec@1 0.000 (1.206)	Prec@5 3.125 (22.923)
Test on T test set - [4][820/1731]	Time 0.210 (0.210)	Loss 8.5863 (8.0928)	Prec@1 0.000 (1.191)	Prec@5 6.250 (22.716)
Test on T test set - [4][830/1731]	Time 0.194 (0.210)	Loss 9.0477 (8.1047)	Prec@1 0.000 (1.177)	Prec@5 3.125 (22.492)
Test on T test set - [4][840/1731]	Time 0.166 (0.210)	Loss 9.1515 (8.1155)	Prec@1 0.000 (1.163)	Prec@5 28.125 (22.295)
Test on T test set - [4][850/1731]	Time 0.151 (0.209)	Loss 7.4118 (8.1092)	Prec@1 6.250 (1.186)	Prec@5 100.000 (23.153)
Test on T test set - [4][860/1731]	Time 0.159 (0.209)	Loss 7.3252 (8.1028)	Prec@1 9.375 (1.212)	Prec@5 87.500 (23.995)
Test on T test set - [4][870/1731]	Time 0.157 (0.208)	Loss 7.9721 (8.0927)	Prec@1 0.000 (1.263)	Prec@5 96.875 (24.795)
Test on T test set - [4][880/1731]	Time 0.158 (0.208)	Loss 7.7777 (8.0859)	Prec@1 3.125 (1.284)	Prec@5 96.875 (25.575)
Test on T test set - [4][890/1731]	Time 0.170 (0.207)	Loss 7.6097 (8.0813)	Prec@1 3.125 (1.315)	Prec@5 100.000 (26.364)
Test on T test set - [4][900/1731]	Time 0.166 (0.207)	Loss 7.6542 (8.0738)	Prec@1 3.125 (1.353)	Prec@5 90.625 (27.116)
Test on T test set - [4][910/1731]	Time 0.170 (0.206)	Loss 0.4493 (8.0274)	Prec@1 93.750 (1.887)	Prec@5 93.750 (27.851)
Test on T test set - [4][920/1731]	Time 0.148 (0.206)	Loss 0.5351 (7.9431)	Prec@1 84.375 (2.877)	Prec@5 96.875 (28.617)
Test on T test set - [4][930/1731]	Time 0.224 (0.206)	Loss 0.1662 (7.8629)	Prec@1 96.875 (3.823)	Prec@5 100.000 (29.343)
Test on T test set - [4][940/1731]	Time 0.246 (0.207)	Loss 0.6460 (7.7842)	Prec@1 87.500 (4.736)	Prec@5 96.875 (30.054)
Test on T test set - [4][950/1731]	Time 0.238 (0.208)	Loss 0.3469 (7.7063)	Prec@1 93.750 (5.655)	Prec@5 96.875 (30.751)
Test on T test set - [4][960/1731]	Time 0.225 (0.208)	Loss 0.1035 (7.6305)	Prec@1 96.875 (6.533)	Prec@5 100.000 (31.432)
Test on T test set - [4][970/1731]	Time 0.227 (0.208)	Loss 0.5708 (7.5562)	Prec@1 87.500 (7.412)	Prec@5 96.875 (32.106)
Test on T test set - [4][980/1731]	Time 0.215 (0.208)	Loss 0.3052 (7.4833)	Prec@1 93.750 (8.273)	Prec@5 100.000 (32.773)
Test on T test set - [4][990/1731]	Time 0.220 (0.208)	Loss 0.3823 (7.4114)	Prec@1 93.750 (9.132)	Prec@5 96.875 (33.426)
Test on T test set - [4][1000/1731]	Time 0.222 (0.208)	Loss 0.2906 (7.3408)	Prec@1 93.750 (9.968)	Prec@5 96.875 (34.069)
Test on T test set - [4][1010/1731]	Time 0.193 (0.208)	Loss 0.4957 (7.2731)	Prec@1 90.625 (10.760)	Prec@5 93.750 (34.678)
Test on T test set - [4][1020/1731]	Time 0.202 (0.210)	Loss 0.3512 (7.2063)	Prec@1 87.500 (11.524)	Prec@5 100.000 (35.281)
Test on T test set - [4][1030/1731]	Time 0.168 (0.210)	Loss 0.8766 (7.1410)	Prec@1 90.625 (12.291)	Prec@5 90.625 (35.866)
Test on T test set - [4][1040/1731]	Time 0.165 (0.209)	Loss 0.5072 (7.0763)	Prec@1 87.500 (13.037)	Prec@5 100.000 (36.458)
Test on T test set - [4][1050/1731]	Time 0.169 (0.209)	Loss 0.0617 (7.0120)	Prec@1 96.875 (13.799)	Prec@5 100.000 (37.033)
Test on T test set - [4][1060/1731]	Time 0.157 (0.208)	Loss 0.5581 (6.9485)	Prec@1 87.500 (14.550)	Prec@5 93.750 (37.600)
Test on T test set - [4][1070/1731]	Time 0.198 (0.208)	Loss 0.5010 (6.8876)	Prec@1 87.500 (15.263)	Prec@5 93.750 (38.139)
Test on T test set - [4][1080/1731]	Time 0.162 (0.208)	Loss 0.8382 (6.8283)	Prec@1 87.500 (15.949)	Prec@5 93.750 (38.668)
Test on T test set - [4][1090/1731]	Time 0.166 (0.208)	Loss 7.6719 (6.7985)	Prec@1 3.125 (16.298)	Prec@5 53.125 (39.035)
Test on T test set - [4][1100/1731]	Time 0.194 (0.207)	Loss 8.0047 (6.8097)	Prec@1 3.125 (16.161)	Prec@5 59.375 (39.143)
Test on T test set - [4][1110/1731]	Time 0.206 (0.207)	Loss 7.3601 (6.8192)	Prec@1 0.000 (16.024)	Prec@5 37.500 (39.221)
Test on T test set - [4][1120/1731]	Time 0.185 (0.207)	Loss 7.8425 (6.8296)	Prec@1 3.125 (15.884)	Prec@5 50.000 (39.343)
Test on T test set - [4][1130/1731]	Time 0.182 (0.209)	Loss 8.2196 (6.8407)	Prec@1 0.000 (15.752)	Prec@5 56.250 (39.470)
Test on T test set - [4][1140/1731]	Time 0.183 (0.209)	Loss 8.2171 (6.8501)	Prec@1 0.000 (15.622)	Prec@5 50.000 (39.568)
Test on T test set - [4][1150/1731]	Time 0.179 (0.209)	Loss 7.8364 (6.8592)	Prec@1 0.000 (15.495)	Prec@5 43.750 (39.642)
Test on T test set - [4][1160/1731]	Time 0.168 (0.209)	Loss 8.3288 (6.8692)	Prec@1 0.000 (15.367)	Prec@5 46.875 (39.734)
Test on T test set - [4][1170/1731]	Time 0.173 (0.208)	Loss 8.1016 (6.8795)	Prec@1 0.000 (15.241)	Prec@5 62.500 (39.875)
Test on T test set - [4][1180/1731]	Time 0.192 (0.208)	Loss 8.2289 (6.8884)	Prec@1 0.000 (15.120)	Prec@5 46.875 (39.940)
Test on T test set - [4][1190/1731]	Time 0.188 (0.208)	Loss 7.9571 (6.8984)	Prec@1 0.000 (14.995)	Prec@5 50.000 (40.008)
Test on T test set - [4][1200/1731]	Time 0.171 (0.208)	Loss 7.0995 (6.9072)	Prec@1 0.000 (14.870)	Prec@5 37.500 (40.073)
Test on T test set - [4][1210/1731]	Time 0.184 (0.208)	Loss 7.4602 (6.9170)	Prec@1 0.000 (14.753)	Prec@5 37.500 (40.163)
Test on T test set - [4][1220/1731]	Time 0.164 (0.207)	Loss 9.3470 (6.9332)	Prec@1 0.000 (14.632)	Prec@5 0.000 (39.875)
Test on T test set - [4][1230/1731]	Time 0.143 (0.207)	Loss 9.1656 (6.9490)	Prec@1 0.000 (14.523)	Prec@5 0.000 (39.566)
Test on T test set - [4][1240/1731]	Time 0.174 (0.209)	Loss 8.8307 (6.9654)	Prec@1 0.000 (14.414)	Prec@5 0.000 (39.255)
Test on T test set - [4][1250/1731]	Time 0.171 (0.209)	Loss 8.4052 (6.9798)	Prec@1 3.125 (14.301)	Prec@5 3.125 (38.951)
Test on T test set - [4][1260/1731]	Time 0.180 (0.208)	Loss 8.7975 (6.9943)	Prec@1 0.000 (14.195)	Prec@5 0.000 (38.660)
Test on T test set - [4][1270/1731]	Time 0.173 (0.208)	Loss 9.1316 (7.0095)	Prec@1 0.000 (14.086)	Prec@5 0.000 (38.361)
Test on T test set - [4][1280/1731]	Time 0.192 (0.208)	Loss 8.2762 (7.0236)	Prec@1 0.000 (13.981)	Prec@5 0.000 (38.066)
Test on T test set - [4][1290/1731]	Time 0.169 (0.208)	Loss 8.3457 (7.0377)	Prec@1 3.125 (13.877)	Prec@5 3.125 (37.786)
Test on T test set - [4][1300/1731]	Time 0.178 (0.207)	Loss 8.7406 (7.0507)	Prec@1 0.000 (13.773)	Prec@5 0.000 (37.502)
Test on T test set - [4][1310/1731]	Time 0.188 (0.207)	Loss 8.6525 (7.0639)	Prec@1 0.000 (13.668)	Prec@5 3.125 (37.226)
Test on T test set - [4][1320/1731]	Time 0.195 (0.207)	Loss 8.5869 (7.0765)	Prec@1 0.000 (13.567)	Prec@5 0.000 (36.951)
Test on T test set - [4][1330/1731]	Time 0.172 (0.207)	Loss 8.7815 (7.0906)	Prec@1 0.000 (13.465)	Prec@5 0.000 (36.676)
Test on T test set - [4][1340/1731]	Time 0.161 (0.206)	Loss 9.0573 (7.1036)	Prec@1 0.000 (13.365)	Prec@5 0.000 (36.405)
Test on T test set - [4][1350/1731]	Time 0.166 (0.206)	Loss 8.5928 (7.1178)	Prec@1 3.125 (13.270)	Prec@5 6.250 (36.142)
Test on T test set - [4][1360/1731]	Time 0.164 (0.207)	Loss 8.4451 (7.1307)	Prec@1 0.000 (13.173)	Prec@5 6.250 (35.909)
Test on T test set - [4][1370/1731]	Time 0.151 (0.207)	Loss 8.4967 (7.1405)	Prec@1 0.000 (13.081)	Prec@5 6.250 (35.699)
Test on T test set - [4][1380/1731]	Time 0.172 (0.207)	Loss 8.9371 (7.1490)	Prec@1 0.000 (12.989)	Prec@5 0.000 (35.506)
Test on T test set - [4][1390/1731]	Time 0.168 (0.206)	Loss 8.2513 (7.1565)	Prec@1 0.000 (12.898)	Prec@5 15.625 (35.328)
Test on T test set - [4][1400/1731]	Time 0.166 (0.206)	Loss 8.4288 (7.1657)	Prec@1 0.000 (12.812)	Prec@5 0.000 (35.113)
Test on T test set - [4][1410/1731]	Time 0.166 (0.206)	Loss 7.7304 (7.1728)	Prec@1 0.000 (12.721)	Prec@5 18.750 (34.933)
Test on T test set - [4][1420/1731]	Time 0.153 (0.205)	Loss 8.4066 (7.1794)	Prec@1 0.000 (12.636)	Prec@5 15.625 (34.771)
Test on T test set - [4][1430/1731]	Time 0.205 (0.205)	Loss 9.1298 (7.1881)	Prec@1 0.000 (12.555)	Prec@5 6.250 (34.635)
Test on T test set - [4][1440/1731]	Time 0.253 (0.205)	Loss 8.8811 (7.2003)	Prec@1 0.000 (12.467)	Prec@5 9.375 (34.481)
Test on T test set - [4][1450/1731]	Time 0.233 (0.205)	Loss 8.4075 (7.2114)	Prec@1 0.000 (12.382)	Prec@5 28.125 (34.334)
Test on T test set - [4][1460/1731]	Time 0.230 (0.207)	Loss 8.5662 (7.2225)	Prec@1 0.000 (12.301)	Prec@5 15.625 (34.187)
Test on T test set - [4][1470/1731]	Time 0.232 (0.207)	Loss 8.4551 (7.2342)	Prec@1 0.000 (12.217)	Prec@5 18.750 (34.039)
Test on T test set - [4][1480/1731]	Time 0.235 (0.207)	Loss 8.9458 (7.2449)	Prec@1 0.000 (12.139)	Prec@5 15.625 (33.896)
Test on T test set - [4][1490/1731]	Time 0.221 (0.207)	Loss 9.1493 (7.2563)	Prec@1 0.000 (12.058)	Prec@5 15.625 (33.759)
Test on T test set - [4][1500/1731]	Time 0.237 (0.207)	Loss 9.3329 (7.2683)	Prec@1 0.000 (11.982)	Prec@5 6.250 (33.588)
Test on T test set - [4][1510/1731]	Time 0.226 (0.208)	Loss 8.7795 (7.2805)	Prec@1 0.000 (11.904)	Prec@5 12.500 (33.432)
Test on T test set - [4][1520/1731]	Time 0.223 (0.208)	Loss 8.5639 (7.2908)	Prec@1 0.000 (11.832)	Prec@5 12.500 (33.284)
Test on T test set - [4][1530/1731]	Time 0.204 (0.208)	Loss 9.2569 (7.3019)	Prec@1 0.000 (11.755)	Prec@5 15.625 (33.140)
Test on T test set - [4][1540/1731]	Time 0.185 (0.208)	Loss 9.0469 (7.3121)	Prec@1 0.000 (11.681)	Prec@5 9.375 (33.012)
Test on T test set - [4][1550/1731]	Time 0.232 (0.209)	Loss 9.0746 (7.3210)	Prec@1 3.125 (11.613)	Prec@5 9.375 (32.886)
Test on T test set - [4][1560/1731]	Time 0.186 (0.209)	Loss 8.1215 (7.3282)	Prec@1 0.000 (11.539)	Prec@5 59.375 (32.874)
Test on T test set - [4][1570/1731]	Time 0.184 (0.209)	Loss 7.4289 (7.3304)	Prec@1 0.000 (11.468)	Prec@5 75.000 (33.082)
Test on T test set - [4][1580/1731]	Time 0.159 (0.209)	Loss 7.2906 (7.3311)	Prec@1 0.000 (11.395)	Prec@5 81.250 (33.329)
Test on T test set - [4][1590/1731]	Time 0.160 (0.208)	Loss 7.0465 (7.3321)	Prec@1 0.000 (11.325)	Prec@5 71.875 (33.570)
Test on T test set - [4][1600/1731]	Time 0.181 (0.208)	Loss 7.5941 (7.3335)	Prec@1 0.000 (11.257)	Prec@5 68.750 (33.803)
Test on T test set - [4][1610/1731]	Time 0.183 (0.208)	Loss 7.3096 (7.3346)	Prec@1 0.000 (11.187)	Prec@5 56.250 (34.028)
Test on T test set - [4][1620/1731]	Time 0.187 (0.208)	Loss 8.0322 (7.3349)	Prec@1 0.000 (11.118)	Prec@5 62.500 (34.209)
Test on T test set - [4][1630/1731]	Time 0.176 (0.208)	Loss 6.8033 (7.3345)	Prec@1 0.000 (11.053)	Prec@5 78.125 (34.436)
Test on T test set - [4][1640/1731]	Time 0.224 (0.207)	Loss 7.6226 (7.3342)	Prec@1 0.000 (10.988)	Prec@5 59.375 (34.666)
Test on T test set - [4][1650/1731]	Time 0.215 (0.208)	Loss 7.4333 (7.3352)	Prec@1 0.000 (10.921)	Prec@5 78.125 (34.886)
Test on T test set - [4][1660/1731]	Time 0.208 (0.208)	Loss 7.6753 (7.3377)	Prec@1 0.000 (10.856)	Prec@5 84.375 (35.105)
Test on T test set - [4][1670/1731]	Time 0.203 (0.208)	Loss 7.8569 (7.3388)	Prec@1 0.000 (10.793)	Prec@5 62.500 (35.331)
Test on T test set - [4][1680/1731]	Time 0.191 (0.208)	Loss 7.4024 (7.3401)	Prec@1 0.000 (10.730)	Prec@5 59.375 (35.511)
Test on T test set - [4][1690/1731]	Time 0.219 (0.208)	Loss 7.4516 (7.3415)	Prec@1 0.000 (10.667)	Prec@5 81.250 (35.746)
Test on T test set - [4][1700/1731]	Time 0.215 (0.208)	Loss 7.3579 (7.3438)	Prec@1 0.000 (10.606)	Prec@5 75.000 (35.948)
Test on T test set - [4][1710/1731]	Time 0.229 (0.208)	Loss 8.0375 (7.3468)	Prec@1 0.000 (10.544)	Prec@5 68.750 (36.158)
Test on T test set - [4][1720/1731]	Time 0.201 (0.208)	Loss 7.7588 (7.3479)	Prec@1 0.000 (10.483)	Prec@5 78.125 (36.392)
Test on T test set - [4][1730/1731]	Time 0.166 (0.208)	Loss 7.8430 (7.3513)	Prec@1 0.000 (10.423)	Prec@5 85.714 (36.593)
 * Test on T test set - Prec@1 10.423, Prec@5 36.593
Epoch 4 - Kernel K-means clustering 0: Clustering time 71.307, Prec@1 9.865
Epoch 4 - Kernel K-means clustering 1: Clustering time 61.719, Prec@1 9.275
Epoch 4 - Kernel K-means clustering 2: Clustering time 56.147, Prec@1 8.587
Epoch 4 - Kernel K-means clustering 3: Clustering time 53.750, Prec@1 8.031
Epoch 4 - Kernel K-means clustering 4: Clustering time 51.394, Prec@1 7.641
Epoch 4 - Kernel K-means clustering 5: Clustering time 49.583, Prec@1 7.336
Epoch 4 - Kernel K-means clustering 6: Clustering time 51.358, Prec@1 7.187
Epoch 4 - Kernel K-means clustering 7: Clustering time 48.241, Prec@1 6.992
Epoch 4 - Kernel K-means clustering 8: Clustering time 47.676, Prec@1 6.821
Epoch 4 - Kernel K-means clustering 9: Clustering time 49.770, Prec@1 6.621
Epoch 4 - Kernel K-means clustering 10: Clustering time 46.972, Prec@1 6.478
Epoch 4 - Kernel K-means clustering 11: Clustering time 46.566, Prec@1 6.299
Epoch 4 - Kernel K-means clustering 12: Clustering time 46.397, Prec@1 6.180
Epoch 4 - Kernel K-means clustering 13: Clustering time 46.317, Prec@1 6.126
Epoch 4 - Kernel K-means clustering 14: Clustering time 46.516, Prec@1 6.115
Epoch 4 - Kernel K-means clustering 15: Clustering time 46.297, Prec@1 6.043
Epoch 4 - Kernel K-means clustering 16: Clustering time 47.680, Prec@1 5.960
Epoch 4 - Kernel K-means clustering 17: Clustering time 46.165, Prec@1 5.895
Epoch 4 - Kernel K-means clustering 18: Clustering time 46.298, Prec@1 5.835
Epoch 4 - Kernel K-means clustering 19: Clustering time 45.869, Prec@1 5.817
Epoch 4 - Kernel K-means clustering 20: Clustering time 45.889, Prec@1 5.805
Epoch 4 - Kernel K-means clustering 21: Clustering time 48.063, Prec@1 5.759
Epoch 4 - Kernel K-means clustering 22: Clustering time 46.220, Prec@1 5.712
Epoch 4 - Kernel K-means clustering 23: Clustering time 46.086, Prec@1 5.698
Epoch 4 - Kernel K-means clustering 24: Clustering time 46.099, Prec@1 5.673
Epoch 4 - Kernel K-means clustering 25: Clustering time 45.898, Prec@1 5.669
Epoch 4 - Kernel K-means clustering 26: Clustering time 46.056, Prec@1 5.647
Epoch 4 - Kernel K-means clustering 27: Clustering time 45.924, Prec@1 5.671
Epoch 4 - Kernel K-means clustering 28: Clustering time 47.700, Prec@1 5.653
Epoch 4 - Kernel K-means clustering 29: Clustering time 46.092, Prec@1 5.673
Epoch 4 - Kernel K-means clustering 30: Clustering time 46.085, Prec@1 5.642
Epoch 4 - Kernel K-means clustering 31: Clustering time 46.096, Prec@1 5.649
Epoch 4 - Kernel K-means clustering 32: Clustering time 47.927, Prec@1 5.638
Epoch 4 - Kernel K-means clustering 33: Clustering time 46.079, Prec@1 5.606
Epoch 4 - Kernel K-means clustering 34: Clustering time 45.987, Prec@1 5.568
Epoch 4 - Kernel K-means clustering 35: Clustering time 45.887, Prec@1 5.552
Epoch 4 - Kernel K-means clustering 36: Clustering time 46.077, Prec@1 5.499
Epoch 4 - Kernel K-means clustering 37: Clustering time 45.907, Prec@1 5.508
Epoch 4 - Kernel K-means clustering 38: Clustering time 48.159, Prec@1 5.485
Epoch 4 - Kernel K-means clustering 39: Clustering time 45.910, Prec@1 5.463
Epoch 4 - Kernel K-means clustering 40: Clustering time 45.873, Prec@1 5.460
Epoch 4 - Kernel K-means clustering 41: Clustering time 47.869, Prec@1 5.445
Epoch 4 - Kernel K-means clustering 42: Clustering time 47.816, Prec@1 5.452
Epoch 4 - Kernel K-means clustering 43: Clustering time 46.532, Prec@1 5.447
Epoch 4 - Kernel K-means clustering 44: Clustering time 45.538, Prec@1 5.445
Epoch 4 - Kernel K-means clustering 45: Clustering time 45.736, Prec@1 5.443
Epoch 4 - Kernel K-means clustering 46: Clustering time 46.016, Prec@1 5.406
Epoch 4 - Kernel K-means clustering 47: Clustering time 46.583, Prec@1 5.407
Epoch 4 - Kernel K-means clustering 48: Clustering time 46.501, Prec@1 5.396
Epoch 4 - Kernel K-means clustering 49: Clustering time 45.510, Prec@1 5.380
Epoch 4 - Kernel K-means clustering 50: Clustering time 45.653, Prec@1 5.351
Epoch 4 - Kernel K-means clustering 51: Clustering time 47.522, Prec@1 5.335
Epoch 4 - Kernel K-means clustering 52: Clustering time 45.471, Prec@1 5.322
Epoch 4 - Kernel K-means clustering 53: Clustering time 45.393, Prec@1 5.331
Epoch 4 - Kernel K-means clustering 54: Clustering time 46.607, Prec@1 5.341
Epoch 4 - Kernel K-means clustering 55: Clustering time 46.829, Prec@1 5.342
Epoch 4 - Kernel K-means clustering 56: Clustering time 48.147, Prec@1 5.326
Epoch 4 - Kernel K-means clustering 57: Clustering time 46.103, Prec@1 5.328
Epoch 4 - Kernel K-means clustering 58: Clustering time 45.771, Prec@1 5.312
Epoch 4 - Kernel K-means clustering 59: Clustering time 45.737, Prec@1 5.317
Epoch 4 - Kernel K-means clustering 60: Clustering time 45.620, Prec@1 5.315
Epoch 4 - Kernel K-means clustering 61: Clustering time 45.672, Prec@1 5.328
Epoch 4 - Kernel K-means clustering 62: Clustering time 45.632, Prec@1 5.331
Epoch 4 - Kernel K-means clustering 63: Clustering time 45.636, Prec@1 5.324
Epoch 4 - Kernel K-means clustering 64: Clustering time 45.763, Prec@1 5.328
Epoch 4 - Kernel K-means clustering 65: Clustering time 45.658, Prec@1 5.315
Epoch 4 - Kernel K-means clustering 66: Clustering time 47.898, Prec@1 5.312
Epoch 4 - Kernel K-means clustering 67: Clustering time 46.108, Prec@1 5.304
Epoch 4 - Kernel K-means clustering 68: Clustering time 46.037, Prec@1 5.315
Epoch 4 - Kernel K-means clustering 69: Clustering time 46.270, Prec@1 5.319
Epoch 4 - Kernel K-means clustering 70: Clustering time 45.777, Prec@1 5.324
Epoch 4 - Kernel K-means clustering 71: Clustering time 45.747, Prec@1 5.331
Epoch 4 - Kernel K-means clustering 72: Clustering time 45.660, Prec@1 5.330
Epoch 4 - Kernel K-means clustering 73: Clustering time 45.635, Prec@1 5.331
Epoch 4 - Kernel K-means clustering 74: Clustering time 45.639, Prec@1 5.333
Epoch 4 - Kernel K-means clustering 75: Clustering time 45.657, Prec@1 5.337
Epoch 4 - Kernel K-means clustering 76: Clustering time 45.598, Prec@1 5.341
Epoch 4 - Kernel K-means clustering 77: Clustering time 45.803, Prec@1 5.335
Epoch 4 - Kernel K-means clustering 78: Clustering time 45.667, Prec@1 5.330
Epoch 4 - Kernel K-means clustering 79: Clustering time 45.784, Prec@1 5.335
Epoch 4 - Kernel K-means clustering 80: Clustering time 45.692, Prec@1 5.341
Epoch 4 - Kernel K-means clustering 81: Clustering time 45.682, Prec@1 5.331
Epoch 4 - Kernel K-means clustering 82: Clustering time 45.723, Prec@1 5.333
Epoch 4 - Kernel K-means clustering 83: Clustering time 47.160, Prec@1 5.339
Epoch 4 - Kernel K-means clustering 84: Clustering time 45.613, Prec@1 5.337
Epoch 4 - Kernel K-means clustering 85: Clustering time 45.548, Prec@1 5.346
Epoch 4 - Kernel K-means clustering 86: Clustering time 45.587, Prec@1 5.341
Epoch 4 - Kernel K-means clustering 87: Clustering time 45.589, Prec@1 5.346
Epoch 4 - Kernel K-means clustering 88: Clustering time 45.540, Prec@1 5.344
Epoch 4 - Kernel K-means clustering 89: Clustering time 46.900, Prec@1 5.341
Epoch 4 - Kernel K-means clustering 90: Clustering time 45.613, Prec@1 5.346
Epoch 4 - Kernel K-means clustering 91: Clustering time 45.385, Prec@1 5.348
Epoch 4 - Kernel K-means clustering 92: Clustering time 45.618, Prec@1 5.350
Epoch 4 - Kernel K-means clustering 93: Clustering time 46.130, Prec@1 5.353
Epoch 4 - Kernel K-means clustering 94: Clustering time 45.588, Prec@1 5.359
Epoch 4 - Kernel K-means clustering 95: Clustering time 45.678, Prec@1 5.359
Epoch 4 - Kernel K-means clustering 96: Clustering time 45.358, Prec@1 5.360
Epoch 4 - Kernel K-means clustering 97: Clustering time 45.492, Prec@1 5.362
Epoch 4 - Kernel K-means clustering 98: Clustering time 45.798, Prec@1 5.362
Epoch 4 - Kernel K-means clustering 99: Clustering time 45.522, Prec@1 5.355
Epoch 4 - Kernel K-means clustering 0: Clustering time 68.254, Prec@1 10.298
Epoch 4 - Kernel K-means clustering 1: Clustering time 66.841, Prec@1 10.129
Epoch 4 - Kernel K-means clustering 2: Clustering time 63.891, Prec@1 9.554
Epoch 4 - Kernel K-means clustering 3: Clustering time 59.496, Prec@1 8.594
Epoch 4 - Kernel K-means clustering 4: Clustering time 54.936, Prec@1 7.939
Epoch 4 - Kernel K-means clustering 5: Clustering time 54.952, Prec@1 7.635
Epoch 4 - Kernel K-means clustering 6: Clustering time 51.370, Prec@1 7.543
Epoch 4 - Kernel K-means clustering 7: Clustering time 51.050, Prec@1 7.449
Epoch 4 - Kernel K-means clustering 8: Clustering time 50.338, Prec@1 7.384
Epoch 4 - Kernel K-means clustering 9: Clustering time 50.137, Prec@1 7.341
Epoch 4 - Kernel K-means clustering 10: Clustering time 50.528, Prec@1 7.336
Epoch 4 - Kernel K-means clustering 11: Clustering time 50.006, Prec@1 7.355
Epoch 4 - Kernel K-means clustering 12: Clustering time 50.212, Prec@1 7.336
Epoch 4 - Kernel K-means clustering 13: Clustering time 49.752, Prec@1 7.466
Epoch 4 - Kernel K-means clustering 14: Clustering time 49.337, Prec@1 7.561
Epoch 4 - Kernel K-means clustering 15: Clustering time 50.698, Prec@1 7.597
Epoch 4 - Kernel K-means clustering 16: Clustering time 48.569, Prec@1 7.650
Epoch 4 - Kernel K-means clustering 17: Clustering time 48.405, Prec@1 7.579
Epoch 4 - Kernel K-means clustering 18: Clustering time 47.883, Prec@1 7.603
Epoch 4 - Kernel K-means clustering 19: Clustering time 47.587, Prec@1 7.619
Epoch 4 - Kernel K-means clustering 20: Clustering time 47.363, Prec@1 7.666
Epoch 4 - Kernel K-means clustering 21: Clustering time 46.744, Prec@1 7.632
Epoch 4 - Kernel K-means clustering 22: Clustering time 45.804, Prec@1 7.641
Epoch 4 - Kernel K-means clustering 23: Clustering time 45.749, Prec@1 7.661
Epoch 4 - Kernel K-means clustering 24: Clustering time 45.823, Prec@1 7.662
Epoch 4 - Kernel K-means clustering 25: Clustering time 48.418, Prec@1 7.668
Epoch 4 - Kernel K-means clustering 26: Clustering time 45.887, Prec@1 7.684
Epoch 4 - Kernel K-means clustering 27: Clustering time 45.743, Prec@1 7.698
Epoch 4 - Kernel K-means clustering 28: Clustering time 45.699, Prec@1 7.736
Epoch 4 - Kernel K-means clustering 29: Clustering time 48.054, Prec@1 7.756
Epoch 4 - Kernel K-means clustering 30: Clustering time 45.822, Prec@1 7.753
Epoch 4 - Kernel K-means clustering 31: Clustering time 45.700, Prec@1 7.767
Epoch 4 - Kernel K-means clustering 32: Clustering time 45.703, Prec@1 7.781
Epoch 4 - Kernel K-means clustering 33: Clustering time 45.627, Prec@1 7.792
Epoch 4 - Kernel K-means clustering 34: Clustering time 48.304, Prec@1 7.789
Epoch 4 - Kernel K-means clustering 35: Clustering time 45.766, Prec@1 7.783
Epoch 4 - Kernel K-means clustering 36: Clustering time 45.652, Prec@1 7.789
Epoch 4 - Kernel K-means clustering 37: Clustering time 45.717, Prec@1 7.789
Epoch 4 - Kernel K-means clustering 38: Clustering time 47.202, Prec@1 7.790
Epoch 4 - Kernel K-means clustering 39: Clustering time 45.435, Prec@1 7.790
Epoch 4 - Kernel K-means clustering 40: Clustering time 45.620, Prec@1 7.792
Epoch 4 - Kernel K-means clustering 41: Clustering time 45.498, Prec@1 7.789
Epoch 4 - Kernel K-means clustering 42: Clustering time 45.401, Prec@1 7.794
Epoch 4 - Kernel K-means clustering 43: Clustering time 45.423, Prec@1 7.794
Epoch 4 - Kernel K-means clustering 44: Clustering time 45.475, Prec@1 7.792
Converged at iteration 45
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9398 (2.9398)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9309 (2.9309)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0175 (3.0175)
Train - epoch [5/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9158 (2.9158)
Train - epoch [5/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9175 (2.9175)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.8876 (2.8876)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.0061 (3.0061)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.9481 (2.9481)
Train - epoch [5/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0254 (3.0254)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0961 (3.0961)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1914 (3.1914)
Train - epoch [5/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.1360 (3.1360)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9645 (2.9645)
Train - epoch [5/200]	BT 1.393 (1.393)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.0107 (3.0107)
Train - epoch [5/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.1625 (3.1625)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9631 (2.9631)
Train - epoch [5/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0195 (3.0195)
Train - epoch [5/200]	BT 4.237 (4.237)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0385 (3.0385)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0831 (3.0831)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9735 (2.9735)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.1484 (3.1484)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0252 (3.0252)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9543 (2.9543)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9151 (2.9151)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9686 (2.9686)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0597 (3.0597)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.9494 (2.9494)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.1107 (3.1107)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.8873 (2.8873)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9967 (2.9967)
Train - epoch [5/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9433 (2.9433)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9317 (2.9317)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0154 (3.0154)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0592 (3.0592)
Train - epoch [5/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9463 (2.9463)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.8817 (2.8817)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0140 (3.0140)
Train - epoch [5/200]	BT 4.055 (4.055)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.9979 (2.9979)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0254 (3.0254)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0664 (3.0664)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9267 (2.9267)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.0024 (3.0024)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0023 (3.0023)
Train - epoch [5/200]	BT 4.547 (4.547)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0304 (3.0304)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9634 (2.9634)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9628 (2.9628)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.1451 (3.1451)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0088 (3.0088)
Train - epoch [5/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0117 (3.0117)
Train - epoch [5/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0788 (3.0788)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0121 (3.0121)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0929 (3.0929)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.1359 (3.1359)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.8760 (2.8760)
Train - epoch [5/200]	BT 1.240 (1.240)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0555 (3.0555)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0185 (3.0185)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9662 (2.9662)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0399 (3.0399)
Train - epoch [5/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0380 (3.0380)
Train - epoch [5/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9544 (2.9544)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.8737 (2.8737)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9777 (2.9777)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0584 (3.0584)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9583 (2.9583)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0387 (3.0387)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0576 (3.0576)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9163 (2.9163)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9702 (2.9702)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9210 (2.9210)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0337 (3.0337)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9294 (2.9294)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0815 (3.0815)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9221 (2.9221)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.9663 (2.9663)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0058 (3.0058)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9901 (2.9901)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0651 (3.0651)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9914 (2.9914)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9309 (2.9309)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9576 (2.9576)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0652 (3.0652)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9596 (2.9596)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9537 (2.9537)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9273 (2.9273)
Train - epoch [5/200]	BT 1.245 (1.245)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9125 (2.9125)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0064 (3.0064)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9988 (2.9988)
Train - epoch [5/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0042 (3.0042)
Train - epoch [5/200]	BT 3.824 (3.824)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.8713 (2.8713)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.8987 (2.8987)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9627 (2.9627)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.1581 (3.1581)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9915 (2.9915)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9812 (2.9812)
Train - epoch [5/200]	BT 3.668 (3.668)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0921 (3.0921)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0441 (3.0441)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.1183 (3.1183)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9822 (2.9822)
Train - epoch [5/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9920 (2.9920)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9254 (2.9254)
Train - epoch [5/200]	BT 4.043 (4.043)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1304 (3.1304)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0337 (3.0337)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9698 (2.9698)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9522 (2.9522)
Train - epoch [5/200]	BT 4.423 (4.423)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0047 (3.0047)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9779 (2.9779)
Train - epoch [5/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9532 (2.9532)
Train - epoch [5/200]	BT 3.895 (3.895)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9622 (2.9622)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.8419 (2.8419)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9788 (2.9788)
Train - epoch [5/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.1153 (3.1153)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9819 (2.9819)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9398 (2.9398)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9816 (2.9816)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.8463 (2.8463)
Train - epoch [5/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9275 (2.9275)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0806 (3.0806)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.0712 (3.0712)
Train - epoch [5/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 6.250 (6.250)	Loss 2.9828 (2.9828)
Train - epoch [5/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9539 (2.9539)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9535 (2.9535)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0331 (3.0331)
Train - epoch [5/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9218 (2.9218)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9524 (2.9524)
Train - epoch [5/200]	BT 1.237 (1.237)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.0263 (3.0263)
Train - epoch [5/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9545 (2.9545)
Train - epoch [5/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9356 (2.9356)
Train - epoch [5/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9735 (2.9735)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.0987 (3.0987)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9858 (2.9858)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0335 (3.0335)
Train - epoch [5/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9631 (2.9631)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.1741 (3.1741)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9521 (2.9521)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.9159 (2.9159)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9492 (2.9492)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 2.9274 (2.9274)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.0118 (3.0118)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0218 (3.0218)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9459 (2.9459)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0053 (3.0053)
Train - epoch [5/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0139 (3.0139)
Train - epoch [5/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9677 (2.9677)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.8940 (2.8940)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0686 (3.0686)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.8718 (2.8718)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9503 (2.9503)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0232 (3.0232)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.3250 (3.3250)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9356 (2.9356)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0132 (3.0132)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0244 (3.0244)
Train - epoch [5/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0202 (3.0202)
Train - epoch [5/200]	BT 1.244 (1.244)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9583 (2.9583)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9294 (2.9294)
Train - epoch [5/200]	BT 1.316 (1.316)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9601 (2.9601)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9325 (2.9325)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0304 (3.0304)
Train - epoch [5/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0130 (3.0130)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9148 (2.9148)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9955 (2.9955)
Train - epoch [5/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9348 (2.9348)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.8999 (2.8999)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9681 (2.9681)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9612 (2.9612)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0291 (3.0291)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9932 (2.9932)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.8722 (2.8722)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.1194 (3.1194)
Train - epoch [5/200]	BT 1.445 (1.445)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9757 (2.9757)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9884 (2.9884)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9383 (2.9383)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9169 (2.9169)
Train - epoch [5/200]	BT 1.377 (1.377)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9716 (2.9716)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0190 (3.0190)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.8842 (2.8842)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.8411 (2.8411)
Train - epoch [5/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0361 (3.0361)
Train - epoch [5/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 2.9136 (2.9136)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.1093 (3.1093)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.1062 (3.1062)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9472 (2.9472)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9959 (2.9959)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9697 (2.9697)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0541 (3.0541)
Train - epoch [5/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.1393 (3.1393)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0506 (3.0506)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9464 (2.9464)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0069 (3.0069)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9761 (2.9761)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0245 (3.0245)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.8998 (2.8998)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 2.9676 (2.9676)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9554 (2.9554)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9360 (2.9360)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9369 (2.9369)
Train - epoch [5/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0459 (3.0459)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9358 (2.9358)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9862 (2.9862)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0035 (3.0035)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9785 (2.9785)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9561 (2.9561)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.3610 (3.3610)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.4478 (3.4478)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.2366 (3.2366)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.3650 (3.3650)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3108 (3.3108)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.3816 (3.3816)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.1214 (3.1214)
Train - epoch [5/200]	BT 3.650 (3.650)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.1993 (3.1993)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.2499 (3.2499)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.0811 (3.0811)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.2194 (3.2194)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9814 (2.9814)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0386 (3.0386)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.0138 (3.0138)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9816 (2.9816)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.1914 (3.1914)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 2.9404 (2.9404)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0233 (3.0233)
Train - epoch [5/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.0237 (3.0237)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.1130 (3.1130)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9713 (2.9713)
Train - epoch [5/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9991 (2.9991)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9598 (2.9598)
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.1115 (3.1115)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0916 (3.0916)
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.0410 (3.0410)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9901 (2.9901)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9426 (2.9426)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.0603 (3.0603)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0551 (3.0551)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0447 (3.0447)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.1420 (3.1420)
Train - epoch [5/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.0052 (3.0052)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0204 (3.0204)
Train - epoch [5/200]	BT 3.688 (3.688)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.0102 (3.0102)
Train - epoch [5/200]	BT 1.245 (1.245)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9933 (2.9933)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1310 (3.1310)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 3.125 (3.125)	Loss 2.9969 (2.9969)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9252 (2.9252)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9771 (2.9771)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9710 (2.9710)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9152 (2.9152)
Train - epoch [5/200]	BT 1.513 (1.513)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9380 (2.9380)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0007 (3.0007)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.0834 (3.0834)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.1156 (3.1156)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.0534 (3.0534)
Train - epoch [5/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0155 (3.0155)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9383 (2.9383)
Train - epoch [5/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 6.250 (6.250)	Loss 2.9197 (2.9197)
Train - epoch [5/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9250 (2.9250)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0091 (3.0091)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.1270 (3.1270)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.1036 (3.1036)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9891 (2.9891)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9598 (2.9598)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9549 (2.9549)
Train - epoch [5/200]	BT 4.414 (4.414)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9887 (2.9887)
Train - epoch [5/200]	BT 1.240 (1.240)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9991 (2.9991)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9975 (2.9975)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9268 (2.9268)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0643 (3.0643)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9402 (2.9402)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0609 (3.0609)
Train - epoch [5/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.1229 (3.1229)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.0973 (3.0973)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9056 (2.9056)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.2489 (3.2489)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0227 (3.0227)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0917 (3.0917)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9638 (2.9638)
Train - epoch [5/200]	BT 3.827 (3.827)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9244 (2.9244)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.8933 (2.8933)
Train - epoch [5/200]	BT 1.238 (1.238)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0736 (3.0736)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9273 (2.9273)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0481 (3.0481)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.1764 (3.1764)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0896 (3.0896)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9999 (2.9999)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.0046 (3.0046)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0604 (3.0604)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9044 (2.9044)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.1626 (3.1626)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9623 (2.9623)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9497 (2.9497)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9839 (2.9839)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9290 (2.9290)
Train - epoch [5/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.0137 (3.0137)
Train - epoch [5/200]	BT 4.400 (4.400)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.1933 (3.1933)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9697 (2.9697)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.8776 (2.8776)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9664 (2.9664)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.8568 (2.8568)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.4408 (3.4408)
Train - epoch [5/200]	BT 4.448 (4.448)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9898 (2.9898)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9358 (2.9358)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 2.9996 (2.9996)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0042 (3.0042)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0647 (3.0647)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9594 (2.9594)
Train - epoch [5/200]	BT 4.406 (4.406)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0261 (3.0261)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9810 (2.9810)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1825 (3.1825)
Train - epoch [5/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9896 (2.9896)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0009 (3.0009)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9848 (2.9848)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0150 (3.0150)
Train - epoch [5/200]	BT 4.140 (4.140)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9511 (2.9511)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9863 (2.9863)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9682 (2.9682)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.8981 (2.8981)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0018 (3.0018)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9754 (2.9754)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9758 (2.9758)
Train - epoch [5/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.1519 (3.1519)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0351 (3.0351)
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.0275 (3.0275)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9954 (2.9954)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.9569 (2.9569)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9469 (2.9469)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9067 (2.9067)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9776 (2.9776)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9115 (2.9115)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.8793 (2.8793)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9014 (2.9014)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0241 (3.0241)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9765 (2.9765)
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.8552 (2.8552)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0286 (3.0286)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9974 (2.9974)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9263 (2.9263)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.8362 (2.8362)
Train - epoch [5/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9984 (2.9984)
Train - epoch [5/200]	BT 4.126 (4.126)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9563 (2.9563)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9192 (2.9192)
Train - epoch [5/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9150 (2.9150)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9753 (2.9753)
Train - epoch [5/200]	BT 4.420 (4.420)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9784 (2.9784)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9602 (2.9602)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0882 (3.0882)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.9770 (2.9770)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0011 (3.0011)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9082 (2.9082)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9301 (2.9301)
Train - epoch [5/200]	BT 1.351 (1.351)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.0934 (3.0934)
Train - epoch [5/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 6.250 (6.250)	Loss 2.9683 (2.9683)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9591 (2.9591)
Train - epoch [5/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9717 (2.9717)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9484 (2.9484)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.8954 (2.8954)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.8913 (2.8913)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9208 (2.9208)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.9818 (2.9818)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0921 (3.0921)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0410 (3.0410)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.9715 (2.9715)
Train - epoch [5/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.0159 (3.0159)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9649 (2.9649)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0216 (3.0216)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0091 (3.0091)
Train - epoch [5/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9581 (2.9581)
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0933 (3.0933)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0345 (3.0345)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0374 (3.0374)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.1825 (3.1825)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0172 (3.0172)
Train - epoch [5/200]	BT 1.318 (1.318)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9597 (2.9597)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.8978 (2.8978)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.1974 (3.1974)
Train - epoch [5/200]	BT 3.774 (3.774)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0532 (3.0532)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.8845 (2.8845)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9280 (2.9280)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9980 (2.9980)
Train - epoch [5/200]	BT 4.546 (4.546)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0572 (3.0572)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9151 (2.9151)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0028 (3.0028)
Train - epoch [5/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0296 (3.0296)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0983 (3.0983)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 2.8855 (2.8855)
Train - epoch [5/200]	BT 4.965 (4.965)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9325 (2.9325)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.1181 (3.1181)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.9330 (2.9330)
Train - epoch [5/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0006 (3.0006)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0457 (3.0457)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.0392 (3.0392)
Train - epoch [5/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9599 (2.9599)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9364 (2.9364)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0151 (3.0151)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0257 (3.0257)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9398 (2.9398)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.8836 (2.8836)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9549 (2.9549)
Train - epoch [5/200]	BT 1.314 (1.314)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9548 (2.9548)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9283 (2.9283)
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0396 (3.0396)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0804 (3.0804)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.8795 (2.8795)
Train - epoch [5/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 6.250 (6.250)	Loss 3.0210 (3.0210)
Train - epoch [5/200]	BT 4.070 (4.070)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9639 (2.9639)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9120 (2.9120)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9991 (2.9991)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0599 (3.0599)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0583 (3.0583)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.0761 (3.0761)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9449 (2.9449)
Train - epoch [5/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1018 (3.1018)
Train - epoch [5/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0304 (3.0304)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.1185 (3.1185)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9574 (2.9574)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 2.8935 (2.8935)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 2.9554 (2.9554)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9253 (2.9253)
Train - epoch [5/200]	BT 4.321 (4.321)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9675 (2.9675)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9687 (2.9687)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9441 (2.9441)
Train - epoch [5/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0049 (3.0049)
Train - epoch [5/200]	BT 1.243 (1.243)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0997 (3.0997)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9857 (2.9857)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0616 (3.0616)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.0262 (3.0262)
Train - epoch [5/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.2206 (3.2206)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.8994 (2.8994)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9263 (2.9263)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0331 (3.0331)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 2.9081 (2.9081)
Train - epoch [5/200]	BT 4.013 (4.013)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9823 (2.9823)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9877 (2.9877)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0410 (3.0410)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1326 (3.1326)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9634 (2.9634)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0308 (3.0308)
Train - epoch [5/200]	BT 3.668 (3.668)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9194 (2.9194)
Train - epoch [5/200]	BT 1.242 (1.242)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0705 (3.0705)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9854 (2.9854)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9728 (2.9728)
Train - epoch [5/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.0781 (3.0781)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.0103 (3.0103)
Train - epoch [5/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9621 (2.9621)
Train - epoch [5/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.8932 (2.8932)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.0840 (3.0840)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0427 (3.0427)
Train - epoch [5/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.0022 (3.0022)
Train - epoch [5/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9011 (2.9011)
Train - epoch [5/200]	BT 3.902 (3.902)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9608 (2.9608)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 2.9271 (2.9271)
Train - epoch [5/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9260 (2.9260)
Train - epoch [5/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0517 (3.0517)
Train - epoch [5/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9838 (2.9838)
Train - epoch [5/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.1017 (3.1017)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 2.9859 (2.9859)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9899 (2.9899)
Train - epoch [5/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.0530 (3.0530)
Train - epoch [5/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.3792 (3.3792)
Train - epoch [5/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9665 (2.9665)
Train - epoch [5/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9150 (2.9150)
Train - epoch [5/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9609 (2.9609)
Train - epoch [5/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.8722 (2.8722)
Train - epoch [5/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9003 (2.9003)
Train - epoch [5/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 2.9752 (2.9752)
Train - epoch [5/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9690 (2.9690)
Train - epoch [5/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.1067 (3.1067)
Train - epoch [5/200]	BT 1.244 (1.244)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9528 (2.9528)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.1534 (3.1534)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.0796 (3.0796)
Train - epoch [5/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9455 (2.9455)
Train - epoch [5/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1959 (3.1959)
Train - epoch [5/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 2.9697 (2.9697)
Train - epoch [5/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 2.9470 (2.9470)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.0881 (3.0881)
Train - epoch [5/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 2.9865 (2.9865)
Train - epoch [5/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 2.8975 (2.8975)
Train - epoch [5/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.1010 (3.1010)
Train - epoch [5/200]	BT 3.898 (3.898)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 2.9222 (2.9222)
Train - epoch [5/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 2.9294 (2.9294)
Train - epoch [5/200]	BT 1.221 (1.221)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.1455 (3.1455)
Test on T training set - [5][0/1731]	T 0.291 (0.291)	D 0.187 (0.187)	T@1 0.000 (0.000)	T@5 37.500 (37.500)	L 4.2812 (4.2812)
Test on T training set - [5][10/1731]	T 0.202 (0.210)	D 0.101 (0.108)	T@1 3.125 (1.705)	T@5 50.000 (38.920)	L 4.1096 (4.5460)
Test on T training set - [5][20/1731]	T 0.225 (0.213)	D 0.120 (0.113)	T@1 0.000 (2.232)	T@5 37.500 (35.863)	L 4.7271 (4.5785)
Test on T training set - [5][30/1731]	T 0.204 (0.306)	D 0.102 (0.204)	T@1 3.125 (1.915)	T@5 46.875 (36.996)	L 4.2565 (4.5445)
Test on T training set - [5][40/1731]	T 0.217 (0.283)	D 0.117 (0.181)	T@1 0.000 (2.363)	T@5 31.250 (37.805)	L 4.3762 (4.5242)
Test on T training set - [5][50/1731]	T 0.215 (0.269)	D 0.112 (0.167)	T@1 3.125 (2.451)	T@5 40.625 (37.010)	L 4.7852 (4.4998)
Test on T training set - [5][60/1731]	T 0.211 (0.259)	D 0.116 (0.158)	T@1 0.000 (2.254)	T@5 34.375 (37.807)	L 4.6706 (4.4875)
Test on T training set - [5][70/1731]	T 0.199 (0.251)	D 0.101 (0.150)	T@1 0.000 (2.289)	T@5 34.375 (37.764)	L 4.7889 (4.5014)
Test on T training set - [5][80/1731]	T 0.193 (0.246)	D 0.085 (0.144)	T@1 6.250 (2.392)	T@5 31.250 (37.616)	L 4.3010 (4.5005)
Test on T training set - [5][90/1731]	T 0.189 (0.240)	D 0.081 (0.139)	T@1 0.000 (2.438)	T@5 37.500 (37.225)	L 4.5889 (4.4966)
Test on T training set - [5][100/1731]	T 0.182 (0.235)	D 0.087 (0.134)	T@1 3.125 (2.537)	T@5 31.250 (37.748)	L 4.4329 (4.4791)
Test on T training set - [5][110/1731]	T 0.204 (0.230)	D 0.099 (0.129)	T@1 3.125 (2.675)	T@5 28.125 (37.810)	L 4.4844 (4.4573)
Test on T training set - [5][120/1731]	T 0.197 (0.237)	D 0.090 (0.136)	T@1 0.000 (2.531)	T@5 53.125 (38.998)	L 3.8114 (4.4118)
Test on T training set - [5][130/1731]	T 0.191 (0.234)	D 0.087 (0.132)	T@1 3.125 (2.409)	T@5 65.625 (40.816)	L 3.6701 (4.3594)
Test on T training set - [5][140/1731]	T 0.180 (0.230)	D 0.074 (0.129)	T@1 3.125 (2.283)	T@5 59.375 (42.332)	L 4.0450 (4.3161)
Test on T training set - [5][150/1731]	T 0.188 (0.227)	D 0.093 (0.125)	T@1 0.000 (2.132)	T@5 68.750 (43.543)	L 3.7945 (4.2769)
Test on T training set - [5][160/1731]	T 0.183 (0.224)	D 0.082 (0.123)	T@1 0.000 (2.038)	T@5 37.500 (44.526)	L 3.7812 (4.2407)
Test on T training set - [5][170/1731]	T 0.170 (0.221)	D 0.075 (0.120)	T@1 0.000 (1.937)	T@5 71.875 (45.705)	L 3.4453 (4.2070)
Test on T training set - [5][180/1731]	T 0.161 (0.218)	D 0.055 (0.117)	T@1 0.000 (1.865)	T@5 68.750 (46.806)	L 4.4518 (4.1885)
Test on T training set - [5][190/1731]	T 0.179 (0.215)	D 0.079 (0.114)	T@1 0.000 (1.767)	T@5 62.500 (47.677)	L 4.1128 (4.1641)
Test on T training set - [5][200/1731]	T 0.155 (0.212)	D 0.060 (0.111)	T@1 0.000 (1.710)	T@5 56.250 (48.336)	L 4.0156 (4.1528)
Test on T training set - [5][210/1731]	T 0.175 (0.210)	D 0.069 (0.109)	T@1 0.000 (1.629)	T@5 59.375 (48.786)	L 3.6239 (4.1437)
Test on T training set - [5][220/1731]	T 0.178 (0.209)	D 0.074 (0.107)	T@1 3.125 (1.612)	T@5 68.750 (49.463)	L 3.7169 (4.1305)
Test on T training set - [5][230/1731]	T 0.178 (0.207)	D 0.074 (0.106)	T@1 34.375 (2.922)	T@5 90.625 (51.231)	L 2.5436 (4.0581)
Test on T training set - [5][240/1731]	T 0.232 (0.214)	D 0.125 (0.113)	T@1 21.875 (3.929)	T@5 87.500 (52.801)	L 2.7875 (3.9988)
Test on T training set - [5][250/1731]	T 0.189 (0.214)	D 0.094 (0.113)	T@1 34.375 (5.080)	T@5 93.750 (54.345)	L 2.5042 (3.9371)
Test on T training set - [5][260/1731]	T 0.229 (0.215)	D 0.124 (0.113)	T@1 21.875 (5.963)	T@5 81.250 (55.699)	L 2.8886 (3.8856)
Test on T training set - [5][270/1731]	T 0.223 (0.215)	D 0.125 (0.113)	T@1 21.875 (6.527)	T@5 84.375 (56.861)	L 2.3192 (3.8410)
Test on T training set - [5][280/1731]	T 0.216 (0.215)	D 0.118 (0.113)	T@1 31.250 (7.351)	T@5 87.500 (57.985)	L 2.4122 (3.7920)
Test on T training set - [5][290/1731]	T 0.219 (0.215)	D 0.123 (0.113)	T@1 15.625 (8.022)	T@5 87.500 (59.160)	L 2.6325 (3.7474)
Test on T training set - [5][300/1731]	T 0.212 (0.215)	D 0.108 (0.113)	T@1 37.500 (8.846)	T@5 93.750 (60.206)	L 2.1945 (3.7031)
Test on T training set - [5][310/1731]	T 0.210 (0.215)	D 0.107 (0.113)	T@1 28.125 (9.616)	T@5 90.625 (61.224)	L 2.8803 (3.6602)
Test on T training set - [5][320/1731]	T 0.199 (0.220)	D 0.095 (0.118)	T@1 40.625 (10.290)	T@5 87.500 (62.150)	L 2.2746 (3.6219)
Test on T training set - [5][330/1731]	T 0.202 (0.219)	D 0.096 (0.117)	T@1 28.125 (10.914)	T@5 90.625 (63.019)	L 2.4240 (3.5846)
Test on T training set - [5][340/1731]	T 0.190 (0.218)	D 0.089 (0.116)	T@1 37.500 (11.574)	T@5 90.625 (63.893)	L 2.0152 (3.5468)
Test on T training set - [5][350/1731]	T 0.194 (0.217)	D 0.098 (0.115)	T@1 25.000 (12.197)	T@5 84.375 (64.699)	L 2.4825 (3.5119)
Test on T training set - [5][360/1731]	T 0.230 (0.217)	D 0.125 (0.116)	T@1 25.000 (12.725)	T@5 81.250 (65.461)	L 2.5329 (3.4817)
Test on T training set - [5][370/1731]	T 0.178 (0.217)	D 0.074 (0.115)	T@1 9.375 (12.963)	T@5 68.750 (65.970)	L 3.7864 (3.4610)
Test on T training set - [5][380/1731]	T 0.187 (0.215)	D 0.081 (0.114)	T@1 15.625 (12.910)	T@5 71.875 (65.937)	L 3.7460 (3.4697)
Test on T training set - [5][390/1731]	T 0.170 (0.214)	D 0.065 (0.113)	T@1 21.875 (12.956)	T@5 68.750 (66.049)	L 3.5069 (3.4745)
Test on T training set - [5][400/1731]	T 0.154 (0.213)	D 0.049 (0.112)	T@1 9.375 (12.882)	T@5 71.875 (66.038)	L 3.7743 (3.4849)
Test on T training set - [5][410/1731]	T 0.170 (0.212)	D 0.065 (0.111)	T@1 3.125 (12.766)	T@5 62.500 (66.005)	L 4.3584 (3.4973)
Test on T training set - [5][420/1731]	T 0.153 (0.211)	D 0.058 (0.109)	T@1 9.375 (12.663)	T@5 62.500 (65.966)	L 4.3163 (3.5088)
Test on T training set - [5][430/1731]	T 0.168 (0.215)	D 0.062 (0.113)	T@1 18.750 (12.660)	T@5 59.375 (66.024)	L 3.7189 (3.5174)
Test on T training set - [5][440/1731]	T 0.148 (0.213)	D 0.053 (0.112)	T@1 15.625 (12.606)	T@5 75.000 (66.100)	L 3.6776 (3.5252)
Test on T training set - [5][450/1731]	T 0.157 (0.212)	D 0.060 (0.111)	T@1 6.250 (12.555)	T@5 68.750 (66.103)	L 3.6986 (3.5295)
Test on T training set - [5][460/1731]	T 0.158 (0.211)	D 0.063 (0.110)	T@1 3.125 (12.520)	T@5 59.375 (66.228)	L 3.8746 (3.5295)
Test on T training set - [5][470/1731]	T 0.162 (0.210)	D 0.056 (0.109)	T@1 18.750 (12.546)	T@5 71.875 (66.302)	L 3.4217 (3.5305)
Test on T training set - [5][480/1731]	T 0.160 (0.209)	D 0.057 (0.108)	T@1 9.375 (12.435)	T@5 71.875 (66.385)	L 3.9855 (3.5387)
Test on T training set - [5][490/1731]	T 0.157 (0.208)	D 0.055 (0.107)	T@1 0.000 (12.335)	T@5 65.625 (66.433)	L 4.1937 (3.5436)
Test on T training set - [5][500/1731]	T 0.168 (0.207)	D 0.072 (0.106)	T@1 6.250 (12.282)	T@5 78.125 (66.342)	L 3.1107 (3.5488)
Test on T training set - [5][510/1731]	T 0.160 (0.206)	D 0.062 (0.105)	T@1 0.000 (12.194)	T@5 75.000 (66.371)	L 4.1535 (3.5584)
Test on T training set - [5][520/1731]	T 0.153 (0.205)	D 0.051 (0.104)	T@1 3.125 (12.128)	T@5 56.250 (66.339)	L 4.6637 (3.5699)
Test on T training set - [5][530/1731]	T 0.166 (0.205)	D 0.069 (0.103)	T@1 3.125 (12.041)	T@5 62.500 (66.308)	L 4.5589 (3.5821)
Test on T training set - [5][540/1731]	T 0.154 (0.208)	D 0.059 (0.107)	T@1 3.125 (11.940)	T@5 65.625 (66.364)	L 4.0312 (3.5931)
Test on T training set - [5][550/1731]	T 0.152 (0.207)	D 0.050 (0.106)	T@1 6.250 (11.831)	T@5 75.000 (66.362)	L 4.2511 (3.6042)
Test on T training set - [5][560/1731]	T 0.159 (0.207)	D 0.058 (0.105)	T@1 6.250 (11.748)	T@5 68.750 (66.383)	L 3.9774 (3.6141)
Test on T training set - [5][570/1731]	T 0.187 (0.206)	D 0.085 (0.105)	T@1 9.375 (11.695)	T@5 62.500 (66.419)	L 4.0274 (3.6201)
Test on T training set - [5][580/1731]	T 0.171 (0.205)	D 0.066 (0.104)	T@1 9.375 (11.672)	T@5 59.375 (66.502)	L 4.2468 (3.6236)
Test on T training set - [5][590/1731]	T 0.167 (0.205)	D 0.066 (0.103)	T@1 6.250 (11.643)	T@5 56.250 (66.513)	L 4.1858 (3.6288)
Test on T training set - [5][600/1731]	T 0.168 (0.204)	D 0.063 (0.103)	T@1 12.500 (11.647)	T@5 68.750 (66.571)	L 3.5463 (3.6323)
Test on T training set - [5][610/1731]	T 0.149 (0.203)	D 0.054 (0.102)	T@1 3.125 (11.615)	T@5 81.250 (66.689)	L 3.9228 (3.6349)
Test on T training set - [5][620/1731]	T 0.172 (0.203)	D 0.077 (0.102)	T@1 9.375 (11.614)	T@5 81.250 (66.782)	L 3.3159 (3.6358)
Test on T training set - [5][630/1731]	T 0.157 (0.202)	D 0.053 (0.101)	T@1 9.375 (11.599)	T@5 68.750 (66.828)	L 3.7188 (3.6398)
Test on T training set - [5][640/1731]	T 0.157 (0.206)	D 0.052 (0.105)	T@1 12.500 (11.574)	T@5 71.875 (66.819)	L 3.6973 (3.6428)
Test on T training set - [5][650/1731]	T 0.160 (0.205)	D 0.058 (0.104)	T@1 3.125 (11.516)	T@5 62.500 (66.916)	L 4.5540 (3.6476)
Test on T training set - [5][660/1731]	T 0.173 (0.205)	D 0.067 (0.103)	T@1 15.625 (11.474)	T@5 75.000 (66.949)	L 3.8048 (3.6537)
Test on T training set - [5][670/1731]	T 0.173 (0.204)	D 0.067 (0.103)	T@1 18.750 (11.485)	T@5 75.000 (67.013)	L 3.4190 (3.6577)
Test on T training set - [5][680/1731]	T 0.167 (0.203)	D 0.060 (0.102)	T@1 28.125 (11.454)	T@5 75.000 (67.066)	L 3.2023 (3.6623)
Test on T training set - [5][690/1731]	T 0.211 (0.203)	D 0.116 (0.101)	T@1 6.250 (11.378)	T@5 62.500 (66.991)	L 3.2223 (3.6641)
Test on T training set - [5][700/1731]	T 0.157 (0.202)	D 0.050 (0.101)	T@1 0.000 (11.247)	T@5 0.000 (66.267)	L 5.5556 (3.6780)
Test on T training set - [5][710/1731]	T 0.173 (0.202)	D 0.067 (0.101)	T@1 0.000 (11.089)	T@5 0.000 (65.339)	L 5.0810 (3.6973)
Test on T training set - [5][720/1731]	T 0.169 (0.202)	D 0.060 (0.100)	T@1 0.000 (10.935)	T@5 0.000 (64.433)	L 5.1601 (3.7154)
Test on T training set - [5][730/1731]	T 0.203 (0.201)	D 0.098 (0.100)	T@1 0.000 (10.790)	T@5 0.000 (63.560)	L 4.8925 (3.7335)
Test on T training set - [5][740/1731]	T 0.207 (0.205)	D 0.108 (0.104)	T@1 0.000 (10.644)	T@5 3.125 (62.707)	L 4.9461 (3.7498)
Test on T training set - [5][750/1731]	T 0.185 (0.205)	D 0.085 (0.104)	T@1 0.000 (10.503)	T@5 0.000 (61.872)	L 4.7218 (3.7657)
Test on T training set - [5][760/1731]	T 0.232 (0.205)	D 0.127 (0.104)	T@1 0.000 (10.365)	T@5 0.000 (61.059)	L 4.8925 (3.7811)
Test on T training set - [5][770/1731]	T 0.208 (0.205)	D 0.101 (0.104)	T@1 0.000 (10.234)	T@5 0.000 (60.271)	L 5.0467 (3.7960)
Test on T training set - [5][780/1731]	T 0.216 (0.205)	D 0.120 (0.104)	T@1 0.000 (10.103)	T@5 0.000 (59.499)	L 5.0061 (3.8114)
Test on T training set - [5][790/1731]	T 0.200 (0.205)	D 0.104 (0.104)	T@1 0.000 (9.976)	T@5 0.000 (58.747)	L 5.0578 (3.8253)
Test on T training set - [5][800/1731]	T 0.197 (0.205)	D 0.094 (0.104)	T@1 0.000 (9.851)	T@5 0.000 (58.017)	L 4.9795 (3.8396)
Test on T training set - [5][810/1731]	T 0.188 (0.205)	D 0.093 (0.104)	T@1 0.000 (9.730)	T@5 3.125 (57.306)	L 4.8173 (3.8543)
Test on T training set - [5][820/1731]	T 0.203 (0.205)	D 0.100 (0.104)	T@1 0.000 (9.611)	T@5 0.000 (56.608)	L 4.7434 (3.8687)
Test on T training set - [5][830/1731]	T 0.183 (0.205)	D 0.076 (0.103)	T@1 0.000 (9.495)	T@5 0.000 (55.927)	L 4.7629 (3.8819)
Test on T training set - [5][840/1731]	T 0.168 (0.207)	D 0.064 (0.106)	T@1 3.125 (9.386)	T@5 6.250 (55.269)	L 4.8907 (3.8947)
Test on T training set - [5][850/1731]	T 0.155 (0.207)	D 0.049 (0.105)	T@1 12.500 (9.364)	T@5 31.250 (54.990)	L 4.1004 (3.9002)
Test on T training set - [5][860/1731]	T 0.159 (0.206)	D 0.056 (0.104)	T@1 12.500 (9.357)	T@5 31.250 (54.689)	L 3.8366 (3.9046)
Test on T training set - [5][870/1731]	T 0.152 (0.205)	D 0.053 (0.104)	T@1 3.125 (9.325)	T@5 28.125 (54.474)	L 4.5999 (3.9074)
Test on T training set - [5][880/1731]	T 0.165 (0.205)	D 0.060 (0.103)	T@1 3.125 (9.297)	T@5 37.500 (54.207)	L 4.3239 (3.9116)
Test on T training set - [5][890/1731]	T 0.169 (0.205)	D 0.061 (0.103)	T@1 6.250 (9.256)	T@5 15.625 (53.904)	L 4.7852 (3.9163)
Test on T training set - [5][900/1731]	T 0.153 (0.204)	D 0.057 (0.102)	T@1 3.125 (9.219)	T@5 28.125 (53.656)	L 4.6723 (3.9212)
Test on T training set - [5][910/1731]	T 0.159 (0.204)	D 0.064 (0.102)	T@1 3.125 (9.155)	T@5 6.250 (53.273)	L 4.3924 (3.9262)
Test on T training set - [5][920/1731]	T 0.149 (0.203)	D 0.054 (0.102)	T@1 3.125 (9.087)	T@5 6.250 (52.759)	L 4.1387 (3.9321)
Test on T training set - [5][930/1731]	T 0.215 (0.203)	D 0.120 (0.102)	T@1 6.250 (9.043)	T@5 15.625 (52.333)	L 4.2984 (3.9353)
Test on T training set - [5][940/1731]	T 0.235 (0.204)	D 0.134 (0.102)	T@1 0.000 (8.973)	T@5 15.625 (51.943)	L 4.3044 (3.9388)
Test on T training set - [5][950/1731]	T 0.226 (0.204)	D 0.124 (0.102)	T@1 0.000 (8.945)	T@5 15.625 (51.607)	L 4.2702 (3.9406)
Test on T training set - [5][960/1731]	T 0.209 (0.204)	D 0.101 (0.102)	T@1 3.125 (8.923)	T@5 12.500 (51.258)	L 4.4256 (3.9433)
Test on T training set - [5][970/1731]	T 0.212 (0.204)	D 0.107 (0.102)	T@1 6.250 (8.895)	T@5 18.750 (50.901)	L 3.9018 (3.9457)
Test on T training set - [5][980/1731]	T 0.192 (0.204)	D 0.096 (0.102)	T@1 9.375 (8.856)	T@5 15.625 (50.551)	L 4.5850 (3.9479)
Test on T training set - [5][990/1731]	T 0.220 (0.204)	D 0.116 (0.103)	T@1 6.250 (8.823)	T@5 25.000 (50.189)	L 3.9553 (3.9513)
Test on T training set - [5][1000/1731]	T 0.211 (0.204)	D 0.116 (0.103)	T@1 3.125 (8.801)	T@5 9.375 (49.869)	L 4.1522 (3.9527)
Test on T training set - [5][1010/1731]	T 0.189 (0.204)	D 0.093 (0.102)	T@1 6.250 (8.794)	T@5 12.500 (49.561)	L 4.4803 (3.9553)
Test on T training set - [5][1020/1731]	T 0.182 (0.204)	D 0.087 (0.102)	T@1 12.500 (8.757)	T@5 21.875 (49.226)	L 3.9559 (3.9576)
Test on T training set - [5][1030/1731]	T 0.160 (0.204)	D 0.057 (0.102)	T@1 6.250 (8.723)	T@5 12.500 (48.863)	L 4.3334 (3.9608)
Test on T training set - [5][1040/1731]	T 0.171 (0.203)	D 0.065 (0.102)	T@1 3.125 (8.685)	T@5 9.375 (48.514)	L 4.4000 (3.9645)
Test on T training set - [5][1050/1731]	T 0.175 (0.205)	D 0.067 (0.104)	T@1 3.125 (8.632)	T@5 12.500 (48.121)	L 4.6087 (3.9706)
Test on T training set - [5][1060/1731]	T 0.156 (0.205)	D 0.056 (0.103)	T@1 9.375 (8.580)	T@5 12.500 (47.729)	L 4.2029 (3.9773)
Test on T training set - [5][1070/1731]	T 0.188 (0.204)	D 0.087 (0.103)	T@1 3.125 (8.549)	T@5 9.375 (47.377)	L 4.4102 (3.9820)
Test on T training set - [5][1080/1731]	T 0.149 (0.204)	D 0.054 (0.103)	T@1 9.375 (8.537)	T@5 9.375 (47.069)	L 4.5605 (3.9842)
Test on T training set - [5][1090/1731]	T 0.171 (0.204)	D 0.065 (0.102)	T@1 9.375 (8.559)	T@5 28.125 (46.835)	L 4.1629 (3.9855)
Test on T training set - [5][1100/1731]	T 0.174 (0.204)	D 0.079 (0.102)	T@1 6.250 (8.623)	T@5 18.750 (46.651)	L 4.1240 (3.9856)
Test on T training set - [5][1110/1731]	T 0.198 (0.204)	D 0.102 (0.102)	T@1 15.625 (8.658)	T@5 37.500 (46.459)	L 3.5892 (3.9858)
Test on T training set - [5][1120/1731]	T 0.173 (0.203)	D 0.078 (0.102)	T@1 18.750 (8.678)	T@5 28.125 (46.290)	L 3.8362 (3.9864)
Test on T training set - [5][1130/1731]	T 0.171 (0.203)	D 0.076 (0.102)	T@1 15.625 (8.734)	T@5 21.875 (46.135)	L 4.3329 (3.9869)
Test on T training set - [5][1140/1731]	T 0.192 (0.203)	D 0.086 (0.102)	T@1 9.375 (8.770)	T@5 28.125 (45.966)	L 3.8076 (3.9872)
Test on T training set - [5][1150/1731]	T 0.168 (0.203)	D 0.070 (0.101)	T@1 9.375 (8.827)	T@5 28.125 (45.832)	L 3.9737 (3.9861)
Test on T training set - [5][1160/1731]	T 0.171 (0.203)	D 0.067 (0.101)	T@1 9.375 (8.864)	T@5 21.875 (45.685)	L 4.6116 (3.9863)
Test on T training set - [5][1170/1731]	T 0.175 (0.203)	D 0.068 (0.102)	T@1 6.250 (8.903)	T@5 25.000 (45.519)	L 4.2991 (3.9866)
Test on T training set - [5][1180/1731]	T 0.184 (0.203)	D 0.082 (0.102)	T@1 12.500 (8.968)	T@5 34.375 (45.380)	L 3.7296 (3.9854)
Test on T training set - [5][1190/1731]	T 0.185 (0.203)	D 0.084 (0.101)	T@1 6.250 (8.981)	T@5 37.500 (45.217)	L 4.2219 (3.9870)
Test on T training set - [5][1200/1731]	T 0.172 (0.203)	D 0.065 (0.101)	T@1 31.250 (9.029)	T@5 37.500 (45.059)	L 3.5427 (3.9879)
Test on T training set - [5][1210/1731]	T 0.181 (0.203)	D 0.086 (0.101)	T@1 9.375 (9.060)	T@5 31.250 (44.914)	L 3.9944 (3.9890)
Test on T training set - [5][1220/1731]	T 0.165 (0.202)	D 0.063 (0.101)	T@1 0.000 (8.996)	T@5 18.750 (44.648)	L 4.9244 (3.9938)
Test on T training set - [5][1230/1731]	T 0.153 (0.202)	D 0.055 (0.100)	T@1 0.000 (8.926)	T@5 15.625 (44.372)	L 4.8385 (4.0006)
Test on T training set - [5][1240/1731]	T 0.173 (0.202)	D 0.067 (0.100)	T@1 0.000 (8.854)	T@5 9.375 (44.110)	L 4.4649 (4.0066)
Test on T training set - [5][1250/1731]	T 0.180 (0.201)	D 0.084 (0.100)	T@1 0.000 (8.785)	T@5 15.625 (43.865)	L 4.0871 (4.0102)
Test on T training set - [5][1260/1731]	T 0.183 (0.201)	D 0.076 (0.100)	T@1 0.000 (8.718)	T@5 3.125 (43.619)	L 4.5692 (4.0146)
Test on T training set - [5][1270/1731]	T 0.186 (0.203)	D 0.080 (0.102)	T@1 0.000 (8.652)	T@5 9.375 (43.371)	L 4.3611 (4.0191)
Test on T training set - [5][1280/1731]	T 0.182 (0.203)	D 0.087 (0.101)	T@1 3.125 (8.589)	T@5 15.625 (43.121)	L 4.3606 (4.0229)
Test on T training set - [5][1290/1731]	T 0.161 (0.203)	D 0.065 (0.101)	T@1 0.000 (8.528)	T@5 12.500 (42.891)	L 4.6650 (4.0273)
Test on T training set - [5][1300/1731]	T 0.174 (0.202)	D 0.072 (0.101)	T@1 0.000 (8.465)	T@5 9.375 (42.679)	L 4.3625 (4.0306)
Test on T training set - [5][1310/1731]	T 0.191 (0.202)	D 0.082 (0.101)	T@1 0.000 (8.400)	T@5 21.875 (42.484)	L 4.6273 (4.0335)
Test on T training set - [5][1320/1731]	T 0.185 (0.202)	D 0.089 (0.101)	T@1 3.125 (8.339)	T@5 15.625 (42.267)	L 4.2873 (4.0365)
Test on T training set - [5][1330/1731]	T 0.159 (0.202)	D 0.057 (0.100)	T@1 0.000 (8.276)	T@5 18.750 (42.045)	L 4.5381 (4.0397)
Test on T training set - [5][1340/1731]	T 0.169 (0.201)	D 0.062 (0.100)	T@1 0.000 (8.217)	T@5 6.250 (41.816)	L 4.3984 (4.0434)
Test on T training set - [5][1350/1731]	T 0.170 (0.201)	D 0.067 (0.100)	T@1 0.000 (8.156)	T@5 18.750 (41.606)	L 4.2577 (4.0467)
Test on T training set - [5][1360/1731]	T 0.160 (0.201)	D 0.056 (0.099)	T@1 0.000 (8.098)	T@5 43.750 (41.532)	L 4.1124 (4.0484)
Test on T training set - [5][1370/1731]	T 0.149 (0.202)	D 0.047 (0.101)	T@1 0.000 (8.044)	T@5 40.625 (41.546)	L 3.9882 (4.0477)
Test on T training set - [5][1380/1731]	T 0.161 (0.202)	D 0.059 (0.100)	T@1 0.000 (7.990)	T@5 34.375 (41.526)	L 3.9257 (4.0476)
Test on T training set - [5][1390/1731]	T 0.167 (0.202)	D 0.069 (0.100)	T@1 0.000 (7.937)	T@5 40.625 (41.573)	L 4.3554 (4.0461)
Test on T training set - [5][1400/1731]	T 0.173 (0.201)	D 0.066 (0.100)	T@1 0.000 (7.889)	T@5 37.500 (41.577)	L 3.8378 (4.0458)
Test on T training set - [5][1410/1731]	T 0.165 (0.201)	D 0.069 (0.100)	T@1 3.125 (7.840)	T@5 62.500 (41.624)	L 4.0602 (4.0451)
Test on T training set - [5][1420/1731]	T 0.157 (0.201)	D 0.055 (0.099)	T@1 0.000 (7.792)	T@5 50.000 (41.661)	L 4.0420 (4.0440)
Test on T training set - [5][1430/1731]	T 0.202 (0.201)	D 0.097 (0.099)	T@1 21.875 (7.803)	T@5 96.875 (41.883)	L 2.6154 (4.0403)
Test on T training set - [5][1440/1731]	T 0.244 (0.201)	D 0.135 (0.099)	T@1 12.500 (7.840)	T@5 100.000 (42.269)	L 3.1547 (4.0325)
Test on T training set - [5][1450/1731]	T 0.232 (0.201)	D 0.131 (0.100)	T@1 3.125 (7.870)	T@5 96.875 (42.639)	L 3.3183 (4.0264)
Test on T training set - [5][1460/1731]	T 0.214 (0.201)	D 0.119 (0.100)	T@1 12.500 (7.903)	T@5 100.000 (43.018)	L 2.9140 (4.0195)
Test on T training set - [5][1470/1731]	T 0.224 (0.201)	D 0.121 (0.100)	T@1 9.375 (7.937)	T@5 96.875 (43.385)	L 2.8024 (4.0120)
Test on T training set - [5][1480/1731]	T 0.246 (0.203)	D 0.142 (0.102)	T@1 9.375 (7.974)	T@5 96.875 (43.750)	L 2.9449 (4.0045)
Test on T training set - [5][1490/1731]	T 0.219 (0.203)	D 0.124 (0.102)	T@1 21.875 (8.002)	T@5 100.000 (44.096)	L 2.6148 (3.9967)
Test on T training set - [5][1500/1731]	T 0.243 (0.203)	D 0.138 (0.102)	T@1 12.500 (8.032)	T@5 100.000 (44.447)	L 2.9574 (3.9900)
Test on T training set - [5][1510/1731]	T 0.227 (0.204)	D 0.121 (0.102)	T@1 15.625 (8.093)	T@5 96.875 (44.794)	L 2.6150 (3.9821)
Test on T training set - [5][1520/1731]	T 0.211 (0.204)	D 0.113 (0.102)	T@1 18.750 (8.128)	T@5 87.500 (45.135)	L 2.7177 (3.9747)
Test on T training set - [5][1530/1731]	T 0.220 (0.204)	D 0.118 (0.102)	T@1 12.500 (8.152)	T@5 100.000 (45.481)	L 2.4434 (3.9683)
Test on T training set - [5][1540/1731]	T 0.185 (0.204)	D 0.089 (0.102)	T@1 6.250 (8.170)	T@5 96.875 (45.796)	L 3.3683 (3.9626)
Test on T training set - [5][1550/1731]	T 0.226 (0.204)	D 0.130 (0.102)	T@1 12.500 (8.192)	T@5 100.000 (46.109)	L 3.1154 (3.9576)
Test on T training set - [5][1560/1731]	T 0.195 (0.204)	D 0.089 (0.102)	T@1 25.000 (8.228)	T@5 65.625 (46.369)	L 2.8866 (3.9515)
Test on T training set - [5][1570/1731]	T 0.169 (0.204)	D 0.073 (0.102)	T@1 18.750 (8.333)	T@5 81.250 (46.606)	L 3.3019 (3.9445)
Test on T training set - [5][1580/1731]	T 0.159 (0.205)	D 0.059 (0.103)	T@1 21.875 (8.397)	T@5 75.000 (46.835)	L 3.1571 (3.9395)
Test on T training set - [5][1590/1731]	T 0.150 (0.204)	D 0.050 (0.103)	T@1 18.750 (8.495)	T@5 81.250 (47.056)	L 3.0109 (3.9340)
Test on T training set - [5][1600/1731]	T 0.186 (0.204)	D 0.081 (0.102)	T@1 18.750 (8.573)	T@5 84.375 (47.273)	L 3.3677 (3.9285)
Test on T training set - [5][1610/1731]	T 0.165 (0.204)	D 0.070 (0.102)	T@1 25.000 (8.630)	T@5 87.500 (47.500)	L 2.8643 (3.9240)
Test on T training set - [5][1620/1731]	T 0.184 (0.204)	D 0.076 (0.102)	T@1 31.250 (8.694)	T@5 93.750 (47.704)	L 2.4319 (3.9196)
Test on T training set - [5][1630/1731]	T 0.176 (0.203)	D 0.070 (0.102)	T@1 6.250 (8.764)	T@5 78.125 (47.902)	L 3.7209 (3.9152)
Test on T training set - [5][1640/1731]	T 0.204 (0.203)	D 0.109 (0.102)	T@1 31.250 (8.859)	T@5 65.625 (48.107)	L 2.4991 (3.9101)
Test on T training set - [5][1650/1731]	T 0.222 (0.203)	D 0.113 (0.102)	T@1 18.750 (8.940)	T@5 75.000 (48.283)	L 2.9670 (3.9053)
Test on T training set - [5][1660/1731]	T 0.188 (0.203)	D 0.091 (0.102)	T@1 28.125 (9.051)	T@5 78.125 (48.476)	L 2.3883 (3.8984)
Test on T training set - [5][1670/1731]	T 0.199 (0.203)	D 0.094 (0.102)	T@1 28.125 (9.182)	T@5 87.500 (48.678)	L 2.5609 (3.8918)
Test on T training set - [5][1680/1731]	T 0.181 (0.203)	D 0.079 (0.102)	T@1 18.750 (9.263)	T@5 81.250 (48.877)	L 2.8759 (3.8866)
Test on T training set - [5][1690/1731]	T 0.212 (0.205)	D 0.116 (0.103)	T@1 34.375 (9.392)	T@5 81.250 (49.080)	L 2.5456 (3.8796)
Test on T training set - [5][1700/1731]	T 0.206 (0.205)	D 0.108 (0.103)	T@1 21.875 (9.482)	T@5 71.875 (49.254)	L 3.1226 (3.8738)
Test on T training set - [5][1710/1731]	T 0.207 (0.205)	D 0.112 (0.103)	T@1 18.750 (9.578)	T@5 87.500 (49.463)	L 3.1127 (3.8677)
Test on T training set - [5][1720/1731]	T 0.198 (0.205)	D 0.092 (0.103)	T@1 18.750 (9.658)	T@5 87.500 (49.657)	L 2.7575 (3.8624)
Test on T training set - [5][1730/1731]	T 0.165 (0.205)	D 0.074 (0.103)	T@1 25.000 (9.762)	T@5 78.571 (49.839)	L 2.3988 (3.8550)
 * Test on T training set - Prec@1 9.762, Prec@5 49.839
Test on T test set - [5][0/1731]	Time 0.287 (0.287)	Loss 4.4331 (4.4331)	Prec@1 3.125 (3.125)	Prec@5 50.000 (50.000)
Test on T test set - [5][10/1731]	Time 0.203 (0.193)	Loss 4.1905 (4.3955)	Prec@1 6.250 (3.693)	Prec@5 46.875 (41.193)
Test on T test set - [5][20/1731]	Time 0.211 (0.203)	Loss 4.2461 (4.4688)	Prec@1 0.000 (3.274)	Prec@5 40.625 (37.946)
Test on T test set - [5][30/1731]	Time 0.206 (0.204)	Loss 4.4449 (4.4787)	Prec@1 3.125 (2.621)	Prec@5 50.000 (38.306)
Test on T test set - [5][40/1731]	Time 0.215 (0.204)	Loss 4.6774 (4.5023)	Prec@1 0.000 (2.668)	Prec@5 31.250 (37.881)
Test on T test set - [5][50/1731]	Time 0.204 (0.205)	Loss 4.4868 (4.5005)	Prec@1 0.000 (2.574)	Prec@5 46.875 (37.990)
Test on T test set - [5][60/1731]	Time 0.215 (0.205)	Loss 4.7595 (4.4716)	Prec@1 3.125 (2.561)	Prec@5 28.125 (38.217)
Test on T test set - [5][70/1731]	Time 0.198 (0.205)	Loss 4.9799 (4.4908)	Prec@1 0.000 (2.509)	Prec@5 43.750 (38.160)
Test on T test set - [5][80/1731]	Time 0.186 (0.237)	Loss 4.4932 (4.4851)	Prec@1 3.125 (2.585)	Prec@5 34.375 (38.233)
Test on T test set - [5][90/1731]	Time 0.189 (0.233)	Loss 4.3761 (4.4833)	Prec@1 3.125 (2.679)	Prec@5 43.750 (37.775)
Test on T test set - [5][100/1731]	Time 0.173 (0.228)	Loss 4.0556 (4.4566)	Prec@1 0.000 (2.661)	Prec@5 40.625 (38.428)
Test on T test set - [5][110/1731]	Time 0.199 (0.223)	Loss 4.5873 (4.4339)	Prec@1 0.000 (2.646)	Prec@5 12.500 (38.514)
Test on T test set - [5][120/1731]	Time 0.193 (0.220)	Loss 3.6741 (4.3943)	Prec@1 0.000 (2.531)	Prec@5 56.250 (39.566)
Test on T test set - [5][130/1731]	Time 0.188 (0.217)	Loss 3.7604 (4.3427)	Prec@1 0.000 (2.409)	Prec@5 53.125 (40.983)
Test on T test set - [5][140/1731]	Time 0.166 (0.215)	Loss 3.8547 (4.2899)	Prec@1 3.125 (2.371)	Prec@5 71.875 (42.664)
Test on T test set - [5][150/1731]	Time 0.193 (0.213)	Loss 3.8359 (4.2531)	Prec@1 0.000 (2.235)	Prec@5 68.750 (43.398)
Test on T test set - [5][160/1731]	Time 0.180 (0.211)	Loss 3.5779 (4.2213)	Prec@1 0.000 (2.135)	Prec@5 46.875 (44.507)
Test on T test set - [5][170/1731]	Time 0.158 (0.208)	Loss 3.5119 (4.1871)	Prec@1 0.000 (2.047)	Prec@5 68.750 (45.779)
Test on T test set - [5][180/1731]	Time 0.154 (0.206)	Loss 4.4200 (4.1667)	Prec@1 0.000 (1.968)	Prec@5 68.750 (46.771)
Test on T test set - [5][190/1731]	Time 0.169 (0.215)	Loss 4.0675 (4.1421)	Prec@1 0.000 (1.882)	Prec@5 59.375 (47.595)
Test on T test set - [5][200/1731]	Time 0.151 (0.212)	Loss 3.6807 (4.1333)	Prec@1 0.000 (1.803)	Prec@5 53.125 (48.197)
Test on T test set - [5][210/1731]	Time 0.170 (0.210)	Loss 3.8357 (4.1202)	Prec@1 0.000 (1.718)	Prec@5 68.750 (48.815)
Test on T test set - [5][220/1731]	Time 0.179 (0.208)	Loss 3.6119 (4.1036)	Prec@1 3.125 (1.654)	Prec@5 81.250 (49.406)
Test on T test set - [5][230/1731]	Time 0.169 (0.206)	Loss 2.7819 (4.0307)	Prec@1 31.250 (2.990)	Prec@5 90.625 (51.136)
Test on T test set - [5][240/1731]	Time 0.220 (0.206)	Loss 2.4894 (3.9707)	Prec@1 28.125 (3.942)	Prec@5 93.750 (52.684)
Test on T test set - [5][250/1731]	Time 0.195 (0.207)	Loss 2.4380 (3.9092)	Prec@1 31.250 (4.980)	Prec@5 90.625 (54.146)
Test on T test set - [5][260/1731]	Time 0.227 (0.207)	Loss 2.7847 (3.8613)	Prec@1 21.875 (5.711)	Prec@5 84.375 (55.412)
Test on T test set - [5][270/1731]	Time 0.223 (0.208)	Loss 2.4767 (3.8158)	Prec@1 31.250 (6.504)	Prec@5 90.625 (56.677)
Test on T test set - [5][280/1731]	Time 0.217 (0.208)	Loss 2.3458 (3.7655)	Prec@1 25.000 (7.373)	Prec@5 93.750 (57.896)
Test on T test set - [5][290/1731]	Time 0.219 (0.208)	Loss 2.4200 (3.7216)	Prec@1 21.875 (8.108)	Prec@5 90.625 (59.064)
Test on T test set - [5][300/1731]	Time 0.217 (0.214)	Loss 2.1862 (3.6792)	Prec@1 37.500 (8.721)	Prec@5 93.750 (60.164)
Test on T test set - [5][310/1731]	Time 0.221 (0.214)	Loss 2.3972 (3.6369)	Prec@1 21.875 (9.385)	Prec@5 90.625 (61.214)
Test on T test set - [5][320/1731]	Time 0.189 (0.213)	Loss 2.6205 (3.6014)	Prec@1 28.125 (10.056)	Prec@5 90.625 (62.169)
Test on T test set - [5][330/1731]	Time 0.199 (0.213)	Loss 2.3176 (3.5617)	Prec@1 25.000 (10.763)	Prec@5 96.875 (63.057)
Test on T test set - [5][340/1731]	Time 0.171 (0.212)	Loss 2.2356 (3.5269)	Prec@1 31.250 (11.336)	Prec@5 90.625 (63.948)
Test on T test set - [5][350/1731]	Time 0.191 (0.211)	Loss 3.0952 (3.4956)	Prec@1 15.625 (11.886)	Prec@5 90.625 (64.717)
Test on T test set - [5][360/1731]	Time 0.227 (0.211)	Loss 2.5040 (3.4656)	Prec@1 31.250 (12.422)	Prec@5 87.500 (65.452)
Test on T test set - [5][370/1731]	Time 0.179 (0.211)	Loss 4.0662 (3.4455)	Prec@1 3.125 (12.786)	Prec@5 68.750 (65.979)
Test on T test set - [5][380/1731]	Time 0.178 (0.210)	Loss 3.9253 (3.4576)	Prec@1 12.500 (12.705)	Prec@5 68.750 (65.986)
Test on T test set - [5][390/1731]	Time 0.164 (0.208)	Loss 3.5200 (3.4642)	Prec@1 18.750 (12.612)	Prec@5 65.625 (66.041)
Test on T test set - [5][400/1731]	Time 0.156 (0.207)	Loss 3.8333 (3.4751)	Prec@1 12.500 (12.539)	Prec@5 71.875 (66.124)
Test on T test set - [5][410/1731]	Time 0.156 (0.212)	Loss 3.8438 (3.4851)	Prec@1 6.250 (12.416)	Prec@5 65.625 (66.188)
Test on T test set - [5][420/1731]	Time 0.157 (0.210)	Loss 4.2426 (3.4959)	Prec@1 9.375 (12.337)	Prec@5 65.625 (66.211)
Test on T test set - [5][430/1731]	Time 0.162 (0.209)	Loss 3.6779 (3.5045)	Prec@1 15.625 (12.297)	Prec@5 71.875 (66.154)
Test on T test set - [5][440/1731]	Time 0.155 (0.208)	Loss 3.5708 (3.5138)	Prec@1 15.625 (12.224)	Prec@5 81.250 (66.277)
Test on T test set - [5][450/1731]	Time 0.153 (0.207)	Loss 3.8377 (3.5212)	Prec@1 12.500 (12.181)	Prec@5 71.875 (66.290)
Test on T test set - [5][460/1731]	Time 0.161 (0.206)	Loss 3.7943 (3.5244)	Prec@1 6.250 (12.148)	Prec@5 78.125 (66.411)
Test on T test set - [5][470/1731]	Time 0.149 (0.205)	Loss 3.3723 (3.5275)	Prec@1 12.500 (12.135)	Prec@5 68.750 (66.428)
Test on T test set - [5][480/1731]	Time 0.152 (0.204)	Loss 3.5545 (3.5320)	Prec@1 12.500 (12.097)	Prec@5 68.750 (66.528)
Test on T test set - [5][490/1731]	Time 0.148 (0.203)	Loss 4.4016 (3.5381)	Prec@1 3.125 (12.010)	Prec@5 71.875 (66.612)
Test on T test set - [5][500/1731]	Time 0.159 (0.202)	Loss 3.1248 (3.5421)	Prec@1 12.500 (11.970)	Prec@5 87.500 (66.648)
Test on T test set - [5][510/1731]	Time 0.151 (0.201)	Loss 4.0203 (3.5524)	Prec@1 6.250 (11.870)	Prec@5 78.125 (66.695)
Test on T test set - [5][520/1731]	Time 0.153 (0.200)	Loss 4.7740 (3.5637)	Prec@1 3.125 (11.816)	Prec@5 50.000 (66.627)
Test on T test set - [5][530/1731]	Time 0.170 (0.199)	Loss 4.7402 (3.5775)	Prec@1 3.125 (11.688)	Prec@5 59.375 (66.555)
Test on T test set - [5][540/1731]	Time 0.150 (0.203)	Loss 4.0221 (3.5873)	Prec@1 12.500 (11.657)	Prec@5 65.625 (66.526)
Test on T test set - [5][550/1731]	Time 0.144 (0.202)	Loss 4.1067 (3.5982)	Prec@1 12.500 (11.559)	Prec@5 71.875 (66.521)
Test on T test set - [5][560/1731]	Time 0.160 (0.202)	Loss 4.0571 (3.6079)	Prec@1 6.250 (11.492)	Prec@5 62.500 (66.544)
Test on T test set - [5][570/1731]	Time 0.181 (0.201)	Loss 3.6838 (3.6140)	Prec@1 12.500 (11.455)	Prec@5 62.500 (66.555)
Test on T test set - [5][580/1731]	Time 0.158 (0.200)	Loss 4.2163 (3.6169)	Prec@1 9.375 (11.424)	Prec@5 65.625 (66.674)
Test on T test set - [5][590/1731]	Time 0.172 (0.200)	Loss 3.7454 (3.6228)	Prec@1 15.625 (11.405)	Prec@5 56.250 (66.640)
Test on T test set - [5][600/1731]	Time 0.159 (0.199)	Loss 3.6455 (3.6278)	Prec@1 15.625 (11.418)	Prec@5 62.500 (66.712)
Test on T test set - [5][610/1731]	Time 0.154 (0.199)	Loss 3.9424 (3.6314)	Prec@1 0.000 (11.359)	Prec@5 71.875 (66.852)
Test on T test set - [5][620/1731]	Time 0.166 (0.198)	Loss 3.5244 (3.6338)	Prec@1 9.375 (11.363)	Prec@5 78.125 (66.903)
Test on T test set - [5][630/1731]	Time 0.162 (0.198)	Loss 4.2443 (3.6403)	Prec@1 3.125 (11.311)	Prec@5 62.500 (66.888)
Test on T test set - [5][640/1731]	Time 0.149 (0.197)	Loss 3.9624 (3.6439)	Prec@1 9.375 (11.281)	Prec@5 62.500 (66.883)
Test on T test set - [5][650/1731]	Time 0.143 (0.198)	Loss 4.6110 (3.6476)	Prec@1 6.250 (11.238)	Prec@5 59.375 (66.950)
Test on T test set - [5][660/1731]	Time 0.165 (0.198)	Loss 3.7748 (3.6517)	Prec@1 12.500 (11.233)	Prec@5 75.000 (67.029)
Test on T test set - [5][670/1731]	Time 0.167 (0.197)	Loss 3.5595 (3.6563)	Prec@1 15.625 (11.210)	Prec@5 75.000 (67.008)
Test on T test set - [5][680/1731]	Time 0.158 (0.196)	Loss 3.1129 (3.6598)	Prec@1 18.750 (11.192)	Prec@5 71.875 (67.057)
Test on T test set - [5][690/1731]	Time 0.219 (0.196)	Loss 3.1950 (3.6620)	Prec@1 3.125 (11.157)	Prec@5 56.250 (66.986)
Test on T test set - [5][700/1731]	Time 0.157 (0.196)	Loss 5.7374 (3.6777)	Prec@1 0.000 (11.033)	Prec@5 0.000 (66.262)
Test on T test set - [5][710/1731]	Time 0.164 (0.195)	Loss 5.1905 (3.6969)	Prec@1 0.000 (10.878)	Prec@5 0.000 (65.331)
Test on T test set - [5][720/1731]	Time 0.165 (0.195)	Loss 5.2052 (3.7166)	Prec@1 0.000 (10.727)	Prec@5 0.000 (64.424)
Test on T test set - [5][730/1731]	Time 0.213 (0.195)	Loss 4.7209 (3.7350)	Prec@1 0.000 (10.581)	Prec@5 0.000 (63.543)
Test on T test set - [5][740/1731]	Time 0.202 (0.195)	Loss 4.8969 (3.7520)	Prec@1 0.000 (10.438)	Prec@5 0.000 (62.686)
Test on T test set - [5][750/1731]	Time 0.184 (0.195)	Loss 4.8560 (3.7685)	Prec@1 0.000 (10.299)	Prec@5 0.000 (61.851)
Test on T test set - [5][760/1731]	Time 0.225 (0.195)	Loss 4.7439 (3.7837)	Prec@1 0.000 (10.163)	Prec@5 0.000 (61.046)
Test on T test set - [5][770/1731]	Time 0.203 (0.198)	Loss 4.9217 (3.7986)	Prec@1 0.000 (10.032)	Prec@5 0.000 (60.255)
Test on T test set - [5][780/1731]	Time 0.214 (0.198)	Loss 4.9247 (3.8141)	Prec@1 0.000 (9.903)	Prec@5 0.000 (59.483)
Test on T test set - [5][790/1731]	Time 0.199 (0.198)	Loss 4.9004 (3.8279)	Prec@1 0.000 (9.778)	Prec@5 0.000 (58.731)
Test on T test set - [5][800/1731]	Time 0.192 (0.198)	Loss 4.8712 (3.8425)	Prec@1 0.000 (9.656)	Prec@5 0.000 (57.998)
Test on T test set - [5][810/1731]	Time 0.190 (0.198)	Loss 4.7978 (3.8573)	Prec@1 0.000 (9.537)	Prec@5 0.000 (57.283)
Test on T test set - [5][820/1731]	Time 0.203 (0.198)	Loss 4.7621 (3.8710)	Prec@1 0.000 (9.421)	Prec@5 0.000 (56.585)
Test on T test set - [5][830/1731]	Time 0.168 (0.198)	Loss 4.7902 (3.8839)	Prec@1 0.000 (9.307)	Prec@5 0.000 (55.908)
Test on T test set - [5][840/1731]	Time 0.175 (0.197)	Loss 4.8587 (3.8962)	Prec@1 3.125 (9.200)	Prec@5 6.250 (55.250)
Test on T test set - [5][850/1731]	Time 0.151 (0.197)	Loss 4.1603 (3.9016)	Prec@1 9.375 (9.184)	Prec@5 25.000 (54.946)
Test on T test set - [5][860/1731]	Time 0.160 (0.199)	Loss 4.0345 (3.9066)	Prec@1 9.375 (9.164)	Prec@5 28.125 (54.682)
Test on T test set - [5][870/1731]	Time 0.154 (0.199)	Loss 4.8888 (3.9094)	Prec@1 0.000 (9.138)	Prec@5 31.250 (54.456)
Test on T test set - [5][880/1731]	Time 0.165 (0.199)	Loss 4.7059 (3.9146)	Prec@1 0.000 (9.123)	Prec@5 31.250 (54.154)
Test on T test set - [5][890/1731]	Time 0.167 (0.198)	Loss 4.2981 (3.9188)	Prec@1 9.375 (9.084)	Prec@5 21.875 (53.844)
Test on T test set - [5][900/1731]	Time 0.154 (0.198)	Loss 4.6166 (3.9229)	Prec@1 3.125 (9.039)	Prec@5 28.125 (53.576)
Test on T test set - [5][910/1731]	Time 0.176 (0.197)	Loss 4.4461 (3.9279)	Prec@1 0.000 (8.984)	Prec@5 6.250 (53.173)
Test on T test set - [5][920/1731]	Time 0.155 (0.197)	Loss 3.9866 (3.9326)	Prec@1 6.250 (8.931)	Prec@5 6.250 (52.694)
Test on T test set - [5][930/1731]	Time 0.223 (0.197)	Loss 4.2929 (3.9353)	Prec@1 3.125 (8.905)	Prec@5 15.625 (52.306)
Test on T test set - [5][940/1731]	Time 0.227 (0.197)	Loss 4.1760 (3.9374)	Prec@1 3.125 (8.874)	Prec@5 21.875 (51.953)
Test on T test set - [5][950/1731]	Time 0.224 (0.197)	Loss 4.2526 (3.9394)	Prec@1 0.000 (8.833)	Prec@5 12.500 (51.613)
Test on T test set - [5][960/1731]	Time 0.207 (0.199)	Loss 4.4382 (3.9406)	Prec@1 0.000 (8.822)	Prec@5 9.375 (51.265)
Test on T test set - [5][970/1731]	Time 0.207 (0.199)	Loss 3.9771 (3.9422)	Prec@1 6.250 (8.796)	Prec@5 18.750 (50.927)
Test on T test set - [5][980/1731]	Time 0.198 (0.199)	Loss 4.6803 (3.9441)	Prec@1 3.125 (8.763)	Prec@5 18.750 (50.599)
Test on T test set - [5][990/1731]	Time 0.216 (0.200)	Loss 3.6983 (3.9474)	Prec@1 15.625 (8.732)	Prec@5 31.250 (50.259)
Test on T test set - [5][1000/1731]	Time 0.207 (0.200)	Loss 4.2239 (3.9489)	Prec@1 6.250 (8.701)	Prec@5 15.625 (49.931)
Test on T test set - [5][1010/1731]	Time 0.193 (0.199)	Loss 4.2074 (3.9513)	Prec@1 9.375 (8.680)	Prec@5 18.750 (49.617)
Test on T test set - [5][1020/1731]	Time 0.182 (0.199)	Loss 3.8671 (3.9534)	Prec@1 12.500 (8.656)	Prec@5 25.000 (49.281)
Test on T test set - [5][1030/1731]	Time 0.156 (0.199)	Loss 4.3607 (3.9554)	Prec@1 3.125 (8.648)	Prec@5 6.250 (48.951)
Test on T test set - [5][1040/1731]	Time 0.155 (0.199)	Loss 4.5835 (3.9594)	Prec@1 0.000 (8.601)	Prec@5 0.000 (48.601)
Test on T test set - [5][1050/1731]	Time 0.161 (0.199)	Loss 4.4039 (3.9656)	Prec@1 6.250 (8.551)	Prec@5 6.250 (48.204)
Test on T test set - [5][1060/1731]	Time 0.145 (0.198)	Loss 4.3661 (3.9722)	Prec@1 6.250 (8.503)	Prec@5 6.250 (47.826)
Test on T test set - [5][1070/1731]	Time 0.182 (0.199)	Loss 4.2546 (3.9776)	Prec@1 3.125 (8.473)	Prec@5 3.125 (47.447)
Test on T test set - [5][1080/1731]	Time 0.158 (0.199)	Loss 4.2689 (3.9786)	Prec@1 9.375 (8.470)	Prec@5 15.625 (47.150)
Test on T test set - [5][1090/1731]	Time 0.160 (0.199)	Loss 4.0353 (3.9796)	Prec@1 9.375 (8.476)	Prec@5 31.250 (46.929)
Test on T test set - [5][1100/1731]	Time 0.184 (0.198)	Loss 4.0166 (3.9794)	Prec@1 12.500 (8.541)	Prec@5 18.750 (46.756)
Test on T test set - [5][1110/1731]	Time 0.190 (0.198)	Loss 3.8846 (3.9784)	Prec@1 15.625 (8.610)	Prec@5 34.375 (46.608)
Test on T test set - [5][1120/1731]	Time 0.186 (0.198)	Loss 3.6828 (3.9794)	Prec@1 21.875 (8.628)	Prec@5 31.250 (46.412)
Test on T test set - [5][1130/1731]	Time 0.178 (0.198)	Loss 4.6560 (3.9810)	Prec@1 9.375 (8.659)	Prec@5 15.625 (46.240)
Test on T test set - [5][1140/1731]	Time 0.187 (0.198)	Loss 3.4339 (3.9813)	Prec@1 28.125 (8.720)	Prec@5 40.625 (46.075)
Test on T test set - [5][1150/1731]	Time 0.165 (0.198)	Loss 3.7657 (3.9810)	Prec@1 15.625 (8.775)	Prec@5 28.125 (45.911)
Test on T test set - [5][1160/1731]	Time 0.161 (0.197)	Loss 4.4823 (3.9812)	Prec@1 9.375 (8.831)	Prec@5 21.875 (45.755)
Test on T test set - [5][1170/1731]	Time 0.171 (0.197)	Loss 4.4952 (3.9819)	Prec@1 6.250 (8.855)	Prec@5 18.750 (45.565)
Test on T test set - [5][1180/1731]	Time 0.175 (0.200)	Loss 4.0528 (3.9813)	Prec@1 9.375 (8.907)	Prec@5 31.250 (45.425)
Test on T test set - [5][1190/1731]	Time 0.176 (0.200)	Loss 4.0008 (3.9825)	Prec@1 12.500 (8.934)	Prec@5 25.000 (45.240)
Test on T test set - [5][1200/1731]	Time 0.157 (0.199)	Loss 3.4601 (3.9832)	Prec@1 25.000 (8.982)	Prec@5 37.500 (45.085)
Test on T test set - [5][1210/1731]	Time 0.182 (0.199)	Loss 4.0431 (3.9832)	Prec@1 6.250 (9.029)	Prec@5 18.750 (44.932)
Test on T test set - [5][1220/1731]	Time 0.162 (0.199)	Loss 4.8089 (3.9884)	Prec@1 0.000 (8.963)	Prec@5 12.500 (44.656)
Test on T test set - [5][1230/1731]	Time 0.149 (0.198)	Loss 4.9021 (3.9947)	Prec@1 0.000 (8.893)	Prec@5 9.375 (44.397)
Test on T test set - [5][1240/1731]	Time 0.170 (0.198)	Loss 4.2807 (4.0002)	Prec@1 0.000 (8.821)	Prec@5 6.250 (44.133)
Test on T test set - [5][1250/1731]	Time 0.169 (0.198)	Loss 4.1719 (4.0041)	Prec@1 0.000 (8.753)	Prec@5 15.625 (43.890)
Test on T test set - [5][1260/1731]	Time 0.181 (0.198)	Loss 4.5907 (4.0087)	Prec@1 0.000 (8.684)	Prec@5 0.000 (43.648)
Test on T test set - [5][1270/1731]	Time 0.175 (0.198)	Loss 4.1189 (4.0134)	Prec@1 3.125 (8.618)	Prec@5 6.250 (43.403)
Test on T test set - [5][1280/1731]	Time 0.182 (0.199)	Loss 4.2410 (4.0166)	Prec@1 0.000 (8.553)	Prec@5 15.625 (43.157)
Test on T test set - [5][1290/1731]	Time 0.163 (0.199)	Loss 4.4136 (4.0211)	Prec@1 3.125 (8.496)	Prec@5 12.500 (42.917)
Test on T test set - [5][1300/1731]	Time 0.167 (0.199)	Loss 4.5154 (4.0246)	Prec@1 0.000 (8.433)	Prec@5 15.625 (42.698)
Test on T test set - [5][1310/1731]	Time 0.173 (0.199)	Loss 4.3977 (4.0273)	Prec@1 0.000 (8.371)	Prec@5 12.500 (42.480)
Test on T test set - [5][1320/1731]	Time 0.191 (0.199)	Loss 4.1175 (4.0300)	Prec@1 3.125 (8.310)	Prec@5 25.000 (42.276)
Test on T test set - [5][1330/1731]	Time 0.154 (0.198)	Loss 4.5413 (4.0330)	Prec@1 0.000 (8.248)	Prec@5 21.875 (42.069)
Test on T test set - [5][1340/1731]	Time 0.152 (0.198)	Loss 4.4627 (4.0363)	Prec@1 0.000 (8.189)	Prec@5 15.625 (41.848)
Test on T test set - [5][1350/1731]	Time 0.170 (0.198)	Loss 4.2437 (4.0393)	Prec@1 0.000 (8.128)	Prec@5 21.875 (41.624)
Test on T test set - [5][1360/1731]	Time 0.155 (0.197)	Loss 4.1666 (4.0413)	Prec@1 0.000 (8.073)	Prec@5 34.375 (41.527)
Test on T test set - [5][1370/1731]	Time 0.144 (0.197)	Loss 3.9700 (4.0409)	Prec@1 0.000 (8.017)	Prec@5 46.875 (41.544)
Test on T test set - [5][1380/1731]	Time 0.155 (0.197)	Loss 4.1942 (4.0404)	Prec@1 0.000 (7.963)	Prec@5 34.375 (41.551)
Test on T test set - [5][1390/1731]	Time 0.162 (0.197)	Loss 4.2744 (4.0390)	Prec@1 0.000 (7.908)	Prec@5 31.250 (41.566)
Test on T test set - [5][1400/1731]	Time 0.158 (0.198)	Loss 3.9695 (4.0387)	Prec@1 0.000 (7.854)	Prec@5 34.375 (41.544)
Test on T test set - [5][1410/1731]	Time 0.164 (0.198)	Loss 3.8833 (4.0373)	Prec@1 0.000 (7.805)	Prec@5 56.250 (41.588)
Test on T test set - [5][1420/1731]	Time 0.156 (0.197)	Loss 4.0981 (4.0363)	Prec@1 0.000 (7.756)	Prec@5 28.125 (41.612)
Test on T test set - [5][1430/1731]	Time 0.199 (0.197)	Loss 2.8506 (4.0330)	Prec@1 9.375 (7.759)	Prec@5 96.875 (41.839)
Test on T test set - [5][1440/1731]	Time 0.241 (0.197)	Loss 2.9623 (4.0251)	Prec@1 6.250 (7.805)	Prec@5 96.875 (42.223)
Test on T test set - [5][1450/1731]	Time 0.227 (0.198)	Loss 3.4178 (4.0182)	Prec@1 9.375 (7.833)	Prec@5 96.875 (42.600)
Test on T test set - [5][1460/1731]	Time 0.218 (0.198)	Loss 3.0746 (4.0115)	Prec@1 12.500 (7.863)	Prec@5 100.000 (42.982)
Test on T test set - [5][1470/1731]	Time 0.215 (0.198)	Loss 2.9868 (4.0038)	Prec@1 9.375 (7.899)	Prec@5 100.000 (43.359)
Test on T test set - [5][1480/1731]	Time 0.230 (0.198)	Loss 2.4991 (3.9969)	Prec@1 18.750 (7.951)	Prec@5 96.875 (43.720)
Test on T test set - [5][1490/1731]	Time 0.217 (0.200)	Loss 3.1983 (3.9885)	Prec@1 18.750 (8.032)	Prec@5 100.000 (44.066)
Test on T test set - [5][1500/1731]	Time 0.233 (0.200)	Loss 2.9599 (3.9820)	Prec@1 9.375 (8.059)	Prec@5 100.000 (44.422)
Test on T test set - [5][1510/1731]	Time 0.215 (0.200)	Loss 2.8194 (3.9752)	Prec@1 18.750 (8.099)	Prec@5 93.750 (44.768)
Test on T test set - [5][1520/1731]	Time 0.208 (0.200)	Loss 2.8847 (3.9676)	Prec@1 15.625 (8.132)	Prec@5 96.875 (45.106)
Test on T test set - [5][1530/1731]	Time 0.208 (0.200)	Loss 2.2893 (3.9612)	Prec@1 15.625 (8.150)	Prec@5 93.750 (45.444)
Test on T test set - [5][1540/1731]	Time 0.184 (0.200)	Loss 3.6048 (3.9564)	Prec@1 6.250 (8.166)	Prec@5 93.750 (45.766)
Test on T test set - [5][1550/1731]	Time 0.222 (0.200)	Loss 2.8539 (3.9505)	Prec@1 3.125 (8.178)	Prec@5 90.625 (46.069)
Test on T test set - [5][1560/1731]	Time 0.193 (0.200)	Loss 3.2360 (3.9447)	Prec@1 25.000 (8.224)	Prec@5 68.750 (46.357)
Test on T test set - [5][1570/1731]	Time 0.163 (0.200)	Loss 3.2327 (3.9386)	Prec@1 9.375 (8.313)	Prec@5 75.000 (46.573)
Test on T test set - [5][1580/1731]	Time 0.144 (0.200)	Loss 2.9790 (3.9329)	Prec@1 31.250 (8.414)	Prec@5 78.125 (46.802)
Test on T test set - [5][1590/1731]	Time 0.151 (0.201)	Loss 3.4788 (3.9284)	Prec@1 21.875 (8.483)	Prec@5 71.875 (47.014)
Test on T test set - [5][1600/1731]	Time 0.183 (0.201)	Loss 3.2724 (3.9230)	Prec@1 15.625 (8.555)	Prec@5 84.375 (47.238)
Test on T test set - [5][1610/1731]	Time 0.177 (0.201)	Loss 3.3776 (3.9188)	Prec@1 18.750 (8.609)	Prec@5 78.125 (47.461)
Test on T test set - [5][1620/1731]	Time 0.182 (0.201)	Loss 2.7292 (3.9148)	Prec@1 28.125 (8.671)	Prec@5 87.500 (47.679)
Test on T test set - [5][1630/1731]	Time 0.167 (0.200)	Loss 3.7771 (3.9104)	Prec@1 15.625 (8.739)	Prec@5 75.000 (47.866)
Test on T test set - [5][1640/1731]	Time 0.218 (0.200)	Loss 2.7534 (3.9057)	Prec@1 18.750 (8.808)	Prec@5 75.000 (48.052)
Test on T test set - [5][1650/1731]	Time 0.221 (0.200)	Loss 3.1138 (3.9010)	Prec@1 28.125 (8.894)	Prec@5 81.250 (48.234)
Test on T test set - [5][1660/1731]	Time 0.189 (0.200)	Loss 2.6013 (3.8932)	Prec@1 31.250 (9.023)	Prec@5 78.125 (48.429)
Test on T test set - [5][1670/1731]	Time 0.187 (0.200)	Loss 2.4165 (3.8864)	Prec@1 40.625 (9.132)	Prec@5 87.500 (48.627)
Test on T test set - [5][1680/1731]	Time 0.177 (0.200)	Loss 2.9690 (3.8810)	Prec@1 25.000 (9.223)	Prec@5 75.000 (48.814)
Test on T test set - [5][1690/1731]	Time 0.208 (0.200)	Loss 2.5630 (3.8741)	Prec@1 31.250 (9.336)	Prec@5 84.375 (49.002)
Test on T test set - [5][1700/1731]	Time 0.202 (0.202)	Loss 3.2067 (3.8680)	Prec@1 21.875 (9.436)	Prec@5 71.875 (49.184)
Test on T test set - [5][1710/1731]	Time 0.209 (0.202)	Loss 2.9858 (3.8617)	Prec@1 28.125 (9.547)	Prec@5 90.625 (49.395)
Test on T test set - [5][1720/1731]	Time 0.176 (0.202)	Loss 2.5284 (3.8562)	Prec@1 31.250 (9.640)	Prec@5 84.375 (49.593)
Test on T test set - [5][1730/1731]	Time 0.162 (0.202)	Loss 2.2118 (3.8486)	Prec@1 39.286 (9.762)	Prec@5 85.714 (49.787)
 * Test on T test set - Prec@1 9.762, Prec@5 49.787
Epoch 5 - Kernel K-means clustering 0: Clustering time 45.477, Prec@1 10.051
Epoch 5 - Kernel K-means clustering 1: Clustering time 45.159, Prec@1 9.690
Epoch 5 - Kernel K-means clustering 2: Clustering time 45.182, Prec@1 9.215
Epoch 5 - Kernel K-means clustering 3: Clustering time 44.841, Prec@1 8.897
Epoch 5 - Kernel K-means clustering 4: Clustering time 44.876, Prec@1 8.652
Epoch 5 - Kernel K-means clustering 5: Clustering time 44.680, Prec@1 8.578
Epoch 5 - Kernel K-means clustering 6: Clustering time 44.691, Prec@1 8.496
Epoch 5 - Kernel K-means clustering 7: Clustering time 44.707, Prec@1 8.459
Epoch 5 - Kernel K-means clustering 8: Clustering time 44.783, Prec@1 8.448
Epoch 5 - Kernel K-means clustering 9: Clustering time 44.770, Prec@1 8.435
Epoch 5 - Kernel K-means clustering 10: Clustering time 44.831, Prec@1 8.406
Epoch 5 - Kernel K-means clustering 11: Clustering time 44.784, Prec@1 8.406
Epoch 5 - Kernel K-means clustering 12: Clustering time 44.832, Prec@1 8.413
Epoch 5 - Kernel K-means clustering 13: Clustering time 44.778, Prec@1 8.433
Epoch 5 - Kernel K-means clustering 14: Clustering time 44.724, Prec@1 8.433
Epoch 5 - Kernel K-means clustering 15: Clustering time 47.356, Prec@1 8.433
Epoch 5 - Kernel K-means clustering 16: Clustering time 44.822, Prec@1 8.460
Epoch 5 - Kernel K-means clustering 17: Clustering time 44.837, Prec@1 8.487
Epoch 5 - Kernel K-means clustering 18: Clustering time 44.837, Prec@1 8.473
Epoch 5 - Kernel K-means clustering 19: Clustering time 44.785, Prec@1 8.482
Epoch 5 - Kernel K-means clustering 20: Clustering time 44.795, Prec@1 8.495
Epoch 5 - Kernel K-means clustering 21: Clustering time 44.770, Prec@1 8.482
Epoch 5 - Kernel K-means clustering 22: Clustering time 47.255, Prec@1 8.439
Epoch 5 - Kernel K-means clustering 23: Clustering time 45.654, Prec@1 8.428
Epoch 5 - Kernel K-means clustering 24: Clustering time 44.782, Prec@1 8.410
Epoch 5 - Kernel K-means clustering 25: Clustering time 44.799, Prec@1 8.375
Epoch 5 - Kernel K-means clustering 26: Clustering time 44.847, Prec@1 8.347
Epoch 5 - Kernel K-means clustering 27: Clustering time 44.839, Prec@1 8.287
Epoch 5 - Kernel K-means clustering 28: Clustering time 44.951, Prec@1 8.280
Epoch 5 - Kernel K-means clustering 29: Clustering time 47.987, Prec@1 8.269
Epoch 5 - Kernel K-means clustering 30: Clustering time 44.837, Prec@1 8.242
Epoch 5 - Kernel K-means clustering 31: Clustering time 44.803, Prec@1 8.240
Epoch 5 - Kernel K-means clustering 32: Clustering time 44.848, Prec@1 8.227
Epoch 5 - Kernel K-means clustering 33: Clustering time 44.852, Prec@1 8.209
Epoch 5 - Kernel K-means clustering 34: Clustering time 44.901, Prec@1 8.215
Epoch 5 - Kernel K-means clustering 35: Clustering time 44.852, Prec@1 8.206
Epoch 5 - Kernel K-means clustering 36: Clustering time 44.876, Prec@1 8.197
Epoch 5 - Kernel K-means clustering 37: Clustering time 44.789, Prec@1 8.184
Epoch 5 - Kernel K-means clustering 38: Clustering time 44.879, Prec@1 8.179
Epoch 5 - Kernel K-means clustering 39: Clustering time 46.052, Prec@1 8.175
Epoch 5 - Kernel K-means clustering 40: Clustering time 44.823, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 41: Clustering time 44.851, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 42: Clustering time 44.802, Prec@1 8.168
Epoch 5 - Kernel K-means clustering 43: Clustering time 44.902, Prec@1 8.168
Epoch 5 - Kernel K-means clustering 44: Clustering time 44.815, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 45: Clustering time 44.861, Prec@1 8.173
Epoch 5 - Kernel K-means clustering 46: Clustering time 44.827, Prec@1 8.173
Epoch 5 - Kernel K-means clustering 47: Clustering time 44.877, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 48: Clustering time 44.854, Prec@1 8.175
Epoch 5 - Kernel K-means clustering 49: Clustering time 44.813, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 50: Clustering time 44.815, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 51: Clustering time 45.501, Prec@1 8.166
Epoch 5 - Kernel K-means clustering 52: Clustering time 45.639, Prec@1 8.168
Epoch 5 - Kernel K-means clustering 53: Clustering time 44.832, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 54: Clustering time 44.841, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 55: Clustering time 44.872, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 56: Clustering time 47.118, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 57: Clustering time 45.517, Prec@1 8.171
Epoch 5 - Kernel K-means clustering 58: Clustering time 44.874, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 59: Clustering time 44.858, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 60: Clustering time 44.858, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 61: Clustering time 44.856, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 62: Clustering time 44.840, Prec@1 8.170
Epoch 5 - Kernel K-means clustering 63: Clustering time 44.789, Prec@1 8.168
Converged at iteration 64
Epoch 5 - Kernel K-means clustering 0: Clustering time 45.568, Prec@1 10.065
Epoch 5 - Kernel K-means clustering 1: Clustering time 45.137, Prec@1 9.758
Epoch 5 - Kernel K-means clustering 2: Clustering time 45.037, Prec@1 9.614
Epoch 5 - Kernel K-means clustering 3: Clustering time 44.829, Prec@1 9.625
Epoch 5 - Kernel K-means clustering 4: Clustering time 44.990, Prec@1 9.580
Epoch 5 - Kernel K-means clustering 5: Clustering time 44.885, Prec@1 9.497
Epoch 5 - Kernel K-means clustering 6: Clustering time 44.798, Prec@1 9.352
Epoch 5 - Kernel K-means clustering 7: Clustering time 44.910, Prec@1 9.253
Epoch 5 - Kernel K-means clustering 8: Clustering time 46.545, Prec@1 9.172
Epoch 5 - Kernel K-means clustering 9: Clustering time 44.857, Prec@1 9.132
Epoch 5 - Kernel K-means clustering 10: Clustering time 44.826, Prec@1 9.062
Epoch 5 - Kernel K-means clustering 11: Clustering time 44.834, Prec@1 9.043
Epoch 5 - Kernel K-means clustering 12: Clustering time 46.212, Prec@1 9.020
Epoch 5 - Kernel K-means clustering 13: Clustering time 45.071, Prec@1 9.004
Epoch 5 - Kernel K-means clustering 14: Clustering time 45.783, Prec@1 9.018
Epoch 5 - Kernel K-means clustering 15: Clustering time 44.887, Prec@1 9.007
Epoch 5 - Kernel K-means clustering 16: Clustering time 44.863, Prec@1 8.978
Epoch 5 - Kernel K-means clustering 17: Clustering time 44.920, Prec@1 8.962
Epoch 5 - Kernel K-means clustering 18: Clustering time 44.867, Prec@1 8.935
Epoch 5 - Kernel K-means clustering 19: Clustering time 44.859, Prec@1 8.951
Epoch 5 - Kernel K-means clustering 20: Clustering time 44.843, Prec@1 8.948
Epoch 5 - Kernel K-means clustering 21: Clustering time 44.953, Prec@1 8.953
Epoch 5 - Kernel K-means clustering 22: Clustering time 44.934, Prec@1 8.944
Epoch 5 - Kernel K-means clustering 23: Clustering time 44.974, Prec@1 8.946
Epoch 5 - Kernel K-means clustering 24: Clustering time 47.869, Prec@1 8.950
Epoch 5 - Kernel K-means clustering 25: Clustering time 44.940, Prec@1 8.941
Epoch 5 - Kernel K-means clustering 26: Clustering time 44.891, Prec@1 8.928
Epoch 5 - Kernel K-means clustering 27: Clustering time 44.930, Prec@1 8.946
Epoch 5 - Kernel K-means clustering 28: Clustering time 44.958, Prec@1 8.959
Epoch 5 - Kernel K-means clustering 29: Clustering time 44.906, Prec@1 8.942
Epoch 5 - Kernel K-means clustering 30: Clustering time 45.821, Prec@1 8.939
Epoch 5 - Kernel K-means clustering 31: Clustering time 44.916, Prec@1 8.939
Epoch 5 - Kernel K-means clustering 32: Clustering time 44.922, Prec@1 8.919
Epoch 5 - Kernel K-means clustering 33: Clustering time 44.851, Prec@1 8.897
Epoch 5 - Kernel K-means clustering 34: Clustering time 44.812, Prec@1 8.877
Epoch 5 - Kernel K-means clustering 35: Clustering time 46.323, Prec@1 8.847
Epoch 5 - Kernel K-means clustering 36: Clustering time 46.103, Prec@1 8.852
Epoch 5 - Kernel K-means clustering 37: Clustering time 45.662, Prec@1 8.823
Epoch 5 - Kernel K-means clustering 38: Clustering time 45.284, Prec@1 8.805
Epoch 5 - Kernel K-means clustering 39: Clustering time 45.410, Prec@1 8.789
Epoch 5 - Kernel K-means clustering 40: Clustering time 44.882, Prec@1 8.776
Epoch 5 - Kernel K-means clustering 41: Clustering time 44.784, Prec@1 8.751
Epoch 5 - Kernel K-means clustering 42: Clustering time 44.898, Prec@1 8.713
Epoch 5 - Kernel K-means clustering 43: Clustering time 44.899, Prec@1 8.682
Epoch 5 - Kernel K-means clustering 44: Clustering time 44.890, Prec@1 8.663
Epoch 5 - Kernel K-means clustering 45: Clustering time 44.883, Prec@1 8.637
Epoch 5 - Kernel K-means clustering 46: Clustering time 44.836, Prec@1 8.632
Epoch 5 - Kernel K-means clustering 47: Clustering time 44.856, Prec@1 8.619
Epoch 5 - Kernel K-means clustering 48: Clustering time 44.885, Prec@1 8.599
Epoch 5 - Kernel K-means clustering 49: Clustering time 46.515, Prec@1 8.581
Epoch 5 - Kernel K-means clustering 50: Clustering time 44.804, Prec@1 8.558
Epoch 5 - Kernel K-means clustering 51: Clustering time 44.826, Prec@1 8.533
Epoch 5 - Kernel K-means clustering 52: Clustering time 44.787, Prec@1 8.491
Epoch 5 - Kernel K-means clustering 53: Clustering time 45.618, Prec@1 8.478
Epoch 5 - Kernel K-means clustering 54: Clustering time 44.810, Prec@1 8.482
Epoch 5 - Kernel K-means clustering 55: Clustering time 44.826, Prec@1 8.469
Epoch 5 - Kernel K-means clustering 56: Clustering time 44.849, Prec@1 8.466
Epoch 5 - Kernel K-means clustering 57: Clustering time 44.865, Prec@1 8.455
Epoch 5 - Kernel K-means clustering 58: Clustering time 45.899, Prec@1 8.446
Epoch 5 - Kernel K-means clustering 59: Clustering time 44.840, Prec@1 8.430
Epoch 5 - Kernel K-means clustering 60: Clustering time 44.881, Prec@1 8.415
Epoch 5 - Kernel K-means clustering 61: Clustering time 44.851, Prec@1 8.408
Epoch 5 - Kernel K-means clustering 62: Clustering time 44.795, Prec@1 8.401
Epoch 5 - Kernel K-means clustering 63: Clustering time 44.875, Prec@1 8.410
Epoch 5 - Kernel K-means clustering 64: Clustering time 44.841, Prec@1 8.397
Epoch 5 - Kernel K-means clustering 65: Clustering time 44.817, Prec@1 8.379
Epoch 5 - Kernel K-means clustering 66: Clustering time 44.873, Prec@1 8.381
Epoch 5 - Kernel K-means clustering 67: Clustering time 44.865, Prec@1 8.375
Epoch 5 - Kernel K-means clustering 68: Clustering time 44.858, Prec@1 8.361
Epoch 5 - Kernel K-means clustering 69: Clustering time 44.866, Prec@1 8.366
Epoch 5 - Kernel K-means clustering 70: Clustering time 44.813, Prec@1 8.366
Epoch 5 - Kernel K-means clustering 71: Clustering time 44.773, Prec@1 8.356
Epoch 5 - Kernel K-means clustering 72: Clustering time 47.135, Prec@1 8.361
Epoch 5 - Kernel K-means clustering 73: Clustering time 45.077, Prec@1 8.359
Epoch 5 - Kernel K-means clustering 74: Clustering time 44.784, Prec@1 8.356
Epoch 5 - Kernel K-means clustering 75: Clustering time 44.799, Prec@1 8.359
Epoch 5 - Kernel K-means clustering 76: Clustering time 44.766, Prec@1 8.363
Epoch 5 - Kernel K-means clustering 77: Clustering time 46.215, Prec@1 8.365
Epoch 5 - Kernel K-means clustering 78: Clustering time 44.798, Prec@1 8.366
Epoch 5 - Kernel K-means clustering 79: Clustering time 44.826, Prec@1 8.356
Epoch 5 - Kernel K-means clustering 80: Clustering time 44.817, Prec@1 8.356
Epoch 5 - Kernel K-means clustering 81: Clustering time 44.740, Prec@1 8.352
Epoch 5 - Kernel K-means clustering 82: Clustering time 44.769, Prec@1 8.347
Epoch 5 - Kernel K-means clustering 83: Clustering time 44.775, Prec@1 8.347
Epoch 5 - Kernel K-means clustering 84: Clustering time 45.384, Prec@1 8.343
Epoch 5 - Kernel K-means clustering 85: Clustering time 44.816, Prec@1 8.341
Epoch 5 - Kernel K-means clustering 86: Clustering time 44.817, Prec@1 8.338
Epoch 5 - Kernel K-means clustering 87: Clustering time 44.870, Prec@1 8.339
Converged at iteration 88
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.3229 (3.3229)
Train - epoch [6/200]	BT 3.918 (3.918)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.5037 (3.5037)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.4795 (3.4795)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.6231 (3.6231)
Train - epoch [6/200]	BT 4.361 (4.361)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.4886 (3.4886)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4809 (3.4809)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4723 (3.4723)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.5346 (3.5346)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.4611 (3.4611)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.3517 (3.3517)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 3.125 (3.125)	Loss 3.4158 (3.4158)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4284 (3.4284)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.3564 (3.3564)
Train - epoch [6/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.5276 (3.5276)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 12.500 (12.500)	Loss 3.5743 (3.5743)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.4401 (3.4401)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.6568 (3.6568)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 3.125 (3.125)	Loss 3.4452 (3.4452)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.5095 (3.5095)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4089 (3.4089)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4445 (3.4445)
Train - epoch [6/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.4116 (3.4116)
Train - epoch [6/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.6204 (3.6204)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.4286 (3.4286)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5735 (3.5735)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.3440 (3.3440)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4052 (3.4052)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 9.375 (9.375)	Loss 3.4645 (3.4645)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.3624 (3.3624)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.4623 (3.4623)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4291 (3.4291)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5184 (3.5184)
Train - epoch [6/200]	BT 4.037 (4.037)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4686 (3.4686)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3441 (3.3441)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4883 (3.4883)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4744 (3.4744)
Train - epoch [6/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 3.6143 (3.6143)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4351 (3.4351)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.5709 (3.5709)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4231 (3.4231)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4275 (3.4275)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4786 (3.4786)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3788 (3.3788)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.6103 (3.6103)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4654 (3.4654)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.5741 (3.5741)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4517 (3.4517)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4700 (3.4700)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.6053 (3.6053)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.6200 (3.6200)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4289 (3.4289)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5424 (3.5424)
Train - epoch [6/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.4519 (3.4519)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.7713 (3.7713)
Train - epoch [6/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.5524 (3.5524)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4276 (3.4276)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4315 (3.4315)
Train - epoch [6/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.5824 (3.5824)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5383 (3.5383)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3555 (3.3555)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.3863 (3.3863)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3891 (3.3891)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4265 (3.4265)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 15.625 (15.625)	Loss 3.4662 (3.4662)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4403 (3.4403)
Train - epoch [6/200]	BT 1.296 (1.296)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5195 (3.5195)
Train - epoch [6/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4073 (3.4073)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.2864 (3.2864)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4335 (3.4335)
Train - epoch [6/200]	BT 1.281 (1.281)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4060 (3.4060)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3946 (3.3946)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.7311 (3.7311)
Train - epoch [6/200]	BT 4.172 (4.172)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.5104 (3.5104)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4748 (3.4748)
Train - epoch [6/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4630 (3.4630)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4242 (3.4242)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.5053 (3.5053)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3400 (3.3400)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4529 (3.4529)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.4626 (3.4626)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5299 (3.5299)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4341 (3.4341)
Train - epoch [6/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4218 (3.4218)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.3804 (3.3804)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.5479 (3.5479)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3908 (3.3908)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4113 (3.4113)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4479 (3.4479)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4107 (3.4107)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4331 (3.4331)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5030 (3.5030)
Train - epoch [6/200]	BT 3.997 (3.997)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4393 (3.4393)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4722 (3.4722)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.5711 (3.5711)
Train - epoch [6/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5890 (3.5890)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3579 (3.3579)
Train - epoch [6/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3640 (3.3640)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.6496 (3.6496)
Train - epoch [6/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4322 (3.4322)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.3774 (3.3774)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4272 (3.4272)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4432 (3.4432)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4567 (3.4567)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4012 (3.4012)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3797 (3.3797)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4126 (3.4126)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.5480 (3.5480)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5359 (3.5359)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4506 (3.4506)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.4282 (3.4282)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4429 (3.4429)
Train - epoch [6/200]	BT 4.120 (4.120)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4137 (3.4137)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3996 (3.3996)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3967 (3.3967)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4053 (3.4053)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.3882 (3.3882)
Train - epoch [6/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4102 (3.4102)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.3459 (3.3459)
Train - epoch [6/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4839 (3.4839)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4407 (3.4407)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4978 (3.4978)
Train - epoch [6/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4074 (3.4074)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4755 (3.4755)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4314 (3.4314)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4813 (3.4813)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3625 (3.3625)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5811 (3.5811)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4125 (3.4125)
Train - epoch [6/200]	BT 3.652 (3.652)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3793 (3.3793)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4538 (3.4538)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3857 (3.3857)
Train - epoch [6/200]	BT 1.288 (1.288)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4810 (3.4810)
Train - epoch [6/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4546 (3.4546)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4612 (3.4612)
Train - epoch [6/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3794 (3.3794)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3925 (3.3925)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.3745 (3.3745)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.3992 (3.3992)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4985 (3.4985)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4929 (3.4929)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4276 (3.4276)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4313 (3.4313)
Train - epoch [6/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.3522 (3.3522)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3923 (3.3923)
Train - epoch [6/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4017 (3.4017)
Train - epoch [6/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3536 (3.3536)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 3.4208 (3.4208)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.3426 (3.3426)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3745 (3.3745)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4247 (3.4247)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3764 (3.3764)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3578 (3.3578)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4045 (3.4045)
Train - epoch [6/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4155 (3.4155)
Train - epoch [6/200]	BT 4.245 (4.245)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4618 (3.4618)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3137 (3.3137)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4799 (3.4799)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4216 (3.4216)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4026 (3.4026)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.5033 (3.5033)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4214 (3.4214)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4699 (3.4699)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.4168 (3.4168)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3701 (3.3701)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4409 (3.4409)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4155 (3.4155)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.5096 (3.5096)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3868 (3.3868)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4029 (3.4029)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4290 (3.4290)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.5037 (3.5037)
Train - epoch [6/200]	BT 1.241 (1.241)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4470 (3.4470)
Train - epoch [6/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4173 (3.4173)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4692 (3.4692)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.5135 (3.5135)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5168 (3.5168)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5157 (3.5157)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3739 (3.3739)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.3394 (3.3394)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4276 (3.4276)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4238 (3.4238)
Train - epoch [6/200]	BT 4.078 (4.078)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4299 (3.4299)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3310 (3.3310)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4523 (3.4523)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.5859 (3.5859)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4594 (3.4594)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3833 (3.3833)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.5114 (3.5114)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.4156 (3.4156)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3988 (3.3988)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.5890 (3.5890)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4864 (3.4864)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4625 (3.4625)
Train - epoch [6/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4861 (3.4861)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3826 (3.3826)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4045 (3.4045)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4754 (3.4754)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4084 (3.4084)
Train - epoch [6/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4055 (3.4055)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4704 (3.4704)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.3290 (3.3290)
Train - epoch [6/200]	BT 4.122 (4.122)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4639 (3.4639)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.4859 (3.4859)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4421 (3.4421)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4560 (3.4560)
Train - epoch [6/200]	BT 3.791 (3.791)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4429 (3.4429)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4540 (3.4540)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.5772 (3.5772)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.3365 (3.3365)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4093 (3.4093)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4273 (3.4273)
Train - epoch [6/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4029 (3.4029)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4053 (3.4053)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3340 (3.3340)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.5252 (3.5252)
Train - epoch [6/200]	BT 3.989 (3.989)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3747 (3.3747)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.3662 (3.3662)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3940 (3.3940)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3639 (3.3639)
Train - epoch [6/200]	BT 3.997 (3.997)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4202 (3.4202)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.3584 (3.3584)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4443 (3.4443)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.6389 (3.6389)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4099 (3.4099)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4258 (3.4258)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5256 (3.5256)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4533 (3.4533)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.5451 (3.5451)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4058 (3.4058)
Train - epoch [6/200]	BT 1.303 (1.303)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4912 (3.4912)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.4774 (3.4774)
Train - epoch [6/200]	BT 1.238 (1.238)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4987 (3.4987)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4098 (3.4098)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.5835 (3.5835)
Train - epoch [6/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5223 (3.5223)
Train - epoch [6/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 3.4013 (3.4013)
Train - epoch [6/200]	BT 4.145 (4.145)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.6215 (3.6215)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.5465 (3.5465)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 84.375 (84.375)	Loss 3.4010 (3.4010)
Train - epoch [6/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.5440 (3.5440)
Train - epoch [6/200]	BT 1.497 (1.497)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3674 (3.3674)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3679 (3.3679)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3972 (3.3972)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4001 (3.4001)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.6639 (3.6639)
Train - epoch [6/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3828 (3.3828)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3542 (3.3542)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4170 (3.4170)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.5223 (3.5223)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4601 (3.4601)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4439 (3.4439)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.5531 (3.5531)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3397 (3.3397)
Train - epoch [6/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4024 (3.4024)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4554 (3.4554)
Train - epoch [6/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.2915 (3.2915)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4429 (3.4429)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4521 (3.4521)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3645 (3.3645)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.3750 (3.3750)
Train - epoch [6/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3815 (3.3815)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3916 (3.3916)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3819 (3.3819)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.3372 (3.3372)
Train - epoch [6/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.5309 (3.5309)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5147 (3.5147)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4499 (3.4499)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5419 (3.5419)
Train - epoch [6/200]	BT 3.751 (3.751)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5562 (3.5562)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4192 (3.4192)
Train - epoch [6/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.5070 (3.5070)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3802 (3.3802)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4541 (3.4541)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4115 (3.4115)
Train - epoch [6/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4886 (3.4886)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4411 (3.4411)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.4255 (3.4255)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4889 (3.4889)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.4776 (3.4776)
Train - epoch [6/200]	BT 4.203 (4.203)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3231 (3.3231)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3922 (3.3922)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4404 (3.4404)
Train - epoch [6/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4255 (3.4255)
Train - epoch [6/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.4092 (3.4092)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4407 (3.4407)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4821 (3.4821)
Train - epoch [6/200]	BT 4.118 (4.118)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3207 (3.3207)
Train - epoch [6/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5824 (3.5824)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4240 (3.4240)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3798 (3.3798)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4655 (3.4655)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.3295 (3.3295)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4563 (3.4563)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.6499 (3.6499)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.3845 (3.3845)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4430 (3.4430)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4756 (3.4756)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4169 (3.4169)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4264 (3.4264)
Train - epoch [6/200]	BT 4.355 (4.355)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.4207 (3.4207)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4479 (3.4479)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3989 (3.3989)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3697 (3.3697)
Train - epoch [6/200]	BT 1.282 (1.282)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4286 (3.4286)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.4311 (3.4311)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.5587 (3.5587)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3685 (3.3685)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4054 (3.4054)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 3.4693 (3.4693)
Train - epoch [6/200]	BT 1.293 (1.293)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4274 (3.4274)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3644 (3.3644)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.5059 (3.5059)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3333 (3.3333)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4124 (3.4124)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3917 (3.3917)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4537 (3.4537)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4501 (3.4501)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5760 (3.5760)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.5029 (3.5029)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3822 (3.3822)
Train - epoch [6/200]	BT 4.017 (4.017)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3817 (3.3817)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3372 (3.3372)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.3647 (3.3647)
Train - epoch [6/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4022 (3.4022)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.3901 (3.3901)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3105 (3.3105)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4112 (3.4112)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3743 (3.3743)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.5924 (3.5924)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4348 (3.4348)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.3660 (3.3660)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4663 (3.4663)
Train - epoch [6/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3955 (3.3955)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4162 (3.4162)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3939 (3.3939)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3888 (3.3888)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3890 (3.3890)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3784 (3.3784)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.3886 (3.3886)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.5070 (3.5070)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4510 (3.4510)
Train - epoch [6/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4887 (3.4887)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4226 (3.4226)
Train - epoch [6/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.5074 (3.5074)
Train - epoch [6/200]	BT 4.309 (4.309)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3425 (3.3425)
Train - epoch [6/200]	BT 1.241 (1.241)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4739 (3.4739)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.5944 (3.5944)
Train - epoch [6/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4540 (3.4540)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3832 (3.3832)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3881 (3.3881)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4845 (3.4845)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4292 (3.4292)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4948 (3.4948)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3614 (3.3614)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4082 (3.4082)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4412 (3.4412)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4026 (3.4026)
Train - epoch [6/200]	BT 4.198 (4.198)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4607 (3.4607)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4933 (3.4933)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3794 (3.3794)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4021 (3.4021)
Train - epoch [6/200]	BT 4.344 (4.344)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4113 (3.4113)
Train - epoch [6/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4077 (3.4077)
Train - epoch [6/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3681 (3.3681)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3889 (3.3889)
Train - epoch [6/200]	BT 4.434 (4.434)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4342 (3.4342)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.7773 (3.7773)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4409 (3.4409)
Train - epoch [6/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4360 (3.4360)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4393 (3.4393)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4275 (3.4275)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4762 (3.4762)
Train - epoch [6/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.3522 (3.3522)
Train - epoch [6/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.4707 (3.4707)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4887 (3.4887)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4117 (3.4117)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4321 (3.4321)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4666 (3.4666)
Train - epoch [6/200]	BT 3.736 (3.736)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3152 (3.3152)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4024 (3.4024)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4636 (3.4636)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4498 (3.4498)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4061 (3.4061)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 21.875 (21.875)	Loss 3.4705 (3.4705)
Train - epoch [6/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.4625 (3.4625)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4848 (3.4848)
Train - epoch [6/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4664 (3.4664)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4459 (3.4459)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.4961 (3.4961)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3849 (3.3849)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.5852 (3.5852)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.5458 (3.5458)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3735 (3.3735)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4200 (3.4200)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4312 (3.4312)
Train - epoch [6/200]	BT 1.308 (1.308)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4507 (3.4507)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4956 (3.4956)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3541 (3.3541)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3446 (3.3446)
Train - epoch [6/200]	BT 4.347 (4.347)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.5367 (3.5367)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4064 (3.4064)
Train - epoch [6/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4627 (3.4627)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3644 (3.3644)
Train - epoch [6/200]	BT 3.937 (3.937)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5057 (3.5057)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4891 (3.4891)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4616 (3.4616)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4390 (3.4390)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3681 (3.3681)
Train - epoch [6/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5457 (3.5457)
Train - epoch [6/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.4687 (3.4687)
Train - epoch [6/200]	BT 4.352 (4.352)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5204 (3.5204)
Train - epoch [6/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5067 (3.5067)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5890 (3.5890)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4541 (3.4541)
Train - epoch [6/200]	BT 3.875 (3.875)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3748 (3.3748)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4650 (3.4650)
Train - epoch [6/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4174 (3.4174)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.3606 (3.3606)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3889 (3.3889)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.5867 (3.5867)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4562 (3.4562)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4363 (3.4363)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4734 (3.4734)
Train - epoch [6/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3697 (3.3697)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3694 (3.3694)
Train - epoch [6/200]	BT 4.262 (4.262)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4935 (3.4935)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.3284 (3.3284)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3194 (3.3194)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4406 (3.4406)
Train - epoch [6/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.3933 (3.3933)
Train - epoch [6/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4609 (3.4609)
Train - epoch [6/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.5220 (3.5220)
Train - epoch [6/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.3975 (3.3975)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3904 (3.3904)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4648 (3.4648)
Train - epoch [6/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4747 (3.4747)
Train - epoch [6/200]	BT 1.387 (1.387)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4473 (3.4473)
Train - epoch [6/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4319 (3.4319)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5793 (3.5793)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.4611 (3.4611)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.3965 (3.3965)
Train - epoch [6/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.4796 (3.4796)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.4174 (3.4174)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3654 (3.3654)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3858 (3.3858)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4928 (3.4928)
Train - epoch [6/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.4828 (3.4828)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.5230 (3.5230)
Train - epoch [6/200]	BT 1.300 (1.300)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3898 (3.3898)
Train - epoch [6/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4607 (3.4607)
Train - epoch [6/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.4539 (3.4539)
Train - epoch [6/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.5337 (3.5337)
Train - epoch [6/200]	BT 4.071 (4.071)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.4673 (3.4673)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.4577 (3.4577)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.3702 (3.3702)
Train - epoch [6/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.5428 (3.5428)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.4977 (3.4977)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5190 (3.5190)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4244 (3.4244)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4607 (3.4607)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.3973 (3.3973)
Train - epoch [6/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.3666 (3.3666)
Train - epoch [6/200]	BT 4.899 (4.899)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.4583 (3.4583)
Train - epoch [6/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 3.6288 (3.6288)
Train - epoch [6/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.5468 (3.5468)
Train - epoch [6/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.3590 (3.3590)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.3492 (3.3492)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.5219 (3.5219)
Train - epoch [6/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.4606 (3.4606)
Train - epoch [6/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.4271 (3.4271)
Train - epoch [6/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4186 (3.4186)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.3621 (3.3621)
Train - epoch [6/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.3497 (3.3497)
Train - epoch [6/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.4339 (3.4339)
Train - epoch [6/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.4223 (3.4223)
Train - epoch [6/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.4341 (3.4341)
Test on T training set - [6][0/1731]	T 0.291 (0.291)	D 0.186 (0.186)	T@1 9.375 (9.375)	T@5 53.125 (53.125)	L 4.2220 (4.2220)
Test on T training set - [6][10/1731]	T 0.199 (0.196)	D 0.101 (0.095)	T@1 3.125 (10.511)	T@5 37.500 (44.318)	L 4.1418 (3.8899)
Test on T training set - [6][20/1731]	T 0.210 (0.205)	D 0.108 (0.104)	T@1 9.375 (9.821)	T@5 46.875 (44.643)	L 3.8289 (3.8822)
Test on T training set - [6][30/1731]	T 0.204 (0.205)	D 0.099 (0.104)	T@1 18.750 (10.685)	T@5 43.750 (42.440)	L 3.6617 (3.8040)
Test on T training set - [6][40/1731]	T 0.222 (0.206)	D 0.122 (0.105)	T@1 3.125 (10.290)	T@5 31.250 (42.226)	L 3.9878 (3.8217)
Test on T training set - [6][50/1731]	T 0.208 (0.206)	D 0.106 (0.105)	T@1 0.000 (9.681)	T@5 37.500 (42.034)	L 4.2323 (3.8452)
Test on T training set - [6][60/1731]	T 0.210 (0.206)	D 0.114 (0.106)	T@1 12.500 (9.477)	T@5 40.625 (42.008)	L 3.7705 (3.8525)
Test on T training set - [6][70/1731]	T 0.206 (0.206)	D 0.098 (0.105)	T@1 12.500 (9.595)	T@5 46.875 (42.121)	L 3.9019 (3.8459)
Test on T training set - [6][80/1731]	T 0.196 (0.205)	D 0.090 (0.104)	T@1 9.375 (9.645)	T@5 43.750 (42.554)	L 3.8789 (3.8441)
Test on T training set - [6][90/1731]	T 0.172 (0.227)	D 0.076 (0.126)	T@1 3.125 (9.787)	T@5 50.000 (42.891)	L 4.1887 (3.8388)
Test on T training set - [6][100/1731]	T 0.172 (0.223)	D 0.076 (0.122)	T@1 15.625 (9.808)	T@5 40.625 (43.193)	L 3.5609 (3.8383)
Test on T training set - [6][110/1731]	T 0.198 (0.219)	D 0.096 (0.118)	T@1 9.375 (10.023)	T@5 46.875 (43.468)	L 4.1554 (3.8389)
Test on T training set - [6][120/1731]	T 0.184 (0.216)	D 0.087 (0.115)	T@1 12.500 (10.072)	T@5 43.750 (43.492)	L 4.4389 (3.8691)
Test on T training set - [6][130/1731]	T 0.190 (0.214)	D 0.086 (0.112)	T@1 12.500 (10.520)	T@5 50.000 (43.822)	L 3.7777 (3.8736)
Test on T training set - [6][140/1731]	T 0.184 (0.211)	D 0.078 (0.110)	T@1 12.500 (10.838)	T@5 43.750 (43.772)	L 3.9516 (3.8874)
Test on T training set - [6][150/1731]	T 0.198 (0.209)	D 0.091 (0.108)	T@1 21.875 (10.969)	T@5 53.125 (43.750)	L 3.6705 (3.9123)
Test on T training set - [6][160/1731]	T 0.177 (0.207)	D 0.075 (0.106)	T@1 6.250 (10.967)	T@5 37.500 (43.556)	L 4.3668 (3.9207)
Test on T training set - [6][170/1731]	T 0.170 (0.205)	D 0.070 (0.104)	T@1 25.000 (11.221)	T@5 53.125 (43.860)	L 3.3941 (3.9276)
Test on T training set - [6][180/1731]	T 0.158 (0.203)	D 0.054 (0.102)	T@1 9.375 (11.274)	T@5 25.000 (43.715)	L 4.4994 (3.9474)
Test on T training set - [6][190/1731]	T 0.174 (0.210)	D 0.079 (0.109)	T@1 9.375 (11.093)	T@5 40.625 (43.390)	L 4.4703 (3.9756)
Test on T training set - [6][200/1731]	T 0.166 (0.208)	D 0.060 (0.107)	T@1 12.500 (11.163)	T@5 28.125 (43.097)	L 4.5372 (3.9881)
Test on T training set - [6][210/1731]	T 0.172 (0.206)	D 0.067 (0.105)	T@1 12.500 (11.241)	T@5 34.375 (42.817)	L 4.9205 (4.0079)
Test on T training set - [6][220/1731]	T 0.179 (0.204)	D 0.075 (0.103)	T@1 21.875 (11.227)	T@5 68.750 (42.774)	L 3.2403 (4.0165)
Test on T training set - [6][230/1731]	T 0.170 (0.203)	D 0.066 (0.102)	T@1 25.000 (11.837)	T@5 59.375 (44.048)	L 3.0191 (3.9786)
Test on T training set - [6][240/1731]	T 0.231 (0.204)	D 0.123 (0.102)	T@1 21.875 (12.331)	T@5 71.875 (45.345)	L 3.3838 (3.9487)
Test on T training set - [6][250/1731]	T 0.198 (0.204)	D 0.095 (0.103)	T@1 31.250 (12.799)	T@5 78.125 (46.539)	L 3.0424 (3.9163)
Test on T training set - [6][260/1731]	T 0.232 (0.205)	D 0.126 (0.104)	T@1 18.750 (13.230)	T@5 78.125 (47.809)	L 2.9591 (3.8813)
Test on T training set - [6][270/1731]	T 0.222 (0.206)	D 0.127 (0.104)	T@1 18.750 (13.561)	T@5 65.625 (48.974)	L 3.2209 (3.8550)
Test on T training set - [6][280/1731]	T 0.223 (0.215)	D 0.123 (0.114)	T@1 21.875 (14.057)	T@5 68.750 (49.967)	L 2.8881 (3.8223)
Test on T training set - [6][290/1731]	T 0.220 (0.215)	D 0.124 (0.114)	T@1 15.625 (14.272)	T@5 87.500 (50.934)	L 3.3157 (3.8034)
Test on T training set - [6][300/1731]	T 0.196 (0.215)	D 0.101 (0.114)	T@1 21.875 (14.618)	T@5 78.125 (51.910)	L 3.5092 (3.7794)
Test on T training set - [6][310/1731]	T 0.216 (0.215)	D 0.113 (0.114)	T@1 34.375 (15.123)	T@5 87.500 (52.894)	L 2.7283 (3.7502)
Test on T training set - [6][320/1731]	T 0.195 (0.215)	D 0.093 (0.114)	T@1 46.875 (15.576)	T@5 84.375 (53.806)	L 2.1599 (3.7261)
Test on T training set - [6][330/1731]	T 0.199 (0.214)	D 0.092 (0.113)	T@1 21.875 (15.918)	T@5 84.375 (54.551)	L 2.8226 (3.7030)
Test on T training set - [6][340/1731]	T 0.182 (0.213)	D 0.082 (0.112)	T@1 25.000 (16.212)	T@5 84.375 (55.224)	L 3.4240 (3.6871)
Test on T training set - [6][350/1731]	T 0.205 (0.213)	D 0.110 (0.111)	T@1 18.750 (16.524)	T@5 71.875 (55.814)	L 3.4591 (3.6724)
Test on T training set - [6][360/1731]	T 0.229 (0.213)	D 0.124 (0.112)	T@1 12.500 (17.019)	T@5 84.375 (56.510)	L 2.8642 (3.6416)
Test on T training set - [6][370/1731]	T 0.179 (0.215)	D 0.072 (0.114)	T@1 6.250 (17.225)	T@5 65.625 (57.109)	L 4.4508 (3.6323)
Test on T training set - [6][380/1731]	T 0.181 (0.214)	D 0.076 (0.113)	T@1 12.500 (17.069)	T@5 71.875 (57.489)	L 3.8010 (3.6383)
Test on T training set - [6][390/1731]	T 0.159 (0.213)	D 0.063 (0.111)	T@1 12.500 (16.864)	T@5 65.625 (57.936)	L 3.8817 (3.6430)
Test on T training set - [6][400/1731]	T 0.158 (0.211)	D 0.054 (0.110)	T@1 3.125 (16.607)	T@5 71.875 (58.237)	L 3.8600 (3.6520)
Test on T training set - [6][410/1731]	T 0.161 (0.210)	D 0.055 (0.109)	T@1 6.250 (16.446)	T@5 59.375 (58.637)	L 4.0933 (3.6595)
Test on T training set - [6][420/1731]	T 0.157 (0.209)	D 0.061 (0.108)	T@1 6.250 (16.286)	T@5 68.750 (59.048)	L 4.1079 (3.6691)
Test on T training set - [6][430/1731]	T 0.163 (0.208)	D 0.060 (0.107)	T@1 9.375 (16.118)	T@5 81.250 (59.375)	L 4.3827 (3.6780)
Test on T training set - [6][440/1731]	T 0.154 (0.207)	D 0.052 (0.106)	T@1 9.375 (15.916)	T@5 75.000 (59.743)	L 4.5347 (3.6909)
Test on T training set - [6][450/1731]	T 0.165 (0.206)	D 0.065 (0.105)	T@1 9.375 (15.736)	T@5 71.875 (60.040)	L 4.2079 (3.6937)
Test on T training set - [6][460/1731]	T 0.159 (0.205)	D 0.064 (0.104)	T@1 6.250 (15.625)	T@5 87.500 (60.392)	L 4.3276 (3.6975)
Test on T training set - [6][470/1731]	T 0.156 (0.204)	D 0.049 (0.103)	T@1 3.125 (15.486)	T@5 75.000 (60.722)	L 4.0908 (3.7013)
Test on T training set - [6][480/1731]	T 0.161 (0.206)	D 0.056 (0.105)	T@1 9.375 (15.333)	T@5 84.375 (60.980)	L 3.7963 (3.7085)
Test on T training set - [6][490/1731]	T 0.153 (0.205)	D 0.053 (0.104)	T@1 15.625 (15.237)	T@5 59.375 (61.195)	L 3.8759 (3.7122)
Test on T training set - [6][500/1731]	T 0.161 (0.204)	D 0.060 (0.103)	T@1 15.625 (15.151)	T@5 87.500 (61.446)	L 3.6938 (3.7141)
Test on T training set - [6][510/1731]	T 0.156 (0.203)	D 0.059 (0.102)	T@1 6.250 (15.020)	T@5 75.000 (61.711)	L 4.3921 (3.7186)
Test on T training set - [6][520/1731]	T 0.150 (0.202)	D 0.052 (0.101)	T@1 0.000 (14.857)	T@5 75.000 (61.900)	L 5.0777 (3.7284)
Test on T training set - [6][530/1731]	T 0.171 (0.202)	D 0.066 (0.100)	T@1 0.000 (14.695)	T@5 62.500 (62.129)	L 4.6793 (3.7379)
Test on T training set - [6][540/1731]	T 0.161 (0.201)	D 0.058 (0.100)	T@1 0.000 (14.539)	T@5 68.750 (62.327)	L 4.0818 (3.7462)
Test on T training set - [6][550/1731]	T 0.154 (0.200)	D 0.049 (0.099)	T@1 9.375 (14.451)	T@5 78.125 (62.494)	L 4.1344 (3.7510)
Test on T training set - [6][560/1731]	T 0.162 (0.200)	D 0.059 (0.098)	T@1 0.000 (14.344)	T@5 62.500 (62.634)	L 4.0480 (3.7545)
Test on T training set - [6][570/1731]	T 0.194 (0.199)	D 0.087 (0.098)	T@1 12.500 (14.257)	T@5 78.125 (62.823)	L 3.8595 (3.7570)
Test on T training set - [6][580/1731]	T 0.175 (0.199)	D 0.069 (0.097)	T@1 9.375 (14.189)	T@5 93.750 (63.065)	L 3.8040 (3.7574)
Test on T training set - [6][590/1731]	T 0.169 (0.198)	D 0.068 (0.097)	T@1 25.000 (14.107)	T@5 84.375 (63.320)	L 3.6085 (3.7612)
Test on T training set - [6][600/1731]	T 0.166 (0.203)	D 0.070 (0.101)	T@1 12.500 (13.992)	T@5 68.750 (63.514)	L 4.0330 (3.7676)
Test on T training set - [6][610/1731]	T 0.150 (0.202)	D 0.055 (0.101)	T@1 6.250 (13.922)	T@5 68.750 (63.727)	L 4.1258 (3.7701)
Test on T training set - [6][620/1731]	T 0.181 (0.202)	D 0.073 (0.100)	T@1 12.500 (13.849)	T@5 84.375 (64.000)	L 4.1637 (3.7732)
Test on T training set - [6][630/1731]	T 0.156 (0.201)	D 0.052 (0.100)	T@1 3.125 (13.793)	T@5 71.875 (64.139)	L 4.4858 (3.7767)
Test on T training set - [6][640/1731]	T 0.160 (0.200)	D 0.054 (0.099)	T@1 15.625 (13.685)	T@5 87.500 (64.309)	L 4.0307 (3.7804)
Test on T training set - [6][650/1731]	T 0.157 (0.200)	D 0.057 (0.098)	T@1 6.250 (13.618)	T@5 68.750 (64.511)	L 4.6639 (3.7840)
Test on T training set - [6][660/1731]	T 0.162 (0.199)	D 0.056 (0.098)	T@1 12.500 (13.526)	T@5 75.000 (64.679)	L 3.9290 (3.7880)
Test on T training set - [6][670/1731]	T 0.150 (0.199)	D 0.055 (0.097)	T@1 21.875 (13.501)	T@5 81.250 (64.838)	L 3.2756 (3.7921)
Test on T training set - [6][680/1731]	T 0.164 (0.198)	D 0.058 (0.097)	T@1 12.500 (13.413)	T@5 78.125 (64.973)	L 4.0337 (3.7971)
Test on T training set - [6][690/1731]	T 0.208 (0.198)	D 0.110 (0.096)	T@1 31.250 (13.404)	T@5 71.875 (64.996)	L 2.6177 (3.7951)
Test on T training set - [6][700/1731]	T 0.146 (0.197)	D 0.047 (0.096)	T@1 12.500 (13.356)	T@5 65.625 (64.898)	L 3.6830 (3.7945)
Test on T training set - [6][710/1731]	T 0.169 (0.197)	D 0.064 (0.096)	T@1 6.250 (13.256)	T@5 65.625 (64.851)	L 3.5677 (3.7977)
Test on T training set - [6][720/1731]	T 0.171 (0.201)	D 0.062 (0.099)	T@1 6.250 (13.237)	T@5 75.000 (64.884)	L 3.5669 (3.7969)
Test on T training set - [6][730/1731]	T 0.199 (0.200)	D 0.104 (0.099)	T@1 12.500 (13.171)	T@5 68.750 (64.877)	L 3.3262 (3.8002)
Test on T training set - [6][740/1731]	T 0.220 (0.201)	D 0.115 (0.099)	T@1 9.375 (13.133)	T@5 71.875 (64.921)	L 3.5411 (3.8022)
Test on T training set - [6][750/1731]	T 0.194 (0.201)	D 0.083 (0.099)	T@1 9.375 (13.087)	T@5 65.625 (64.943)	L 4.0794 (3.8036)
Test on T training set - [6][760/1731]	T 0.239 (0.201)	D 0.134 (0.099)	T@1 3.125 (13.026)	T@5 68.750 (65.013)	L 3.9433 (3.8062)
Test on T training set - [6][770/1731]	T 0.195 (0.201)	D 0.100 (0.099)	T@1 12.500 (12.982)	T@5 56.250 (65.045)	L 3.8995 (3.8088)
Test on T training set - [6][780/1731]	T 0.217 (0.201)	D 0.113 (0.100)	T@1 12.500 (12.940)	T@5 71.875 (65.113)	L 3.6833 (3.8085)
Test on T training set - [6][790/1731]	T 0.205 (0.201)	D 0.110 (0.100)	T@1 3.125 (12.903)	T@5 65.625 (65.186)	L 4.6121 (3.8102)
Test on T training set - [6][800/1731]	T 0.200 (0.201)	D 0.097 (0.100)	T@1 9.375 (12.851)	T@5 56.250 (65.184)	L 4.5772 (3.8153)
Test on T training set - [6][810/1731]	T 0.190 (0.202)	D 0.093 (0.101)	T@1 9.375 (12.878)	T@5 81.250 (65.301)	L 3.4981 (3.8134)
Test on T training set - [6][820/1731]	T 0.205 (0.202)	D 0.100 (0.101)	T@1 15.625 (12.827)	T@5 53.125 (65.309)	L 3.9293 (3.8144)
Test on T training set - [6][830/1731]	T 0.171 (0.202)	D 0.075 (0.101)	T@1 12.500 (12.782)	T@5 65.625 (65.324)	L 3.6716 (3.8156)
Test on T training set - [6][840/1731]	T 0.169 (0.202)	D 0.066 (0.101)	T@1 6.250 (12.734)	T@5 59.375 (65.369)	L 4.1082 (3.8163)
Test on T training set - [6][850/1731]	T 0.145 (0.201)	D 0.048 (0.100)	T@1 12.500 (12.709)	T@5 40.625 (65.225)	L 3.6198 (3.8177)
Test on T training set - [6][860/1731]	T 0.167 (0.201)	D 0.062 (0.100)	T@1 15.625 (12.703)	T@5 50.000 (65.066)	L 3.5525 (3.8205)
Test on T training set - [6][870/1731]	T 0.162 (0.201)	D 0.060 (0.099)	T@1 6.250 (12.705)	T@5 46.875 (64.882)	L 4.2667 (3.8199)
Test on T training set - [6][880/1731]	T 0.157 (0.200)	D 0.062 (0.099)	T@1 12.500 (12.653)	T@5 43.750 (64.664)	L 3.6110 (3.8197)
Test on T training set - [6][890/1731]	T 0.168 (0.200)	D 0.063 (0.098)	T@1 12.500 (12.623)	T@5 46.875 (64.422)	L 3.8207 (3.8210)
Test on T training set - [6][900/1731]	T 0.173 (0.199)	D 0.065 (0.098)	T@1 12.500 (12.597)	T@5 31.250 (64.227)	L 4.0470 (3.8221)
Test on T training set - [6][910/1731]	T 0.168 (0.201)	D 0.064 (0.100)	T@1 0.000 (12.517)	T@5 3.125 (63.759)	L 5.1436 (3.8309)
Test on T training set - [6][920/1731]	T 0.162 (0.201)	D 0.059 (0.100)	T@1 0.000 (12.391)	T@5 0.000 (63.087)	L 5.8574 (3.8472)
Test on T training set - [6][930/1731]	T 0.217 (0.201)	D 0.121 (0.100)	T@1 0.000 (12.282)	T@5 3.125 (62.460)	L 4.9258 (3.8615)
Test on T training set - [6][940/1731]	T 0.248 (0.201)	D 0.143 (0.100)	T@1 0.000 (12.161)	T@5 0.000 (61.819)	L 5.3093 (3.8764)
Test on T training set - [6][950/1731]	T 0.232 (0.201)	D 0.130 (0.100)	T@1 0.000 (12.037)	T@5 0.000 (61.202)	L 5.2092 (3.8904)
Test on T training set - [6][960/1731]	T 0.209 (0.202)	D 0.103 (0.100)	T@1 3.125 (11.928)	T@5 6.250 (60.611)	L 5.4143 (3.9040)
Test on T training set - [6][970/1731]	T 0.207 (0.202)	D 0.108 (0.100)	T@1 0.000 (11.818)	T@5 3.125 (60.044)	L 5.4999 (3.9173)
Test on T training set - [6][980/1731]	T 0.203 (0.202)	D 0.103 (0.100)	T@1 0.000 (11.710)	T@5 3.125 (59.467)	L 5.0509 (3.9315)
Test on T training set - [6][990/1731]	T 0.213 (0.202)	D 0.116 (0.101)	T@1 0.000 (11.604)	T@5 0.000 (58.905)	L 5.0412 (3.9441)
Test on T training set - [6][1000/1731]	T 0.209 (0.203)	D 0.113 (0.102)	T@1 0.000 (11.504)	T@5 0.000 (58.373)	L 5.5472 (3.9569)
Test on T training set - [6][1010/1731]	T 0.196 (0.203)	D 0.090 (0.102)	T@1 3.125 (11.418)	T@5 6.250 (57.845)	L 5.0989 (3.9695)
Test on T training set - [6][1020/1731]	T 0.185 (0.203)	D 0.090 (0.102)	T@1 0.000 (11.315)	T@5 6.250 (57.318)	L 5.0660 (3.9811)
Test on T training set - [6][1030/1731]	T 0.163 (0.203)	D 0.060 (0.101)	T@1 3.125 (11.224)	T@5 3.125 (56.796)	L 4.9715 (3.9931)
Test on T training set - [6][1040/1731]	T 0.160 (0.202)	D 0.065 (0.101)	T@1 3.125 (11.128)	T@5 3.125 (56.292)	L 5.1403 (4.0053)
Test on T training set - [6][1050/1731]	T 0.164 (0.202)	D 0.067 (0.101)	T@1 3.125 (11.031)	T@5 3.125 (55.789)	L 5.2821 (4.0169)
Test on T training set - [6][1060/1731]	T 0.158 (0.202)	D 0.054 (0.101)	T@1 0.000 (10.942)	T@5 3.125 (55.310)	L 5.4434 (4.0294)
Test on T training set - [6][1070/1731]	T 0.196 (0.201)	D 0.094 (0.100)	T@1 3.125 (10.857)	T@5 6.250 (54.852)	L 5.4587 (4.0412)
Test on T training set - [6][1080/1731]	T 0.150 (0.201)	D 0.055 (0.100)	T@1 3.125 (10.780)	T@5 3.125 (54.385)	L 4.8905 (4.0517)
Test on T training set - [6][1090/1731]	T 0.178 (0.201)	D 0.072 (0.100)	T@1 0.000 (10.710)	T@5 9.375 (53.970)	L 5.4091 (4.0613)
Test on T training set - [6][1100/1731]	T 0.181 (0.203)	D 0.086 (0.101)	T@1 0.000 (10.621)	T@5 3.125 (53.585)	L 4.9711 (4.0703)
Test on T training set - [6][1110/1731]	T 0.207 (0.203)	D 0.105 (0.101)	T@1 0.000 (10.534)	T@5 3.125 (53.212)	L 4.7440 (4.0786)
Test on T training set - [6][1120/1731]	T 0.173 (0.202)	D 0.077 (0.101)	T@1 0.000 (10.448)	T@5 6.250 (52.830)	L 5.2872 (4.0887)
Test on T training set - [6][1130/1731]	T 0.184 (0.202)	D 0.078 (0.101)	T@1 0.000 (10.367)	T@5 6.250 (52.484)	L 5.2723 (4.0969)
Test on T training set - [6][1140/1731]	T 0.183 (0.202)	D 0.088 (0.101)	T@1 6.250 (10.282)	T@5 12.500 (52.123)	L 4.8147 (4.1055)
Test on T training set - [6][1150/1731]	T 0.185 (0.202)	D 0.084 (0.101)	T@1 0.000 (10.200)	T@5 6.250 (51.767)	L 4.9406 (4.1143)
Test on T training set - [6][1160/1731]	T 0.163 (0.202)	D 0.067 (0.100)	T@1 0.000 (10.123)	T@5 15.625 (51.429)	L 5.2100 (4.1242)
Test on T training set - [6][1170/1731]	T 0.178 (0.202)	D 0.071 (0.100)	T@1 0.000 (10.045)	T@5 15.625 (51.097)	L 4.9932 (4.1321)
Test on T training set - [6][1180/1731]	T 0.179 (0.201)	D 0.082 (0.100)	T@1 0.000 (9.965)	T@5 12.500 (50.789)	L 5.2476 (4.1395)
Test on T training set - [6][1190/1731]	T 0.179 (0.201)	D 0.084 (0.100)	T@1 0.000 (9.887)	T@5 15.625 (50.462)	L 5.0346 (4.1464)
Test on T training set - [6][1200/1731]	T 0.183 (0.202)	D 0.074 (0.101)	T@1 0.000 (9.807)	T@5 18.750 (50.159)	L 5.2405 (4.1545)
Test on T training set - [6][1210/1731]	T 0.192 (0.202)	D 0.086 (0.101)	T@1 0.000 (9.744)	T@5 9.375 (49.861)	L 5.1710 (4.1628)
Test on T training set - [6][1220/1731]	T 0.164 (0.202)	D 0.063 (0.100)	T@1 6.250 (9.705)	T@5 25.000 (49.703)	L 4.7757 (4.1665)
Test on T training set - [6][1230/1731]	T 0.157 (0.201)	D 0.049 (0.100)	T@1 0.000 (9.664)	T@5 25.000 (49.566)	L 4.9859 (4.1715)
Test on T training set - [6][1240/1731]	T 0.177 (0.201)	D 0.070 (0.100)	T@1 9.375 (9.637)	T@5 40.625 (49.428)	L 4.0943 (4.1747)
Test on T training set - [6][1250/1731]	T 0.177 (0.201)	D 0.080 (0.100)	T@1 6.250 (9.612)	T@5 28.125 (49.298)	L 4.1210 (4.1770)
Test on T training set - [6][1260/1731]	T 0.176 (0.201)	D 0.078 (0.099)	T@1 0.000 (9.598)	T@5 34.375 (49.187)	L 4.7797 (4.1793)
Test on T training set - [6][1270/1731]	T 0.175 (0.200)	D 0.079 (0.099)	T@1 0.000 (9.567)	T@5 37.500 (49.080)	L 4.2496 (4.1818)
Test on T training set - [6][1280/1731]	T 0.191 (0.200)	D 0.086 (0.099)	T@1 3.125 (9.534)	T@5 43.750 (48.944)	L 4.0181 (4.1849)
Test on T training set - [6][1290/1731]	T 0.160 (0.200)	D 0.064 (0.099)	T@1 12.500 (9.518)	T@5 46.875 (48.867)	L 4.4414 (4.1866)
Test on T training set - [6][1300/1731]	T 0.180 (0.200)	D 0.072 (0.099)	T@1 3.125 (9.493)	T@5 43.750 (48.794)	L 4.2751 (4.1881)
Test on T training set - [6][1310/1731]	T 0.183 (0.200)	D 0.079 (0.098)	T@1 9.375 (9.473)	T@5 37.500 (48.691)	L 4.0791 (4.1889)
Test on T training set - [6][1320/1731]	T 0.185 (0.201)	D 0.089 (0.099)	T@1 9.375 (9.441)	T@5 43.750 (48.583)	L 3.8466 (4.1898)
Test on T training set - [6][1330/1731]	T 0.159 (0.200)	D 0.056 (0.099)	T@1 9.375 (9.424)	T@5 37.500 (48.455)	L 4.6514 (4.1917)
Test on T training set - [6][1340/1731]	T 0.158 (0.200)	D 0.056 (0.099)	T@1 3.125 (9.394)	T@5 34.375 (48.364)	L 4.4106 (4.1934)
Test on T training set - [6][1350/1731]	T 0.172 (0.200)	D 0.068 (0.098)	T@1 9.375 (9.363)	T@5 43.750 (48.284)	L 3.9844 (4.1949)
Test on T training set - [6][1360/1731]	T 0.161 (0.200)	D 0.056 (0.098)	T@1 9.375 (9.380)	T@5 18.750 (48.156)	L 4.4570 (4.1946)
Test on T training set - [6][1370/1731]	T 0.159 (0.199)	D 0.055 (0.098)	T@1 6.250 (9.411)	T@5 12.500 (47.962)	L 4.0885 (4.1925)
Test on T training set - [6][1380/1731]	T 0.161 (0.199)	D 0.061 (0.098)	T@1 18.750 (9.450)	T@5 37.500 (47.801)	L 3.5872 (4.1908)
Test on T training set - [6][1390/1731]	T 0.171 (0.199)	D 0.068 (0.097)	T@1 18.750 (9.456)	T@5 28.125 (47.610)	L 3.6561 (4.1899)
Test on T training set - [6][1400/1731]	T 0.175 (0.199)	D 0.068 (0.097)	T@1 15.625 (9.478)	T@5 15.625 (47.424)	L 4.0508 (4.1884)
Test on T training set - [6][1410/1731]	T 0.179 (0.198)	D 0.074 (0.097)	T@1 12.500 (9.499)	T@5 18.750 (47.234)	L 3.9342 (4.1870)
Test on T training set - [6][1420/1731]	T 0.157 (0.198)	D 0.053 (0.097)	T@1 15.625 (9.536)	T@5 18.750 (47.058)	L 4.2799 (4.1859)
Test on T training set - [6][1430/1731]	T 0.202 (0.198)	D 0.105 (0.096)	T@1 15.625 (9.558)	T@5 100.000 (47.194)	L 3.3235 (4.1833)
Test on T training set - [6][1440/1731]	T 0.245 (0.200)	D 0.135 (0.098)	T@1 18.750 (9.611)	T@5 96.875 (47.545)	L 2.9915 (4.1747)
Test on T training set - [6][1450/1731]	T 0.233 (0.200)	D 0.131 (0.099)	T@1 34.375 (9.685)	T@5 93.750 (47.889)	L 2.2533 (4.1657)
Test on T training set - [6][1460/1731]	T 0.222 (0.200)	D 0.119 (0.099)	T@1 34.375 (9.736)	T@5 100.000 (48.233)	L 2.4290 (4.1586)
Test on T training set - [6][1470/1731]	T 0.226 (0.200)	D 0.121 (0.099)	T@1 9.375 (9.785)	T@5 96.875 (48.568)	L 3.6393 (4.1511)
Test on T training set - [6][1480/1731]	T 0.226 (0.201)	D 0.127 (0.099)	T@1 21.875 (9.858)	T@5 100.000 (48.905)	L 2.6301 (4.1429)
Test on T training set - [6][1490/1731]	T 0.220 (0.201)	D 0.124 (0.099)	T@1 12.500 (9.912)	T@5 96.875 (49.233)	L 3.4130 (4.1359)
Test on T training set - [6][1500/1731]	T 0.250 (0.201)	D 0.143 (0.100)	T@1 9.375 (9.935)	T@5 100.000 (49.559)	L 2.5614 (4.1300)
Test on T training set - [6][1510/1731]	T 0.228 (0.201)	D 0.122 (0.100)	T@1 12.500 (9.979)	T@5 96.875 (49.874)	L 2.7514 (4.1225)
Test on T training set - [6][1520/1731]	T 0.210 (0.202)	D 0.114 (0.100)	T@1 15.625 (10.024)	T@5 96.875 (50.191)	L 3.0649 (4.1151)
Test on T training set - [6][1530/1731]	T 0.217 (0.202)	D 0.113 (0.101)	T@1 12.500 (10.063)	T@5 96.875 (50.496)	L 3.2672 (4.1084)
Test on T training set - [6][1540/1731]	T 0.190 (0.202)	D 0.091 (0.101)	T@1 6.250 (10.097)	T@5 100.000 (50.793)	L 3.7663 (4.1032)
Test on T training set - [6][1550/1731]	T 0.226 (0.202)	D 0.130 (0.101)	T@1 21.875 (10.131)	T@5 100.000 (51.080)	L 2.7193 (4.0975)
Test on T training set - [6][1560/1731]	T 0.196 (0.202)	D 0.091 (0.101)	T@1 15.625 (10.164)	T@5 68.750 (51.313)	L 3.2493 (4.0928)
Test on T training set - [6][1570/1731]	T 0.168 (0.202)	D 0.072 (0.101)	T@1 12.500 (10.199)	T@5 65.625 (51.436)	L 3.5462 (4.0868)
Test on T training set - [6][1580/1731]	T 0.150 (0.202)	D 0.055 (0.100)	T@1 12.500 (10.233)	T@5 65.625 (51.565)	L 3.5820 (4.0827)
Test on T training set - [6][1590/1731]	T 0.158 (0.202)	D 0.057 (0.100)	T@1 12.500 (10.259)	T@5 71.875 (51.679)	L 3.8472 (4.0781)
Test on T training set - [6][1600/1731]	T 0.186 (0.201)	D 0.081 (0.100)	T@1 6.250 (10.273)	T@5 53.125 (51.786)	L 4.2614 (4.0747)
Test on T training set - [6][1610/1731]	T 0.176 (0.201)	D 0.071 (0.100)	T@1 18.750 (10.314)	T@5 62.500 (51.880)	L 3.3285 (4.0698)
Test on T training set - [6][1620/1731]	T 0.188 (0.201)	D 0.080 (0.099)	T@1 15.625 (10.343)	T@5 71.875 (51.978)	L 2.8267 (4.0662)
Test on T training set - [6][1630/1731]	T 0.172 (0.202)	D 0.073 (0.101)	T@1 12.500 (10.375)	T@5 78.125 (52.102)	L 3.2687 (4.0614)
Test on T training set - [6][1640/1731]	T 0.203 (0.202)	D 0.099 (0.100)	T@1 18.750 (10.415)	T@5 84.375 (52.230)	L 2.7620 (4.0562)
Test on T training set - [6][1650/1731]	T 0.208 (0.202)	D 0.112 (0.100)	T@1 18.750 (10.443)	T@5 84.375 (52.387)	L 2.4979 (4.0505)
Test on T training set - [6][1660/1731]	T 0.206 (0.202)	D 0.105 (0.101)	T@1 9.375 (10.470)	T@5 75.000 (52.519)	L 3.2655 (4.0442)
Test on T training set - [6][1670/1731]	T 0.198 (0.202)	D 0.093 (0.101)	T@1 18.750 (10.521)	T@5 62.500 (52.656)	L 2.9227 (4.0364)
Test on T training set - [6][1680/1731]	T 0.193 (0.202)	D 0.090 (0.101)	T@1 15.625 (10.529)	T@5 65.625 (52.759)	L 3.1788 (4.0306)
Test on T training set - [6][1690/1731]	T 0.206 (0.202)	D 0.110 (0.101)	T@1 0.000 (10.565)	T@5 71.875 (52.901)	L 2.7082 (4.0232)
Test on T training set - [6][1700/1731]	T 0.203 (0.202)	D 0.108 (0.101)	T@1 21.875 (10.606)	T@5 75.000 (53.033)	L 2.5412 (4.0159)
Test on T training set - [6][1710/1731]	T 0.203 (0.202)	D 0.107 (0.101)	T@1 15.625 (10.630)	T@5 65.625 (53.141)	L 3.1652 (4.0105)
Test on T training set - [6][1720/1731]	T 0.197 (0.203)	D 0.090 (0.101)	T@1 9.375 (10.652)	T@5 71.875 (53.268)	L 2.9602 (4.0045)
Test on T training set - [6][1730/1731]	T 0.162 (0.203)	D 0.071 (0.101)	T@1 14.286 (10.674)	T@5 85.714 (53.387)	L 3.4412 (3.9990)
 * Test on T training set - Prec@1 10.674, Prec@5 53.387
Test on T test set - [6][0/1731]	Time 0.282 (0.282)	Loss 4.0915 (4.0915)	Prec@1 9.375 (9.375)	Prec@5 59.375 (59.375)
Test on T test set - [6][10/1731]	Time 0.194 (0.191)	Loss 4.1338 (3.7503)	Prec@1 0.000 (10.511)	Prec@5 37.500 (45.739)
Test on T test set - [6][20/1731]	Time 0.208 (0.201)	Loss 3.6331 (3.7672)	Prec@1 9.375 (9.821)	Prec@5 46.875 (44.940)
Test on T test set - [6][30/1731]	Time 0.200 (0.201)	Loss 3.6556 (3.7412)	Prec@1 12.500 (10.081)	Prec@5 46.875 (44.052)
Test on T test set - [6][40/1731]	Time 0.210 (0.202)	Loss 4.2351 (3.7404)	Prec@1 3.125 (9.985)	Prec@5 40.625 (44.512)
Test on T test set - [6][50/1731]	Time 0.203 (0.202)	Loss 4.0549 (3.7788)	Prec@1 3.125 (9.314)	Prec@5 40.625 (44.240)
Test on T test set - [6][60/1731]	Time 0.211 (0.203)	Loss 3.6410 (3.7917)	Prec@1 6.250 (8.965)	Prec@5 40.625 (44.109)
Test on T test set - [6][70/1731]	Time 0.200 (0.202)	Loss 4.0162 (3.7843)	Prec@1 12.500 (9.199)	Prec@5 53.125 (43.970)
Test on T test set - [6][80/1731]	Time 0.184 (0.202)	Loss 3.6766 (3.7798)	Prec@1 3.125 (9.414)	Prec@5 46.875 (44.329)
Test on T test set - [6][90/1731]	Time 0.183 (0.215)	Loss 3.5926 (3.7834)	Prec@1 12.500 (9.444)	Prec@5 46.875 (44.849)
Test on T test set - [6][100/1731]	Time 0.170 (0.212)	Loss 3.5249 (3.7920)	Prec@1 15.625 (9.561)	Prec@5 50.000 (44.988)
Test on T test set - [6][110/1731]	Time 0.200 (0.209)	Loss 4.0094 (3.7904)	Prec@1 12.500 (9.825)	Prec@5 43.750 (44.904)
Test on T test set - [6][120/1731]	Time 0.184 (0.206)	Loss 4.3282 (3.8323)	Prec@1 9.375 (9.711)	Prec@5 50.000 (44.680)
Test on T test set - [6][130/1731]	Time 0.188 (0.205)	Loss 3.2140 (3.8328)	Prec@1 15.625 (10.115)	Prec@5 59.375 (44.990)
Test on T test set - [6][140/1731]	Time 0.184 (0.203)	Loss 3.8621 (3.8335)	Prec@1 6.250 (10.550)	Prec@5 56.250 (45.434)
Test on T test set - [6][150/1731]	Time 0.188 (0.201)	Loss 3.9507 (3.8600)	Prec@1 15.625 (10.700)	Prec@5 53.125 (45.157)
Test on T test set - [6][160/1731]	Time 0.177 (0.200)	Loss 4.0681 (3.8727)	Prec@1 15.625 (10.870)	Prec@5 50.000 (45.148)
Test on T test set - [6][170/1731]	Time 0.173 (0.198)	Loss 3.6378 (3.8867)	Prec@1 15.625 (11.020)	Prec@5 43.750 (45.048)
Test on T test set - [6][180/1731]	Time 0.156 (0.196)	Loss 4.0741 (3.9024)	Prec@1 9.375 (11.102)	Prec@5 37.500 (44.613)
Test on T test set - [6][190/1731]	Time 0.177 (0.206)	Loss 4.5060 (3.9334)	Prec@1 6.250 (10.995)	Prec@5 34.375 (43.995)
Test on T test set - [6][200/1731]	Time 0.163 (0.204)	Loss 4.9834 (3.9497)	Prec@1 6.250 (10.992)	Prec@5 31.250 (43.812)
Test on T test set - [6][210/1731]	Time 0.170 (0.201)	Loss 5.1844 (3.9786)	Prec@1 6.250 (10.930)	Prec@5 28.125 (43.306)
Test on T test set - [6][220/1731]	Time 0.168 (0.200)	Loss 3.2659 (3.9864)	Prec@1 18.750 (10.987)	Prec@5 56.250 (43.368)
Test on T test set - [6][230/1731]	Time 0.166 (0.199)	Loss 3.5063 (3.9495)	Prec@1 21.875 (11.675)	Prec@5 71.875 (44.738)
Test on T test set - [6][240/1731]	Time 0.226 (0.199)	Loss 3.5675 (3.9191)	Prec@1 12.500 (12.085)	Prec@5 78.125 (45.954)
Test on T test set - [6][250/1731]	Time 0.194 (0.200)	Loss 2.9754 (3.8892)	Prec@1 37.500 (12.625)	Prec@5 81.250 (47.136)
Test on T test set - [6][260/1731]	Time 0.229 (0.201)	Loss 2.9894 (3.8544)	Prec@1 25.000 (13.087)	Prec@5 81.250 (48.420)
Test on T test set - [6][270/1731]	Time 0.222 (0.202)	Loss 3.1210 (3.8278)	Prec@1 12.500 (13.457)	Prec@5 65.625 (49.539)
Test on T test set - [6][280/1731]	Time 0.211 (0.202)	Loss 2.8813 (3.7970)	Prec@1 21.875 (13.890)	Prec@5 75.000 (50.523)
Test on T test set - [6][290/1731]	Time 0.222 (0.217)	Loss 3.2116 (3.7810)	Prec@1 31.250 (14.143)	Prec@5 84.375 (51.396)
Test on T test set - [6][300/1731]	Time 0.218 (0.217)	Loss 3.3104 (3.7569)	Prec@1 28.125 (14.431)	Prec@5 90.625 (52.305)
Test on T test set - [6][310/1731]	Time 0.214 (0.216)	Loss 2.7691 (3.7309)	Prec@1 28.125 (14.891)	Prec@5 81.250 (53.105)
Test on T test set - [6][320/1731]	Time 0.190 (0.216)	Loss 2.5800 (3.7051)	Prec@1 40.625 (15.352)	Prec@5 75.000 (53.991)
Test on T test set - [6][330/1731]	Time 0.199 (0.215)	Loss 3.3592 (3.6836)	Prec@1 21.875 (15.710)	Prec@5 71.875 (54.626)
Test on T test set - [6][340/1731]	Time 0.165 (0.214)	Loss 3.2673 (3.6697)	Prec@1 28.125 (16.056)	Prec@5 75.000 (55.260)
Test on T test set - [6][350/1731]	Time 0.197 (0.213)	Loss 3.5294 (3.6514)	Prec@1 18.750 (16.426)	Prec@5 75.000 (55.903)
Test on T test set - [6][360/1731]	Time 0.221 (0.213)	Loss 2.8182 (3.6176)	Prec@1 12.500 (16.984)	Prec@5 81.250 (56.570)
Test on T test set - [6][370/1731]	Time 0.177 (0.213)	Loss 4.0430 (3.6066)	Prec@1 6.250 (17.175)	Prec@5 65.625 (57.109)
Test on T test set - [6][380/1731]	Time 0.187 (0.212)	Loss 3.5568 (3.6110)	Prec@1 15.625 (17.019)	Prec@5 87.500 (57.653)
Test on T test set - [6][390/1731]	Time 0.154 (0.218)	Loss 3.9771 (3.6206)	Prec@1 6.250 (16.752)	Prec@5 62.500 (58.040)
Test on T test set - [6][400/1731]	Time 0.159 (0.216)	Loss 3.9590 (3.6310)	Prec@1 9.375 (16.529)	Prec@5 75.000 (58.385)
Test on T test set - [6][410/1731]	Time 0.164 (0.215)	Loss 4.0936 (3.6373)	Prec@1 9.375 (16.416)	Prec@5 75.000 (58.782)
Test on T test set - [6][420/1731]	Time 0.157 (0.214)	Loss 4.1967 (3.6470)	Prec@1 6.250 (16.226)	Prec@5 65.625 (59.100)
Test on T test set - [6][430/1731]	Time 0.169 (0.212)	Loss 4.5907 (3.6554)	Prec@1 6.250 (16.089)	Prec@5 84.375 (59.506)
Test on T test set - [6][440/1731]	Time 0.144 (0.211)	Loss 4.4585 (3.6676)	Prec@1 6.250 (15.880)	Prec@5 71.875 (59.878)
Test on T test set - [6][450/1731]	Time 0.156 (0.210)	Loss 4.2113 (3.6693)	Prec@1 12.500 (15.771)	Prec@5 71.875 (60.262)
Test on T test set - [6][460/1731]	Time 0.165 (0.209)	Loss 4.6853 (3.6741)	Prec@1 6.250 (15.659)	Prec@5 84.375 (60.656)
Test on T test set - [6][470/1731]	Time 0.157 (0.208)	Loss 3.8012 (3.6791)	Prec@1 9.375 (15.539)	Prec@5 71.875 (60.981)
Test on T test set - [6][480/1731]	Time 0.154 (0.207)	Loss 3.5476 (3.6846)	Prec@1 15.625 (15.463)	Prec@5 87.500 (61.285)
Test on T test set - [6][490/1731]	Time 0.146 (0.206)	Loss 3.6607 (3.6880)	Prec@1 15.625 (15.370)	Prec@5 65.625 (61.552)
Test on T test set - [6][500/1731]	Time 0.153 (0.205)	Loss 3.6175 (3.6907)	Prec@1 12.500 (15.282)	Prec@5 84.375 (61.795)
Test on T test set - [6][510/1731]	Time 0.155 (0.204)	Loss 4.1409 (3.6965)	Prec@1 9.375 (15.148)	Prec@5 81.250 (62.072)
Test on T test set - [6][520/1731]	Time 0.155 (0.206)	Loss 4.7983 (3.7068)	Prec@1 0.000 (14.995)	Prec@5 78.125 (62.248)
Test on T test set - [6][530/1731]	Time 0.169 (0.205)	Loss 4.4421 (3.7160)	Prec@1 0.000 (14.831)	Prec@5 68.750 (62.441)
Test on T test set - [6][540/1731]	Time 0.159 (0.204)	Loss 4.1719 (3.7240)	Prec@1 3.125 (14.701)	Prec@5 84.375 (62.685)
Test on T test set - [6][550/1731]	Time 0.145 (0.203)	Loss 4.0059 (3.7288)	Prec@1 9.375 (14.615)	Prec@5 84.375 (62.959)
Test on T test set - [6][560/1731]	Time 0.166 (0.202)	Loss 4.1188 (3.7330)	Prec@1 6.250 (14.489)	Prec@5 59.375 (63.107)
Test on T test set - [6][570/1731]	Time 0.187 (0.202)	Loss 3.9940 (3.7363)	Prec@1 9.375 (14.410)	Prec@5 81.250 (63.365)
Test on T test set - [6][580/1731]	Time 0.157 (0.201)	Loss 3.6505 (3.7384)	Prec@1 3.125 (14.307)	Prec@5 81.250 (63.565)
Test on T test set - [6][590/1731]	Time 0.168 (0.200)	Loss 3.3939 (3.7423)	Prec@1 12.500 (14.192)	Prec@5 84.375 (63.801)
Test on T test set - [6][600/1731]	Time 0.173 (0.200)	Loss 4.3128 (3.7477)	Prec@1 3.125 (14.070)	Prec@5 71.875 (64.024)
Test on T test set - [6][610/1731]	Time 0.156 (0.199)	Loss 3.9675 (3.7497)	Prec@1 9.375 (14.009)	Prec@5 75.000 (64.224)
Test on T test set - [6][620/1731]	Time 0.180 (0.199)	Loss 3.9427 (3.7525)	Prec@1 15.625 (13.964)	Prec@5 71.875 (64.442)
Test on T test set - [6][630/1731]	Time 0.158 (0.198)	Loss 4.4454 (3.7562)	Prec@1 6.250 (13.877)	Prec@5 65.625 (64.590)
Test on T test set - [6][640/1731]	Time 0.155 (0.198)	Loss 3.8199 (3.7590)	Prec@1 9.375 (13.782)	Prec@5 84.375 (64.752)
Test on T test set - [6][650/1731]	Time 0.144 (0.200)	Loss 4.9128 (3.7624)	Prec@1 0.000 (13.686)	Prec@5 71.875 (64.919)
Test on T test set - [6][660/1731]	Time 0.149 (0.199)	Loss 3.7917 (3.7662)	Prec@1 6.250 (13.583)	Prec@5 78.125 (65.034)
Test on T test set - [6][670/1731]	Time 0.158 (0.198)	Loss 3.2250 (3.7693)	Prec@1 21.875 (13.534)	Prec@5 71.875 (65.197)
Test on T test set - [6][680/1731]	Time 0.160 (0.198)	Loss 4.0479 (3.7756)	Prec@1 6.250 (13.454)	Prec@5 78.125 (65.340)
Test on T test set - [6][690/1731]	Time 0.213 (0.197)	Loss 2.6972 (3.7741)	Prec@1 28.125 (13.427)	Prec@5 75.000 (65.449)
Test on T test set - [6][700/1731]	Time 0.152 (0.197)	Loss 3.8785 (3.7724)	Prec@1 6.250 (13.400)	Prec@5 75.000 (65.393)
Test on T test set - [6][710/1731]	Time 0.172 (0.197)	Loss 3.4661 (3.7741)	Prec@1 12.500 (13.339)	Prec@5 65.625 (65.326)
Test on T test set - [6][720/1731]	Time 0.169 (0.196)	Loss 3.8846 (3.7750)	Prec@1 3.125 (13.276)	Prec@5 78.125 (65.391)
Test on T test set - [6][730/1731]	Time 0.206 (0.196)	Loss 3.5049 (3.7780)	Prec@1 21.875 (13.244)	Prec@5 75.000 (65.424)
Test on T test set - [6][740/1731]	Time 0.211 (0.196)	Loss 4.1313 (3.7812)	Prec@1 6.250 (13.196)	Prec@5 71.875 (65.503)
Test on T test set - [6][750/1731]	Time 0.176 (0.200)	Loss 3.8057 (3.7815)	Prec@1 3.125 (13.182)	Prec@5 84.375 (65.558)
Test on T test set - [6][760/1731]	Time 0.221 (0.200)	Loss 4.0164 (3.7844)	Prec@1 3.125 (13.120)	Prec@5 68.750 (65.646)
Test on T test set - [6][770/1731]	Time 0.206 (0.200)	Loss 4.0635 (3.7850)	Prec@1 9.375 (13.059)	Prec@5 62.500 (65.682)
Test on T test set - [6][780/1731]	Time 0.221 (0.200)	Loss 3.1539 (3.7841)	Prec@1 9.375 (13.024)	Prec@5 75.000 (65.797)
Test on T test set - [6][790/1731]	Time 0.204 (0.200)	Loss 4.0689 (3.7866)	Prec@1 3.125 (12.962)	Prec@5 59.375 (65.803)
Test on T test set - [6][800/1731]	Time 0.199 (0.200)	Loss 4.4040 (3.7908)	Prec@1 6.250 (12.921)	Prec@5 68.750 (65.816)
Test on T test set - [6][810/1731]	Time 0.183 (0.200)	Loss 3.5559 (3.7882)	Prec@1 12.500 (12.947)	Prec@5 71.875 (65.933)
Test on T test set - [6][820/1731]	Time 0.196 (0.200)	Loss 4.3179 (3.7894)	Prec@1 3.125 (12.892)	Prec@5 53.125 (65.987)
Test on T test set - [6][830/1731]	Time 0.168 (0.200)	Loss 3.4050 (3.7903)	Prec@1 6.250 (12.853)	Prec@5 71.875 (66.020)
Test on T test set - [6][840/1731]	Time 0.174 (0.203)	Loss 3.8570 (3.7891)	Prec@1 6.250 (12.842)	Prec@5 50.000 (66.063)
Test on T test set - [6][850/1731]	Time 0.143 (0.202)	Loss 3.8391 (3.7911)	Prec@1 9.375 (12.801)	Prec@5 40.625 (65.886)
Test on T test set - [6][860/1731]	Time 0.156 (0.201)	Loss 3.6053 (3.7932)	Prec@1 12.500 (12.790)	Prec@5 56.250 (65.738)
Test on T test set - [6][870/1731]	Time 0.150 (0.201)	Loss 4.2255 (3.7921)	Prec@1 3.125 (12.780)	Prec@5 53.125 (65.560)
Test on T test set - [6][880/1731]	Time 0.162 (0.200)	Loss 3.8865 (3.7916)	Prec@1 9.375 (12.766)	Prec@5 31.250 (65.338)
Test on T test set - [6][890/1731]	Time 0.165 (0.200)	Loss 4.0577 (3.7928)	Prec@1 6.250 (12.717)	Prec@5 40.625 (65.141)
Test on T test set - [6][900/1731]	Time 0.154 (0.200)	Loss 4.1334 (3.7934)	Prec@1 3.125 (12.698)	Prec@5 40.625 (64.959)
Test on T test set - [6][910/1731]	Time 0.166 (0.199)	Loss 5.2328 (3.8021)	Prec@1 0.000 (12.617)	Prec@5 3.125 (64.493)
Test on T test set - [6][920/1731]	Time 0.158 (0.199)	Loss 5.5340 (3.8173)	Prec@1 0.000 (12.493)	Prec@5 3.125 (63.827)
Test on T test set - [6][930/1731]	Time 0.216 (0.199)	Loss 4.9729 (3.8314)	Prec@1 0.000 (12.372)	Prec@5 9.375 (63.198)
Test on T test set - [6][940/1731]	Time 0.241 (0.199)	Loss 5.0148 (3.8461)	Prec@1 0.000 (12.248)	Prec@5 0.000 (62.566)
Test on T test set - [6][950/1731]	Time 0.225 (0.199)	Loss 5.3608 (3.8599)	Prec@1 0.000 (12.139)	Prec@5 0.000 (61.948)
Test on T test set - [6][960/1731]	Time 0.207 (0.201)	Loss 5.4623 (3.8746)	Prec@1 3.125 (12.028)	Prec@5 3.125 (61.352)
Test on T test set - [6][970/1731]	Time 0.210 (0.201)	Loss 5.5314 (3.8884)	Prec@1 3.125 (11.924)	Prec@5 3.125 (60.775)
Test on T test set - [6][980/1731]	Time 0.201 (0.201)	Loss 5.0104 (3.9014)	Prec@1 0.000 (11.815)	Prec@5 3.125 (60.190)
Test on T test set - [6][990/1731]	Time 0.217 (0.201)	Loss 4.9990 (3.9135)	Prec@1 0.000 (11.712)	Prec@5 3.125 (59.618)
Test on T test set - [6][1000/1731]	Time 0.210 (0.201)	Loss 5.4320 (3.9261)	Prec@1 0.000 (11.613)	Prec@5 0.000 (59.066)
Test on T test set - [6][1010/1731]	Time 0.186 (0.201)	Loss 5.0901 (3.9390)	Prec@1 3.125 (11.529)	Prec@5 6.250 (58.534)
Test on T test set - [6][1020/1731]	Time 0.188 (0.201)	Loss 5.1243 (3.9511)	Prec@1 0.000 (11.429)	Prec@5 6.250 (57.992)
Test on T test set - [6][1030/1731]	Time 0.156 (0.201)	Loss 5.0276 (3.9637)	Prec@1 0.000 (11.321)	Prec@5 3.125 (57.450)
Test on T test set - [6][1040/1731]	Time 0.168 (0.201)	Loss 5.3117 (3.9764)	Prec@1 3.125 (11.218)	Prec@5 3.125 (56.925)
Test on T test set - [6][1050/1731]	Time 0.168 (0.200)	Loss 5.3895 (3.9887)	Prec@1 0.000 (11.114)	Prec@5 0.000 (56.414)
Test on T test set - [6][1060/1731]	Time 0.145 (0.202)	Loss 4.7406 (4.0001)	Prec@1 3.125 (11.027)	Prec@5 6.250 (55.926)
Test on T test set - [6][1070/1731]	Time 0.188 (0.202)	Loss 5.2314 (4.0127)	Prec@1 3.125 (10.939)	Prec@5 6.250 (55.456)
Test on T test set - [6][1080/1731]	Time 0.158 (0.202)	Loss 4.7717 (4.0227)	Prec@1 6.250 (10.858)	Prec@5 9.375 (54.995)
Test on T test set - [6][1090/1731]	Time 0.161 (0.202)	Loss 5.1996 (4.0322)	Prec@1 0.000 (10.776)	Prec@5 12.500 (54.563)
Test on T test set - [6][1100/1731]	Time 0.189 (0.201)	Loss 5.2348 (4.0411)	Prec@1 0.000 (10.689)	Prec@5 6.250 (54.155)
Test on T test set - [6][1110/1731]	Time 0.206 (0.201)	Loss 4.8200 (4.0498)	Prec@1 0.000 (10.601)	Prec@5 3.125 (53.772)
Test on T test set - [6][1120/1731]	Time 0.168 (0.201)	Loss 5.0931 (4.0588)	Prec@1 3.125 (10.521)	Prec@5 6.250 (53.381)
Test on T test set - [6][1130/1731]	Time 0.169 (0.201)	Loss 5.3419 (4.0691)	Prec@1 0.000 (10.433)	Prec@5 9.375 (53.023)
Test on T test set - [6][1140/1731]	Time 0.177 (0.200)	Loss 4.4896 (4.0771)	Prec@1 6.250 (10.350)	Prec@5 18.750 (52.668)
Test on T test set - [6][1150/1731]	Time 0.160 (0.200)	Loss 5.0447 (4.0863)	Prec@1 0.000 (10.263)	Prec@5 6.250 (52.308)
Test on T test set - [6][1160/1731]	Time 0.164 (0.200)	Loss 5.4564 (4.0955)	Prec@1 0.000 (10.188)	Prec@5 18.750 (51.962)
Test on T test set - [6][1170/1731]	Time 0.162 (0.200)	Loss 4.9103 (4.1038)	Prec@1 0.000 (10.109)	Prec@5 18.750 (51.633)
Test on T test set - [6][1180/1731]	Time 0.169 (0.201)	Loss 5.2950 (4.1118)	Prec@1 0.000 (10.029)	Prec@5 12.500 (51.323)
Test on T test set - [6][1190/1731]	Time 0.175 (0.200)	Loss 4.8910 (4.1193)	Prec@1 9.375 (9.957)	Prec@5 15.625 (51.000)
Test on T test set - [6][1200/1731]	Time 0.171 (0.200)	Loss 5.5269 (4.1269)	Prec@1 3.125 (9.882)	Prec@5 15.625 (50.690)
Test on T test set - [6][1210/1731]	Time 0.178 (0.200)	Loss 5.3350 (4.1352)	Prec@1 0.000 (9.814)	Prec@5 9.375 (50.390)
Test on T test set - [6][1220/1731]	Time 0.163 (0.200)	Loss 4.5902 (4.1388)	Prec@1 9.375 (9.790)	Prec@5 37.500 (50.251)
Test on T test set - [6][1230/1731]	Time 0.155 (0.199)	Loss 4.8427 (4.1435)	Prec@1 0.000 (9.761)	Prec@5 28.125 (50.112)
Test on T test set - [6][1240/1731]	Time 0.160 (0.199)	Loss 4.2871 (4.1466)	Prec@1 9.375 (9.753)	Prec@5 40.625 (50.008)
Test on T test set - [6][1250/1731]	Time 0.166 (0.199)	Loss 4.3587 (4.1486)	Prec@1 0.000 (9.725)	Prec@5 40.625 (49.888)
Test on T test set - [6][1260/1731]	Time 0.180 (0.199)	Loss 4.6304 (4.1502)	Prec@1 0.000 (9.705)	Prec@5 43.750 (49.819)
Test on T test set - [6][1270/1731]	Time 0.181 (0.198)	Loss 4.7172 (4.1536)	Prec@1 0.000 (9.660)	Prec@5 31.250 (49.702)
Test on T test set - [6][1280/1731]	Time 0.187 (0.200)	Loss 4.0127 (4.1553)	Prec@1 3.125 (9.631)	Prec@5 43.750 (49.602)
Test on T test set - [6][1290/1731]	Time 0.156 (0.200)	Loss 4.3164 (4.1570)	Prec@1 18.750 (9.615)	Prec@5 40.625 (49.518)
Test on T test set - [6][1300/1731]	Time 0.169 (0.200)	Loss 4.2176 (4.1583)	Prec@1 3.125 (9.594)	Prec@5 40.625 (49.431)
Test on T test set - [6][1310/1731]	Time 0.175 (0.200)	Loss 4.4328 (4.1587)	Prec@1 3.125 (9.568)	Prec@5 43.750 (49.359)
Test on T test set - [6][1320/1731]	Time 0.188 (0.199)	Loss 4.1787 (4.1596)	Prec@1 6.250 (9.538)	Prec@5 40.625 (49.257)
Test on T test set - [6][1330/1731]	Time 0.166 (0.199)	Loss 4.8532 (4.1632)	Prec@1 3.125 (9.509)	Prec@5 31.250 (49.134)
Test on T test set - [6][1340/1731]	Time 0.148 (0.199)	Loss 4.3033 (4.1647)	Prec@1 3.125 (9.482)	Prec@5 37.500 (49.059)
Test on T test set - [6][1350/1731]	Time 0.162 (0.199)	Loss 3.8606 (4.1667)	Prec@1 9.375 (9.458)	Prec@5 46.875 (48.971)
Test on T test set - [6][1360/1731]	Time 0.159 (0.198)	Loss 4.5091 (4.1671)	Prec@1 6.250 (9.471)	Prec@5 9.375 (48.820)
Test on T test set - [6][1370/1731]	Time 0.157 (0.198)	Loss 3.9061 (4.1649)	Prec@1 12.500 (9.512)	Prec@5 18.750 (48.623)
Test on T test set - [6][1380/1731]	Time 0.156 (0.198)	Loss 3.1383 (4.1634)	Prec@1 25.000 (9.547)	Prec@5 37.500 (48.448)
Test on T test set - [6][1390/1731]	Time 0.162 (0.197)	Loss 3.7656 (4.1627)	Prec@1 21.875 (9.559)	Prec@5 34.375 (48.248)
Test on T test set - [6][1400/1731]	Time 0.164 (0.198)	Loss 4.0547 (4.1617)	Prec@1 6.250 (9.569)	Prec@5 18.750 (48.053)
Test on T test set - [6][1410/1731]	Time 0.158 (0.198)	Loss 4.3209 (4.1610)	Prec@1 3.125 (9.583)	Prec@5 15.625 (47.856)
Test on T test set - [6][1420/1731]	Time 0.155 (0.197)	Loss 4.1498 (4.1590)	Prec@1 15.625 (9.621)	Prec@5 21.875 (47.706)
Test on T test set - [6][1430/1731]	Time 0.198 (0.197)	Loss 3.1341 (4.1559)	Prec@1 21.875 (9.655)	Prec@5 100.000 (47.816)
Test on T test set - [6][1440/1731]	Time 0.229 (0.197)	Loss 3.2488 (4.1476)	Prec@1 15.625 (9.709)	Prec@5 96.875 (48.163)
Test on T test set - [6][1450/1731]	Time 0.231 (0.198)	Loss 2.4410 (4.1393)	Prec@1 34.375 (9.778)	Prec@5 93.750 (48.505)
Test on T test set - [6][1460/1731]	Time 0.210 (0.198)	Loss 2.5890 (4.1316)	Prec@1 28.125 (9.831)	Prec@5 100.000 (48.847)
Test on T test set - [6][1470/1731]	Time 0.222 (0.198)	Loss 3.0543 (4.1241)	Prec@1 18.750 (9.878)	Prec@5 96.875 (49.174)
Test on T test set - [6][1480/1731]	Time 0.224 (0.198)	Loss 2.9203 (4.1165)	Prec@1 18.750 (9.940)	Prec@5 100.000 (49.502)
Test on T test set - [6][1490/1731]	Time 0.226 (0.199)	Loss 3.5079 (4.1084)	Prec@1 9.375 (10.016)	Prec@5 93.750 (49.824)
Test on T test set - [6][1500/1731]	Time 0.236 (0.200)	Loss 2.8818 (4.1025)	Prec@1 12.500 (10.041)	Prec@5 100.000 (50.139)
Test on T test set - [6][1510/1731]	Time 0.222 (0.200)	Loss 2.7348 (4.0952)	Prec@1 15.625 (10.082)	Prec@5 93.750 (50.455)
Test on T test set - [6][1520/1731]	Time 0.207 (0.200)	Loss 3.1915 (4.0881)	Prec@1 9.375 (10.135)	Prec@5 96.875 (50.775)
Test on T test set - [6][1530/1731]	Time 0.213 (0.200)	Loss 3.1478 (4.0818)	Prec@1 21.875 (10.179)	Prec@5 96.875 (51.080)
Test on T test set - [6][1540/1731]	Time 0.183 (0.200)	Loss 3.5835 (4.0772)	Prec@1 15.625 (10.208)	Prec@5 96.875 (51.373)
Test on T test set - [6][1550/1731]	Time 0.221 (0.200)	Loss 2.7122 (4.0709)	Prec@1 25.000 (10.266)	Prec@5 100.000 (51.656)
Test on T test set - [6][1560/1731]	Time 0.190 (0.200)	Loss 3.1978 (4.0657)	Prec@1 18.750 (10.314)	Prec@5 68.750 (51.868)
Test on T test set - [6][1570/1731]	Time 0.168 (0.200)	Loss 3.6399 (4.0604)	Prec@1 3.125 (10.346)	Prec@5 75.000 (51.993)
Test on T test set - [6][1580/1731]	Time 0.151 (0.200)	Loss 3.3592 (4.0560)	Prec@1 12.500 (10.379)	Prec@5 62.500 (52.125)
Test on T test set - [6][1590/1731]	Time 0.149 (0.201)	Loss 3.9212 (4.0521)	Prec@1 9.375 (10.412)	Prec@5 71.875 (52.251)
Test on T test set - [6][1600/1731]	Time 0.181 (0.200)	Loss 3.9643 (4.0483)	Prec@1 6.250 (10.427)	Prec@5 59.375 (52.356)
Test on T test set - [6][1610/1731]	Time 0.176 (0.200)	Loss 3.1466 (4.0438)	Prec@1 18.750 (10.459)	Prec@5 71.875 (52.444)
Test on T test set - [6][1620/1731]	Time 0.174 (0.200)	Loss 3.0439 (4.0408)	Prec@1 9.375 (10.462)	Prec@5 65.625 (52.568)
Test on T test set - [6][1630/1731]	Time 0.168 (0.200)	Loss 3.4803 (4.0363)	Prec@1 9.375 (10.492)	Prec@5 75.000 (52.675)
Test on T test set - [6][1640/1731]	Time 0.206 (0.200)	Loss 2.5832 (4.0312)	Prec@1 15.625 (10.535)	Prec@5 78.125 (52.805)
Test on T test set - [6][1650/1731]	Time 0.217 (0.200)	Loss 2.6018 (4.0256)	Prec@1 18.750 (10.560)	Prec@5 84.375 (52.938)
Test on T test set - [6][1660/1731]	Time 0.195 (0.200)	Loss 3.2394 (4.0193)	Prec@1 15.625 (10.600)	Prec@5 68.750 (53.072)
Test on T test set - [6][1670/1731]	Time 0.192 (0.200)	Loss 2.8492 (4.0117)	Prec@1 18.750 (10.643)	Prec@5 75.000 (53.217)
Test on T test set - [6][1680/1731]	Time 0.175 (0.200)	Loss 3.4556 (4.0058)	Prec@1 3.125 (10.667)	Prec@5 71.875 (53.315)
Test on T test set - [6][1690/1731]	Time 0.208 (0.200)	Loss 2.5545 (3.9984)	Prec@1 15.625 (10.707)	Prec@5 71.875 (53.447)
Test on T test set - [6][1700/1731]	Time 0.197 (0.201)	Loss 2.4450 (3.9919)	Prec@1 25.000 (10.742)	Prec@5 78.125 (53.559)
Test on T test set - [6][1710/1731]	Time 0.198 (0.201)	Loss 3.1040 (3.9870)	Prec@1 9.375 (10.763)	Prec@5 65.625 (53.647)
Test on T test set - [6][1720/1731]	Time 0.185 (0.201)	Loss 3.6286 (3.9813)	Prec@1 12.500 (10.788)	Prec@5 75.000 (53.766)
Test on T test set - [6][1730/1731]	Time 0.161 (0.201)	Loss 2.5447 (3.9751)	Prec@1 21.429 (10.813)	Prec@5 89.286 (53.889)
 * Test on T test set - Prec@1 10.813, Prec@5 53.889
Epoch 6 - Kernel K-means clustering 0: Clustering time 44.358, Prec@1 10.459
Epoch 6 - Kernel K-means clustering 1: Clustering time 44.407, Prec@1 10.520
Epoch 6 - Kernel K-means clustering 2: Clustering time 44.436, Prec@1 10.464
Epoch 6 - Kernel K-means clustering 3: Clustering time 44.481, Prec@1 10.426
Epoch 6 - Kernel K-means clustering 4: Clustering time 44.527, Prec@1 10.370
Epoch 6 - Kernel K-means clustering 5: Clustering time 44.558, Prec@1 10.329
Epoch 6 - Kernel K-means clustering 6: Clustering time 44.608, Prec@1 10.224
Epoch 6 - Kernel K-means clustering 7: Clustering time 44.646, Prec@1 10.118
Epoch 6 - Kernel K-means clustering 8: Clustering time 46.061, Prec@1 10.047
Epoch 6 - Kernel K-means clustering 9: Clustering time 44.674, Prec@1 10.022
Epoch 6 - Kernel K-means clustering 10: Clustering time 44.658, Prec@1 9.981
Epoch 6 - Kernel K-means clustering 11: Clustering time 44.682, Prec@1 9.905
Epoch 6 - Kernel K-means clustering 12: Clustering time 44.751, Prec@1 9.845
Epoch 6 - Kernel K-means clustering 13: Clustering time 44.702, Prec@1 9.780
Epoch 6 - Kernel K-means clustering 14: Clustering time 44.695, Prec@1 9.767
Epoch 6 - Kernel K-means clustering 15: Clustering time 44.663, Prec@1 9.739
Epoch 6 - Kernel K-means clustering 16: Clustering time 44.670, Prec@1 9.686
Epoch 6 - Kernel K-means clustering 17: Clustering time 44.673, Prec@1 9.601
Epoch 6 - Kernel K-means clustering 18: Clustering time 44.689, Prec@1 9.540
Epoch 6 - Kernel K-means clustering 19: Clustering time 44.661, Prec@1 9.513
Epoch 6 - Kernel K-means clustering 20: Clustering time 44.690, Prec@1 9.515
Epoch 6 - Kernel K-means clustering 21: Clustering time 44.676, Prec@1 9.517
Epoch 6 - Kernel K-means clustering 22: Clustering time 46.431, Prec@1 9.452
Epoch 6 - Kernel K-means clustering 23: Clustering time 44.221, Prec@1 9.381
Epoch 6 - Kernel K-means clustering 24: Clustering time 44.083, Prec@1 9.331
Epoch 6 - Kernel K-means clustering 25: Clustering time 44.032, Prec@1 9.284
Epoch 6 - Kernel K-means clustering 26: Clustering time 44.056, Prec@1 9.251
Epoch 6 - Kernel K-means clustering 27: Clustering time 44.038, Prec@1 9.217
Epoch 6 - Kernel K-means clustering 28: Clustering time 44.092, Prec@1 9.184
Epoch 6 - Kernel K-means clustering 29: Clustering time 44.081, Prec@1 9.164
Epoch 6 - Kernel K-means clustering 30: Clustering time 44.057, Prec@1 9.128
Epoch 6 - Kernel K-means clustering 31: Clustering time 44.098, Prec@1 9.094
Epoch 6 - Kernel K-means clustering 32: Clustering time 47.251, Prec@1 9.065
Epoch 6 - Kernel K-means clustering 33: Clustering time 44.664, Prec@1 9.051
Epoch 6 - Kernel K-means clustering 34: Clustering time 44.624, Prec@1 9.042
Epoch 6 - Kernel K-means clustering 35: Clustering time 44.617, Prec@1 9.031
Epoch 6 - Kernel K-means clustering 36: Clustering time 44.589, Prec@1 9.025
Epoch 6 - Kernel K-means clustering 37: Clustering time 44.652, Prec@1 9.015
Epoch 6 - Kernel K-means clustering 38: Clustering time 44.589, Prec@1 9.013
Epoch 6 - Kernel K-means clustering 39: Clustering time 44.606, Prec@1 8.989
Epoch 6 - Kernel K-means clustering 40: Clustering time 46.992, Prec@1 8.971
Epoch 6 - Kernel K-means clustering 41: Clustering time 44.611, Prec@1 8.975
Epoch 6 - Kernel K-means clustering 42: Clustering time 44.621, Prec@1 8.969
Epoch 6 - Kernel K-means clustering 43: Clustering time 44.577, Prec@1 8.968
Epoch 6 - Kernel K-means clustering 44: Clustering time 44.630, Prec@1 8.959
Epoch 6 - Kernel K-means clustering 45: Clustering time 44.617, Prec@1 8.948
Epoch 6 - Kernel K-means clustering 46: Clustering time 44.641, Prec@1 8.944
Epoch 6 - Kernel K-means clustering 47: Clustering time 44.654, Prec@1 8.928
Epoch 6 - Kernel K-means clustering 48: Clustering time 44.618, Prec@1 8.933
Epoch 6 - Kernel K-means clustering 49: Clustering time 44.635, Prec@1 8.941
Epoch 6 - Kernel K-means clustering 50: Clustering time 48.068, Prec@1 8.939
Epoch 6 - Kernel K-means clustering 51: Clustering time 44.939, Prec@1 8.941
Epoch 6 - Kernel K-means clustering 52: Clustering time 44.581, Prec@1 8.933
Epoch 6 - Kernel K-means clustering 53: Clustering time 44.617, Prec@1 8.935
Epoch 6 - Kernel K-means clustering 54: Clustering time 44.590, Prec@1 8.935
Epoch 6 - Kernel K-means clustering 55: Clustering time 44.631, Prec@1 8.939
Epoch 6 - Kernel K-means clustering 56: Clustering time 44.584, Prec@1 8.930
Epoch 6 - Kernel K-means clustering 57: Clustering time 44.613, Prec@1 8.926
Epoch 6 - Kernel K-means clustering 58: Clustering time 44.591, Prec@1 8.923
Epoch 6 - Kernel K-means clustering 59: Clustering time 45.428, Prec@1 8.917
Epoch 6 - Kernel K-means clustering 60: Clustering time 44.598, Prec@1 8.915
Epoch 6 - Kernel K-means clustering 61: Clustering time 44.650, Prec@1 8.912
Epoch 6 - Kernel K-means clustering 62: Clustering time 44.621, Prec@1 8.906
Epoch 6 - Kernel K-means clustering 63: Clustering time 44.631, Prec@1 8.915
Epoch 6 - Kernel K-means clustering 64: Clustering time 44.593, Prec@1 8.921
Epoch 6 - Kernel K-means clustering 65: Clustering time 44.614, Prec@1 8.926
Epoch 6 - Kernel K-means clustering 66: Clustering time 44.625, Prec@1 8.930
Epoch 6 - Kernel K-means clustering 67: Clustering time 44.621, Prec@1 8.923
Epoch 6 - Kernel K-means clustering 68: Clustering time 44.607, Prec@1 8.924
Epoch 6 - Kernel K-means clustering 69: Clustering time 47.085, Prec@1 8.926
Epoch 6 - Kernel K-means clustering 70: Clustering time 44.587, Prec@1 8.930
Epoch 6 - Kernel K-means clustering 71: Clustering time 44.580, Prec@1 8.942
Epoch 6 - Kernel K-means clustering 72: Clustering time 44.641, Prec@1 8.942
Epoch 6 - Kernel K-means clustering 73: Clustering time 44.600, Prec@1 8.941
Epoch 6 - Kernel K-means clustering 74: Clustering time 44.631, Prec@1 8.941
Epoch 6 - Kernel K-means clustering 75: Clustering time 44.608, Prec@1 8.941
Epoch 6 - Kernel K-means clustering 76: Clustering time 44.618, Prec@1 8.950
Epoch 6 - Kernel K-means clustering 77: Clustering time 44.593, Prec@1 8.960
Epoch 6 - Kernel K-means clustering 78: Clustering time 44.584, Prec@1 8.964
Epoch 6 - Kernel K-means clustering 79: Clustering time 44.516, Prec@1 8.957
Epoch 6 - Kernel K-means clustering 80: Clustering time 44.601, Prec@1 8.964
Epoch 6 - Kernel K-means clustering 81: Clustering time 45.382, Prec@1 8.964
Epoch 6 - Kernel K-means clustering 82: Clustering time 45.355, Prec@1 8.973
Epoch 6 - Kernel K-means clustering 83: Clustering time 44.632, Prec@1 8.975
Epoch 6 - Kernel K-means clustering 84: Clustering time 44.601, Prec@1 8.973
Epoch 6 - Kernel K-means clustering 85: Clustering time 44.613, Prec@1 8.973
Epoch 6 - Kernel K-means clustering 86: Clustering time 44.638, Prec@1 8.986
Epoch 6 - Kernel K-means clustering 87: Clustering time 44.595, Prec@1 8.982
Epoch 6 - Kernel K-means clustering 88: Clustering time 44.579, Prec@1 8.980
Epoch 6 - Kernel K-means clustering 89: Clustering time 44.598, Prec@1 8.986
Epoch 6 - Kernel K-means clustering 90: Clustering time 44.623, Prec@1 8.997
Epoch 6 - Kernel K-means clustering 91: Clustering time 44.644, Prec@1 8.989
Epoch 6 - Kernel K-means clustering 92: Clustering time 44.604, Prec@1 8.995
Epoch 6 - Kernel K-means clustering 93: Clustering time 44.610, Prec@1 8.989
Epoch 6 - Kernel K-means clustering 94: Clustering time 44.602, Prec@1 8.993
Epoch 6 - Kernel K-means clustering 95: Clustering time 44.643, Prec@1 8.991
Epoch 6 - Kernel K-means clustering 96: Clustering time 44.765, Prec@1 8.988
Epoch 6 - Kernel K-means clustering 97: Clustering time 44.786, Prec@1 8.997
Epoch 6 - Kernel K-means clustering 98: Clustering time 44.616, Prec@1 8.997
Epoch 6 - Kernel K-means clustering 99: Clustering time 44.646, Prec@1 8.998
Epoch 6 - Kernel K-means clustering 0: Clustering time 44.328, Prec@1 10.614
Epoch 6 - Kernel K-means clustering 1: Clustering time 44.356, Prec@1 10.564
Epoch 6 - Kernel K-means clustering 2: Clustering time 44.422, Prec@1 10.506
Epoch 6 - Kernel K-means clustering 3: Clustering time 46.045, Prec@1 10.439
Epoch 6 - Kernel K-means clustering 4: Clustering time 44.601, Prec@1 10.363
Epoch 6 - Kernel K-means clustering 5: Clustering time 44.631, Prec@1 10.248
Epoch 6 - Kernel K-means clustering 6: Clustering time 44.647, Prec@1 10.062
Epoch 6 - Kernel K-means clustering 7: Clustering time 44.681, Prec@1 9.919
Epoch 6 - Kernel K-means clustering 8: Clustering time 44.656, Prec@1 9.832
Epoch 6 - Kernel K-means clustering 9: Clustering time 46.542, Prec@1 9.771
Epoch 6 - Kernel K-means clustering 10: Clustering time 44.590, Prec@1 9.719
Epoch 6 - Kernel K-means clustering 11: Clustering time 44.675, Prec@1 9.666
Epoch 6 - Kernel K-means clustering 12: Clustering time 44.638, Prec@1 9.625
Epoch 6 - Kernel K-means clustering 13: Clustering time 44.644, Prec@1 9.601
Epoch 6 - Kernel K-means clustering 14: Clustering time 44.684, Prec@1 9.581
Epoch 6 - Kernel K-means clustering 15: Clustering time 44.653, Prec@1 9.574
Epoch 6 - Kernel K-means clustering 16: Clustering time 44.670, Prec@1 9.571
Epoch 6 - Kernel K-means clustering 17: Clustering time 44.619, Prec@1 9.554
Epoch 6 - Kernel K-means clustering 18: Clustering time 44.685, Prec@1 9.544
Epoch 6 - Kernel K-means clustering 19: Clustering time 44.707, Prec@1 9.538
Epoch 6 - Kernel K-means clustering 20: Clustering time 44.720, Prec@1 9.533
Epoch 6 - Kernel K-means clustering 21: Clustering time 44.654, Prec@1 9.531
Epoch 6 - Kernel K-means clustering 22: Clustering time 44.674, Prec@1 9.533
Epoch 6 - Kernel K-means clustering 23: Clustering time 44.679, Prec@1 9.540
Epoch 6 - Kernel K-means clustering 24: Clustering time 44.656, Prec@1 9.538
Epoch 6 - Kernel K-means clustering 25: Clustering time 44.656, Prec@1 9.542
Epoch 6 - Kernel K-means clustering 26: Clustering time 44.695, Prec@1 9.545
Epoch 6 - Kernel K-means clustering 27: Clustering time 44.660, Prec@1 9.544
Epoch 6 - Kernel K-means clustering 28: Clustering time 44.676, Prec@1 9.542
Epoch 6 - Kernel K-means clustering 29: Clustering time 44.677, Prec@1 9.544
Epoch 6 - Kernel K-means clustering 30: Clustering time 44.693, Prec@1 9.545
Epoch 6 - Kernel K-means clustering 31: Clustering time 44.719, Prec@1 9.545
Epoch 6 - Kernel K-means clustering 32: Clustering time 44.684, Prec@1 9.545
Epoch 6 - Kernel K-means clustering 33: Clustering time 44.682, Prec@1 9.542
Epoch 6 - Kernel K-means clustering 34: Clustering time 45.271, Prec@1 9.540
Epoch 6 - Kernel K-means clustering 35: Clustering time 44.803, Prec@1 9.536
Epoch 6 - Kernel K-means clustering 36: Clustering time 44.727, Prec@1 9.538
Epoch 6 - Kernel K-means clustering 37: Clustering time 44.695, Prec@1 9.540
Converged at iteration 38
Train - epoch [7/200]	BT 4.412 (4.412)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0393 (4.0393)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9297 (3.9297)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 18.750 (18.750)	Loss 4.0591 (4.0591)
Train - epoch [7/200]	BT 1.286 (1.286)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0420 (4.0420)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.1082 (4.1082)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.8908 (3.8908)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9854 (3.9854)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0295 (4.0295)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.9931 (3.9931)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0753 (4.0753)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9691 (3.9691)
Train - epoch [7/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0047 (4.0047)
Train - epoch [7/200]	BT 4.189 (4.189)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.9196 (3.9196)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0255 (4.0255)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0636 (4.0636)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9589 (3.9589)
Train - epoch [7/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0289 (4.0289)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9604 (3.9604)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0103 (4.0103)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0519 (4.0519)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9838 (3.9838)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9853 (3.9853)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1789 (4.1789)
Train - epoch [7/200]	BT 1.278 (1.278)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.1790 (4.1790)
Train - epoch [7/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1187 (4.1187)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0007 (4.0007)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9873 (3.9873)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.1047 (4.1047)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0604 (4.0604)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0647 (4.0647)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 3.9882 (3.9882)
Train - epoch [7/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0299 (4.0299)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0980 (4.0980)
Train - epoch [7/200]	BT 4.188 (4.188)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0560 (4.0560)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0994 (4.0994)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0423 (4.0423)
Train - epoch [7/200]	BT 3.484 (3.484)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0057 (4.0057)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0196 (4.0196)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0312 (4.0312)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.9701 (3.9701)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9346 (3.9346)
Train - epoch [7/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0944 (4.0944)
Train - epoch [7/200]	BT 4.407 (4.407)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.9873 (3.9873)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1153 (4.1153)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9791 (3.9791)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0270 (4.0270)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0336 (4.0336)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.2225 (4.2225)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.8881 (3.8881)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1235 (4.1235)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.1530 (4.1530)
Train - epoch [7/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.1210 (4.1210)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9719 (3.9719)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9169 (3.9169)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9111 (3.9111)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.1009 (4.1009)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.2518 (4.2518)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9723 (3.9723)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0660 (4.0660)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9502 (3.9502)
Train - epoch [7/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.8422 (3.8422)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0799 (4.0799)
Train - epoch [7/200]	BT 3.905 (3.905)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0822 (4.0822)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.1030 (4.1030)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9640 (3.9640)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1049 (4.1049)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 4.0428 (4.0428)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9474 (3.9474)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.1259 (4.1259)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0164 (4.0164)
Train - epoch [7/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 4.0095 (4.0095)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9702 (3.9702)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9833 (3.9833)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9265 (3.9265)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0746 (4.0746)
Train - epoch [7/200]	BT 4.139 (4.139)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0680 (4.0680)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0799 (4.0799)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.1213 (4.1213)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0235 (4.0235)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9611 (3.9611)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.9412 (3.9412)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 4.0134 (4.0134)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.2027 (4.2027)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1002 (4.1002)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9334 (3.9334)
Train - epoch [7/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0118 (4.0118)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0347 (4.0347)
Train - epoch [7/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 78.125 (78.125)	Loss 4.0092 (4.0092)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0505 (4.0505)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0190 (4.0190)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0108 (4.0108)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.9710 (3.9710)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0800 (4.0800)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 4.0773 (4.0773)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0301 (4.0301)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.0181 (4.0181)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0085 (4.0085)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0911 (4.0911)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0277 (4.0277)
Train - epoch [7/200]	BT 4.195 (4.195)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.2281 (4.2281)
Train - epoch [7/200]	BT 1.277 (1.277)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0318 (4.0318)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0314 (4.0314)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0623 (4.0623)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0987 (4.0987)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1429 (4.1429)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0338 (4.0338)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0269 (4.0269)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0499 (4.0499)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0024 (4.0024)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0380 (4.0380)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0753 (4.0753)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9035 (3.9035)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9131 (3.9131)
Train - epoch [7/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0056 (4.0056)
Train - epoch [7/200]	BT 4.230 (4.230)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0322 (4.0322)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0704 (4.0704)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0026 (4.0026)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1453 (4.1453)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0229 (4.0229)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.9956 (3.9956)
Train - epoch [7/200]	BT 4.042 (4.042)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 4.0113 (4.0113)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.1386 (4.1386)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.1622 (4.1622)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9182 (3.9182)
Train - epoch [7/200]	BT 3.745 (3.745)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.8359 (3.8359)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9762 (3.9762)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9662 (3.9662)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0160 (4.0160)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0022 (4.0022)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.1088 (4.1088)
Train - epoch [7/200]	BT 4.488 (4.488)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 4.0701 (4.0701)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0909 (4.0909)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1655 (4.1655)
Train - epoch [7/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0998 (4.0998)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0085 (4.0085)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1177 (4.1177)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0527 (4.0527)
Train - epoch [7/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0657 (4.0657)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0384 (4.0384)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 3.9786 (3.9786)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0380 (4.0380)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9984 (3.9984)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9811 (3.9811)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0232 (4.0232)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9149 (3.9149)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9602 (3.9602)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0153 (4.0153)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9817 (3.9817)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0016 (4.0016)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0386 (4.0386)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 3.9999 (3.9999)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0022 (4.0022)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9245 (3.9245)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9295 (3.9295)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9593 (3.9593)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0692 (4.0692)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9831 (3.9831)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.9349 (3.9349)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.9958 (3.9958)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0613 (4.0613)
Train - epoch [7/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9333 (3.9333)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9180 (3.9180)
Train - epoch [7/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1522 (4.1522)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9639 (3.9639)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0877 (4.0877)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0675 (4.0675)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0365 (4.0365)
Train - epoch [7/200]	BT 4.130 (4.130)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0386 (4.0386)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9772 (3.9772)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0106 (4.0106)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1634 (4.1634)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.9842 (3.9842)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9432 (3.9432)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 4.0090 (4.0090)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1961 (4.1961)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9431 (3.9431)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0937 (4.0937)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0345 (4.0345)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0619 (4.0619)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1318 (4.1318)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0455 (4.0455)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1099 (4.1099)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 4.0322 (4.0322)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0797 (4.0797)
Train - epoch [7/200]	BT 4.182 (4.182)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9729 (3.9729)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0859 (4.0859)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9391 (3.9391)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9863 (3.9863)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0235 (4.0235)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 4.1496 (4.1496)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1754 (4.1754)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9936 (3.9936)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.1011 (4.1011)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0816 (4.0816)
Train - epoch [7/200]	BT 4.172 (4.172)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0534 (4.0534)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9754 (3.9754)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 4.0831 (4.0831)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0665 (4.0665)
Train - epoch [7/200]	BT 1.290 (1.290)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9724 (3.9724)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9514 (3.9514)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.8627 (3.8627)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9772 (3.9772)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0882 (4.0882)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9962 (3.9962)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0754 (4.0754)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0153 (4.0153)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9575 (3.9575)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0949 (4.0949)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9653 (3.9653)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.2110 (4.2110)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0882 (4.0882)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0523 (4.0523)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0673 (4.0673)
Train - epoch [7/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.1150 (4.1150)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9529 (3.9529)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9710 (3.9710)
Train - epoch [7/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1027 (4.1027)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9351 (3.9351)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9831 (3.9831)
Train - epoch [7/200]	BT 3.927 (3.927)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0051 (4.0051)
Train - epoch [7/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0341 (4.0341)
Train - epoch [7/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.1304 (4.1304)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0334 (4.0334)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.1143 (4.1143)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0665 (4.0665)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0613 (4.0613)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9081 (3.9081)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.8979 (3.8979)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0831 (4.0831)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.1533 (4.1533)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0809 (4.0809)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9975 (3.9975)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0977 (4.0977)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.8858 (3.8858)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0637 (4.0637)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0651 (4.0651)
Train - epoch [7/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9977 (3.9977)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0260 (4.0260)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0323 (4.0323)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.9756 (3.9756)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9577 (3.9577)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0239 (4.0239)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9903 (3.9903)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0083 (4.0083)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9676 (3.9676)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0808 (4.0808)
Train - epoch [7/200]	BT 3.786 (3.786)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0142 (4.0142)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0286 (4.0286)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9721 (3.9721)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9695 (3.9695)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 3.9475 (3.9475)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0659 (4.0659)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.1560 (4.1560)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.2038 (4.2038)
Train - epoch [7/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0455 (4.0455)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0524 (4.0524)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9362 (3.9362)
Train - epoch [7/200]	BT 4.024 (4.024)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0511 (4.0511)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0637 (4.0637)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0326 (4.0326)
Train - epoch [7/200]	BT 1.308 (1.308)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0919 (4.0919)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.1744 (4.1744)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.1212 (4.1212)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.0592 (4.0592)
Train - epoch [7/200]	BT 1.246 (1.246)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1897 (4.1897)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0244 (4.0244)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0303 (4.0303)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9838 (3.9838)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0669 (4.0669)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0763 (4.0763)
Train - epoch [7/200]	BT 3.979 (3.979)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9350 (3.9350)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1499 (4.1499)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0251 (4.0251)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.1729 (4.1729)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0518 (4.0518)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0814 (4.0814)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0656 (4.0656)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0648 (4.0648)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9679 (3.9679)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9834 (3.9834)
Train - epoch [7/200]	BT 3.976 (3.976)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9783 (3.9783)
Train - epoch [7/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9998 (3.9998)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0724 (4.0724)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0380 (4.0380)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 25.000 (25.000)	Loss 4.0820 (4.0820)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9263 (3.9263)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0334 (4.0334)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9974 (3.9974)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1157 (4.1157)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9895 (3.9895)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9016 (3.9016)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0609 (4.0609)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9718 (3.9718)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.1546 (4.1546)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0125 (4.0125)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9697 (3.9697)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0878 (4.0878)
Train - epoch [7/200]	BT 1.273 (1.273)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9220 (3.9220)
Train - epoch [7/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9269 (3.9269)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0800 (4.0800)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9631 (3.9631)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.2014 (4.2014)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.1119 (4.1119)
Train - epoch [7/200]	BT 4.384 (4.384)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9545 (3.9545)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0709 (4.0709)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9599 (3.9599)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1860 (4.1860)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0002 (4.0002)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9588 (3.9588)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 71.875 (71.875)	Loss 4.0242 (4.0242)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0332 (4.0332)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0931 (4.0931)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0090 (4.0090)
Train - epoch [7/200]	BT 3.664 (3.664)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0282 (4.0282)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0538 (4.0538)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0723 (4.0723)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0712 (4.0712)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.1285 (4.1285)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9598 (3.9598)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9316 (3.9316)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0137 (4.0137)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9936 (3.9936)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9456 (3.9456)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0906 (4.0906)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.2015 (4.2015)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9662 (3.9662)
Train - epoch [7/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0028 (4.0028)
Train - epoch [7/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9976 (3.9976)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1308 (4.1308)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.7849 (3.7849)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9154 (3.9154)
Train - epoch [7/200]	BT 4.685 (4.685)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9819 (3.9819)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0481 (4.0481)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0330 (4.0330)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0164 (4.0164)
Train - epoch [7/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9933 (3.9933)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0603 (4.0603)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0367 (4.0367)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0076 (4.0076)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9666 (3.9666)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 81.250 (81.250)	Loss 4.0594 (4.0594)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 3.9767 (3.9767)
Train - epoch [7/200]	BT 1.279 (1.279)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0316 (4.0316)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 3.9709 (3.9709)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0441 (4.0441)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9939 (3.9939)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9650 (3.9650)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0627 (4.0627)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.1319 (4.1319)
Train - epoch [7/200]	BT 4.024 (4.024)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0935 (4.0935)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9004 (3.9004)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.1177 (4.1177)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9648 (3.9648)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.1327 (4.1327)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9486 (3.9486)
Train - epoch [7/200]	BT 1.275 (1.275)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 3.9592 (3.9592)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9694 (3.9694)
Train - epoch [7/200]	BT 1.247 (1.247)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.1591 (4.1591)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0186 (4.0186)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9849 (3.9849)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0119 (4.0119)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0237 (4.0237)
Train - epoch [7/200]	BT 3.794 (3.794)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0158 (4.0158)
Train - epoch [7/200]	BT 1.283 (1.283)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0399 (4.0399)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9203 (3.9203)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0420 (4.0420)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0491 (4.0491)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9243 (3.9243)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0330 (4.0330)
Train - epoch [7/200]	BT 3.809 (3.809)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0599 (4.0599)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.1220 (4.1220)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0626 (4.0626)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.1584 (4.1584)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9565 (3.9565)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 28.125 (28.125)	Loss 4.0986 (4.0986)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.1507 (4.1507)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9742 (3.9742)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1180 (4.1180)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9786 (3.9786)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0965 (4.0965)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0355 (4.0355)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0594 (4.0594)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0261 (4.0261)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.0005 (4.0005)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 3.9984 (3.9984)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9581 (3.9581)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0358 (4.0358)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.0182 (4.0182)
Train - epoch [7/200]	BT 1.248 (1.248)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0479 (4.0479)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9832 (3.9832)
Train - epoch [7/200]	BT 3.998 (3.998)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.1100 (4.1100)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9422 (3.9422)
Train - epoch [7/200]	BT 1.255 (1.255)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1341 (4.1341)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0672 (4.0672)
Train - epoch [7/200]	BT 3.711 (3.711)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9089 (3.9089)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9249 (3.9249)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.1518 (4.1518)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0381 (4.0381)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9986 (3.9986)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1089 (4.1089)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1260 (4.1260)
Train - epoch [7/200]	BT 1.272 (1.272)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.2078 (4.2078)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9666 (3.9666)
Train - epoch [7/200]	BT 1.280 (1.280)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9799 (3.9799)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0674 (4.0674)
Train - epoch [7/200]	BT 1.287 (1.287)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.1478 (4.1478)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 3.9719 (3.9719)
Train - epoch [7/200]	BT 1.250 (1.250)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.0775 (4.0775)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9984 (3.9984)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9681 (3.9681)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0553 (4.0553)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0671 (4.0671)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0847 (4.0847)
Train - epoch [7/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0072 (4.0072)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0750 (4.0750)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 3.9457 (3.9457)
Train - epoch [7/200]	BT 1.276 (1.276)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9553 (3.9553)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1219 (4.1219)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 3.9322 (3.9322)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.0878 (4.0878)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1027 (4.1027)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 3.9780 (3.9780)
Train - epoch [7/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0445 (4.0445)
Train - epoch [7/200]	BT 4.200 (4.200)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1513 (4.1513)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9780 (3.9780)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 3.9346 (3.9346)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9860 (3.9860)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0824 (4.0824)
Train - epoch [7/200]	BT 1.268 (1.268)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1427 (4.1427)
Train - epoch [7/200]	BT 1.270 (1.270)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9558 (3.9558)
Train - epoch [7/200]	BT 3.863 (3.863)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.8862 (3.8862)
Train - epoch [7/200]	BT 1.263 (1.263)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.1138 (4.1138)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.0550 (4.0550)
Train - epoch [7/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.0806 (4.0806)
Train - epoch [7/200]	BT 1.258 (1.258)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.1032 (4.1032)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9994 (3.9994)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.1042 (4.1042)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1033 (4.1033)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.0772 (4.0772)
Train - epoch [7/200]	BT 1.274 (1.274)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.0036 (4.0036)
Train - epoch [7/200]	BT 3.969 (3.969)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9331 (3.9331)
Train - epoch [7/200]	BT 1.251 (1.251)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 3.9667 (3.9667)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 31.250 (31.250)	Loss 4.0435 (4.0435)
Train - epoch [7/200]	BT 1.271 (1.271)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0552 (4.0552)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 3.9244 (3.9244)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 43.750 (43.750)	Loss 4.0124 (4.0124)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9658 (3.9658)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.0432 (4.0432)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1015 (4.1015)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.1091 (4.1091)
Train - epoch [7/200]	BT 1.253 (1.253)	DT 0.000 (0.000)	S@1 37.500 (37.500)	Loss 4.1457 (4.1457)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0708 (4.0708)
Train - epoch [7/200]	BT 1.252 (1.252)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.2495 (4.2495)
Train - epoch [7/200]	BT 3.882 (3.882)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.2506 (4.2506)
Train - epoch [7/200]	BT 1.260 (1.260)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 4.2619 (4.2619)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 75.000 (75.000)	Loss 4.1718 (4.1718)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.1366 (4.1366)
Train - epoch [7/200]	BT 1.269 (1.269)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0693 (4.0693)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9636 (3.9636)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0674 (4.0674)
Train - epoch [7/200]	BT 1.284 (1.284)	DT 0.000 (0.000)	S@1 68.750 (68.750)	Loss 4.1872 (4.1872)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 40.625 (40.625)	Loss 4.1639 (4.1639)
Train - epoch [7/200]	BT 1.267 (1.267)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0276 (4.0276)
Train - epoch [7/200]	BT 4.315 (4.315)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 3.9151 (3.9151)
Train - epoch [7/200]	BT 1.262 (1.262)	DT 0.000 (0.000)	S@1 53.125 (53.125)	Loss 4.5324 (4.5324)
Train - epoch [7/200]	BT 1.266 (1.266)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.0976 (4.0976)
Train - epoch [7/200]	BT 1.264 (1.264)	DT 0.000 (0.000)	S@1 46.875 (46.875)	Loss 4.2548 (4.2548)
Train - epoch [7/200]	BT 1.261 (1.261)	DT 0.000 (0.000)	S@1 50.000 (50.000)	Loss 4.1046 (4.1046)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 4.1829 (4.1829)
Train - epoch [7/200]	BT 1.256 (1.256)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.2118 (4.2118)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.0350 (4.0350)
Train - epoch [7/200]	BT 1.254 (1.254)	DT 0.000 (0.000)	S@1 62.500 (62.500)	Loss 3.9673 (3.9673)
Train - epoch [7/200]	BT 1.265 (1.265)	DT 0.000 (0.000)	S@1 34.375 (34.375)	Loss 4.1749 (4.1749)
Train - epoch [7/200]	BT 1.249 (1.249)	DT 0.000 (0.000)	S@1 59.375 (59.375)	Loss 4.1632 (4.1632)
Train - epoch [7/200]	BT 1.257 (1.257)	DT 0.000 (0.000)	S@1 65.625 (65.625)	Loss 4.0465 (4.0465)
Train - epoch [7/200]	BT 1.259 (1.259)	DT 0.000 (0.000)	S@1 56.250 (56.250)	Loss 4.2792 (4.2792)
Test on T training set - [7][0/1731]	T 0.286 (0.286)	D 0.182 (0.182)	T@1 15.625 (15.625)	T@5 68.750 (68.750)	L 3.2750 (3.2750)
Test on T training set - [7][10/1731]	T 0.201 (0.195)	D 0.103 (0.093)	T@1 15.625 (12.500)	T@5 46.875 (55.966)	L 3.6304 (3.6618)
Test on T training set - [7][20/1731]	T 0.214 (0.204)	D 0.112 (0.103)	T@1 3.125 (10.714)	T@5 53.125 (54.762)	L 3.8099 (3.7631)
Test on T training set - [7][30/1731]	T 0.207 (0.204)	D 0.102 (0.104)	T@1 6.250 (10.786)	T@5 56.250 (54.335)	L 3.7639 (3.7677)
Test on T training set - [7][40/1731]	T 0.224 (0.206)	D 0.123 (0.105)	T@1 12.500 (10.823)	T@5 56.250 (54.497)	L 3.7531 (3.7839)
Test on T training set - [7][50/1731]	T 0.204 (0.206)	D 0.108 (0.106)	T@1 9.375 (10.417)	T@5 50.000 (53.493)	L 3.9148 (3.8264)
Test on T training set - [7][60/1731]	T 0.209 (0.207)	D 0.114 (0.107)	T@1 12.500 (10.656)	T@5 53.125 (54.150)	L 3.8806 (3.7890)
Test on T training set - [7][70/1731]	T 0.203 (0.207)	D 0.095 (0.106)	T@1 9.375 (10.607)	T@5 50.000 (54.093)	L 4.0754 (3.7846)
Test on T training set - [7][80/1731]	T 0.202 (0.206)	D 0.096 (0.105)	T@1 6.250 (10.610)	T@5 46.875 (53.549)	L 3.8940 (3.8019)
Test on T training set - [7][90/1731]	T 0.181 (0.205)	D 0.083 (0.105)	T@1 21.875 (10.577)	T@5 56.250 (53.537)	L 3.9016 (3.8243)
Test on T training set - [7][100/1731]	T 0.177 (0.203)	D 0.082 (0.103)	T@1 15.625 (10.891)	T@5 56.250 (53.434)	L 3.6917 (3.8176)
Test on T training set - [7][110/1731]	T 0.194 (0.215)	D 0.099 (0.115)	T@1 0.000 (11.261)	T@5 53.125 (53.491)	L 4.5146 (3.8067)
Test on T training set - [7][120/1731]	T 0.184 (0.213)	D 0.087 (0.113)	T@1 9.375 (11.080)	T@5 28.125 (51.834)	L 4.1496 (3.8324)
Test on T training set - [7][130/1731]	T 0.186 (0.211)	D 0.081 (0.111)	T@1 6.250 (10.806)	T@5 34.375 (50.239)	L 4.0251 (3.8540)
Test on T training set - [7][140/1731]	T 0.174 (0.209)	D 0.071 (0.108)	T@1 9.375 (10.727)	T@5 21.875 (48.958)	L 4.2063 (3.8731)
Test on T training set - [7][150/1731]	T 0.204 (0.207)	D 0.098 (0.107)	T@1 9.375 (10.741)	T@5 34.375 (47.848)	L 4.1331 (3.8876)
Test on T training set - [7][160/1731]	T 0.187 (0.205)	D 0.084 (0.105)	T@1 15.625 (10.792)	T@5 40.625 (46.914)	L 3.8228 (3.8927)
Test on T training set - [7][170/1731]	T 0.172 (0.204)	D 0.065 (0.103)	T@1 0.000 (10.490)	T@5 21.875 (45.833)	L 4.2889 (3.9162)
Test on T training set - [7][180/1731]	T 0.161 (0.202)	D 0.055 (0.101)	T@1 0.000 (10.169)	T@5 21.875 (44.682)	L 4.9141 (3.9490)
Test on T training set - [7][190/1731]	T 0.169 (0.199)	D 0.070 (0.099)	T@1 3.125 (9.784)	T@5 18.750 (43.243)	L 4.5825 (3.9764)
Test on T training set - [7][200/1731]	T 0.153 (0.198)	D 0.058 (0.097)	T@1 12.500 (9.530)	T@5 31.250 (42.211)	L 3.7366 (4.0000)
Test on T training set - [7][210/1731]	T 0.178 (0.204)	D 0.071 (0.103)	T@1 9.375 (9.331)	T@5 28.125 (41.069)	L 4.3804 (4.0296)
Test on T training set - [7][220/1731]	T 0.182 (0.203)	D 0.076 (0.102)	T@1 6.250 (9.163)	T@5 25.000 (40.611)	L 4.2513 (4.0380)
Test on T training set - [7][230/1731]	T 0.164 (0.202)	D 0.068 (0.101)	T@1 3.125 (9.118)	T@5 78.125 (41.829)	L 3.8176 (4.0301)
Test on T training set - [7][240/1731]	T 0.236 (0.203)	D 0.128 (0.102)	T@1 9.375 (8.934)	T@5 71.875 (43.205)	L 3.8677 (4.0229)
Test on T training set - [7][250/1731]	T 0.196 (0.203)	D 0.095 (0.102)	T@1 18.750 (8.852)	T@5 71.875 (44.709)	L 3.6813 (4.0148)
Test on T training set - [7][260/1731]	T 0.233 (0.204)	D 0.129 (0.103)	T@1 9.375 (8.728)	T@5 84.375 (46.109)	L 3.8968 (4.0108)
Test on T training set - [7][270/1731]	T 0.221 (0.205)	D 0.126 (0.104)	T@1 15.625 (8.695)	T@5 84.375 (47.348)	L 3.3976 (4.0006)
Test on T training set - [7][280/1731]	T 0.225 (0.205)	D 0.125 (0.104)	T@1 12.500 (8.630)	T@5 84.375 (48.421)	L 4.0193 (4.0015)
Test on T training set - [7][290/1731]	T 0.221 (0.205)	D 0.126 (0.105)	T@1 3.125 (8.537)	T@5 81.250 (49.592)	L 3.9286 (3.9951)
Test on T training set - [7][300/1731]	T 0.220 (0.209)	D 0.111 (0.108)	T@1 9.375 (8.420)	T@5 78.125 (50.592)	L 3.8965 (3.9940)
Test on T training set - [7][310/1731]	T 0.216 (0.209)	D 0.113 (0.108)	T@1 3.125 (8.360)	T@5 81.250 (51.517)	L 3.9019 (3.9889)
Test on T training set - [7][320/1731]	T 0.194 (0.209)	D 0.092 (0.108)	T@1 6.250 (8.363)	T@5 78.125 (52.463)	L 3.5220 (3.9807)
Test on T training set - [7][330/1731]	T 0.200 (0.209)	D 0.094 (0.107)	T@1 3.125 (8.252)	T@5 71.875 (53.295)	L 4.1179 (3.9752)
Test on T training set - [7][340/1731]	T 0.180 (0.208)	D 0.079 (0.107)	T@1 6.250 (8.220)	T@5 78.125 (53.977)	L 3.6883 (3.9745)
Test on T training set - [7][350/1731]	T 0.198 (0.207)	D 0.100 (0.106)	T@1 3.125 (8.253)	T@5 78.125 (54.701)	L 4.0528 (3.9682)
Test on T training set - [7][360/1731]	T 0.226 (0.207)	D 0.120 (0.106)	T@1 9.375 (8.293)	T@5 87.500 (55.549)	L 3.5888 (3.9609)
Test on T training set - [7][370/1731]	T 0.174 (0.207)	D 0.069 (0.106)	T@1 25.000 (8.373)	T@5 65.625 (56.191)	L 2.8108 (3.9479)
Test on T training set - [7][380/1731]	T 0.182 (0.206)	D 0.076 (0.105)	T@1 31.250 (8.866)	T@5 84.375 (56.644)	L 1.9341 (3.9133)
Test on T training set - [7][390/1731]	T 0.170 (0.205)	D 0.063 (0.104)	T@1 25.000 (9.191)	T@5 78.125 (57.193)	L 2.6741 (3.8786)
Test on T training set - [7][400/1731]	T 0.162 (0.204)	D 0.058 (0.103)	T@1 25.000 (9.702)	T@5 75.000 (57.637)	L 2.6014 (3.8461)
Test on T training set - [7][410/1731]	T 0.159 (0.207)	D 0.054 (0.105)	T@1 15.625 (10.052)	T@5 71.875 (58.022)	L 2.7750 (3.8195)
Test on T training set - [7][420/1731]	T 0.157 (0.206)	D 0.052 (0.104)	T@1 31.250 (10.392)	T@5 71.875 (58.351)	L 2.5091 (3.7948)
Test on T training set - [7][430/1731]	T 0.163 (0.204)	D 0.062 (0.103)	T@1 25.000 (10.695)	T@5 59.375 (58.679)	L 3.6247 (3.7758)
Test on T training set - [7][440/1731]	T 0.148 (0.203)	D 0.050 (0.102)	T@1 31.250 (11.019)	T@5 84.375 (59.056)	L 2.4653 (3.7516)
Test on T training set - [7][450/1731]	T 0.158 (0.202)	D 0.059 (0.101)	T@1 28.125 (11.301)	T@5 78.125 (59.500)	L 2.5031 (3.7266)
Test on T training set - [7][460/1731]	T 0.159 (0.202)	D 0.063 (0.100)	T@1 18.750 (11.551)	T@5 75.000 (59.890)	L 2.7677 (3.7026)
Test on T training set - [7][470/1731]	T 0.156 (0.201)	D 0.051 (0.100)	T@1 34.375 (11.823)	T@5 78.125 (60.145)	L 2.5526 (3.6838)
Test on T training set - [7][480/1731]	T 0.149 (0.200)	D 0.053 (0.099)	T@1 34.375 (12.097)	T@5 90.625 (60.466)	L 2.2729 (3.6641)
Test on T training set - [7][490/1731]	T 0.160 (0.199)	D 0.059 (0.098)	T@1 9.375 (12.379)	T@5 81.250 (60.769)	L 2.9050 (3.6435)
Test on T training set - [7][500/1731]	T 0.174 (0.199)	D 0.069 (0.097)	T@1 21.875 (12.506)	T@5 78.125 (61.022)	L 2.6553 (3.6295)
Test on T training set - [7][510/1731]	T 0.166 (0.198)	D 0.067 (0.096)	T@1 31.250 (12.751)	T@5 75.000 (61.356)	L 2.2324 (3.6083)
Test on T training set - [7][520/1731]	T 0.155 (0.197)	D 0.051 (0.096)	T@1 21.875 (12.926)	T@5 53.125 (61.474)	L 3.2567 (3.5962)
Test on T training set - [7][530/1731]	T 0.161 (0.196)	D 0.066 (0.095)	T@1 25.000 (13.089)	T@5 59.375 (61.629)	L 3.7796 (3.5859)
Test on T training set - [7][540/1731]	T 0.153 (0.198)	D 0.057 (0.097)	T@1 37.500 (13.234)	T@5 75.000 (61.755)	L 2.2819 (3.5756)
Test on T training set - [7][550/1731]	T 0.150 (0.197)	D 0.048 (0.096)	T@1 18.750 (13.402)	T@5 81.250 (61.910)	L 2.5570 (3.5630)
Test on T training set - [7][560/1731]	T 0.167 (0.197)	D 0.067 (0.095)	T@1 15.625 (13.586)	T@5 62.500 (62.004)	L 4.0611 (3.5537)
Test on T training set - [7][570/1731]	T 0.192 (0.196)	D 0.086 (0.095)	T@1 31.250 (13.748)	T@5 59.375 (62.177)	L 2.6747 (3.5390)
Test on T training set - [7][580/1731]	T 0.171 (0.196)	D 0.064 (0.094)	T@1 31.250 (14.001)	T@5 78.125 (62.414)	L 2.3745 (3.5223)
Test on T training set - [7][590/1731]	T 0.163 (0.195)	D 0.068 (0.094)	T@1 50.000 (14.345)	T@5 78.125 (62.643)	L 2.1572 (3.5047)
Test on T training set - [7][600/1731]	T 0.163 (0.195)	D 0.061 (0.093)	T@1 28.125 (14.580)	T@5 71.875 (62.848)	L 2.8261 (3.4898)
Test on T training set - [7][610/1731]	T 0.152 (0.194)	D 0.051 (0.093)	T@1 18.750 (14.766)	T@5 71.875 (63.170)	L 2.7978 (3.4729)
Test on T training set - [7][620/1731]	T 0.184 (0.194)	D 0.077 (0.093)	T@1 31.250 (15.092)	T@5 81.250 (63.491)	L 2.0626 (3.4535)
Test on T training set - [7][630/1731]	T 0.154 (0.194)	D 0.058 (0.092)	T@1 31.250 (15.343)	T@5 75.000 (63.743)	L 2.5049 (3.4355)
Test on T training set - [7][640/1731]	T 0.156 (0.193)	D 0.052 (0.092)	T@1 34.375 (15.547)	T@5 68.750 (63.914)	L 2.4463 (3.4213)
Test on T training set - [7][650/1731]	T 0.157 (0.195)	D 0.062 (0.093)	T@1 15.625 (15.774)	T@5 56.250 (64.089)	L 3.0346 (3.4070)
Test on T training set - [7][660/1731]	T 0.162 (0.194)	D 0.056 (0.093)	T@1 15.625 (15.918)	T@5 71.875 (64.278)	L 2.8428 (3.3952)
Test on T training set - [7][670/1731]	T 0.161 (0.194)	D 0.056 (0.092)	T@1 21.875 (16.044)	T@5 81.250 (64.451)	L 2.1672 (3.3833)
Test on T training set - [7][680/1731]	T 0.148 (0.193)	D 0.052 (0.092)	T@1 34.375 (16.244)	T@5 87.500 (64.684)	L 1.8927 (3.3693)
Test on T training set - [7][690/1731]	T 0.214 (0.193)	D 0.116 (0.091)	T@1 9.375 (16.217)	T@5 62.500 (64.743)	L 3.2619 (3.3643)
Test on T training set - [7][700/1731]	T 0.161 (0.192)	D 0.057 (0.091)	T@1 3.125 (16.031)	T@5 31.250 (64.274)	L 4.6970 (3.3835)
Test on T training set - [7][710/1731]	T 0.181 (0.192)	D 0.074 (0.091)	T@1 9.375 (15.889)	T@5 18.750 (63.713)	L 4.4820 (3.4011)
Test on T training set - [7][720/1731]	T 0.163 (0.192)	D 0.062 (0.090)	T@1 6.250 (15.742)	T@5 28.125 (63.206)	L 4.8641 (3.4173)
Test on T training set - [7][730/1731]	T 0.217 (0.192)	D 0.112 (0.090)	T@1 3.125 (15.625)	T@5 25.000 (62.748)	L 4.5910 (3.4329)
Test on T training set - [7][740/1731]	T 0.213 (0.192)	D 0.109 (0.091)	T@1 3.125 (15.532)	T@5 18.750 (62.310)	L 5.0272 (3.4490)
Test on T training set - [7][750/1731]	T 0.190 (0.192)	D 0.086 (0.091)	T@1 18.750 (15.446)	T@5 34.375 (61.855)	L 3.8886 (3.4624)
Test on T training set - [7][760/1731]	T 1.691 (0.194)	D 1.592 (0.093)	T@1 18.750 (15.370)	T@5 43.750 (61.449)	L 3.4534 (3.4740)
Test on T training set - [7][770/1731]	T 0.199 (0.195)	D 0.102 (0.093)	T@1 18.750 (15.317)	T@5 37.500 (61.049)	L 4.1897 (3.4858)
Test on T training set - [7][780/1731]	T 0.214 (0.195)	D 0.115 (0.093)	T@1 9.375 (15.233)	T@5 25.000 (60.595)	L 4.4965 (3.4987)
Test on T training set - [7][790/1731]	T 0.201 (0.195)	D 0.104 (0.094)	T@1 9.375 (15.135)	T@5 37.500 (60.205)	L 4.5254 (3.5106)
Test on T training set - [7][800/1731]	T 0.200 (0.195)	D 0.098 (0.094)	T@1 3.125 (15.048)	T@5 25.000 (59.831)	L 4.4423 (3.5252)
Test on T training set - [7][810/1731]	T 0.186 (0.195)	D 0.091 (0.094)	T@1 12.500 (15.001)	T@5 37.500 (59.444)	L 4.3152 (3.5358)
Test on T training set - [7][820/1731]	T 0.201 (0.195)	D 0.098 (0.094)	T@1 6.250 (14.917)	T@5 43.750 (59.082)	L 4.2892 (3.5469)
Test on T training set - [7][830/1731]	T 0.185 (0.195)	D 0.076 (0.094)	T@1 9.375 (14.820)	T@5 43.750 (58.739)	L 4.2267 (3.5575)
Test on T training set - [7][840/1731]	T 0.162 (0.195)	D 0.066 (0.093)	T@1 12.500 (14.752)	T@5 28.125 (58.420)	L 4.7128 (3.5667)
Test on T training set - [7][850/1731]	T 0.158 (0.194)	D 0.051 (0.093)	T@1 3.125 (14.593)	T@5 31.250 (58.119)	L 4.7512 (3.5896)
Test on T training set - [7][860/1731]	T 0.159 (0.194)	D 0.057 (0.093)	T@1 0.000 (14.438)	T@5 25.000 (57.814)	L 5.5115 (3.6122)
Test on T training set - [7][870/1731]	T 0.161 (0.194)	D 0.059 (0.092)	T@1 0.000 (14.287)	T@5 25.000 (57.524)	L 6.0630 (3.6353)
Test on T training set - [7][880/1731]	T 0.159 (0.195)	D 0.061 (0.094)	T@1 3.125 (14.146)	T@5 34.375 (57.194)	L 6.1065 (3.6580)
Test on T training set - [7][890/1731]	T 0.168 (0.195)	D 0.062 (0.094)	T@1 0.000 (13.998)	T@5 12.500 (56.867)	L 5.5705 (3.6813)
Test on T training set - [7][900/1731]	T 0.162 (0.195)	D 0.063 (0.093)	T@1 0.000 (13.849)	T@5 21.875 (56.635)	L 5.8061 (3.7032)
Test on T training set - [7][910/1731]	T 0.158 (0.194)	D 0.063 (0.093)	T@1 18.750 (13.834)	T@5 93.750 (56.727)	L 2.4367 (3.7068)
Test on T training set - [7][920/1731]	T 0.157 (0.194)	D 0.053 (0.093)	T@1 18.750 (13.895)	T@5 90.625 (57.132)	L 2.3048 (3.6924)
Test on T training set - [7][930/1731]	T 0.224 (0.194)	D 0.123 (0.093)	T@1 37.500 (14.135)	T@5 100.000 (57.552)	L 1.7452 (3.6746)
Test on T training set - [7][940/1731]	T 0.232 (0.194)	D 0.134 (0.093)	T@1 31.250 (14.327)	T@5 93.750 (57.974)	L 1.9194 (3.6570)
Test on T training set - [7][950/1731]	T 0.234 (0.195)	D 0.131 (0.093)	T@1 28.125 (14.534)	T@5 96.875 (58.392)	L 2.2574 (3.6401)
Test on T training set - [7][960/1731]	T 0.221 (0.195)	D 0.113 (0.094)	T@1 34.375 (14.731)	T@5 100.000 (58.777)	L 2.1188 (3.6241)
Test on T training set - [7][970/1731]	T 0.211 (0.198)	D 0.109 (0.096)	T@1 34.375 (14.933)	T@5 96.875 (59.150)	L 2.0564 (3.6075)
Test on T training set - [7][980/1731]	T 0.199 (0.198)	D 0.104 (0.096)	T@1 34.375 (15.125)	T@5 87.500 (59.522)	L 2.4167 (3.5914)
Test on T training set - [7][990/1731]	T 0.216 (0.198)	D 0.112 (0.097)	T@1 56.250 (15.288)	T@5 100.000 (59.895)	L 1.6189 (3.5772)
Test on T training set - [7][1000/1731]	T 0.213 (0.198)	D 0.113 (0.097)	T@1 34.375 (15.456)	T@5 100.000 (60.277)	L 1.8862 (3.5610)
Test on T training set - [7][1010/1731]	T 0.195 (0.198)	D 0.094 (0.097)	T@1 18.750 (15.566)	T@5 93.750 (60.630)	L 2.4188 (3.5473)
Test on T training set - [7][1020/1731]	T 0.187 (0.198)	D 0.091 (0.096)	T@1 31.250 (15.714)	T@5 93.750 (60.979)	L 2.3522 (3.5337)
Test on T training set - [7][1030/1731]	T 0.160 (0.198)	D 0.058 (0.096)	T@1 28.125 (15.834)	T@5 96.875 (61.318)	L 2.1965 (3.5204)
Test on T training set - [7][1040/1731]	T 0.168 (0.197)	D 0.061 (0.096)	T@1 25.000 (15.937)	T@5 90.625 (61.644)	L 2.6209 (3.5080)
Test on T training set - [7][1050/1731]	T 0.175 (0.197)	D 0.068 (0.096)	T@1 28.125 (15.958)	T@5 93.750 (61.914)	L 2.5136 (3.5003)
Test on T training set - [7][1060/1731]	T 0.156 (0.197)	D 0.053 (0.095)	T@1 12.500 (15.937)	T@5 96.875 (62.194)	L 2.5507 (3.4931)
Test on T training set - [7][1070/1731]	T 0.195 (0.197)	D 0.092 (0.095)	T@1 28.125 (15.963)	T@5 100.000 (62.442)	L 2.3554 (3.4857)
Test on T training set - [7][1080/1731]	T 0.160 (0.198)	D 0.054 (0.097)	T@1 18.750 (16.093)	T@5 96.875 (62.743)	L 2.5338 (3.4737)
Test on T training set - [7][1090/1731]	T 0.173 (0.198)	D 0.072 (0.097)	T@1 6.250 (16.112)	T@5 9.375 (62.743)	L 4.5732 (3.4707)
Test on T training set - [7][1100/1731]	T 0.194 (0.198)	D 0.092 (0.096)	T@1 6.250 (15.991)	T@5 15.625 (62.296)	L 4.7118 (3.4825)
Test on T training set - [7][1110/1731]	T 0.197 (0.198)	D 0.094 (0.096)	T@1 0.000 (15.889)	T@5 18.750 (61.890)	L 4.9010 (3.4919)
Test on T training set - [7][1120/1731]	T 0.175 (0.197)	D 0.080 (0.096)	T@1 3.125 (15.784)	T@5 12.500 (61.477)	L 4.5699 (3.5020)
Test on T training set - [7][1130/1731]	T 0.179 (0.197)	D 0.073 (0.096)	T@1 3.125 (15.683)	T@5 12.500 (61.105)	L 4.3659 (3.5115)
Test on T training set - [7][1140/1731]	T 0.186 (0.197)	D 0.090 (0.096)	T@1 3.125 (15.576)	T@5 12.500 (60.728)	L 4.6024 (3.5210)
Test on T training set - [7][1150/1731]	T 0.175 (0.197)	D 0.078 (0.096)	T@1 0.000 (15.468)	T@5 21.875 (60.371)	L 4.8768 (3.5298)
Test on T training set - [7][1160/1731]	T 0.170 (0.197)	D 0.066 (0.096)	T@1 6.250 (15.364)	T@5 25.000 (60.021)	L 4.6297 (3.5391)
Test on T training set - [7][1170/1731]	T 0.177 (0.199)	D 0.070 (0.098)	T@1 6.250 (15.262)	T@5 18.750 (59.653)	L 4.9817 (3.5493)
Test on T training set - [7][1180/1731]	T 0.178 (0.199)	D 0.074 (0.097)	T@1 3.125 (15.180)	T@5 25.000 (59.293)	L 4.4552 (3.5578)
Test on T training set - [7][1190/1731]	T 0.182 (0.199)	D 0.087 (0.097)	T@1 0.000 (15.069)	T@5 15.625 (58.924)	L 5.2645 (3.5683)
Test on T training set - [7][1200/1731]	T 0.165 (0.199)	D 0.065 (0.097)	T@1 3.125 (14.988)	T@5 34.375 (58.613)	L 4.6060 (3.5763)
Test on T training set - [7][1210/1731]	T 0.192 (0.198)	D 0.086 (0.097)	T@1 3.125 (14.913)	T@5 31.250 (58.278)	L 4.0791 (3.5840)
Test on T training set - [7][1220/1731]	T 0.157 (0.198)	D 0.062 (0.097)	T@1 3.125 (14.814)	T@5 21.875 (57.978)	L 5.3555 (3.5957)
Test on T training set - [7][1230/1731]	T 0.149 (0.198)	D 0.051 (0.096)	T@1 0.000 (14.724)	T@5 25.000 (57.700)	L 5.0720 (3.6073)
Test on T training set - [7][1240/1731]	T 0.179 (0.198)	D 0.072 (0.096)	T@1 3.125 (14.628)	T@5 34.375 (57.441)	L 4.5170 (3.6192)
Test on T training set - [7][1250/1731]	T 0.183 (0.197)	D 0.079 (0.096)	T@1 6.250 (14.548)	T@5 21.875 (57.217)	L 4.3434 (3.6283)
Test on T training set - [7][1260/1731]	T 0.183 (0.197)	D 0.077 (0.096)	T@1 3.125 (14.478)	T@5 21.875 (57.001)	L 4.4973 (3.6366)
Test on T training set - [7][1270/1731]	T 0.179 (0.197)	D 0.077 (0.096)	T@1 9.375 (14.403)	T@5 31.250 (56.776)	L 4.7324 (3.6454)
Test on T training set - [7][1280/1731]	T 0.183 (0.198)	D 0.088 (0.096)	T@1 9.375 (14.339)	T@5 40.625 (56.560)	L 4.5369 (3.6532)
Test on T training set - [7][1290/1731]	T 0.165 (0.197)	D 0.068 (0.096)	T@1 6.250 (14.272)	T@5 28.125 (56.344)	L 4.8531 (3.6623)
Test on T training set - [7][1300/1731]	T 0.168 (0.197)	D 0.073 (0.096)	T@1 9.375 (14.215)	T@5 37.500 (56.142)	L 4.4267 (3.6693)
Test on T training set - [7][1310/1731]	T 0.187 (0.197)	D 0.081 (0.096)	T@1 6.250 (14.171)	T@5 43.750 (55.957)	L 4.3817 (3.6752)
Test on T training set - [7][1320/1731]	T 0.182 (0.197)	D 0.087 (0.096)	T@1 6.250 (14.106)	T@5 46.875 (55.784)	L 4.1602 (3.6817)
Test on T training set - [7][1330/1731]	T 0.162 (0.197)	D 0.066 (0.095)	T@1 6.250 (14.047)	T@5 21.875 (55.588)	L 4.5065 (3.6895)
Test on T training set - [7][1340/1731]	T 0.158 (0.196)	D 0.055 (0.095)	T@1 0.000 (13.973)	T@5 25.000 (55.355)	L 4.7163 (3.6973)
Test on T training set - [7][1350/1731]	T 0.169 (0.196)	D 0.066 (0.095)	T@1 3.125 (13.911)	T@5 25.000 (55.158)	L 4.3190 (3.7045)
Test on T training set - [7][1360/1731]	T 0.163 (0.196)	D 0.058 (0.095)	T@1 6.250 (13.834)	T@5 15.625 (54.891)	L 5.0849 (3.7149)
Test on T training set - [7][1370/1731]	T 0.161 (0.196)	D 0.057 (0.094)	T@1 0.000 (13.747)	T@5 12.500 (54.582)	L 5.3420 (3.7247)
Test on T training set - [7][1380/1731]	T 0.160 (0.197)	D 0.060 (0.096)	T@1 3.125 (13.659)	T@5 12.500 (54.293)	L 5.1666 (3.7355)
Test on T training set - [7][1390/1731]	T 0.177 (0.197)	D 0.070 (0.096)	T@1 3.125 (13.578)	T@5 12.500 (54.003)	L 5.3955 (3.7460)
Test on T training set - [7][1400/1731]	T 0.169 (0.197)	D 0.066 (0.095)	T@1 0.000 (13.495)	T@5 9.375 (53.692)	L 5.1657 (3.7565)
Test on T training set - [7][1410/1731]	T 0.161 (0.197)	D 0.065 (0.095)	T@1 6.250 (13.415)	T@5 18.750 (53.393)	L 4.9889 (3.7669)
Test on T training set - [7][1420/1731]	T 0.165 (0.196)	D 0.059 (0.095)	T@1 3.125 (13.344)	T@5 18.750 (53.129)	L 5.1129 (3.7754)
Test on T training set - [7][1430/1731]	T 0.204 (0.196)	D 0.099 (0.095)	T@1 18.750 (13.308)	T@5 71.875 (53.116)	L 3.5842 (3.7788)
Test on T training set - [7][1440/1731]	T 0.234 (0.196)	D 0.133 (0.095)	T@1 12.500 (13.341)	T@5 84.375 (53.335)	L 3.3665 (3.7751)
Test on T training set - [7][1450/1731]	T 0.229 (0.197)	D 0.128 (0.095)	T@1 25.000 (13.366)	T@5 93.750 (53.564)	L 3.0681 (3.7719)
Test on T training set - [7][1460/1731]	T 0.231 (0.197)	D 0.121 (0.095)	T@1 15.625 (13.377)	T@5 78.125 (53.756)	L 3.4127 (3.7697)
Test on T training set - [7][1470/1731]	T 0.221 (0.199)	D 0.118 (0.098)	T@1 25.000 (13.377)	T@5 81.250 (53.939)	L 3.0645 (3.7681)
Test on T training set - [7][1480/1731]	T 0.235 (0.200)	D 0.140 (0.098)	T@1 9.375 (13.390)	T@5 87.500 (54.144)	L 3.0661 (3.7649)
Test on T training set - [7][1490/1731]	T 0.228 (0.200)	D 0.128 (0.098)	T@1 9.375 (13.403)	T@5 78.125 (54.322)	L 3.9908 (3.7628)
Test on T training set - [7][1500/1731]	T 0.246 (0.200)	D 0.140 (0.099)	T@1 18.750 (13.401)	T@5 81.250 (54.491)	L 3.2223 (3.7607)
Test on T training set - [7][1510/1731]	T 0.223 (0.200)	D 0.123 (0.099)	T@1 9.375 (13.404)	T@5 87.500 (54.660)	L 3.1481 (3.7593)
Test on T training set - [7][1520/1731]	T 0.211 (0.200)	D 0.116 (0.099)	T@1 15.625 (13.418)	T@5 81.250 (54.836)	L 3.5378 (3.7570)
Test on T training set - [7][1530/1731]	T 0.210 (0.200)	D 0.115 (0.099)	T@1 15.625 (13.435)	T@5 81.250 (55.001)	L 3.5414 (3.7545)
Test on T training set - [7][1540/1731]	T 0.187 (0.200)	D 0.091 (0.099)	T@1 0.000 (13.413)	T@5 75.000 (55.139)	L 4.5274 (3.7553)
Test on T training set - [7][1550/1731]	T 0.237 (0.202)	D 0.130 (0.101)	T@1 12.500 (13.395)	T@5 90.625 (55.265)	L 3.4587 (3.7555)
Test on T training set - [7][1560/1731]	T 0.197 (0.202)	D 0.092 (0.101)	T@1 28.125 (13.453)	T@5 78.125 (55.433)	L 3.6265 (3.7518)
Test on T training set - [7][1570/1731]	T 0.169 (0.202)	D 0.073 (0.100)	T@1 37.500 (13.596)	T@5 87.500 (55.627)	L 2.4601 (3.7431)
Test on T training set - [7][1580/1731]	T 0.155 (0.202)	D 0.059 (0.100)	T@1 28.125 (13.749)	T@5 84.375 (55.841)	L 2.4982 (3.7323)
Test on T training set - [7][1590/1731]	T 0.158 (0.201)	D 0.057 (0.100)	T@1 40.625 (13.904)	T@5 84.375 (56.038)	L 2.5035 (3.7230)
Test on T training set - [7][1600/1731]	T 0.188 (0.201)	D 0.083 (0.100)	T@1 31.250 (14.030)	T@5 81.250 (56.232)	L 2.4416 (3.7135)
Test on T training set - [7][1610/1731]	T 0.177 (0.201)	D 0.073 (0.100)	T@1 31.250 (14.155)	T@5 81.250 (56.409)	L 2.1789 (3.7047)
Test on T training set - [7][1620/1731]	T 0.184 (0.201)	D 0.076 (0.099)	T@1 31.250 (14.254)	T@5 96.875 (56.578)	L 2.1094 (3.6969)
Test on T training set - [7][1630/1731]	T 0.175 (0.201)	D 0.073 (0.099)	T@1 53.125 (14.401)	T@5 87.500 (56.763)	L 1.6230 (3.6874)
Test on T training set - [7][1640/1731]	T 0.208 (0.201)	D 0.112 (0.099)	T@1 28.125 (14.541)	T@5 96.875 (56.960)	L 2.2066 (3.6792)
Test on T training set - [7][1650/1731]	T 0.226 (0.202)	D 0.118 (0.101)	T@1 25.000 (14.660)	T@5 84.375 (57.147)	L 2.8086 (3.6715)
Test on T training set - [7][1660/1731]	T 0.198 (0.202)	D 0.103 (0.101)	T@1 37.500 (14.776)	T@5 87.500 (57.326)	L 2.0014 (3.6629)
Test on T training set - [7][1670/1731]	T 0.202 (0.202)	D 0.096 (0.101)	T@1 31.250 (14.898)	T@5 93.750 (57.507)	L 2.3257 (3.6542)
Test on T training set - [7][1680/1731]	T 0.174 (0.202)	D 0.075 (0.101)	T@1 34.375 (14.993)	T@5 87.500 (57.689)	L 2.4755 (3.6466)
Test on T training set - [7][1690/1731]	T 0.210 (0.202)	D 0.114 (0.101)	T@1 34.375 (15.089)	T@5 93.750 (57.874)	L 2.1272 (3.6387)
Test on T training set - [7][1700/1731]	T 0.208 (0.202)	D 0.113 (0.101)	T@1 31.250 (15.179)	T@5 90.625 (58.041)	L 2.1964 (3.6319)
Test on T training set - [7][1710/1731]	T 0.209 (0.202)	D 0.114 (0.101)	T@1 53.125 (15.302)	T@5 96.875 (58.230)	L 1.9225 (3.6237)
Test on T training set - [7][1720/1731]	T 0.195 (0.202)	D 0.088 (0.101)	T@1 56.250 (15.434)	T@5 90.625 (58.405)	L 1.9296 (3.6154)
Test on T training set - [7][1730/1731]	T 0.166 (0.202)	D 0.074 (0.101)	T@1 42.857 (15.530)	T@5 96.429 (58.563)	L 1.7220 (3.6082)
 * Test on T training set - Prec@1 15.530, Prec@5 58.563
Test on T test set - [7][0/1731]	Time 0.283 (0.283)	Loss 3.1709 (3.1709)	Prec@1 18.750 (18.750)	Prec@5 68.750 (68.750)
Test on T test set - [7][10/1731]	Time 0.204 (0.190)	Loss 3.2758 (3.6915)	Prec@1 21.875 (12.216)	Prec@5 40.625 (55.966)
Test on T test set - [7][20/1731]	Time 0.208 (0.200)	Loss 4.0140 (3.7973)	Prec@1 3.125 (10.268)	Prec@5 40.625 (54.167)
Test on T test set - [7][30/1731]	Time 0.213 (0.253)	Loss 3.6101 (3.7922)	Prec@1 9.375 (10.383)	Prec@5 46.875 (54.335)
Test on T test set - [7][40/1731]	Time 0.208 (0.241)	Loss 3.8476 (3.8073)	Prec@1 12.500 (10.442)	Prec@5 56.250 (54.649)
Test on T test set - [7][50/1731]	Time 0.202 (0.234)	Loss 4.1098 (3.8327)	Prec@1 12.500 (10.172)	Prec@5 53.125 (54.044)
Test on T test set - [7][60/1731]	Time 0.205 (0.229)	Loss 3.6680 (3.8045)	Prec@1 9.375 (10.502)	Prec@5 59.375 (54.867)
Test on T test set - [7][70/1731]	Time 0.179 (0.225)	Loss 3.9884 (3.8005)	Prec@1 12.500 (10.563)	Prec@5 50.000 (54.445)
Test on T test set - [7][80/1731]	Time 0.183 (0.221)	Loss 3.7669 (3.8209)	Prec@1 9.375 (10.648)	Prec@5 43.750 (54.205)
Test on T test set - [7][90/1731]	Time 0.190 (0.218)	Loss 3.9223 (3.8403)	Prec@1 15.625 (10.337)	Prec@5 53.125 (53.846)
Test on T test set - [7][100/1731]	Time 0.168 (0.214)	Loss 3.6149 (3.8399)	Prec@1 18.750 (10.489)	Prec@5 56.250 (53.837)
Test on T test set - [7][110/1731]	Time 0.189 (0.211)	Loss 4.2498 (3.8211)	Prec@1 12.500 (11.120)	Prec@5 43.750 (54.139)
Test on T test set - [7][120/1731]	Time 0.184 (0.224)	Loss 4.0065 (3.8523)	Prec@1 9.375 (10.899)	Prec@5 34.375 (52.350)
Test on T test set - [7][130/1731]	Time 0.175 (0.221)	Loss 3.9065 (3.8761)	Prec@1 6.250 (10.687)	Prec@5 28.125 (50.668)
Test on T test set - [7][140/1731]	Time 0.175 (0.218)	Loss 4.2340 (3.8956)	Prec@1 9.375 (10.594)	Prec@5 21.875 (49.335)
Test on T test set - [7][150/1731]	Time 0.198 (0.215)	Loss 4.1325 (3.9084)	Prec@1 12.500 (10.555)	Prec@5 31.250 (48.158)
Test on T test set - [7][160/1731]	Time 0.183 (0.213)	Loss 3.8740 (3.9136)	Prec@1 9.375 (10.481)	Prec@5 40.625 (47.496)
Test on T test set - [7][170/1731]	Time 0.156 (0.210)	Loss 4.2048 (3.9341)	Prec@1 0.000 (10.307)	Prec@5 21.875 (46.363)
Test on T test set - [7][180/1731]	Time 0.148 (0.207)	Loss 4.5114 (3.9676)	Prec@1 3.125 (10.031)	Prec@5 15.625 (44.924)
Test on T test set - [7][190/1731]	Time 0.183 (0.204)	Loss 4.5646 (3.9934)	Prec@1 3.125 (9.670)	Prec@5 25.000 (43.505)
Test on T test set - [7][200/1731]	Time 0.161 (0.202)	Loss 3.8155 (4.0164)	Prec@1 15.625 (9.499)	Prec@5 25.000 (42.304)
Test on T test set - [7][210/1731]	Time 0.168 (0.200)	Loss 4.3884 (4.0459)	Prec@1 6.250 (9.331)	Prec@5 21.875 (41.158)
Test on T test set - [7][220/1731]	Time 0.169 (0.210)	Loss 4.1388 (4.0560)	Prec@1 6.250 (9.205)	Prec@5 28.125 (40.597)
Test on T test set - [7][230/1731]	Time 0.159 (0.208)	Loss 3.7955 (4.0450)	Prec@1 3.125 (9.118)	Prec@5 81.250 (41.964)
Test on T test set - [7][240/1731]	Time 0.211 (0.208)	Loss 3.7020 (4.0355)	Prec@1 6.250 (8.973)	Prec@5 81.250 (43.413)
Test on T test set - [7][250/1731]	Time 0.186 (0.210)	Loss 3.7880 (4.0285)	Prec@1 12.500 (8.914)	Prec@5 71.875 (45.007)
Test on T test set - [7][260/1731]	Time 0.223 (0.210)	Loss 4.1231 (4.0246)	Prec@1 9.375 (8.872)	Prec@5 78.125 (46.384)
Test on T test set - [7][270/1731]	Time 0.219 (0.210)	Loss 3.6455 (4.0161)	Prec@1 3.125 (8.787)	Prec@5 84.375 (47.636)
Test on T test set - [7][280/1731]	Time 0.210 (0.210)	Loss 3.8168 (4.0150)	Prec@1 3.125 (8.641)	Prec@5 81.250 (48.721)
Test on T test set - [7][290/1731]	Time 0.218 (0.210)	Loss 3.6477 (4.0078)	Prec@1 9.375 (8.602)	Prec@5 71.875 (49.850)
Test on T test set - [7][300/1731]	Time 0.206 (0.210)	Loss 4.0062 (4.0072)	Prec@1 9.375 (8.503)	Prec@5 75.000 (50.872)
Test on T test set - [7][310/1731]	Time 0.207 (0.210)	Loss 3.8251 (4.0017)	Prec@1 9.375 (8.471)	Prec@5 81.250 (51.869)
Test on T test set - [7][320/1731]	Time 0.185 (0.216)	Loss 3.5930 (3.9936)	Prec@1 6.250 (8.431)	Prec@5 87.500 (52.852)
Test on T test set - [7][330/1731]	Time 0.196 (0.215)	Loss 4.3008 (3.9909)	Prec@1 3.125 (8.327)	Prec@5 75.000 (53.691)
Test on T test set - [7][340/1731]	Time 0.177 (0.214)	Loss 3.9640 (3.9904)	Prec@1 9.375 (8.312)	Prec@5 81.250 (54.390)
Test on T test set - [7][350/1731]	Time 0.189 (0.213)	Loss 4.0622 (3.9872)	Prec@1 3.125 (8.324)	Prec@5 59.375 (55.048)
Test on T test set - [7][360/1731]	Time 0.223 (0.213)	Loss 3.7476 (3.9812)	Prec@1 12.500 (8.293)	Prec@5 90.625 (55.912)
Test on T test set - [7][370/1731]	Time 0.177 (0.213)	Loss 3.0797 (3.9713)	Prec@1 31.250 (8.389)	Prec@5 65.625 (56.520)
Test on T test set - [7][380/1731]	Time 0.175 (0.211)	Loss 2.0565 (3.9357)	Prec@1 25.000 (8.866)	Prec@5 87.500 (57.046)
Test on T test set - [7][390/1731]	Time 0.162 (0.210)	Loss 2.3953 (3.8991)	Prec@1 31.250 (9.319)	Prec@5 81.250 (57.593)
Test on T test set - [7][400/1731]	Time 0.150 (0.209)	Loss 2.3697 (3.8667)	Prec@1 31.250 (9.780)	Prec@5 84.375 (58.066)
Test on T test set - [7][410/1731]	Time 0.158 (0.208)	Loss 2.7075 (3.8377)	Prec@1 9.375 (10.143)	Prec@5 75.000 (58.516)
Test on T test set - [7][420/1731]	Time 0.156 (0.212)	Loss 2.6797 (3.8140)	Prec@1 25.000 (10.444)	Prec@5 78.125 (58.841)
Test on T test set - [7][430/1731]	Time 0.162 (0.211)	Loss 3.6467 (3.7934)	Prec@1 15.625 (10.673)	Prec@5 56.250 (59.179)
Test on T test set - [7][440/1731]	Time 0.150 (0.209)	Loss 2.4876 (3.7679)	Prec@1 28.125 (10.976)	Prec@5 84.375 (59.566)
Test on T test set - [7][450/1731]	Time 0.150 (0.208)	Loss 2.5906 (3.7411)	Prec@1 31.250 (11.329)	Prec@5 75.000 (59.957)
Test on T test set - [7][460/1731]	Time 0.164 (0.207)	Loss 2.6143 (3.7160)	Prec@1 25.000 (11.666)	Prec@5 81.250 (60.324)
Test on T test set - [7][470/1731]	Time 0.154 (0.206)	Loss 2.8987 (3.6958)	Prec@1 21.875 (11.916)	Prec@5 78.125 (60.589)
Test on T test set - [7][480/1731]	Time 0.143 (0.205)	Loss 2.2098 (3.6757)	Prec@1 37.500 (12.169)	Prec@5 78.125 (60.902)
Test on T test set - [7][490/1731]	Time 0.155 (0.204)	Loss 2.7202 (3.6549)	Prec@1 15.625 (12.443)	Prec@5 81.250 (61.214)
Test on T test set - [7][500/1731]	Time 0.165 (0.203)	Loss 2.7191 (3.6406)	Prec@1 25.000 (12.594)	Prec@5 68.750 (61.415)
Test on T test set - [7][510/1731]	Time 0.152 (0.202)	Loss 2.2782 (3.6201)	Prec@1 28.125 (12.812)	Prec@5 84.375 (61.784)
Test on T test set - [7][520/1731]	Time 0.159 (0.201)	Loss 3.3893 (3.6088)	Prec@1 15.625 (12.974)	Prec@5 65.625 (61.876)
Test on T test set - [7][530/1731]	Time 0.161 (0.204)	Loss 3.5617 (3.5981)	Prec@1 25.000 (13.153)	Prec@5 59.375 (61.994)
Test on T test set - [7][540/1731]	Time 0.147 (0.203)	Loss 2.2541 (3.5859)	Prec@1 34.375 (13.343)	Prec@5 81.250 (62.165)
Test on T test set - [7][550/1731]	Time 0.140 (0.202)	Loss 2.4865 (3.5719)	Prec@1 25.000 (13.544)	Prec@5 78.125 (62.347)
Test on T test set - [7][560/1731]	Time 0.154 (0.202)	Loss 3.6849 (3.5612)	Prec@1 12.500 (13.686)	Prec@5 71.875 (62.489)
Test on T test set - [7][570/1731]	Time 0.174 (0.201)	Loss 2.7644 (3.5468)	Prec@1 31.250 (13.846)	Prec@5 68.750 (62.653)
Test on T test set - [7][580/1731]	Time 0.170 (0.200)	Loss 2.5139 (3.5299)	Prec@1 37.500 (14.076)	Prec@5 68.750 (62.893)
Test on T test set - [7][590/1731]	Time 0.166 (0.200)	Loss 2.1570 (3.5125)	Prec@1 34.375 (14.351)	Prec@5 78.125 (63.113)
Test on T test set - [7][600/1731]	Time 0.156 (0.199)	Loss 2.5787 (3.4958)	Prec@1 31.250 (14.642)	Prec@5 75.000 (63.348)
Test on T test set - [7][610/1731]	Time 0.153 (0.199)	Loss 2.8692 (3.4777)	Prec@1 34.375 (14.878)	Prec@5 68.750 (63.671)
Test on T test set - [7][620/1731]	Time 0.179 (0.198)	Loss 2.0844 (3.4585)	Prec@1 28.125 (15.142)	Prec@5 81.250 (63.985)
Test on T test set - [7][630/1731]	Time 0.152 (0.198)	Loss 2.4665 (3.4414)	Prec@1 15.625 (15.348)	Prec@5 75.000 (64.219)
Test on T test set - [7][640/1731]	Time 0.155 (0.199)	Loss 2.5695 (3.4258)	Prec@1 31.250 (15.532)	Prec@5 71.875 (64.411)
Test on T test set - [7][650/1731]	Time 0.152 (0.199)	Loss 3.0832 (3.4114)	Prec@1 18.750 (15.779)	Prec@5 59.375 (64.564)
Test on T test set - [7][660/1731]	Time 0.148 (0.198)	Loss 3.0626 (3.3992)	Prec@1 21.875 (15.961)	Prec@5 71.875 (64.755)
Test on T test set - [7][670/1731]	Time 0.156 (0.198)	Loss 1.8558 (3.3867)	Prec@1 40.625 (16.142)	Prec@5 90.625 (64.926)
Test on T test set - [7][680/1731]	Time 0.159 (0.197)	Loss 1.9414 (3.3712)	Prec@1 43.750 (16.359)	Prec@5 87.500 (65.166)
Test on T test set - [7][690/1731]	Time 0.211 (0.196)	Loss 3.4275 (3.3658)	Prec@1 6.250 (16.362)	Prec@5 62.500 (65.209)
Test on T test set - [7][700/1731]	Time 0.158 (0.196)	Loss 4.8338 (3.3858)	Prec@1 0.000 (16.173)	Prec@5 21.875 (64.716)
Test on T test set - [7][710/1731]	Time 0.169 (0.196)	Loss 4.5688 (3.4033)	Prec@1 6.250 (16.043)	Prec@5 18.750 (64.148)
Test on T test set - [7][720/1731]	Time 0.165 (0.195)	Loss 5.1529 (3.4209)	Prec@1 3.125 (15.872)	Prec@5 21.875 (63.631)
Test on T test set - [7][730/1731]	Time 0.207 (0.195)	Loss 4.5721 (3.4355)	Prec@1 6.250 (15.766)	Prec@5 31.250 (63.175)
Test on T test set - [7][740/1731]	Time 0.219 (0.195)	Loss 4.7835 (3.4520)	Prec@1 6.250 (15.650)	Prec@5 34.375 (62.770)
Test on T test set - [7][750/1731]	Time 0.180 (0.196)	Loss 3.8104 (3.4652)	Prec@1 21.875 (15.563)	Prec@5 37.500 (62.338)
Test on T test set - [7][760/1731]	Time 0.223 (0.197)	Loss 3.5702 (3.4770)	Prec@1 15.625 (15.481)	Prec@5 46.875 (61.884)
Test on T test set - [7][770/1731]	Time 0.202 (0.197)	Loss 4.4775 (3.4895)	Prec@1 18.750 (15.406)	Prec@5 31.250 (61.475)
Test on T test set - [7][780/1731]	Time 0.218 (0.197)	Loss 4.5764 (3.5033)	Prec@1 12.500 (15.309)	Prec@5 31.250 (61.048)
Test on T test set - [7][790/1731]	Time 0.204 (0.197)	Loss 4.3219 (3.5146)	Prec@1 12.500 (15.226)	Prec@5 28.125 (60.659)
Test on T test set - [7][800/1731]	Time 0.196 (0.197)	Loss 4.4057 (3.5287)	Prec@1 0.000 (15.122)	Prec@5 28.125 (60.284)
Test on T test set - [7][810/1731]	Time 0.184 (0.197)	Loss 4.4675 (3.5397)	Prec@1 15.625 (15.059)	Prec@5 28.125 (59.914)
Test on T test set - [7][820/1731]	Time 0.202 (0.197)	Loss 4.2616 (3.5517)	Prec@1 6.250 (14.959)	Prec@5 37.500 (59.573)
Test on T test set - [7][830/1731]	Time 0.174 (0.196)	Loss 4.2160 (3.5631)	Prec@1 15.625 (14.892)	Prec@5 43.750 (59.202)
Test on T test set - [7][840/1731]	Time 0.169 (0.196)	Loss 4.3128 (3.5719)	Prec@1 15.625 (14.819)	Prec@5 40.625 (58.892)
Test on T test set - [7][850/1731]	Time 0.142 (0.196)	Loss 4.8866 (3.5943)	Prec@1 0.000 (14.656)	Prec@5 21.875 (58.527)
Test on T test set - [7][860/1731]	Time 0.150 (0.197)	Loss 5.9176 (3.6181)	Prec@1 6.250 (14.514)	Prec@5 37.500 (58.253)
Test on T test set - [7][870/1731]	Time 0.159 (0.197)	Loss 6.0696 (3.6406)	Prec@1 0.000 (14.355)	Prec@5 25.000 (57.947)
Test on T test set - [7][880/1731]	Time 0.157 (0.197)	Loss 6.2180 (3.6633)	Prec@1 0.000 (14.210)	Prec@5 21.875 (57.609)
Test on T test set - [7][890/1731]	Time 0.155 (0.196)	Loss 5.5057 (3.6856)	Prec@1 0.000 (14.057)	Prec@5 18.750 (57.309)
Test on T test set - [7][900/1731]	Time 0.154 (0.196)	Loss 6.0932 (3.7077)	Prec@1 0.000 (13.901)	Prec@5 28.125 (57.058)
Test on T test set - [7][910/1731]	Time 0.167 (0.195)	Loss 2.3656 (3.7106)	Prec@1 28.125 (13.893)	Prec@5 93.750 (57.138)
Test on T test set - [7][920/1731]	Time 0.154 (0.195)	Loss 2.2893 (3.6960)	Prec@1 25.000 (13.939)	Prec@5 93.750 (57.533)
Test on T test set - [7][930/1731]	Time 0.219 (0.195)	Loss 1.9246 (3.6781)	Prec@1 34.375 (14.168)	Prec@5 96.875 (57.955)
Test on T test set - [7][940/1731]	Time 0.251 (0.195)	Loss 1.9168 (3.6611)	Prec@1 28.125 (14.360)	Prec@5 93.750 (58.365)
Test on T test set - [7][950/1731]	Time 0.224 (0.196)	Loss 2.1057 (3.6443)	Prec@1 34.375 (14.580)	Prec@5 96.875 (58.774)
Test on T test set - [7][960/1731]	Time 0.207 (0.196)	Loss 2.3811 (3.6285)	Prec@1 25.000 (14.763)	Prec@5 100.000 (59.157)
Test on T test set - [7][970/1731]	Time 0.214 (0.198)	Loss 2.0070 (3.6116)	Prec@1 37.500 (14.952)	Prec@5 96.875 (59.536)
Test on T test set - [7][980/1731]	Time 0.197 (0.198)	Loss 2.3159 (3.5955)	Prec@1 25.000 (15.109)	Prec@5 87.500 (59.920)
Test on T test set - [7][990/1731]	Time 0.218 (0.199)	Loss 1.7598 (3.5815)	Prec@1 46.875 (15.288)	Prec@5 96.875 (60.283)
Test on T test set - [7][1000/1731]	Time 0.212 (0.199)	Loss 2.0959 (3.5653)	Prec@1 34.375 (15.478)	Prec@5 96.875 (60.655)
Test on T test set - [7][1010/1731]	Time 0.184 (0.198)	Loss 2.2179 (3.5513)	Prec@1 31.250 (15.600)	Prec@5 93.750 (60.995)
Test on T test set - [7][1020/1731]	Time 0.184 (0.198)	Loss 2.3932 (3.5379)	Prec@1 34.375 (15.732)	Prec@5 87.500 (61.334)
Test on T test set - [7][1030/1731]	Time 0.155 (0.198)	Loss 2.2569 (3.5238)	Prec@1 28.125 (15.852)	Prec@5 90.625 (61.660)
Test on T test set - [7][1040/1731]	Time 0.163 (0.198)	Loss 2.6290 (3.5122)	Prec@1 25.000 (15.940)	Prec@5 90.625 (61.981)
Test on T test set - [7][1050/1731]	Time 0.161 (0.198)	Loss 2.4915 (3.5043)	Prec@1 15.625 (15.961)	Prec@5 93.750 (62.250)
Test on T test set - [7][1060/1731]	Time 0.149 (0.199)	Loss 2.4765 (3.4971)	Prec@1 12.500 (15.931)	Prec@5 96.875 (62.524)
Test on T test set - [7][1070/1731]	Time 0.190 (0.199)	Loss 2.2812 (3.4894)	Prec@1 28.125 (15.963)	Prec@5 100.000 (62.783)
Test on T test set - [7][1080/1731]	Time 0.157 (0.199)	Loss 2.4968 (3.4777)	Prec@1 18.750 (16.079)	Prec@5 84.375 (63.067)
Test on T test set - [7][1090/1731]	Time 0.166 (0.198)	Loss 4.4311 (3.4751)	Prec@1 6.250 (16.095)	Prec@5 9.375 (63.061)
Test on T test set - [7][1100/1731]	Time 0.180 (0.198)	Loss 4.9823 (3.4876)	Prec@1 3.125 (15.971)	Prec@5 15.625 (62.605)
Test on T test set - [7][1110/1731]	Time 0.194 (0.198)	Loss 4.8665 (3.4971)	Prec@1 0.000 (15.867)	Prec@5 15.625 (62.191)
Test on T test set - [7][1120/1731]	Time 0.170 (0.198)	Loss 4.4798 (3.5075)	Prec@1 3.125 (15.750)	Prec@5 9.375 (61.761)
Test on T test set - [7][1130/1731]	Time 0.182 (0.198)	Loss 4.3433 (3.5171)	Prec@1 0.000 (15.642)	Prec@5 18.750 (61.386)
Test on T test set - [7][1140/1731]	Time 0.187 (0.198)	Loss 4.5096 (3.5269)	Prec@1 3.125 (15.535)	Prec@5 12.500 (60.996)
Test on T test set - [7][1150/1731]	Time 0.162 (0.197)	Loss 4.7843 (3.5361)	Prec@1 0.000 (15.432)	Prec@5 25.000 (60.632)
Test on T test set - [7][1160/1731]	Time 0.164 (0.197)	Loss 4.1780 (3.5455)	Prec@1 3.125 (15.326)	Prec@5 21.875 (60.263)
Test on T test set - [7][1170/1731]	Time 0.174 (0.197)	Loss 4.8137 (3.5558)	Prec@1 6.250 (15.225)	Prec@5 15.625 (59.866)
Test on T test set - [7][1180/1731]	Time 0.173 (0.198)	Loss 4.4594 (3.5643)	Prec@1 6.250 (15.141)	Prec@5 18.750 (59.510)
Test on T test set - [7][1190/1731]	Time 0.180 (0.198)	Loss 5.1590 (3.5746)	Prec@1 0.000 (15.032)	Prec@5 6.250 (59.136)
Test on T test set - [7][1200/1731]	Time 0.175 (0.198)	Loss 4.5077 (3.5831)	Prec@1 3.125 (14.943)	Prec@5 21.875 (58.805)
Test on T test set - [7][1210/1731]	Time 0.185 (0.197)	Loss 4.1703 (3.5905)	Prec@1 6.250 (14.877)	Prec@5 25.000 (58.477)
Test on T test set - [7][1220/1731]	Time 0.155 (0.197)	Loss 5.4324 (3.6016)	Prec@1 0.000 (14.783)	Prec@5 18.750 (58.172)
Test on T test set - [7][1230/1731]	Time 0.151 (0.197)	Loss 4.8874 (3.6129)	Prec@1 3.125 (14.696)	Prec@5 21.875 (57.877)
Test on T test set - [7][1240/1731]	Time 0.159 (0.196)	Loss 4.2421 (3.6239)	Prec@1 0.000 (14.603)	Prec@5 40.625 (57.622)
Test on T test set - [7][1250/1731]	Time 0.175 (0.196)	Loss 4.3009 (3.6333)	Prec@1 3.125 (14.516)	Prec@5 28.125 (57.392)
Test on T test set - [7][1260/1731]	Time 0.177 (0.196)	Loss 4.5715 (3.6422)	Prec@1 3.125 (14.438)	Prec@5 15.625 (57.145)
Test on T test set - [7][1270/1731]	Time 0.179 (0.196)	Loss 4.6200 (3.6507)	Prec@1 6.250 (14.374)	Prec@5 28.125 (56.906)
Test on T test set - [7][1280/1731]	Time 0.180 (0.196)	Loss 4.5232 (3.6585)	Prec@1 9.375 (14.310)	Prec@5 31.250 (56.677)
Test on T test set - [7][1290/1731]	Time 0.158 (0.196)	Loss 4.5495 (3.6670)	Prec@1 3.125 (14.243)	Prec@5 34.375 (56.475)
Test on T test set - [7][1300/1731]	Time 0.166 (0.196)	Loss 4.4760 (3.6733)	Prec@1 15.625 (14.196)	Prec@5 34.375 (56.267)
Test on T test set - [7][1310/1731]	Time 0.179 (0.196)	Loss 4.7931 (3.6799)	Prec@1 3.125 (14.140)	Prec@5 21.875 (56.076)
Test on T test set - [7][1320/1731]	Time 0.190 (0.196)	Loss 4.3269 (3.6864)	Prec@1 6.250 (14.085)	Prec@5 56.250 (55.905)
Test on T test set - [7][1330/1731]	Time 0.164 (0.196)	Loss 4.4287 (3.6949)	Prec@1 6.250 (14.017)	Prec@5 25.000 (55.703)
Test on T test set - [7][1340/1731]	Time 0.160 (0.195)	Loss 4.9409 (3.7025)	Prec@1 0.000 (13.945)	Prec@5 21.875 (55.462)
Test on T test set - [7][1350/1731]	Time 0.165 (0.195)	Loss 4.3094 (3.7098)	Prec@1 3.125 (13.888)	Prec@5 21.875 (55.248)
